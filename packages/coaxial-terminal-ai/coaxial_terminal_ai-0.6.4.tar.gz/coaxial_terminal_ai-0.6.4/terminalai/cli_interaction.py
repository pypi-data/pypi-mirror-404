"""CLI interaction functionality for TerminalAI."""
import os
import sys
import argparse
import requests
import re
import traceback
from rich.text import Text
from terminalai.command_utils import run_shell_command, is_shell_command
from terminalai.command_extraction import is_stateful_command, is_risky_command
from terminalai.formatting import ColoredDescriptionFormatter
from terminalai.clipboard_utils import copy_to_clipboard

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description=(
            "TerminalAI: Your command-line AI assistant.\n"
            "Ask questions or request commands, and AI will suggest appropriate actions.\n"
            "- With the latest shell integration, stateful commands (like cd, export, etc.) "
            "are now executable in all modes if the integration is installed.\n"
            "- Each command should be in its own code block, with no comments or explanations "
            "inside. Explanations must be outside code blocks.\n"
            "- If the AI puts multiple commands in a single code block, TerminalAI will still "
            "extract and show each as a separate command.\n"
            "\nExamples of correct formatting:\n"
            "```bash\nls\n```\n```bash\nls -l\n```\n"
            "Explanation: The first command lists files, the second lists them in long format.\n"
            "Incorrect:\n"
            "```bash\n# List files\nls\n# List files in long format\nls -l\n```\n"
            "(Never put comments or multiple commands in a single code block.)\n"
        ),
        epilog="For more details, visit https://github.com/coaxialdolor/terminalai",
        formatter_class=ColoredDescriptionFormatter
    )

    parser.add_argument(
        "query",
        nargs="?",
        help="Your question or request"
    )

    parser.add_argument(
        "-y", "--yes",
        action="store_true",
        help="Automatically confirm execution of non-risky commands"
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Request a more detailed response from the AI"
    )

    parser.add_argument(
        "-l", "--long",
        action="store_true",
        help="Request a longer, more comprehensive response"
    )

    parser.add_argument(
        "--setup",
        action="store_true",
        help="Run the setup wizard"
    )

    parser.add_argument(
        "--version",
        action="store_true",
        help="Show version information"
    )

    parser.add_argument(
        "--eval-mode",
        action="store_true",
        help=argparse.SUPPRESS
    )

    parser.add_argument(
        "--chat",
        action="store_true",
        help="Enter persistent AI chat mode (does not exit after one response)"
    )

    parser.add_argument(
        "--set-default",
        action="store_true",
        help="Interactively set the default AI provider"
    )

    parser.add_argument(
        "--set-ollama",
        action="store_true",
        help="Interactively configure Ollama host and model"
    )

    parser.add_argument(
        "--explain",
        type=str,
        help="Read a file and ask AI to explain it"
    )

    parser.add_argument(
        "--read-file",
        type=str,
        help="Read a file and include its content in your query"
    )

    return parser.parse_args()

def handle_commands(commands, auto_confirm=False, eval_mode=False, rich_to_stderr=False):
    """Handle extracted commands, prompting the user and executing if confirmed."""
    from rich.console import Console
    from rich.panel import Panel
    from rich.text import Text

    console = Console(file=sys.stderr if rich_to_stderr else None)

    # Detect shell integration
    shell_integration_active = os.environ.get("TERMINALAI_SHELL_INTEGRATION") == "1"

    if not commands:
        return

    n_commands = len(commands)

    # Always enumerate and prompt for selection if more than one command
    if n_commands > 1:
        cmd_list = []
        for i, cmd in enumerate(commands, 1):
            is_risky_cmd = is_risky_command(cmd)
            is_stateful_cmd = is_stateful_command(cmd)
            cmd_text = f"[cyan]{i}[/cyan]: [white]{cmd}[/white]"
            if is_risky_cmd:
                cmd_text += " [bold red][RISKY][/bold red]"
            if is_stateful_cmd:
                cmd_text += " [bold yellow][STATEFUL][/bold yellow]"
            cmd_list.append(cmd_text)
        console.print(Panel(
            "\n".join(cmd_list),
            title=f"Found {n_commands} commands",
            border_style="blue"
        ))
        console.print(Text("Enter command number, 'a' for all, or 'q' to quit: ", style="bold cyan"), end="")
        choice = input().lower()

        if choice == "q":
            return
        elif choice == "a":
            for cmd in commands:
                is_cmd_risky = is_risky_command(cmd)
                if is_cmd_risky:
                    console.print(Text(f"[RISKY] Execute risky command '{cmd}'? [y/N]: ", style="red bold"), end="")
                    subchoice = input().lower()
                    if subchoice != "y":
                        continue
                run_command(cmd)
            return  # Always return after handling 'a'
        elif choice.isdigit():
            idx = int(choice) - 1
            if 0 <= idx < len(commands):
                cmd = commands[idx]
                is_cmd_risky = is_risky_command(cmd)
                if is_cmd_risky:
                    console.print(Text(f"[RISKY] Execute risky command '{cmd}'? [y/N]: ", style="red bold"), end="")
                    subchoice = input().lower()
                    if subchoice == "y":
                        run_command(cmd)
                    else:
                        console.print("[Cancelled]")
                        return
                else:
                    run_command(cmd)
            else:
                console.print(f"[red]Invalid choice: {choice}[/red]")
            return

    # Single command logic
    command = commands[0]
    is_risky_cmd = is_risky_command(command)
    if eval_mode or shell_integration_active:
        if is_risky_cmd:
            confirm_msg = "Execute? [y/N]: "
            default_choice = "n"
        else:
            confirm_msg = "Execute? [Y/n]: "
            default_choice = "y"
        style = "yellow" if is_risky_cmd else "green"
        print(confirm_msg, end="", file=sys.stderr if rich_to_stderr else sys.stdout)
        (sys.stderr if rich_to_stderr else sys.stdout).flush()
        choice = input().lower()
        if not choice:
            choice = default_choice
        if choice == "y":
            print(command)
            sys.exit(0)
        else:
            print("[Cancelled]", file=sys.stderr if rich_to_stderr else sys.stdout)
            return  # Never sys.exit(1) on cancel
    if is_stateful_command(command):
        prompt_text = (
            f"[STATEFUL COMMAND] '{command}' changes shell state. "
            "To execute seamlessly, install the ai shell integration (see setup). "
            "Copy to clipboard instead? [Y/n]: "
        )
        console.print(Text(prompt_text, style="yellow bold"), end="")
        choice = input().lower()
        if choice != 'n':
            copy_to_clipboard(command)
            console.print("[green]Command copied to clipboard. Paste and run manually.[/green]")
        return
    confirm_msg = "Execute? [y/N]: " if is_risky_cmd else "Execute? [Y/n]: "
    default_choice = "n" if is_risky_cmd else "y"
    if auto_confirm and not is_risky_cmd:
        console.print(f"[green]Auto-executing: {command}[/green]")
        run_command(command)
        return
    style = "yellow" if is_risky_cmd else "green"
    console.print(Text(confirm_msg, style=style), end="")
    choice = input().lower()
    if not choice:
        choice = default_choice
    if choice == "y":
        run_command(command)
    else:
        console.print("[Cancelled]")
    return

def run_command(command):
    """Execute a shell command with error handling."""
    from rich.console import Console
    from rich.panel import Panel

    console = Console()

    if not command:
        return

    if not is_shell_command(command):
        console.print(f"[yellow]Warning: '{command}' doesn't look like a valid shell command.[/yellow]")
        console.print("[yellow]Execute anyway? [y/N]:[/yellow]", end=" ")
        choice = input().lower()
        if choice != "y":
            return

    console.print(Panel(f"[bold white]Executing: [/bold white][cyan]{command}[/cyan]",
                       border_style="green",
                       title="Command Execution",
                       title_align="left"))

    success = run_shell_command(command)
    if not success:
        console.print(f"[bold red]Command failed: {command}[/bold red]")

def interactive_mode(chat_mode=False):
    """Run TerminalAI in interactive mode. If chat_mode is True, stay in a loop."""
    from terminalai.config import load_config
    from rich.console import Console
    from rich.text import Text
    from rich.panel import Panel
    from rich.rule import Rule

    config = load_config()
    console = Console()

    # Determine current provider/model for display
    current_provider = config.get("default_provider", "Not configured")
    
    # Get model with fallbacks for hardcoded defaults in ai_providers.py
    # This ensures what we show matches what is likely used
    provider_config = config.get("providers", {}).get(current_provider, {})
    current_model = provider_config.get("model", "")
    
    if not current_model:
        if current_provider == "openrouter":
            current_model = "openai/gpt-3.5-turbo"
        elif current_provider == "gemini":
            current_model = "gemini-pro"
        elif current_provider == "mistral":
            current_model = "mistral-tiny"
        elif current_provider == "ollama":
            current_model = "llama3"
        else:
            current_model = "default"

    # Construct the display string for the panel
    display_info = f"Provider: {current_provider} ({current_model})"

    if chat_mode:
        console.print(Panel.fit(
            Text(f"TerminalAI AI Chat Mode: You are now chatting with the AI.\nType 'exit' to quit.", style="bold magenta"),
            border_style="magenta"
        ))
        console.print("[dim]Type 'exit', 'quit', or 'q' to return to your shell.[/dim]")
    else:
        console.print(Panel.fit(
            Text(f"TerminalAI: What is your question? (Type 'exit' to quit)", style="bold cyan"),
            border_style="cyan"
        ))

    while True:
        # Add visual separation between interactions
        console.print("")
        
        # customized prompt with provider and model
        prompt_text = Text()
        prompt_text.append("[", style="bold white")
        prompt_text.append(current_provider, style="bold blue")
        prompt_text.append(":", style="bold white")
        prompt_text.append(current_model, style="bold yellow")
        prompt_text.append("] > ", style="bold green")
        
        console.print(prompt_text, end="")
        query = input().strip()

        if query.lower() in ["exit", "quit", "q"]:
            console.print("[bold cyan]Goodbye![/bold cyan]")
            sys.exit(0)

        if not query:
            continue

        from terminalai.shell_integration import get_system_context
        system_context = get_system_context()

        from terminalai.ai_providers import get_provider
        provider = get_provider(config.get("default_provider", ""))
        if not provider:
            console.print("[bold red]No AI provider configured. Please run 'ai setup' first.[/bold red]")
            break

        try:
            # Show a thinking indicator
            console.print("[dim]Thinking...[/dim]")

            response = provider.generate_response(query, system_context, verbose=False)

            # Clear the thinking indicator with a visual separator
            console.print(Rule(style="dim"))

            from terminalai.formatting import print_ai_answer_with_rich
            print_ai_answer_with_rich(response)

            # Extract and handle commands from the response, no max_commands limit
            from terminalai.command_extraction import extract_commands_from_output
            commands = extract_commands_from_output(response)

            # --- Casing enforcement post-processing ---
            # Try to extract likely file/folder names from the user query
            import re
            # Simple heuristic: look for quoted or single-word folder/file names in the query
            # (You can improve this with more advanced NLP if needed)
            query_words = re.findall(r'"([^"]+)"|\'([^\']+)\'|\b([a-zA-Z0-9_\-]+)\b', query)
            # Flatten and filter empty
            query_names = [w for tup in query_words for w in tup if w]
            # Remove common words
            blacklist = set(['the', 'folder', 'file', 'directory', 'to', 'in', 'on', 'find', 'go', 'cd', 'show', 'list', 'and', 'of', 'with', 'for', 'named', 'called', 'a', 'an', 'is', 'as', 'from', 'by', 'at', 'into', 'this', 'that', 'it', 'my', 'your', 'their', 'our', 'his', 'her', 'its', 'which', 'where', 'how', 'do', 'does', 'can', 'i', 'you', 'we', 'they', 'he', 'she', 'or', 'not', 'be', 'are', 'was', 'were', 'will', 'would', 'should', 'could', 'has', 'have', 'had', 'use', 'using', 'make', 'create', 'delete', 'remove', 'move', 'copy', 'open', 'close', 'edit', 'run', 'execute', 'print', 'output', 'input', 'set', 'get', 'change', 'switch', 'start', 'stop', 'restart', 'install', 'uninstall', 'update', 'upgrade', 'downgrade', 'enable', 'disable', 'turn', 'off', 'on', 'up', 'down', 'left', 'right', 'back', 'forward', 'previous', 'next', 'first', 'last', 'all', 'each', 'every', 'any', 'some', 'none', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])
            likely_names = [n for n in query_names if n.lower() not in blacklist and len(n) > 2]
            # For each command, replace any instance of a likely name with the exact casing from the query
            if likely_names:
                def enforce_casing(cmd):
                    for name in likely_names:
                        # Replace all case-insensitive matches with the exact casing
                        cmd = re.sub(r'(?i)'+re.escape(name), name, cmd)
                    return cmd
                commands = [enforce_casing(cmd) for cmd in commands]
            # --- End casing enforcement ---

            # Always prompt for execution if there are commands
            if commands:
                # Custom inline handler for chat mode: print only the command and exit if confirmed
                command = commands[0]
                is_stateful = is_stateful_command(command)
                is_risky = is_risky_command(command)
                confirm_msg = "Execute? [y/N]: " if is_risky else "Execute? [Y/n]: "
                default_choice = "n" if is_risky else "y"
                style = "yellow" if is_risky else "green"
                console.print(Text(confirm_msg, style=style), end="")
                choice = input().lower()
                if not choice:
                    choice = default_choice
                if choice == "y":
                    # Print ONLY the command to stdout and exit
                    print(command)
                    sys.exit(0)
                else:
                    console.print("[Cancelled]")
                # Always exit after showing a response and handling commands, unless in chat_mode
                if not chat_mode:
                    sys.exit(0)
            # Always exit after showing a response and handling commands, unless in chat_mode
            if not chat_mode:
                sys.exit(0)

        except SystemExit:
            # Allow clean exit without traceback
            raise
        except (ValueError, TypeError, OSError, KeyboardInterrupt) as e:
            # Catch common user/AI errors, but not all exceptions
            console.print(f"[bold red]Error during processing: {str(e)}[/bold red]")
            traceback.print_exc()
        except RuntimeError as e:
            # Catch-all for truly unexpected errors (should be rare)
            console.print(f"[bold red]Unexpected error: {str(e)}[/bold red]")
            traceback.print_exc()
        # If not in chat_mode, exit after one question/command
        if not chat_mode:
            sys.exit(0)

def get_available_models():
    """Get available models from the configured Ollama server.
    
    Returns:
        List of model names or error message.
    """
    from terminalai.ai_providers import OllamaProvider
    from terminalai.config import load_config
    
    config = load_config()
    ollama_config = config.get("providers", {}).get("ollama", {})
    
    # Validate that Ollama is configured
    if not ollama_config:
        return "[Ollama API error] Ollama is not configured. Please run 'ai setup' and configure Ollama host."
    
    host = ollama_config.get("host", "http://localhost:11434")
    
    # Validate host format
    if not host or not isinstance(host, str):
        return "[Ollama API error] Invalid Ollama host configuration."
    
    provider = OllamaProvider(host)
    models = provider.list_models()
    
    if isinstance(models, str) and models.startswith("[Ollama API error]"):
        return models
    
    return models

def _set_default_provider_interactive(console):
    """Interactively sets the default AI provider and saves it to config."""
    from terminalai.config import load_config, save_config
    config = load_config()
    providers = list(config['providers'].keys())
    console.print("\n[bold]Available providers:[/bold]")
    for idx, p_item in enumerate(providers, 1):
        is_default = ""
        if p_item == config.get('default_provider'):
            is_default = ' (default)'
        console.print(f"[bold yellow]{idx}[/bold yellow]. {p_item}{is_default}")
    sel_prompt = f"[bold green]Select provider (1-{len(providers)}): [/bold green]"
    sel = console.input(sel_prompt).strip()
    if sel.isdigit() and 1 <= int(sel) <= len(providers):
        selected_provider = providers[int(sel)-1]
        config['default_provider'] = selected_provider
        save_config(config)
        console.print(f"[bold green]Default provider set to "
                      f"{selected_provider}.[/bold green]")
        return True
    else:
        console.print("[red]Invalid selection.[/red]")
        return False

def _set_ollama_model_interactive(console):
    """Interactively sets the Ollama model and saves it to config."""
    import sys
    import os
    debug_mode = os.environ.get("TERMINALAI_DEBUG", "0") == "1"
    if debug_mode:
        print("[DEBUG] Entered _set_ollama_model_interactive", file=sys.stderr)
    from terminalai.config import load_config, save_config
    config = load_config()
    pname = 'ollama' # We are specifically configuring Ollama here

    if pname not in config['providers']:
        config['providers'][pname] = {} # Ensure ollama provider entry exists

    current_host = config['providers'][pname].get('host', 'http://localhost:11434')
    console.print(f"Current Ollama host: {current_host}")
    ollama_host_prompt = (
        "Enter Ollama host (leave blank to keep current, e.g., http://localhost:11434): "
    )
    sys.stdout.flush()
    if debug_mode:
        print("[DEBUG] About to prompt for Ollama host", file=sys.stderr)
    new_host_input = console.input(ollama_host_prompt).strip()
    console.print()  # Add a blank line for separation
    if debug_mode:
        print(f"[DEBUG] Got Ollama host input: '{new_host_input}'", file=sys.stderr)
    host_to_use = current_host
    if new_host_input:
        config['providers'][pname]['host'] = new_host_input
        host_to_use = new_host_input
        console.print("[bold green]Ollama host updated.[/bold green]")

    current_model = config['providers'][pname].get('model', 'llama3')
    console.print(f"Current Ollama model: {current_model}")

    available_models = []
    try:
        tags_url = f"{host_to_use}/api/tags"
        console.print(f"[dim]Fetching models from {tags_url}...[/dim]")
        sys.stdout.flush()
        if debug_mode:
            print(f"[DEBUG] About to fetch models from {tags_url}", file=sys.stderr)
        response = requests.get(tags_url, timeout=5)
        response.raise_for_status()
        models_data = response.json().get("models", [])
        if debug_mode:
            print(f"[DEBUG] Models data: {models_data}", file=sys.stderr)
        if models_data:
            available_models = [m.get("name") for m in models_data if m.get("name")]

            if available_models:
                console.print("[bold]Available Ollama models:[/bold]")
                for i, model_name_option in enumerate(available_models, 1):
                    console.print(f"  [bold yellow]{i}[/bold yellow]. {model_name_option}")
                if debug_mode:
                    print(f"[DEBUG] Printed {len(available_models)} models", file=sys.stderr)
                model_choice_prompt = (
                    "[bold green]Choose a model number, or enter 'c' to cancel: [/bold green]"
                )
                sys.stdout.flush()
                if debug_mode:
                    print("[DEBUG] About to prompt for model selection", file=sys.stderr)
                while True:
                    model_sel = console.input(model_choice_prompt).strip()
                    if debug_mode:
                        print(f"[DEBUG] Got model selection input: '{model_sel}'", file=sys.stderr)
                    if model_sel.lower() == 'c':
                        console.print("[yellow]Model selection cancelled. Model remains: {}[/yellow]".format(current_model))
                        break
                    if model_sel.isdigit() and 1 <= int(model_sel) <= len(available_models):
                        selected_model_name = available_models[int(model_sel)-1]
                        config['providers'][pname]['model'] = selected_model_name
                        console.print(f"[bold green]Ollama model set to: {selected_model_name}[/bold green]")
                        break
                    else:
                        console.print(f"[red]Invalid selection. Please enter a number between 1 and {len(available_models)}, or 'c' to cancel.[/red]")
        else:
            console.print(f"[yellow]No models found via Ollama API or API not reachable at {host_to_use}.[/yellow]")
            console.print("[yellow]You can still enter a model name manually.[/yellow]")
            manual_model_prompt = f"Enter Ollama model name (e.g., mistral:latest, current: {current_model}): "
            sys.stdout.flush()
            if debug_mode:
                print("[DEBUG] About to prompt for manual model entry", file=sys.stderr)
            manual_model_input = console.input(manual_model_prompt).strip()
            if debug_mode:
                print(f"[DEBUG] Got manual model input: '{manual_model_input}'", file=sys.stderr)
            if manual_model_input:
                config['providers'][pname]['model'] = manual_model_input
                console.print(f"[bold green]Ollama model set to: {manual_model_input}[/bold green]")
            else:
                console.print(f"[yellow]No model entered. Model remains: {current_model}[/yellow]")

    except requests.exceptions.RequestException as e:
        console.print(f"[red]Error fetching Ollama models: {e}[/red]")
        console.print("[yellow]Please ensure Ollama is running and accessible at the specified host.[/yellow]")
        console.print("[yellow]You can enter a model name manually.[/yellow]")
        manual_model_prompt_on_error = f"Enter Ollama model name (e.g., mistral:latest, current: {current_model}): "
        sys.stdout.flush()
        if debug_mode:
            print("[DEBUG] About to prompt for manual model entry after error", file=sys.stderr)
        manual_model_input_on_error = console.input(manual_model_prompt_on_error).strip()
        if debug_mode:
            print(f"[DEBUG] Got manual model input after error: '{manual_model_input_on_error}'", file=sys.stderr)
        if manual_model_input_on_error:
            config['providers'][pname]['model'] = manual_model_input_on_error
            console.print(f"[bold green]Ollama model set to: {manual_model_input_on_error}[/bold green]")
        else:
            console.print(f"[yellow]No model entered. Model remains: {current_model}[/yellow]")

    # Print summary of current host and model
    summary_host = config['providers'][pname].get('host', host_to_use)
    summary_model = config['providers'][pname].get('model', current_model)
    console.print("\n[bold cyan]Ollama configuration summary:[/bold cyan]")
    console.print(f"  [bold]Host:[/bold] [green]{summary_host}[/green]")
    console.print(f"  [bold]Model:[/bold] [yellow]{summary_model}[/yellow]\n")
    save_config(config)
    if debug_mode:
        print("[DEBUG] Exiting _set_ollama_model_interactive", file=sys.stderr)
    return True # Assuming success unless an unhandled exception occurs

def setup_wizard():
    """Run the setup wizard to configure TerminalAI."""
    from terminalai.config import (
        load_config, save_config,
        get_system_prompt, DEFAULT_SYSTEM_PROMPT
    )
    from rich.console import Console

    config = load_config()
    console = Console()

    logo = '''
████████╗███████╗██████╗ ███╗   ███╗██╗███╗   ██╗ █████╗ ██║       █████╗ ██╗
╚══██╔══╝██╔════╝██╔══██╗████╗ ████║██║████╗  ██║██╔══██╗██║      ██╔══██╗██║
   ██║   █████╗  ██████╔╝██╔████╔██║██║██╔██╗ ██║███████║██║      ███████║██║
   ██║   ██╔══╝  ██╔══██╗██║╚██╔╝██║██║██║╚██╗██║██╔══██║██║      ██╔══██║██║
   ██║   ███████╗██║  ██║██║ ╚═╝ ██║██║██║ ╚████║██║  ██║███████╗ ██║  ██║██║
   ╚═╝   ╚══════╝╚═╝  ╚═╝╚═╝     ╚═╝╚═╝╚═╝  ╚═══╝╚═╝  ╚═╝╚══════╝ ╚═╝  ╚═╝╚═╝
'''
    while True:
        console.clear()
        console.print(logo, style="bold cyan")
        console.print("[bold magenta]TerminalAI Setup Menu:[/bold magenta]")
        menu_options = [
            "1. Set default provider",
            "2. See current system prompt",
            "3. Edit current system prompt",
            "4. Reset system prompt to default",
            "5. Setup API keys",
            "6. See current API keys",
            "7. Install ai shell integration",
            "8. Uninstall ai shell integration",
            "9. Check ai shell integration",
            "10. View quick setup guide",
            "11. About TerminalAI",
            "12. List available Ollama models",
            "13. Exit"
        ]
        menu_info = {
            '1': ("Set which AI provider (OpenRouter, Gemini, Mistral, Ollama) "
                  "is used by default for all queries."),
            '2': "View the current system prompt that guides the AI's behavior.",
            '3': "Edit the system prompt to customize how the AI responds to your queries.",
            '4': "Reset the system prompt to the default recommended by TerminalAI.",
            '5': "Set/update API key/host for any provider.",
            '6': "List providers and their stored API key/host.",
            '7': "Install the 'ai' shell function for seamless stateful command execution (recommended for advanced users).",
            '8': "Uninstall the 'ai' shell function from your shell config.",
            '9': "Check if the 'ai' shell integration is installed and highlight it in your shell config.",
            '10': "Display the quick setup guide to help you get started with TerminalAI.",
            '11': "View information about TerminalAI, including version and links.",
            '12': "List available Ollama models and select default model.",
            '13': "Exit the setup menu."
        }
        for opt in menu_options:
            num, desc = opt.split('.', 1)
            console.print(f"[bold yellow]{num}[/bold yellow].[white]{desc}[/white]")
        info_prompt = ("Type 'i' followed by a number (e.g., i1) "
                       "for more info about an option.")
        console.print(f"[dim]{info_prompt}[/dim]")
        choice = console.input("[bold green]Choose an action (1-12): [/bold green]").strip()
        config = load_config()
        if choice.startswith('i') and choice[1:].isdigit():
            info_num = choice[1:]
            if info_num in menu_info:
                info_text = menu_info[info_num]
                console.print(f"[bold cyan]Info for option {info_num}:[/bold cyan]")
                console.print(info_text)
            else:
                console.print("[red]No info available for that option.[/red]")
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '1':
            providers = list(config['providers'].keys())
            console.print("\n[bold]Available providers:[/bold]")
            for idx, p_item in enumerate(providers, 1):
                is_default = ""
                if p_item == config.get('default_provider'):
                    is_default = ' (default)'
                console.print(f"[bold yellow]{idx}[/bold yellow]. {p_item}{is_default}")
            sel_prompt = f"[bold green]Select provider (1-{len(providers)}): [/bold green]"
            sel = console.input(sel_prompt).strip()
            if sel.isdigit() and 1 <= int(sel) <= len(providers):
                selected_provider = providers[int(sel)-1]
                config['default_provider'] = selected_provider
                save_config(config)
                console.print(f"[bold green]Default provider set to "
                              f"{selected_provider}.[/bold green]")
            else:
                console.print("[red]Invalid selection.[/red]")
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '2':
            console.print("\n[bold]Current system prompt:[/bold]\n")
            console.print(get_system_prompt())
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '3':
            console.print("\n[bold]Current system prompt:[/bold]\n")
            console.print(config.get('system_prompt', ''))
            new_prompt_input = (
                "\n[bold green]Enter new system prompt "
                "(leave blank to cancel):\n[/bold green]"
            )
            new_prompt = console.input(new_prompt_input)
            if new_prompt.strip():
                config['system_prompt'] = new_prompt.strip()
                save_config(config)
                console.print(
                    "[bold green]System prompt updated.[/bold green]"
                )
            else:
                console.print("[yellow]No changes made.[/yellow]")
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '4':
            config['system_prompt'] = DEFAULT_SYSTEM_PROMPT
            save_config(config)
            console.print("[bold green]System prompt reset to default.[/bold green]")
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '5':
            providers = list(config['providers'].keys())
            console.print("\n[bold]Providers:[/bold]")
            for idx, p_item in enumerate(providers, 1):
                console.print(f"[bold yellow]{idx}[/bold yellow]. {p_item}")
            sel_prompt = (f"[bold green]Select provider to set API key/host "
                          f"(1-{len(providers)}): [/bold green]")
            sel = console.input(sel_prompt).strip()
            if sel.isdigit() and 1 <= int(sel) <= len(providers):
                pname = providers[int(sel)-1]
                if pname == 'ollama':
                    current = config['providers'][pname].get('host', '')
                    console.print(f"Current host: {current}")
                    ollama_host_prompt = (
                        "Enter new Ollama host (e.g., http://localhost:11434) or press Enter to skip: "
                    )
                    new_host = console.input(ollama_host_prompt).strip()
                    if new_host:
                        config['providers'][pname]['host'] = new_host
                        save_config(config)
                        console.print(
                            "[bold green]Ollama host updated.[/bold green]"
                        )
                    
                    # Show available models for Ollama
                    try:
                        from terminalai.ai_providers import OllamaProvider
                        host = config['providers'][pname].get('host', 'http://localhost:11434')
                        provider = OllamaProvider(host)
                        models = provider.list_models()
                        if isinstance(models, list) and models:
                            console.print(f"\n[bold]Available models for {pname}:[/bold]")
                            for i, model in enumerate(models, 1):
                                model_name = model.get("name", model.get("model", "Unknown"))
                                console.print(f"[bold yellow]{i}[/bold yellow]. {model_name}")
                            
                            try:
                                model_choice = int(console.input("Select model (or press Enter to skip): "))
                                if 1 <= model_choice <= len(models):
                                    selected_model = models[model_choice - 1].get("name", models[model_choice - 1].get("model", ""))
                                    config['providers'][pname]['model'] = selected_model
                                    console.print(f"[bold green]Model set to: {selected_model}[/bold green]")
                                else:
                                    console.print("[red]Invalid model selection.[/red]")
                            except ValueError:
                                console.print("[yellow]Skipping model selection.[/yellow]")
                        else:
                            console.print("[yellow]No models available or unable to fetch models.[/yellow]")
                    except Exception as e:
                        console.print(f"[red]Error fetching models: {e}[/red]")
                    
                    console.print("[yellow]No changes made.[/yellow]")
                else:
                    current = config['providers'][pname].get('api_key', '')
                    if current:
                        console.print(f"Current API key: [hidden]")
                        new_key_prompt = f"Enter new API key for {pname} (or press Enter to skip): "
                        new_key = console.input(new_key_prompt).strip()
                        if new_key:
                            config['providers'][pname]['api_key'] = new_key
                            save_config(config)
                            console.print(
                                f"[bold green]API key for {pname} updated.[/bold green]"
                            )
                        
                        # Show available models for API-based providers
                        try:
                            from terminalai.ai_providers import get_provider
                            temp_provider = get_provider(pname)
                            if temp_provider and hasattr(temp_provider, 'list_models'):
                                models = temp_provider.list_models()
                                if isinstance(models, list) and models:
                                    console.print(f"\n[bold]Available models for {pname}:[/bold]")
                                    for i, model in enumerate(models, 1):
                                        model_name = model.get("id", model.get("name", "Unknown"))
                                        model_desc = model.get("description", "")
                                        if model_desc:
                                            console.print(f"[bold yellow]{i}[/bold yellow]. {model_name} - {model_desc}")
                                        else:
                                            console.print(f"[bold yellow]{i}[/bold yellow]. {model_name}")
                                    
                                    try:
                                        model_choice = int(console.input("Select model (or press Enter to skip): "))
                                        if 1 <= model_choice <= len(models):
                                            selected_model = models[model_choice - 1].get("id", models[model_choice - 1].get("name", ""))
                                            config['providers'][pname]['model'] = selected_model
                                            console.print(f"[bold green]Model set to: {selected_model}[/bold green]")
                                        else:
                                            console.print("[red]Invalid model selection.[/red]")
                                    except ValueError:
                                        console.print("[yellow]Skipping model selection.[/yellow]")
                                else:
                                    console.print("[yellow]No models available or unable to fetch models.[/yellow]")
                        except Exception as e:
                            console.print(f"[red]Error fetching models: {e}[/red]")
                        
                        console.print("[yellow]No changes made.[/yellow]")
                    else:
                        console.print(f"Current API key: (not set)")
                        new_key_prompt = f"Enter API key for {pname}: "
                        new_key = console.input(new_key_prompt).strip()
                        if new_key:
                            config['providers'][pname]['api_key'] = new_key
                            save_config(config)
                            console.print(
                                f"[bold green]API key for {pname} set.[/bold green]"
                            )
                        
                        # Show available models for API-based providers
                        try:
                            from terminalai.ai_providers import get_provider
                            temp_provider = get_provider(pname)
                            if temp_provider and hasattr(temp_provider, 'list_models'):
                                models = temp_provider.list_models()
                                if isinstance(models, list) and models:
                                    console.print(f"\n[bold]Available models for {pname}:[/bold]")
                                    for i, model in enumerate(models, 1):
                                        model_name = model.get("id", model.get("name", "Unknown"))
                                        model_desc = model.get("description", "")
                                        if model_desc:
                                            console.print(f"[bold yellow]{i}[/bold yellow]. {model_name} - {model_desc}")
                                        else:
                                            console.print(f"[bold yellow]{i}[/bold yellow]. {model_name}")
                                    
                                    try:
                                        model_choice = int(console.input("Select model (or press Enter to skip): "))
                                        if 1 <= model_choice <= len(models):
                                            selected_model = models[model_choice - 1].get("id", models[model_choice - 1].get("name", ""))
                                            config['providers'][pname]['model'] = selected_model
                                            console.print(f"[bold green]Model set to: {selected_model}[/bold green]")
                                        else:
                                            console.print("[red]Invalid model selection.[/red]")
                                    except ValueError:
                                        console.print("[yellow]Skipping model selection.[/yellow]")
                                else:
                                    console.print("[yellow]No models available or unable to fetch models.[/yellow]")
                        except Exception as e:
                            console.print(f"[red]Error fetching models: {e}[/red]")
                        
                        console.print("[yellow]No changes made.[/yellow]")
            else:
                console.print("[red]Invalid selection.[/red]")
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '6':
            providers = list(config['providers'].keys())
            console.print("\n[bold]Current API keys / hosts:[/bold]")
            for p_item in providers:
                if p_item == 'ollama':
                    val = config['providers'][p_item].get('host', '')
                    shown = val if val else '[not set]'
                else:
                    val = config['providers'][p_item].get('api_key', '')
                    shown = '[not set]' if not val else '[hidden]'
                console.print(f"[bold yellow]{p_item}:[/bold yellow] {shown}")
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '7':
            from terminalai.shell_integration import install_shell_integration
            install_shell_integration()
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '8':
            from terminalai.shell_integration import uninstall_shell_integration
            uninstall_shell_integration()
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '9':
            from terminalai.shell_integration import check_shell_integration
            check_shell_integration()
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '10':
            console.print("\n[bold cyan]Quick Setup Guide:[/bold cyan]\n")
            guide = """
[bold yellow]1. Installation[/bold yellow]

You have two options to install TerminalAI:

[bold green]Option A: Install from PyPI (Recommended)[/bold green]
    pip install coaxial-terminal-ai

[bold green]Option B: Install from source[/bold green]
    git clone https://github.com/coaxialdolor/terminalai.git
    cd terminalai
    pip install -e .

[bold yellow]2. Initial Configuration[/bold yellow]

In a terminal window, run:
    ai setup

• Enter [bold]5[/bold] to select "Setup API Keys"
• Select your preferred AI provider:
  - Mistral is recommended for its good performance and generous free tier limits
  - Ollama is ideal if you prefer locally hosted AI
  - You can also use OpenRouter or Gemini
• Enter the API key for your selected provider(s)
• Press Enter to return to the setup menu

[bold yellow]3. Set Default Provider[/bold yellow]

• At the setup menu, select [bold]1[/bold] to "Setup default provider"
• Choose a provider that you've saved an API key for
• Press Enter to return to the setup menu

[bold yellow]4. Understanding Stateful Command Execution[/bold yellow]

For commands like 'cd' or 'export' that change your shell's state, TerminalAI
will offer to copy the command to your clipboard. You can then paste and run it.

(Optional) Shell Integration:
• You can still install a shell integration via option [bold]7[/bold] in the setup menu.
  This is for advanced users who prefer a shell function for such commands.
  Note that the primary method is now copy-to-clipboard.

[bold yellow]5. Start Using TerminalAI[/bold yellow]
You're now ready to use TerminalAI! Here's how:

[bold green]Direct Query with Quotes[/bold green]
    ai "how do I find all text files in the current directory?"

[bold green]Interactive Mode[/bold green]
    ai
    AI: What is your question?
    : how do I find all text files in the current directory?

[bold green]Running Commands[/bold green]
• When TerminalAI suggests terminal commands, you'll be prompted:
  - For a single command: Enter Y to run or N to skip
  - For multiple commands: Enter the number of the command you want to run
  - For stateful (shell state-changing) commands, you'll be prompted to copy them
    to your clipboard to run manually.
"""
            console.print(guide)
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '11':
            from terminalai.__init__ import __version__
            console.print("\n[bold cyan]About TerminalAI:[/bold cyan]\n")
            console.print(f"[bold]Version:[/bold] {__version__}")
            console.print("[bold]GitHub:[/bold] https://github.com/coaxialdolor/terminalai")
            console.print("[bold]PyPI:[/bold] https://pypi.org/project/coaxial-terminal-ai/")
            console.print("\n[bold]Description:[/bold]")
            console.print(
                "TerminalAI is a command-line AI assistant designed to interpret user"
            )
            console.print(
                "requests, suggest relevant terminal commands, "
                "and execute them interactively."
            )
            console.print("\n[bold red]Disclaimer:[/bold red]")
            console.print(
                "This application is provided as-is without any warranties. "
                "Use at your own risk."
            )
            console.print(
                "The developers cannot be held responsible for any data loss, system damage,"
            )
            console.print(
                "or other issues that may occur from executing "
                "suggested commands."
            )
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '12':
            # List available Ollama models
            console.print("\n[bold cyan]Fetching available Ollama models...[/bold cyan]")
            
            models = get_available_models()
            
            if isinstance(models, str) and models.startswith("[Ollama API error]"):
                console.print(f"[red]{models}[/red]")
                console.print("[yellow]Make sure Ollama is running and the host is correct.[/yellow]")
            elif not models:
                console.print("[yellow]No models found. Make sure Ollama is running and has models installed.[/yellow]")
            else:
                console.print(f"\n[bold green]Found {len(models)} available model(s):[/bold green]\n")
                
                # Display models with details
                for i, model in enumerate(models, 1):
                    model_name = model.get('name', 'Unknown')
                    model_size = model.get('size', 0)
                    model_modified = model.get('modified_at', 'Unknown')
                    
                    # Format size in human-readable format
                    if model_size > 0:
                        if model_size >= 1024**3:
                            size_str = f"{model_size / (1024**3):.1f} GB"
                        elif model_size >= 1024**2:
                            size_str = f"{model_size / (1024**2):.1f} MB"
                        elif model_size >= 1024:
                            size_str = f"{model_size / 1024:.1f} KB"
                        else:
                            size_str = f"{model_size} B"
                    else:
                        size_str = "Unknown size"
                    
                    console.print(f"[bold yellow]{i}[/bold yellow]. [cyan]{model_name}[/cyan]")
                    console.print(f"   Size: {size_str}")
                    console.print(f"   Modified: {model_modified}")
                    console.print("")
                
                # Ask if user wants to select a model
                console.print("[bold green]Current default model:[/bold green] " + config.get("providers", {}).get("ollama", {}).get("model", "llama3"))
                console.print(Text("Select a model as default? [y/N]: ", style="bold green"), end="")
                choice = input().lower()
                
                if choice == "y":
                    console.print(Text("Enter model number (1-{}): ".format(len(models)), style="bold green"), end="")
                    model_choice = input().strip()
                    
                    if model_choice.isdigit() and 1 <= int(model_choice) <= len(models):
                        selected_model = models[int(model_choice) - 1]['name']
                        config['providers']['ollama']['model'] = selected_model
                        save_config(config)
                        console.print(f"[bold green]Default Ollama model set to: {selected_model}[/bold green]")
                    else:
                        console.print("[red]Invalid selection.[/red]")
            
            console.input("[dim]Press Enter to continue...[/dim]")
        elif choice == '13':
            console.print(
                "[bold cyan]Exiting setup.[/bold cyan]"
            )
            break
        else:
            error_msg = (
                "Invalid choice. Please select a number from 1 to 12."
            )
            console.print(f"[red]{error_msg}[/red]")
            console.input("[dim]Press Enter to continue...[/dim]")
