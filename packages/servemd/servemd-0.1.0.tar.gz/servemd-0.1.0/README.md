# servemd

**Serve docs to humans and AI.**

Beautiful markdown documentation with native llms.txt support. Zero configuration, production-ready.

[![PyPI](https://img.shields.io/pypi/v/servemd.svg)](https://pypi.org/project/servemd/)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128+-green.svg)](https://fastapi.tiangolo.com/)
[![Tests](https://img.shields.io/badge/tests-71%20passing-brightgreen.svg)](tests/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache_2.0-yellow.svg)](LICENSE)

---

## Why servemd?

Unlike basic markdown servers, **servemd** is built for the AI era:

```
Markdown â†’ Beautiful HTML    â†’ Humans
         â†’ llms.txt          â†’ AI/LLMs
         â†’ llms-full.txt     â†’ Complete AI context
         â†’ /mcp endpoint     â†’ AI assistants (250x less context)
```

**For humans:** Nuxt UI-inspired design, three-column layout, zero configuration.
**For AI:** Native llms.txt support, structured context, ready for the Model Context Protocol era.

---

## âœ¨ Features

- ðŸŽ¨ **Beautiful Design** â€” Nuxt UI-inspired three-column layout (sidebar, content, TOC)
- ðŸ¤– **AI-Native** â€” Built-in llms.txt and llms-full.txt for Claude, ChatGPT, Cursor, etc.
- âœ¨ **Zero Configuration** â€” Drop `.md` files and go
- âš¡ **Fast** â€” Smart disk caching, <5ms cached responses
- ðŸ³ **Docker Ready** â€” Production-optimized container
- ðŸ§ª **Well Tested** â€” 71 tests, 100% passing
- ðŸ“± **Responsive** â€” Mobile, tablet, and desktop support

---

## ðŸš€ Quick Start

### Install

```bash
pip install servemd
```

### Run

```bash
# Serve docs from current directory
servemd

# Or specify a directory
servemd ./my-docs
```

Visit **http://localhost:8080** â€” your documentation is live.

### Alternative: Docker

```bash
# With volume mount
docker run -p 8080:8080 -v $(pwd):/app/docs ghcr.io/servemd/servemd:latest

# Or build a custom image with your docs baked in
FROM ghcr.io/servemd/servemd:latest
COPY ./docs /app/docs/
```

### Alternative: uvx (no install)

```bash
uvx servemd ./my-docs
```

ðŸ“š **[Complete Setup Guide â†’](docs/quick-start-user.md)**

### For Contributors

```bash
git clone https://github.com/servemd/servemd
cd servemd
uv sync
uv run python -m docs_server
```

---

## ðŸ¤– AI-Native: llms.txt Support

servemd automatically serves your docs in AI-friendly formats:

| Endpoint | Purpose | Audience |
|----------|---------|----------|
| `/{page}.html` | Rendered HTML with navigation | Humans |
| `/{page}.md` | Raw markdown | AI/LLMs |
| `/llms.txt` | Documentation index | AI assistants |
| `/llms-full.txt` | Complete context (all pages) | AI deep context |

**Example:** Give an AI assistant your docs:
```
"Read my documentation at https://docs.example.com/llms.txt"
```

The AI gets a structured index with absolute URLs to every page. For complete context, use `/llms-full.txt` which includes all page content inline.

---

## âœ¨ Key Features

### For Humans
- ðŸŽ¨ Nuxt UI-inspired three-column layout (sidebar, content, TOC)
- ðŸŽ¨ Syntax highlighting with Pygments
- ðŸŽ¨ Responsive design (mobile, tablet, desktop)
- ðŸŽ¨ Dark mode ready
- âœ… Tables, task lists, footnotes, Mermaid diagrams

### For AI
- ðŸ¤– **llms.txt** â€” structured documentation index
- ðŸ¤– **llms-full.txt** â€” complete context export
- ðŸ¤– **MCP endpoint** â€” interactive queries (250x less context)
- ðŸ¤– Automatic link transformation to absolute URLs
- ðŸ¤– Curated or auto-generated indexes

### For Developers
- âš¡ Fast â€” disk caching, <5ms cached responses
- ðŸ”¥ Hot reload in debug mode
- ðŸ”§ Zero configuration required
- ðŸ Python 3.13+, FastAPI, Pydantic
- ðŸ§ª 71 tests, 100% passing

---

## ðŸ“ File Structure

Your documentation needs just 3 required files:

```
docs/
â”œâ”€â”€ index.md       # Homepage (required)
â”œâ”€â”€ sidebar.md     # Navigation (required)
â”œâ”€â”€ topbar.md      # Top bar (required)
â”œâ”€â”€ llms.txt       # AI index (optional)
â””â”€â”€ your-content.md # Your pages
```

---

## âš™ï¸ Configuration

Configure via environment variables:

```bash
DOCS_ROOT=./docs              # Documentation directory
CACHE_ROOT=./__cache__        # Cache directory
PORT=8080                     # Server port
DEBUG=true                    # Enable debug mode
BASE_URL=https://docs.site.com  # Base URL for llms.txt
```

See [Configuration Guide](docs/configuration.md) for details.

---

## ðŸŽ¯ Use Cases

**servemd** is perfect for:

- **SaaS Documentation** â€” Customer-facing support docs with AI assistant integration
- **Open Source Projects** â€” Self-hosted, beautiful docs
- **Internal Teams** â€” Company knowledge bases and wikis
- **API Documentation** â€” REST/GraphQL API docs
- **Technical Writing** â€” Blogs and tutorials

### ðŸ“˜ Deployment

| Method | Best For |
|--------|----------|
| [Local Development](docs/deployment/local-development.md) | Development, previewing |
| [Docker](docs/deployment/docker.md) | Production, CI/CD |
| [Cloud Platforms](docs/deployment/cloud-platforms.md) | Heroku, Railway, Fly.io, DigitalOcean |
| [Kubernetes](docs/deployment/kubernetes.md) | k8s, k3s, Helm charts |

### ðŸ› ï¸ Examples

Check **[examples/](examples/)** for ready-to-use templates:
- `Dockerfile.user-template` â€” Custom Docker image
- `docker-compose.user.yml` â€” Docker Compose setup
- `k8s-simple.yaml` â€” Kubernetes deployment

---

## ðŸ—ï¸ Architecture

Clean, modular FastAPI application:

```
src/docs_server/
â”œâ”€â”€ config.py           # Settings & environment
â”œâ”€â”€ helpers.py          # Utilities & navigation
â”œâ”€â”€ caching.py          # Smart caching
â”œâ”€â”€ markdown_service.py # Markdown rendering
â”œâ”€â”€ llms_service.py     # LLMs.txt generation
â”œâ”€â”€ templates.py        # HTML templates
â””â”€â”€ main.py            # FastAPI routes
```

---

## ðŸ§ª Testing

```bash
uv run pytest tests/ -v

# 71 tests, 100% passing âœ…
```

---

## ðŸ”§ Development

```bash
git clone https://github.com/servemd/servemd
cd servemd
uv sync --group dev
uv run pytest tests/ -v
DEBUG=true uv run python -m docs_server
```

---

## ðŸ“Š Performance

| Endpoint | First Request | Cached |
|----------|---------------|--------|
| Rendered HTML | 50-100ms | <5ms |
| Raw Markdown | <10ms | <10ms |
| LLMs.txt | 100-200ms | <5ms |

---

## ðŸ“– Documentation

- **[Quick Setup](docs/quick-setup.md)** â€” Get running in 5 minutes
- **[Markdown Features](docs/features/markdown.md)** â€” Tables, code blocks, diagrams
- **[LLMs.txt Guide](docs/features/llms-txt.md)** â€” AI assistant integration
- **[MCP Integration](docs/features/mcp.md)** â€” Interactive queries for LLMs
- **[Navigation](docs/features/navigation.md)** â€” Sidebar and topbar configuration
- **[Configuration](docs/configuration.md)** â€” Environment variables
- **[API Reference](docs/api/endpoints.md)** â€” HTTP endpoints

---

## ðŸ™‹ Support

- ðŸ“– **Documentation**: [docs.servemd.dev](https://docs.servemd.dev) or run locally
- ðŸ› **Issues**: [GitHub Issues](https://github.com/servemd/servemd/issues)
- ðŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/servemd/servemd/discussions)

---

## ðŸ“œ License

MIT License â€” use freely for any project.

---

## ðŸŽ‰ Get Started Now

```bash
pip install servemd
servemd ./my-docs
```

Visit **http://localhost:8080** â€” beautiful docs for humans, structured context for AI.

---

<div align="center">

**servemd** â€” Serve docs to humans and AI

Built with Python, FastAPI, and Markdown

[Documentation](https://docs.servemd.dev) Â· [PyPI](https://pypi.org/project/servemd/) Â· [GitHub](https://github.com/servemd/servemd)

</div>
