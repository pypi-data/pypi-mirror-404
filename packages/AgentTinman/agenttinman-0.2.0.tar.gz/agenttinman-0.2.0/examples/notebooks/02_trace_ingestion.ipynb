{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace Ingestion with Tinman\n",
    "\n",
    "This notebook demonstrates how to ingest traces from various observability platforms\n",
    "into Tinman for failure analysis.\n",
    "\n",
    "Supported formats:\n",
    "- OpenTelemetry (OTLP)\n",
    "- Datadog APM\n",
    "- AWS X-Ray\n",
    "- Generic JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinman.ingest import (\n",
    "    OTLPAdapter,\n",
    "    DatadogAdapter,\n",
    "    XRayAdapter,\n",
    "    JSONAdapter,\n",
    "    AdapterRegistry,\n",
    "    parse_traces,\n",
    "    Trace,\n",
    "    Span,\n",
    "    SpanStatus,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OpenTelemetry (OTLP) Traces\n",
    "\n",
    "OTLP is the native format for OpenTelemetry data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OTLP data\n",
    "otlp_data = {\n",
    "    \"resourceSpans\": [\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"attributes\": [\n",
    "                    {\"key\": \"service.name\", \"value\": {\"stringValue\": \"ai-assistant\"}},\n",
    "                    {\"key\": \"service.version\", \"value\": {\"stringValue\": \"1.2.3\"}},\n",
    "                ]\n",
    "            },\n",
    "            \"scopeSpans\": [\n",
    "                {\n",
    "                    \"spans\": [\n",
    "                        {\n",
    "                            \"traceId\": \"0123456789abcdef0123456789abcdef\",\n",
    "                            \"spanId\": \"0123456789abcdef\",\n",
    "                            \"name\": \"llm.completion\",\n",
    "                            \"kind\": 2,\n",
    "                            \"startTimeUnixNano\": \"1704067200000000000\",\n",
    "                            \"endTimeUnixNano\": \"1704067203000000000\",\n",
    "                            \"status\": {\"code\": 2, \"message\": \"Tool execution failed\"},\n",
    "                            \"attributes\": [\n",
    "                                {\"key\": \"llm.model\", \"value\": {\"stringValue\": \"claude-3\"}},\n",
    "                                {\"key\": \"llm.tokens.input\", \"value\": {\"intValue\": \"1500\"}},\n",
    "                                {\"key\": \"llm.tokens.output\", \"value\": {\"intValue\": \"500\"}},\n",
    "                            ],\n",
    "                            \"events\": [\n",
    "                                {\n",
    "                                    \"name\": \"exception\",\n",
    "                                    \"timeUnixNano\": \"1704067202500000000\",\n",
    "                                    \"attributes\": [\n",
    "                                        {\n",
    "                                            \"key\": \"exception.type\",\n",
    "                                            \"value\": {\"stringValue\": \"ToolExecutionError\"},\n",
    "                                        },\n",
    "                                        {\n",
    "                                            \"key\": \"exception.message\",\n",
    "                                            \"value\": {\n",
    "                                                \"stringValue\": \"Invalid parameters for search tool\"\n",
    "                                            },\n",
    "                                        },\n",
    "                                    ],\n",
    "                                }\n",
    "                            ],\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse with OTLP adapter\n",
    "adapter = OTLPAdapter()\n",
    "traces = list(adapter.parse(otlp_data))\n",
    "\n",
    "print(f\"Parsed {len(traces)} trace(s)\")\n",
    "for trace in traces:\n",
    "    print(f\"\\nTrace ID: {trace.trace_id}\")\n",
    "    print(f\"Spans: {trace.span_count}\")\n",
    "    print(f\"Has errors: {trace.has_errors}\")\n",
    "\n",
    "    for span in trace.spans:\n",
    "        print(f\"  - {span.name} ({span.duration_ms:.0f}ms) [{span.status.value}]\")\n",
    "        if span.has_exception():\n",
    "            for exc in span.get_exceptions():\n",
    "                print(f\"    Exception: {exc['type']}: {exc['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datadog APM Traces\n",
    "\n",
    "Import traces from Datadog's APM format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Datadog data\n",
    "datadog_data = [\n",
    "    [\n",
    "        {\n",
    "            \"trace_id\": 12345678901234567890,\n",
    "            \"span_id\": 9876543210987654321,\n",
    "            \"name\": \"web.request\",\n",
    "            \"service\": \"ai-gateway\",\n",
    "            \"resource\": \"/v1/chat/completions\",\n",
    "            \"type\": \"web\",\n",
    "            \"start\": 1704067200000000000,\n",
    "            \"duration\": 2500000000,\n",
    "            \"error\": 1,\n",
    "            \"meta\": {\n",
    "                \"http.method\": \"POST\",\n",
    "                \"http.url\": \"/v1/chat/completions\",\n",
    "                \"http.status_code\": \"500\",\n",
    "                \"error.type\": \"RateLimitError\",\n",
    "                \"error.msg\": \"Rate limit exceeded for model claude-3-opus\",\n",
    "            },\n",
    "            \"metrics\": {\"_dd.measured\": 1},\n",
    "        },\n",
    "        {\n",
    "            \"trace_id\": 12345678901234567890,\n",
    "            \"span_id\": 1111111111111111111,\n",
    "            \"parent_id\": 9876543210987654321,\n",
    "            \"name\": \"llm.call\",\n",
    "            \"service\": \"ai-gateway\",\n",
    "            \"resource\": \"claude-3-opus\",\n",
    "            \"type\": \"custom\",\n",
    "            \"start\": 1704067200100000000,\n",
    "            \"duration\": 2400000000,\n",
    "            \"error\": 1,\n",
    "            \"meta\": {\n",
    "                \"llm.model\": \"claude-3-opus\",\n",
    "                \"error.type\": \"RateLimitError\",\n",
    "                \"error.msg\": \"429 Too Many Requests\",\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Parse with Datadog adapter\n",
    "adapter = DatadogAdapter()\n",
    "traces = list(adapter.parse(datadog_data))\n",
    "\n",
    "print(f\"Parsed {len(traces)} trace(s)\")\n",
    "for trace in traces:\n",
    "    print(f\"\\nTrace ID: {trace.trace_id}\")\n",
    "    print(f\"Services: {trace.services}\")\n",
    "    print(f\"Error spans: {len(trace.error_spans)}\")\n",
    "\n",
    "    for span in trace.spans:\n",
    "        status_icon = \"❌\" if span.is_error else \"✓\"\n",
    "        print(f\"  {status_icon} {span.name} - {span.service_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AWS X-Ray Traces\n",
    "\n",
    "Parse traces from AWS X-Ray format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example X-Ray data\n",
    "xray_data = {\n",
    "    \"Traces\": [\n",
    "        {\n",
    "            \"Segments\": [\n",
    "                {\n",
    "                    \"trace_id\": \"1-5f84c7a5-abc123def456789012345678\",\n",
    "                    \"id\": \"abc123def456\",\n",
    "                    \"name\": \"ai-assistant-lambda\",\n",
    "                    \"start_time\": 1704067200.0,\n",
    "                    \"end_time\": 1704067205.0,\n",
    "                    \"origin\": \"AWS::Lambda::Function\",\n",
    "                    \"fault\": True,\n",
    "                    \"http\": {\n",
    "                        \"request\": {\"method\": \"POST\", \"url\": \"https://api.example.com/invoke\"},\n",
    "                        \"response\": {\"status\": 500},\n",
    "                    },\n",
    "                    \"cause\": {\n",
    "                        \"exceptions\": [\n",
    "                            {\n",
    "                                \"id\": \"exc-001\",\n",
    "                                \"type\": \"TimeoutError\",\n",
    "                                \"message\": \"Lambda execution timed out after 30 seconds\",\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"subsegments\": [\n",
    "                        {\n",
    "                            \"id\": \"sub-001\",\n",
    "                            \"name\": \"anthropic-api-call\",\n",
    "                            \"start_time\": 1704067201.0,\n",
    "                            \"end_time\": 1704067204.0,\n",
    "                            \"namespace\": \"remote\",\n",
    "                            \"error\": True,\n",
    "                            \"annotations\": {\"model\": \"claude-3\", \"tokens_used\": 5000},\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Parse with X-Ray adapter\n",
    "adapter = XRayAdapter()\n",
    "traces = list(adapter.parse(xray_data))\n",
    "\n",
    "print(f\"Parsed {len(traces)} trace(s)\")\n",
    "for trace in traces:\n",
    "    print(f\"\\nTrace ID: {trace.trace_id}\")\n",
    "    print(f\"Duration: {trace.duration_ms:.0f}ms\")\n",
    "\n",
    "    for span in trace.spans:\n",
    "        indent = \"  \" if span.is_root else \"    \"\n",
    "        print(f\"{indent}{span.name} [{span.kind}] - {span.duration_ms:.0f}ms\")\n",
    "        if span.has_exception():\n",
    "            for exc in span.get_exceptions():\n",
    "                print(f\"{indent}  ⚠️ {exc['type']}: {exc['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Auto-Detection with Registry\n",
    "\n",
    "The adapter registry can automatically detect the trace format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect and parse\n",
    "registry = AdapterRegistry()\n",
    "registry.register(OTLPAdapter)\n",
    "registry.register(DatadogAdapter)\n",
    "registry.register(XRayAdapter)\n",
    "registry.register(JSONAdapter)\n",
    "\n",
    "# Test auto-detection\n",
    "print(\"Format detection results:\")\n",
    "print(f\"OTLP data -> {registry.detect_format(otlp_data)}\")\n",
    "print(f\"Datadog data -> {registry.detect_format(datadog_data)}\")\n",
    "print(f\"X-Ray data -> {registry.detect_format(xray_data)}\")\n",
    "\n",
    "# Parse with auto-detection\n",
    "traces = registry.parse_auto(otlp_data)\n",
    "print(f\"\\nAuto-parsed {len(traces)} trace(s) from OTLP data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Traces for Failures\n",
    "\n",
    "Extract failure patterns from ingested traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trace_for_failures(trace: Trace) -> list[dict]:\n",
    "    \"\"\"Extract potential failures from a trace.\"\"\"\n",
    "    findings = []\n",
    "\n",
    "    for span in trace.error_spans:\n",
    "        finding = {\n",
    "            \"trace_id\": trace.trace_id,\n",
    "            \"span_id\": span.span_id,\n",
    "            \"service\": span.service_name,\n",
    "            \"operation\": span.name,\n",
    "            \"duration_ms\": span.duration_ms,\n",
    "            \"status_message\": span.status_message,\n",
    "            \"exceptions\": span.get_exceptions(),\n",
    "            \"attributes\": span.attributes,\n",
    "        }\n",
    "        findings.append(finding)\n",
    "\n",
    "    return findings\n",
    "\n",
    "\n",
    "# Analyze all parsed traces\n",
    "all_traces = (\n",
    "    list(OTLPAdapter().parse(otlp_data))\n",
    "    + list(DatadogAdapter().parse(datadog_data))\n",
    "    + list(XRayAdapter().parse(xray_data))\n",
    ")\n",
    "\n",
    "print(f\"\\nAnalyzing {len(all_traces)} traces for failures...\\n\")\n",
    "\n",
    "all_findings = []\n",
    "for trace in all_traces:\n",
    "    findings = analyze_trace_for_failures(trace)\n",
    "    all_findings.extend(findings)\n",
    "\n",
    "print(f\"Found {len(all_findings)} potential failures:\\n\")\n",
    "\n",
    "for i, finding in enumerate(all_findings, 1):\n",
    "    print(f\"{i}. {finding['service']} / {finding['operation']}\")\n",
    "    print(f\"   Duration: {finding['duration_ms']:.0f}ms\")\n",
    "    if finding[\"exceptions\"]:\n",
    "        exc = finding[\"exceptions\"][0]\n",
    "        print(f\"   Error: {exc.get('type', 'Unknown')}: {exc.get('message', 'No message')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ingesting Traces into Tinman\n",
    "\n",
    "Feed traces to Tinman for automated failure analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinman import create_tinman\n",
    "from tinman.config.modes import OperatingMode\n",
    "\n",
    "\n",
    "async def ingest_and_analyze():\n",
    "    # Create Tinman instance\n",
    "    tinman = await create_tinman(\n",
    "        mode=OperatingMode.LAB,\n",
    "        skip_db=True,\n",
    "    )\n",
    "\n",
    "    # Parse traces\n",
    "    traces = list(OTLPAdapter().parse(otlp_data))\n",
    "\n",
    "    # Feed traces to Tinman for analysis\n",
    "    for trace in traces:\n",
    "        # Add error spans as observations\n",
    "        for span in trace.error_spans:\n",
    "            observation = {\n",
    "                \"type\": \"trace_error\",\n",
    "                \"trace_id\": trace.trace_id,\n",
    "                \"span_name\": span.name,\n",
    "                \"service\": span.service_name,\n",
    "                \"error_type\": span.get_exceptions()[0].get(\"type\")\n",
    "                if span.has_exception()\n",
    "                else \"unknown\",\n",
    "                \"error_message\": span.status_message or \"\",\n",
    "                \"attributes\": span.attributes,\n",
    "            }\n",
    "\n",
    "            # Store in memory graph for analysis\n",
    "            if tinman.graph:\n",
    "                tinman.graph.add_observation(\n",
    "                    source=\"trace_ingestion\",\n",
    "                    observation_type=\"error_span\",\n",
    "                    data=observation,\n",
    "                )\n",
    "\n",
    "    print(f\"Ingested {len(traces)} traces\")\n",
    "    print(f\"\\nAsking Tinman to analyze...\")\n",
    "\n",
    "    # Ask Tinman to analyze the ingested data\n",
    "    response = await tinman.discuss(\n",
    "        \"I've just ingested trace data showing errors. \"\n",
    "        \"Can you analyze the patterns and suggest hypotheses for investigation?\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTinman's Analysis:\\n{response}\")\n",
    "\n",
    "    await tinman.close()\n",
    "\n",
    "\n",
    "await ingest_and_analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Set up continuous trace ingestion from your observability platform\n",
    "- Configure alert rules based on failure patterns\n",
    "- Create custom adapters for proprietary trace formats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
