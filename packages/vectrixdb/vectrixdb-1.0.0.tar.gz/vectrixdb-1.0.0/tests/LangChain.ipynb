{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VectrixDB LangChain Integration\n",
    "\n",
    "Using VectrixDB with LangChain for RAG applications.\n",
    "\n",
    "Note: This shows a simple custom integration pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, set up your OpenAI API key for LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:16.906395Z",
     "iopub.status.busy": "2026-02-01T09:35:16.905394Z",
     "iopub.status.idle": "2026-02-01T09:35:16.933395Z",
     "shell.execute_reply": "2026-02-01T09:35:16.933395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Warning: OPENAI_API_KEY not set. Create a .env file with your key.\")\n",
    "    print(\"Example: OPENAI_API_KEY=sk-...\")\n",
    "else:\n",
    "    print(\"OpenAI API key loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LangChain Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:16.976225Z",
     "iopub.status.busy": "2026-02-01T09:35:16.976225Z",
     "iopub.status.idle": "2026-02-01T09:35:18.900348Z",
     "shell.execute_reply": "2026-02-01T09:35:18.899842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ready with 4 documents.\n"
     ]
    }
   ],
   "source": [
    "from vectrixdb import Vectrix\n",
    "\n",
    "# Create VectrixDB instance\n",
    "db = Vectrix(\"langchain_test\", tier=\"hybrid\", language=\"en\")\n",
    "\n",
    "# Add documents\n",
    "db.add([\n",
    "    \"VectrixDB is a lightweight vector database.\",\n",
    "    \"It supports hybrid search with dense and sparse vectors.\",\n",
    "    \"LangChain integration enables RAG applications.\",\n",
    "    \"The database runs entirely locally without external services.\"\n",
    "])\n",
    "\n",
    "print(f\"Database ready with {len(db)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Retriever Pattern\n",
    "\n",
    "You can easily create a retriever function for use with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:18.904875Z",
     "iopub.status.busy": "2026-02-01T09:35:18.903877Z",
     "iopub.status.idle": "2026-02-01T09:35:19.188366Z",
     "shell.execute_reply": "2026-02-01T09:35:19.188366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents:\n",
      "  - It supports hybrid search with dense and sparse vectors.\n",
      "  - VectrixDB is a lightweight vector database.\n",
      "  - LangChain integration enables RAG applications.\n"
     ]
    }
   ],
   "source": [
    "# Create a simple retriever function\n",
    "def retrieve(query: str, k: int = 3):\n",
    "    \"\"\"Retrieve relevant documents from VectrixDB.\"\"\"\n",
    "    results = db.search(query, limit=k)\n",
    "    return [r.text for r in results]\n",
    "\n",
    "# Test retriever\n",
    "docs = retrieve(\"vector search\")\n",
    "print(\"Retrieved documents:\")\n",
    "for doc in docs:\n",
    "    print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:19.193006Z",
     "iopub.status.busy": "2026-02-01T09:35:19.192008Z",
     "iopub.status.idle": "2026-02-01T09:35:19.461364Z",
     "shell.execute_reply": "2026-02-01T09:35:19.460358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results with scores:\n",
      "  Score: 0.0180 | The database runs entirely locally without external services.\n",
      "  Score: 0.0177 | VectrixDB is a lightweight vector database.\n",
      "  Score: 0.0079 | It supports hybrid search with dense and sparse vectors.\n"
     ]
    }
   ],
   "source": [
    "# Get results with scores\n",
    "results = db.search(\"local database\", limit=3)\n",
    "\n",
    "print(\"Search results with scores:\")\n",
    "for r in results:\n",
    "    print(f\"  Score: {r.score:.4f} | {r.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Document Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:19.464367Z",
     "iopub.status.busy": "2026-02-01T09:35:19.464367Z",
     "iopub.status.idle": "2026-02-01T09:35:19.475185Z",
     "shell.execute_reply": "2026-02-01T09:35:19.474176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain not installed. Install with: pip install langchain\n"
     ]
    }
   ],
   "source": [
    "# Convert VectrixDB results to LangChain Document format\n",
    "try:\n",
    "    from langchain.schema import Document\n",
    "    \n",
    "    def search_as_documents(query: str, k: int = 3):\n",
    "        \"\"\"Search and return LangChain Documents.\"\"\"\n",
    "        results = db.search(query, limit=k)\n",
    "        return [\n",
    "            Document(\n",
    "                page_content=r.text,\n",
    "                metadata=r.metadata or {}\n",
    "            )\n",
    "            for r in results\n",
    "        ]\n",
    "    \n",
    "    # Test\n",
    "    lc_docs = search_as_documents(\"hybrid search\")\n",
    "    print(\"LangChain Documents:\")\n",
    "    for doc in lc_docs:\n",
    "        print(f\"  - {doc.page_content}\")\n",
    "except ImportError:\n",
    "    print(\"LangChain not installed. Install with: pip install langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Documents with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:19.479193Z",
     "iopub.status.busy": "2026-02-01T09:35:19.478196Z",
     "iopub.status.idle": "2026-02-01T09:35:19.993596Z",
     "shell.execute_reply": "2026-02-01T09:35:19.992587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents now: 6\n"
     ]
    }
   ],
   "source": [
    "# Add documents with metadata\n",
    "db.add(\n",
    "    texts=[\n",
    "        \"VectrixDB supports multiple search modes.\",\n",
    "        \"Reranking improves search quality.\"\n",
    "    ],\n",
    "    metadata=[\n",
    "        {\"source\": \"docs\", \"page\": 1},\n",
    "        {\"source\": \"docs\", \"page\": 2}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Total documents now: {len(db)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:19.996804Z",
     "iopub.status.busy": "2026-02-01T09:35:19.996804Z",
     "iopub.status.idle": "2026-02-01T09:35:20.274135Z",
     "shell.execute_reply": "2026-02-01T09:35:20.273627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered search results (source=docs):\n",
      "  - VectrixDB supports multiple search modes.\n",
      "    Metadata: {'source': 'docs', 'page': 1}\n",
      "  - Reranking improves search quality.\n",
      "    Metadata: {'source': 'docs', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "# Search with metadata filter\n",
    "results = db.search(\"search modes\", filter={\"source\": \"docs\"}, limit=3)\n",
    "\n",
    "print(\"Filtered search results (source=docs):\")\n",
    "for r in results:\n",
    "    print(f\"  - {r.text}\")\n",
    "    print(f\"    Metadata: {r.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-01T09:35:20.277144Z",
     "iopub.status.busy": "2026-02-01T09:35:20.277144Z",
     "iopub.status.idle": "2026-02-01T09:35:20.281622Z",
     "shell.execute_reply": "2026-02-01T09:35:20.281622Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "if os.path.exists(\"langchain_test\"):\n",
    "    shutil.rmtree(\"langchain_test\")\n",
    "    print(\"Deleted langchain_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
