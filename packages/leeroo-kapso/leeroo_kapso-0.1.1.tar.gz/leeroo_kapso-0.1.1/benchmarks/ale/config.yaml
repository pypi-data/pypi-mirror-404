# ALE-Bench Configuration
# Configuration for AtCoder Heuristic Contest algorithmic problems
#
# Coding agents are configured in: src/agents/coding_agents/agents.yaml
# Just specify the agent type here - defaults come from agents.yaml
#
# Available agents: aider, gemini, claude_code, openhands
# Use --list-agents to see details
#
# Available search strategies:
#   - benchmark_tree_search: Tree search with handler.run() for evaluation
#
# Knowledge search backends are pluggable via KnowledgeSearchFactory.
# Available: kg_llm_navigation (more can be added via @register_knowledge_search decorator)

# Default mode to use
default_mode: ALE_CONFIGS

# Available configuration modes
modes:
  # ===========================================
  # Production Modes
  # ===========================================
  # Production configuration for ALE-Bench
  ALE_CONFIGS:
    # Search strategy configuration
    search_strategy:
      type: "benchmark_tree_search"
      params:
        reasoning_effort: "high"
        code_debug_tries: 3
        node_expansion_limit: 3
        node_expansion_new_childs_count: 20
        idea_generation_steps: 1
        first_experiment_factor: 2
        experimentation_per_run: 15
        per_step_maximum_solution_count: 25
        exploration_budget_percent: 15
        idea_generation_model: "gemini/gemini-2.5-pro"
        idea_generation_ensemble_models:
          - "gemini/gemini-2.5-pro"
          - "gemini/gemini-2.5-pro"
          - "gemini/gemini-2.5-pro"

    # Coding agent configuration
    coding_agent:
      type: "aider"
      model: "gemini/gemini-2.5-pro"
      debug_model: "gemini/gemini-2.5-flash"
    
    # Knowledge search configuration
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: false
      params:
        search_top_k: 1
        navigation_steps: 3
        expansion_limit: 3
        search_node_type: "specialization"
    
    # ALE uses C++, no HuggingFace models needed
    fetch_huggingface_models: false
  
  # Production configuration for ALE-Bench and long competitions.
  ALE_CONFIGS_LONG:
    # Search strategy configuration
    search_strategy:
      type: "benchmark_tree_search"
      params:
        reasoning_effort: "high"
        code_debug_tries: 3
        node_expansion_limit: 3
        node_expansion_new_childs_count: 10
        idea_generation_steps: 1
        first_experiment_factor: 2
        experimentation_per_run: 7
        per_step_maximum_solution_count: 10
        exploration_budget_percent: 66
        idea_generation_model: "gemini/gemini-2.5-pro"
        idea_generation_ensemble_models:
          - "gemini/gemini-2.5-pro"
          - "gemini/gemini-2.5-pro"
          - "gemini/gemini-2.5-pro"

    # Coding agent configuration
    coding_agent:
      type: "aider"
      model: "gemini/gemini-2.5-pro"
      debug_model: "gemini/gemini-2.5-flash"
    
    # Knowledge search configuration
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: false
      params:
        search_top_k: 1
        navigation_steps: 3
        expansion_limit: 3
        search_node_type: "specialization"
    
    # ALE uses C++, no HuggingFace models needed
    fetch_huggingface_models: false

  # Heavy thinking - deeper reasoning per solution
  HEAVY_THINKING:
    search_strategy:
      type: "benchmark_tree_search"
      params:
        reasoning_effort: "high"
        code_debug_tries: 5
        node_expansion_limit: 2
        node_expansion_new_childs_count: 10
        idea_generation_steps: 1
        first_experiment_factor: 1
        experimentation_per_run: 1
        per_step_maximum_solution_count: 10
        exploration_budget_percent: 50
        idea_generation_model: "o3"
        idea_generation_ensemble_models:
          - "o3"
          - "o3"
          - "o3"
    
    coding_agent:
      type: "aider"
      model: "gpt-4.1-mini"
      debug_model: "gpt-4.1-mini"
    
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: true
      params:
        search_top_k: 1
        navigation_steps: 3
        expansion_limit: 3
        search_node_type: "specialization"
    
    fetch_huggingface_models: false

  # ===========================================
  # Testing Modes
  # ===========================================
  
  # Minimal configuration for quick testing
  MINIMAL:
    search_strategy:
      type: "benchmark_tree_search"
      params:
        reasoning_effort: "medium"
        code_debug_tries: 2
        node_expansion_limit: 2
        node_expansion_new_childs_count: 3
        idea_generation_steps: 1
        first_experiment_factor: 1
        experimentation_per_run: 1
        per_step_maximum_solution_count: 3
        exploration_budget_percent: 50
        idea_generation_model: "gpt-4o-mini"
        idea_generation_ensemble_models:
          - "gpt-4o-mini"
    
    coding_agent:
      type: "aider"
      model: "gpt-4o-mini"
      debug_model: "gpt-4o-mini"
    
    knowledge_search:
      type: "kg_llm_navigation"
      enabled: false
    
    fetch_huggingface_models: false
