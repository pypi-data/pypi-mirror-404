"""
Policy Agent for MCP Architecture

Enhanced compliance and security standards checking for smart contracts.

ARCHITECTURAL NOTE - LAYER 6 + LAYER 7 INTEGRATION:
====================================================
This agent implements both Layer 6 (Policy/Compliance) and Layer 7 (Audit Readiness)
of MIESC's defense-in-depth architecture as an integrated component.

Design Rationale:
- Audit readiness assessment requires access to all compliance data
- Trail of Bits checklist scoring reuses Layer 6 vulnerability classification
- Tight coupling enables efficient cross-standard correlation
- Single audit trail for all compliance and audit evidence (MCP Context Bus)

Layer Separation:
- Layer 6 (Policy/Compliance): Lines 201-1299
  * ISO 27001, NIST SSDF, OWASP SC Top 10, SCSVS, CCSS
  * SWC Registry, DASP Top 10, ConsenSys Best Practices
  * EU MiCA, DORA, DeFi Risk Assessment

- Layer 7 (Audit Readiness): Lines 850-954, 1391-1402, 1545-1563
  * Trail of Bits Audit Checklist (_audit_checklist_score)
  * Audit readiness assessment (_assess_audit_readiness)
  * Audit report generation (audit_assessment section)

Supported Standards:
- ISO/IEC 27001:2022 (Information Security) [Layer 6]
- NIST SSDF (Secure Software Development Framework) [Layer 6]
- OWASP SC Top 10 (Smart Contract Top 10) [Layer 6]
- OWASP SCSVS (Smart Contract Security Verification Standard) [Layer 6]
- CCSS v9.0 (CryptoCurrency Security Standard) [Layer 6]
- SWC Registry (Smart Contract Weakness Classification) [Layer 6]
- DASP Top 10 (Decentralized Application Security Project) [Layer 6]
- EEA DeFi Risk Assessment Guidelines [Layer 6]
- EU MiCA (Markets in Crypto-Assets Regulation) [Layer 6]
- DORA (Digital Operational Resilience Act) [Layer 6]
- Trail of Bits Audit Checklist [Layer 7 - Audit Readiness]
- ConsenSys Best Practices [Layer 6]

Publishes compliance reports and standards mapping to Context Bus.
"""
import logging
from typing import Dict, Any, List
from datetime import datetime
from src.agents.base_agent import BaseAgent
from src.mcp.context_bus import MCPMessage

# Layer 7 - Audit Readiness Analyzers (OpenZeppelin Guide)
from src.agents.audit_readiness import (
    DocumentationAnalyzer,
    TestingAnalyzer,
    MaturityAnalyzer,
    SecurityPracticesAnalyzer
)

logger = logging.getLogger(__name__)


class PolicyAgent(BaseAgent):
    """
    Agent for compliance and policy checking

    Capabilities:
    - ISO/IEC 27001:2022 control mapping
    - NIST SSDF practice validation
    - OWASP SC Top 10 coverage checking
    - Compliance report generation

    Subscribes to:
    - All findings from other agents

    Published Context Types:
    - "compliance_report": Complete compliance assessment [Layer 6 + Layer 7]
    - "iso27001_status": ISO 27001 controls status [Layer 6]
    - "nist_ssdf_status": NIST SSDF practices status [Layer 6]
    - "owasp_coverage": OWASP SC Top 10 coverage [Layer 6]
    - "swc_classification": SWC Registry classification [Layer 6]
    - "dasp_coverage": DASP Top 10 coverage [Layer 6]
    - "scsvs_status": OWASP SCSVS verification level [Layer 6]
    - "ccss_status": CCSS v9.0 compliance [Layer 6]
    - "defi_risk_assessment": EEA DeFi risk analysis [Layer 6]
    - "mica_compliance": EU MiCA regulation status [Layer 6]
    - "dora_resilience": DORA operational resilience [Layer 6]
    - "audit_checklist": Trail of Bits checklist score [Layer 7 - Audit Readiness]
    """

    def __init__(self):
        super().__init__(
            agent_name="PolicyAgent",
            capabilities=[
                "compliance_checking",
                "standards_mapping",
                "coverage_analysis",
                "report_generation"
            ],
            agent_type="policy"
        )

        # Subscribe to all findings
        self.subscribe_to(
            context_types=[
                "static_findings",
                "dynamic_findings",
                "symbolic_findings",
                "formal_findings",
                "ai_triage"
            ],
            callback=self._handle_findings
        )

        # Initialize Layer 7 - Audit Readiness Analyzers
        logger.info("Initializing Layer 7 (Audit Readiness) analyzers")
        try:
            self.documentation_analyzer = DocumentationAnalyzer()
            self.testing_analyzer = TestingAnalyzer()
            self.maturity_analyzer = MaturityAnalyzer()
            self.security_practices_analyzer = SecurityPracticesAnalyzer()
            logger.info("Layer 7 analyzers initialized successfully")
        except Exception as e:
            logger.warning(f"Layer 7 analyzers initialization failed: {e}")
            # Set to None so we can gracefully handle missing analyzers
            self.documentation_analyzer = None
            self.testing_analyzer = None
            self.maturity_analyzer = None
            self.security_practices_analyzer = None

    def get_context_types(self) -> List[str]:
        return [
            "compliance_report",
            "iso27001_status",
            "nist_ssdf_status",
            "owasp_coverage",
            "swc_classification",
            "dasp_coverage",
            "scsvs_status",
            "ccss_status",
            "defi_risk_assessment",
            "mica_compliance",
            "dora_resilience",
            "audit_checklist"
        ]

    def analyze(self, contract_path: str, **kwargs) -> Dict[str, Any]:
        """
        Perform comprehensive compliance analysis on aggregated findings

        Args:
            contract_path: Path to Solidity contract
            **kwargs: Optional parameters

        Returns:
            Dictionary with compliance results across all standards
        """
        results = {
            "compliance_report": {},
            "iso27001_status": {},
            "nist_ssdf_status": {},
            "owasp_coverage": {},
            "swc_classification": {},
            "dasp_coverage": {},
            "scsvs_status": {},
            "ccss_status": {},
            "defi_risk_assessment": {},
            "mica_compliance": {},
            "dora_resilience": {},
            "audit_checklist": {}
        }

        # Aggregate all findings from Context Bus
        all_findings = self._aggregate_all_findings()

        # Phase 1: Quick Wins - Classification and mapping
        logger.info("PolicyAgent: Phase 1 - Classification mapping")
        results["swc_classification"] = self._map_to_swc_registry(all_findings)
        results["dasp_coverage"] = self._check_dasp_top10(all_findings)
        results["audit_checklist"] = self._check_consensys_practices(all_findings)

        # Existing checks
        logger.info("PolicyAgent: Checking ISO/IEC 27001:2022 compliance")
        results["iso27001_status"] = self._check_iso27001(all_findings)

        logger.info("PolicyAgent: Checking NIST SSDF compliance")
        results["nist_ssdf_status"] = self._check_nist_ssdf(all_findings)

        logger.info("PolicyAgent: Checking OWASP SC Top 10 coverage")
        results["owasp_coverage"] = self._check_owasp_coverage(all_findings)

        # Phase 2: High Priority Standards
        logger.info("PolicyAgent: Phase 2 - High priority standards")
        results["scsvs_status"] = self._check_scsvs_compliance(all_findings)
        results["ccss_status"] = self._check_ccss_compliance(all_findings)
        results["audit_checklist"].update(self._audit_checklist_score(all_findings))

        # Phase 3: Regulatory Compliance
        logger.info("PolicyAgent: Phase 3 - Regulatory compliance")
        results["defi_risk_assessment"] = self._assess_defi_risks(all_findings)
        results["mica_compliance"] = self._check_mica_compliance(all_findings)
        results["dora_resilience"] = self._check_dora_resilience(all_findings)

        # Layer 7: Audit Readiness Assessment (OpenZeppelin Guide)
        logger.info("PolicyAgent: Layer 7 - Comprehensive audit readiness assessment")
        try:
            # Get project root from contract path
            from pathlib import Path
            project_root = str(Path(contract_path).parent)

            # Run comprehensive assessment if analyzers are available
            if self.documentation_analyzer and self.testing_analyzer and \
               self.maturity_analyzer and self.security_practices_analyzer:
                results["audit_readiness"] = self._comprehensive_audit_readiness_assessment(
                    all_findings,
                    contract_path,
                    project_root
                )
                logger.info(f"Audit readiness: {results['audit_readiness'].get('readiness_status', 'unknown')}")
                logger.info(f"OpenZeppelin compliance: {results['audit_readiness'].get('openzeppelin_compliance', 0):.1f}%")
            else:
                logger.warning("Audit readiness analyzers not available - skipping Layer 7 assessment")
                results["audit_readiness"] = {
                    "status": "unavailable",
                    "message": "Layer 7 analyzers not initialized"
                }
        except Exception as e:
            logger.error(f"Error in audit readiness assessment: {e}")
            results["audit_readiness"] = {
                "status": "error",
                "message": str(e)
            }

        # Generate comprehensive compliance report
        results["compliance_report"] = self._generate_compliance_report(
            contract_path,
            all_findings,
            results
        )

        return results

    def _handle_findings(self, message: MCPMessage) -> None:
        """
        Callback to handle incoming findings for compliance tracking

        Args:
            message: MCP message with findings
        """
        logger.info(f"PolicyAgent: Tracking {message.context_type} from {message.agent}")

    def _aggregate_all_findings(self) -> List[Dict[str, Any]]:
        """
        Aggregate all findings from Context Bus

        Returns:
            List of all findings
        """
        context_types = [
            "static_findings",
            "dynamic_findings",
            "symbolic_findings",
            "formal_findings",
            "ai_triage"
        ]

        aggregated_contexts = self.aggregate_contexts(context_types)
        all_findings = []

        for context_type, messages in aggregated_contexts.items():
            for message in messages:
                if isinstance(message.data, list):
                    all_findings.extend(message.data)
                elif isinstance(message.data, dict) and "findings" in message.data:
                    all_findings.extend(message.data["findings"])

        return all_findings

    def _check_iso27001(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check compliance with ISO/IEC 27001:2022 controls

        Returns:
            Dictionary with control status
        """
        controls = {
            "A.8.8": {
                "name": "Management of technical vulnerabilities",
                "status": "implemented",
                "evidence": f"{len(findings)} vulnerabilities detected and tracked",
                "compliant": True
            },
            "A.8.15": {
                "name": "Logging",
                "status": "implemented",
                "evidence": "Complete audit trail via MCP Context Bus",
                "compliant": True
            },
            "A.8.16": {
                "name": "Monitoring activities",
                "status": "implemented",
                "evidence": "Real-time monitoring via CoordinatorAgent",
                "compliant": True
            },
            "A.8.30": {
                "name": "Testing",
                "status": "implemented",
                "evidence": "Multi-layer testing (static, dynamic, formal)",
                "compliant": True
            },
            "A.14.2.5": {
                "name": "Secure system engineering principles",
                "status": "implemented",
                "evidence": "Defense-in-Depth architecture",
                "compliant": True
            }
        }

        # Check if critical vulnerabilities exist
        critical_vulns = [f for f in findings if f.get("severity") == "Critical"]
        if critical_vulns:
            controls["A.8.8"]["evidence"] += f" ({len(critical_vulns)} critical)"

        compliance_score = sum(1 for c in controls.values() if c["compliant"]) / len(controls)

        return {
            "controls": controls,
            "total_controls": len(controls),
            "compliant_controls": sum(1 for c in controls.values() if c["compliant"]),
            "compliance_score": compliance_score,
            "overall_status": "compliant" if compliance_score >= 0.8 else "partial"
        }

    def _check_nist_ssdf(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check compliance with NIST SP 800-218 practices

        Returns:
            Dictionary with practice status
        """
        practices = {
            "PO.3.1": {
                "name": "Ensure acquisition of genuine software",
                "status": "implemented",
                "evidence": "Tool verification via checksums",
                "compliant": True
            },
            "PS.2": {
                "name": "Review the software design",
                "status": "implemented",
                "evidence": "Architecture analysis via Surya and formal verification",
                "compliant": True
            },
            "PW.8": {
                "name": "Review and/or analyze developed code",
                "status": "implemented",
                "evidence": f"Multi-tool analysis: {len(findings)} findings",
                "compliant": True
            },
            "RV.1.1": {
                "name": "Identify publicly disclosed vulnerabilities",
                "status": "implemented",
                "evidence": "SWC/CWE mapping for all findings",
                "compliant": True
            },
            "RV.3": {
                "name": "Analyze vulnerabilities to determine root causes",
                "status": "implemented",
                "evidence": "AI-powered root cause analysis",
                "compliant": True
            }
        }

        compliance_score = sum(1 for p in practices.values() if p["compliant"]) / len(practices)

        return {
            "practices": practices,
            "total_practices": len(practices),
            "compliant_practices": sum(1 for p in practices.values() if p["compliant"]),
            "compliance_score": compliance_score,
            "overall_status": "compliant" if compliance_score >= 0.8 else "partial"
        }

    def _check_owasp_coverage(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check OWASP Smart Contract Top 10 coverage

        Returns:
            Dictionary with category coverage
        """
        categories = {
            "SC01-Reentrancy": {"detected": 0, "tools": set()},
            "SC02-Access-Control": {"detected": 0, "tools": set()},
            "SC03-Arithmetic": {"detected": 0, "tools": set()},
            "SC04-Unchecked-Calls": {"detected": 0, "tools": set()},
            "SC05-DoS": {"detected": 0, "tools": set()},
            "SC06-Bad-Randomness": {"detected": 0, "tools": set()},
            "SC07-Front-Running": {"detected": 0, "tools": set()},
            "SC08-Time-Manipulation": {"detected": 0, "tools": set()},
            "SC09-Short-Address": {"detected": 0, "tools": set()},
            "SC10-Unknown-Unknowns": {"detected": 0, "tools": set()}
        }

        # Count findings by OWASP category
        for finding in findings:
            owasp_cat = finding.get("owasp_category")
            if owasp_cat and owasp_cat in categories:
                categories[owasp_cat]["detected"] += 1
                source = finding.get("source", "unknown")
                categories[owasp_cat]["tools"].add(source)

        # Convert sets to lists for JSON serialization
        for cat in categories.values():
            cat["tools"] = list(cat["tools"])

        coverage_score = sum(1 for c in categories.values() if c["detected"] > 0) / len(categories)

        return {
            "categories": categories,
            "total_categories": len(categories),
            "covered_categories": sum(1 for c in categories.values() if c["detected"] > 0),
            "coverage_score": coverage_score,
            "overall_status": "high" if coverage_score >= 0.7 else "medium"
        }

    # ========================================
    # PHASE 1: Quick Wins - Classification & Mapping
    # ========================================

    def _map_to_swc_registry(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Map findings to SWC (Smart Contract Weakness Classification) Registry

        Returns:
            Dictionary with SWC classification statistics
        """
        # SWC Registry mapping (37 weakness types)
        swc_mapping = {
            "reentrancy": "SWC-107",
            "access_control": "SWC-105",
            "arithmetic": "SWC-101",
            "unchecked_call": "SWC-104",
            "delegatecall": "SWC-112",
            "tx_origin": "SWC-115",
            "timestamp_dependence": "SWC-116",
            "weak_randomness": "SWC-120",
            "denial_of_service": "SWC-128",
            "uninitialized_storage": "SWC-109",
            "floating_pragma": "SWC-103",
            "outdated_compiler": "SWC-102",
            "use_of_deprecated": "SWC-111",
            "shadowing": "SWC-119",
            "state_variable_shadowing": "SWC-119",
            "incorrect_constructor": "SWC-118",
            "unprotected_selfdestruct": "SWC-106",
            "assert_violation": "SWC-110",
            "requirement_violation": "SWC-123",
            "write_after_write": "SWC-124",
            "hash_collision": "SWC-133",
            "signature_malleability": "SWC-117",
            "unencrypted_secrets": "SWC-136"
        }

        classified = {}
        unclassified = []

        for finding in findings:
            # Try to map based on finding type, check, or description
            finding_type = finding.get("check", "").lower()
            description = finding.get("description", "").lower()

            swc_id = None
            for keyword, swc in swc_mapping.items():
                if keyword in finding_type or keyword in description:
                    swc_id = swc
                    break

            if swc_id:
                if swc_id not in classified:
                    classified[swc_id] = {
                        "count": 0,
                        "severity_distribution": {},
                        "findings": []
                    }
                classified[swc_id]["count"] += 1
                severity = finding.get("severity", "Unknown")
                classified[swc_id]["severity_distribution"][severity] = \
                    classified[swc_id]["severity_distribution"].get(severity, 0) + 1
                classified[swc_id]["findings"].append({
                    "source": finding.get("source", "unknown"),
                    "severity": severity,
                    "description": finding.get("description", "")[:100]
                })
            else:
                unclassified.append(finding)

        return {
            "classified_weaknesses": classified,
            "total_swc_types": len(classified),
            "total_classified": sum(data["count"] for data in classified.values()),
            "unclassified_count": len(unclassified),
            "coverage_score": len(classified) / 37.0,  # 37 SWC types
            "most_common": sorted(
                classified.items(),
                key=lambda x: x[1]["count"],
                reverse=True
            )[:5] if classified else []
        }

    def _check_dasp_top10(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check coverage of DASP (Decentralized Application Security Project) Top 10

        Returns:
            Dictionary with DASP coverage analysis
        """
        dasp_categories = {
            "DASP-01-Reentrancy": {
                "name": "Reentrancy",
                "keywords": ["reentrancy", "reentrant", "callback"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-02-Access-Control": {
                "name": "Access Control",
                "keywords": ["access control", "unauthorized", "permission", "onlyowner"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-03-Arithmetic": {
                "name": "Arithmetic Issues",
                "keywords": ["overflow", "underflow", "arithmetic", "integer"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-04-Unchecked-Calls": {
                "name": "Unchecked Return Values",
                "keywords": ["unchecked", "call", "return value", "low-level"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-05-DoS": {
                "name": "Denial of Service",
                "keywords": ["dos", "denial of service", "gas limit", "loop"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-06-Bad-Randomness": {
                "name": "Bad Randomness",
                "keywords": ["random", "blockhash", "timestamp", "predictable"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-07-Front-Running": {
                "name": "Front-Running",
                "keywords": ["front-run", "frontrun", "transaction ordering", "mev"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-08-Time-Manipulation": {
                "name": "Time Manipulation",
                "keywords": ["timestamp", "block.timestamp", "now", "time"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-09-Short-Address": {
                "name": "Short Address Attack",
                "keywords": ["short address", "address length"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            },
            "DASP-10-Unknown-Unknowns": {
                "name": "Unknown Unknowns",
                "keywords": ["logic", "business logic", "design flaw"],
                "detected": 0,
                "tools": set(),
                "severity_max": "Low"
            }
        }

        severity_rank = {"Critical": 4, "High": 3, "Medium": 2, "Low": 1, "Info": 0}

        for finding in findings:
            description = finding.get("description", "").lower()
            check = finding.get("check", "").lower()
            combined = description + " " + check
            severity = finding.get("severity", "Low")

            for dasp_id, category in dasp_categories.items():
                if any(keyword in combined for keyword in category["keywords"]):
                    category["detected"] += 1
                    category["tools"].add(finding.get("source", "unknown"))

                    # Track maximum severity
                    current_max = severity_rank.get(category["severity_max"], 0)
                    new_severity = severity_rank.get(severity, 0)
                    if new_severity > current_max:
                        category["severity_max"] = severity

        # Convert sets to lists for JSON serialization
        for category in dasp_categories.values():
            category["tools"] = list(category["tools"])

        coverage_score = sum(1 for c in dasp_categories.values() if c["detected"] > 0) / len(dasp_categories)

        return {
            "categories": dasp_categories,
            "total_categories": len(dasp_categories),
            "covered_categories": sum(1 for c in dasp_categories.values() if c["detected"] > 0),
            "coverage_score": coverage_score,
            "overall_status": "excellent" if coverage_score >= 0.8 else "good" if coverage_score >= 0.5 else "needs_improvement",
            "critical_areas": [
                dasp_id for dasp_id, cat in dasp_categories.items()
                if cat["detected"] > 0 and cat["severity_max"] in ["Critical", "High"]
            ]
        }

    def _check_consensys_practices(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check against ConsenSys Smart Contract Best Practices

        Returns:
            Dictionary with best practices compliance
        """
        practices = {
            "security_tools": {
                "name": "Use security analysis tools",
                "status": "implemented",
                "evidence": "Multi-layer analysis framework active",
                "compliant": True
            },
            "external_calls": {
                "name": "Handle external call failures",
                "status": "checking",
                "evidence": "",
                "compliant": False
            },
            "gas_limits": {
                "name": "Be aware of gas limits",
                "status": "checking",
                "evidence": "",
                "compliant": False
            },
            "integer_overflow": {
                "name": "Protect against overflow/underflow",
                "status": "checking",
                "evidence": "",
                "compliant": False
            },
            "reentrancy": {
                "name": "Prevent reentrancy attacks",
                "status": "checking",
                "evidence": "",
                "compliant": False
            },
            "access_control": {
                "name": "Implement proper access controls",
                "status": "checking",
                "evidence": "",
                "compliant": False
            }
        }

        # Check findings for evidence of best practices
        for finding in findings:
            desc_lower = finding.get("description", "").lower()
            check_lower = finding.get("check", "").lower()

            if "unchecked" in desc_lower or "call" in desc_lower:
                practices["external_calls"]["evidence"] = "External call issues detected"
                practices["external_calls"]["compliant"] = False

            if "gas" in desc_lower or "loop" in desc_lower:
                practices["gas_limits"]["evidence"] = "Gas-related issues detected"
                practices["gas_limits"]["compliant"] = False

            if "overflow" in desc_lower or "underflow" in desc_lower:
                practices["integer_overflow"]["evidence"] = "Arithmetic issues detected"
                practices["integer_overflow"]["compliant"] = False

            if "reentrancy" in desc_lower or "reentrant" in desc_lower:
                practices["reentrancy"]["evidence"] = "Reentrancy risks detected"
                practices["reentrancy"]["compliant"] = False

            if "access" in desc_lower or "unauthorized" in check_lower:
                practices["access_control"]["evidence"] = "Access control issues detected"
                practices["access_control"]["compliant"] = False

        # If no issues found, mark as compliant
        for key, practice in practices.items():
            if key != "security_tools" and practice["evidence"] == "":
                practice["evidence"] = "No issues detected"
                practice["compliant"] = True
                practice["status"] = "implemented"

        compliance_score = sum(1 for p in practices.values() if p["compliant"]) / len(practices)

        return {
            "practices": practices,
            "total_practices": len(practices),
            "compliant_practices": sum(1 for p in practices.values() if p["compliant"]),
            "compliance_score": compliance_score,
            "overall_status": "compliant" if compliance_score >= 0.8 else "partial"
        }

    # ========================================
    # PHASE 2: High Priority Standards
    # ========================================

    def _check_scsvs_compliance(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check OWASP Smart Contract Security Verification Standard (SCSVS) compliance

        SCSVS defines 3 verification levels:
        - Level 1: Basic (automated tools)
        - Level 2: Standard (manual review + tools)
        - Level 3: Advanced (formal verification)

        Returns:
            Dictionary with SCSVS level assessment
        """
        level_checks = {
            "L1": {
                "name": "Level 1 - Basic Security",
                "requirements": [
                    "Static analysis performed",
                    "Common vulnerabilities checked",
                    "Compiler warnings addressed"
                ],
                "met": 0,
                "total": 3
            },
            "L2": {
                "name": "Level 2 - Standard Security",
                "requirements": [
                    "Dynamic analysis performed",
                    "Business logic reviewed",
                    "Access controls verified",
                    "Gas optimization checked"
                ],
                "met": 0,
                "total": 4
            },
            "L3": {
                "name": "Level 3 - Advanced Security",
                "requirements": [
                    "Formal verification performed",
                    "Symbolic execution completed",
                    "All invariants proven",
                    "Security properties verified"
                ],
                "met": 0,
                "total": 4
            }
        }

        # Check L1 requirements
        has_static = any(f.get("layer") == "static" for f in findings)
        has_common_checks = len(findings) > 0
        level_checks["L1"]["met"] = sum([has_static, has_common_checks, True])  # Assume compiler warnings checked

        # Check L2 requirements
        has_dynamic = any(f.get("layer") == "dynamic" for f in findings)
        has_access_checks = any("access" in str(f.get("check", "")).lower() for f in findings)
        level_checks["L2"]["met"] = sum([has_dynamic, has_access_checks, True, True])

        # Check L3 requirements
        has_formal = any(f.get("layer") == "formal" for f in findings)
        has_symbolic = any(f.get("layer") == "symbolic" for f in findings)
        level_checks["L3"]["met"] = sum([has_formal, has_symbolic, has_formal, has_formal])

        # Determine achieved level
        achieved_level = "None"
        if level_checks["L1"]["met"] == level_checks["L1"]["total"]:
            achieved_level = "L1"
        if level_checks["L2"]["met"] == level_checks["L2"]["total"]:
            achieved_level = "L2"
        if level_checks["L3"]["met"] == level_checks["L3"]["total"]:
            achieved_level = "L3"

        return {
            "achieved_level": achieved_level,
            "level_checks": level_checks,
            "l1_score": level_checks["L1"]["met"] / level_checks["L1"]["total"],
            "l2_score": level_checks["L2"]["met"] / level_checks["L2"]["total"],
            "l3_score": level_checks["L3"]["met"] / level_checks["L3"]["total"],
            "recommendation": self._scsvs_recommendation(achieved_level)
        }

    def _scsvs_recommendation(self, achieved_level: str) -> str:
        """Generate SCSVS recommendation based on achieved level"""
        recommendations = {
            "None": "Start with Level 1 verification using automated static analysis tools",
            "L1": "Advance to Level 2 by adding manual code review and dynamic analysis",
            "L2": "Achieve Level 3 by implementing formal verification and symbolic execution",
            "L3": "Maintain Level 3 compliance through continuous verification"
        }
        return recommendations.get(achieved_level, "Unknown level")

    def _check_ccss_compliance(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Check CryptoCurrency Security Standard (CCSS) v9.0 compliance

        CCSS focuses on:
        1. Key/Wallet Security
        2. Operational Security
        3. Data Security

        Returns:
            Dictionary with CCSS compliance status
        """
        ccss_aspects = {
            "key_generation": {
                "name": "Cryptographic Key Generation",
                "status": "not_applicable",
                "evidence": "Contract-level analysis (not wallet level)",
                "compliant": True
            },
            "key_usage": {
                "name": "Key Usage and Storage",
                "status": "checking",
                "evidence": "",
                "compliant": False
            },
            "wallet_security": {
                "name": "Wallet Creation and Backup",
                "status": "not_applicable",
                "evidence": "Contract-level analysis (not wallet level)",
                "compliant": True
            },
            "private_key_exposure": {
                "name": "Private Key Non-Exposure",
                "status": "checking",
                "evidence": "",
                "compliant": True
            },
            "signature_verification": {
                "name": "Transaction Signature Verification",
                "status": "checking",
                "evidence": "",
                "compliant": True
            },
            "secure_comms": {
                "name": "Secure Communication",
                "status": "not_applicable",
                "evidence": "On-chain contracts (no direct comms)",
                "compliant": True
            },
            "audit_logging": {
                "name": "Audit and Logging",
                "status": "implemented",
                "evidence": "Events and state changes logged on-chain",
                "compliant": True
            },
            "access_controls": {
                "name": "Access Controls",
                "status": "checking",
                "evidence": "",
                "compliant": False
            },
            "operator_security": {
                "name": "Operator Security Training",
                "status": "not_applicable",
                "evidence": "Organizational requirement (not code)",
                "compliant": True
            },
            "governance": {
                "name": "Governance and Risk Management",
                "status": "checking",
                "evidence": "",
                "compliant": False
            }
        }

        # Analyze findings for CCSS-related issues
        for finding in findings:
            desc = finding.get("description", "").lower()
            check = finding.get("check", "").lower()

            # Private key exposure
            if "private" in desc or "secret" in desc or "key" in desc:
                ccss_aspects["private_key_exposure"]["evidence"] = "Potential key exposure detected"
                ccss_aspects["private_key_exposure"]["compliant"] = False

            # Signature issues
            if "signature" in desc or "ecrecover" in check:
                ccss_aspects["signature_verification"]["evidence"] = "Signature handling detected"
                ccss_aspects["signature_verification"]["compliant"] = True

            # Access control
            if "access" in desc or "authorization" in check:
                ccss_aspects["access_controls"]["evidence"] = "Access control mechanisms found"
                ccss_aspects["access_controls"]["compliant"] = True

            # Governance
            if "admin" in desc or "owner" in desc or "governance" in check:
                ccss_aspects["governance"]["evidence"] = "Governance mechanisms detected"
                ccss_aspects["governance"]["compliant"] = True

        # Set defaults for unchecked items
        for aspect in ccss_aspects.values():
            if aspect["status"] == "checking" and aspect["evidence"] == "":
                aspect["evidence"] = "No issues detected"
                aspect["compliant"] = True

        applicable_aspects = {k: v for k, v in ccss_aspects.items()
                             if v["status"] != "not_applicable"}
        compliance_score = sum(1 for a in applicable_aspects.values() if a["compliant"]) / len(applicable_aspects) if applicable_aspects else 1.0

        return {
            "aspects": ccss_aspects,
            "total_aspects": len(ccss_aspects),
            "applicable_aspects": len(applicable_aspects),
            "compliant_aspects": sum(1 for a in applicable_aspects.values() if a["compliant"]),
            "compliance_score": compliance_score,
            "overall_status": "compliant" if compliance_score >= 0.8 else "partial"
        }

    # ========================================
    # LAYER 7: AUDIT READINESS
    # ========================================
    # The following methods implement Layer 7 (Audit Readiness) functionality
    # integrated within PolicyAgent for efficiency and data reuse.
    #
    # Design Decision: Layer 7 is intentionally NOT separated into a standalone
    # AuditAgent because:
    # 1. Audit checklist scoring requires access to all compliance data from Layer 6
    # 2. Trail of Bits checklist reuses vulnerability classifications from Layer 6
    # 3. Prevents duplication of compliance evidence and audit trail
    # 4. Maintains single source of truth for all regulatory reporting
    #
    # Layer 7 Methods:
    # - _audit_checklist_score() [lines 850-954]: Trail of Bits checklist
    # - _assess_audit_readiness() [lines 1545-1563]: Final audit readiness
    # - audit_assessment section in _generate_compliance_report() [lines 1391-1402]
    # ========================================

    def _audit_checklist_score(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        [LAYER 7 - AUDIT READINESS]
        Trail of Bits Audit Checklist scoring

        Maps detected vulnerabilities to Trail of Bits audit checklist items
        to assess audit readiness and completeness.

        Returns:
            Dictionary with checklist completion status
        """
        checklist_categories = {
            "access_control": {
                "name": "Access Control and Authorization",
                "items_checked": 0,
                "items_total": 8,
                "findings": []
            },
            "arithmetic": {
                "name": "Arithmetic and Numeric Issues",
                "items_checked": 0,
                "items_total": 6,
                "findings": []
            },
            "reentrancy": {
                "name": "Reentrancy Vulnerabilities",
                "items_checked": 0,
                "items_total": 4,
                "findings": []
            },
            "gas_optimization": {
                "name": "Gas Usage and Optimization",
                "items_checked": 0,
                "items_total": 5,
                "findings": []
            },
            "code_quality": {
                "name": "Code Quality and Maintainability",
                "items_checked": 0,
                "items_total": 7,
                "findings": []
            },
            "external_calls": {
                "name": "External Calls and Interfaces",
                "items_checked": 0,
                "items_total": 5,
                "findings": []
            },
            "cryptography": {
                "name": "Cryptographic Operations",
                "items_checked": 0,
                "items_total": 4,
                "findings": []
            },
            "upgradability": {
                "name": "Upgradability and Governance",
                "items_checked": 0,
                "items_total": 3,
                "findings": []
            }
        }

        # Map findings to checklist items
        for finding in findings:
            desc = finding.get("description", "").lower()
            check = finding.get("check", "").lower()

            if "access" in desc or "authorization" in check or "permission" in desc:
                checklist_categories["access_control"]["items_checked"] += 1
                checklist_categories["access_control"]["findings"].append(finding.get("check", "unknown"))

            if "overflow" in desc or "underflow" in desc or "arithmetic" in check:
                checklist_categories["arithmetic"]["items_checked"] += 1
                checklist_categories["arithmetic"]["findings"].append(finding.get("check", "unknown"))

            if "reentrancy" in desc or "reentrant" in check:
                checklist_categories["reentrancy"]["items_checked"] += 1
                checklist_categories["reentrancy"]["findings"].append(finding.get("check", "unknown"))

            if "gas" in desc or "optimization" in check:
                checklist_categories["gas_optimization"]["items_checked"] += 1
                checklist_categories["gas_optimization"]["findings"].append(finding.get("check", "unknown"))

            if "external" in desc or "call" in check:
                checklist_categories["external_calls"]["items_checked"] += 1
                checklist_categories["external_calls"]["findings"].append(finding.get("check", "unknown"))

            if "crypto" in desc or "signature" in check or "hash" in check:
                checklist_categories["cryptography"]["items_checked"] += 1
                checklist_categories["cryptography"]["findings"].append(finding.get("check", "unknown"))

        # Limit items_checked to items_total
        for category in checklist_categories.values():
            category["items_checked"] = min(category["items_checked"], category["items_total"])
            category["findings"] = list(set(category["findings"]))[:5]  # Unique, max 5

        total_items = sum(c["items_total"] for c in checklist_categories.values())
        total_checked = sum(c["items_checked"] for c in checklist_categories.values())
        completion_score = total_checked / total_items if total_items > 0 else 0

        return {
            "checklist_categories": checklist_categories,
            "total_items": total_items,
            "items_checked": total_checked,
            "completion_score": completion_score,
            "audit_readiness": "ready" if completion_score >= 0.7 else "in_progress",
            "methodology": "Trail of Bits Smart Contract Audit Checklist"
        }

    # ========================================
    # PHASE 3: Regulatory Compliance
    # ========================================

    def _assess_defi_risks(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        EEA (Enterprise Ethereum Alliance) DeFi Risk Assessment

        Returns:
            Dictionary with DeFi-specific risk assessment
        """
        risk_categories = {
            "smart_contract_risk": {
                "name": "Smart Contract Technical Risk",
                "level": "low",
                "score": 0,
                "factors": []
            },
            "oracle_risk": {
                "name": "Oracle and Data Feed Risk",
                "level": "low",
                "score": 0,
                "factors": []
            },
            "economic_risk": {
                "name": "Economic and Game Theory Risk",
                "level": "low",
                "score": 0,
                "factors": []
            },
            "governance_risk": {
                "name": "Governance and Admin Risk",
                "level": "low",
                "score": 0,
                "factors": []
            },
            "liquidity_risk": {
                "name": "Liquidity and Market Risk",
                "level": "low",
                "score": 0,
                "factors": []
            },
            "composability_risk": {
                "name": "DeFi Composability Risk",
                "level": "low",
                "score": 0,
                "factors": []
            }
        }

        # Analyze findings for DeFi risks
        critical_count = len([f for f in findings if f.get("severity") == "Critical"])
        high_count = len([f for f in findings if f.get("severity") == "High"])

        for finding in findings:
            desc = finding.get("description", "").lower()
            severity = finding.get("severity", "Low")

            # Smart contract risk
            if severity in ["Critical", "High"]:
                risk_categories["smart_contract_risk"]["score"] += 10 if severity == "Critical" else 5
                risk_categories["smart_contract_risk"]["factors"].append(finding.get("check", "unknown"))

            # Oracle risk
            if "oracle" in desc or "price" in desc or "feed" in desc:
                risk_categories["oracle_risk"]["score"] += 15
                risk_categories["oracle_risk"]["factors"].append("Oracle dependency detected")

            # Economic risk
            if "token" in desc or "balance" in desc or "transfer" in desc:
                risk_categories["economic_risk"]["score"] += 5
                risk_categories["economic_risk"]["factors"].append("Token economic logic")

            # Governance risk
            if "admin" in desc or "owner" in desc or "governance" in desc:
                risk_categories["governance_risk"]["score"] += 10
                risk_categories["governance_risk"]["factors"].append("Centralized control detected")

            # Composability risk
            if "external" in desc or "delegatecall" in desc or "interface" in desc:
                risk_categories["composability_risk"]["score"] += 8
                risk_categories["composability_risk"]["factors"].append("External dependencies")

        # Assign risk levels based on scores
        for category in risk_categories.values():
            score = category["score"]
            if score >= 30:
                category["level"] = "critical"
            elif score >= 20:
                category["level"] = "high"
            elif score >= 10:
                category["level"] = "medium"
            else:
                category["level"] = "low"

            # Limit factors
            category["factors"] = list(set(category["factors"]))[:5]

        # Overall risk assessment
        max_risk_level = max((c["level"] for c in risk_categories.values()),
                            key=lambda x: {"low": 0, "medium": 1, "high": 2, "critical": 3}[x])

        return {
            "risk_categories": risk_categories,
            "overall_risk_level": max_risk_level,
            "critical_findings": critical_count,
            "high_findings": high_count,
            "recommendation": self._defi_risk_recommendation(max_risk_level),
            "framework": "EEA DeFi Risk Assessment Guidelines v1.0"
        }

    def _defi_risk_recommendation(self, risk_level: str) -> str:
        """Generate DeFi risk recommendation"""
        recommendations = {
            "low": "Risk profile acceptable for deployment with standard monitoring",
            "medium": "Address identified risks before mainnet deployment",
            "high": "Significant risks detected - comprehensive audit recommended",
            "critical": "Critical risks present - do not deploy until resolved"
        }
        return recommendations.get(risk_level, "Unknown risk level")

    def _check_mica_compliance(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        EU MiCA (Markets in Crypto-Assets) Regulation compliance check

        MiCA Requirements:
        - Technical standards for custody
        - Operational resilience
        - Risk management
        - Consumer protection

        Returns:
            Dictionary with MiCA compliance status
        """
        mica_requirements = {
            "custody_security": {
                "name": "Custody and Asset Security (Title III)",
                "status": "checking",
                "evidence": "",
                "compliant": False,
                "criticality": "high"
            },
            "operational_resilience": {
                "name": "Operational Resilience (Title IV)",
                "status": "checking",
                "evidence": "",
                "compliant": False,
                "criticality": "high"
            },
            "governance": {
                "name": "Governance Arrangements",
                "status": "checking",
                "evidence": "",
                "compliant": False,
                "criticality": "medium"
            },
            "risk_management": {
                "name": "Risk Management Framework",
                "status": "checking",
                "evidence": "",
                "compliant": False,
                "criticality": "high"
            },
            "consumer_protection": {
                "name": "Consumer Protection Measures",
                "status": "checking",
                "evidence": "",
                "compliant": False,
                "criticality": "medium"
            }
        }

        # Check findings for MiCA-related aspects
        critical_vulns = [f for f in findings if f.get("severity") == "Critical"]

        # Custody security
        if not critical_vulns:
            mica_requirements["custody_security"]["evidence"] = "No critical vulnerabilities affecting asset custody"
            mica_requirements["custody_security"]["compliant"] = True
        else:
            mica_requirements["custody_security"]["evidence"] = f"{len(critical_vulns)} critical vulnerabilities detected"
            mica_requirements["custody_security"]["compliant"] = False

        # Operational resilience (check for upgrade mechanisms, pause functionality)
        upgrade_patterns = ["upgradeable", "proxy", "pause", "emergency"]
        has_resilience = any(
            any(pattern in str(f.get("description", "")).lower() for pattern in upgrade_patterns)
            for f in findings
        )
        if has_resilience:
            mica_requirements["operational_resilience"]["evidence"] = "Resilience mechanisms detected"
            mica_requirements["operational_resilience"]["compliant"] = True
        else:
            mica_requirements["operational_resilience"]["evidence"] = "No emergency controls detected"
            mica_requirements["operational_resilience"]["compliant"] = False

        # Governance
        governance_patterns = ["admin", "owner", "multisig", "timelock"]
        has_governance = any(
            any(pattern in str(f.get("description", "")).lower() for pattern in governance_patterns)
            for f in findings
        )
        if has_governance:
            mica_requirements["governance"]["evidence"] = "Governance structures present"
            mica_requirements["governance"]["compliant"] = True

        # Risk management (presence of monitoring, access controls)
        if len(findings) > 0:
            mica_requirements["risk_management"]["evidence"] = "Active risk monitoring via multi-layer analysis"
            mica_requirements["risk_management"]["compliant"] = True

        # Set defaults
        for req in mica_requirements.values():
            if req["evidence"] == "":
                req["evidence"] = "Insufficient data for assessment"
                req["status"] = "needs_review"

        high_priority = {k: v for k, v in mica_requirements.items() if v["criticality"] == "high"}
        compliance_score = sum(1 for r in high_priority.values() if r["compliant"]) / len(high_priority) if high_priority else 0

        return {
            "requirements": mica_requirements,
            "total_requirements": len(mica_requirements),
            "compliant_requirements": sum(1 for r in mica_requirements.values() if r["compliant"]),
            "high_priority_compliance": compliance_score,
            "overall_status": "compliant" if compliance_score >= 0.8 else "non_compliant",
            "regulation": "EU MiCA (Regulation 2023/1114)",
            "effective_date": "December 30, 2024",
            "recommendation": "Consult legal counsel for full MiCA compliance assessment"
        }

    def _check_dora_resilience(self, findings: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        DORA (Digital Operational Resilience Act) compliance check

        DORA Requirements (EU Regulation 2022/2554):
        - ICT risk management
        - Incident reporting
        - Operational resilience testing
        - Third-party risk management
        - Information sharing

        Returns:
            Dictionary with DORA compliance status
        """
        dora_pillars = {
            "ict_risk_management": {
                "name": "ICT Risk Management (Chapter II)",
                "requirements": [
                    "Risk identification and assessment",
                    "Protection and prevention measures",
                    "Detection mechanisms",
                    "Response and recovery procedures"
                ],
                "compliant": 0,
                "total": 4,
                "evidence": []
            },
            "incident_reporting": {
                "name": "ICT Incident Reporting (Chapter III)",
                "requirements": [
                    "Incident classification",
                    "Incident logging",
                    "Escalation procedures"
                ],
                "compliant": 0,
                "total": 3,
                "evidence": []
            },
            "resilience_testing": {
                "name": "Operational Resilience Testing (Chapter IV)",
                "requirements": [
                    "Regular testing programs",
                    "Threat-led penetration testing",
                    "Red team exercises"
                ],
                "compliant": 0,
                "total": 3,
                "evidence": []
            },
            "third_party_risk": {
                "name": "Third-Party ICT Risk (Chapter V)",
                "requirements": [
                    "Due diligence on third parties",
                    "Contractual arrangements",
                    "Exit strategies"
                ],
                "compliant": 0,
                "total": 3,
                "evidence": []
            }
        }

        # ICT Risk Management assessment
        if len(findings) > 0:
            dora_pillars["ict_risk_management"]["compliant"] += 1  # Risk identification
            dora_pillars["ict_risk_management"]["evidence"].append("Automated risk identification active")

        has_protection = any(f.get("severity") == "Critical" for f in findings)
        if not has_protection:
            dora_pillars["ict_risk_management"]["compliant"] += 1  # Protection measures working
            dora_pillars["ict_risk_management"]["evidence"].append("No critical vulnerabilities")

        dora_pillars["ict_risk_management"]["compliant"] += 1  # Detection via tools
        dora_pillars["ict_risk_management"]["evidence"].append("Multi-layer detection framework")

        # Incident reporting (check for event logging)
        event_patterns = ["event", "log", "emit"]
        has_logging = any(
            any(pattern in str(f.get("description", "")).lower() for pattern in event_patterns)
            for f in findings
        )
        if has_logging:
            dora_pillars["incident_reporting"]["compliant"] += 2
            dora_pillars["incident_reporting"]["evidence"].append("On-chain event logging detected")

        # Resilience testing
        dora_pillars["resilience_testing"]["compliant"] += 3  # Framework provides testing
        dora_pillars["resilience_testing"]["evidence"].append("Comprehensive test suite executed")

        # Third-party risk (check for external dependencies)
        external_patterns = ["external", "interface", "import", "library"]
        has_external = any(
            any(pattern in str(f.get("description", "")).lower() for pattern in external_patterns)
            for f in findings
        )
        if has_external:
            dora_pillars["third_party_risk"]["evidence"].append("External dependencies identified")

        # Calculate overall compliance
        total_requirements = sum(p["total"] for p in dora_pillars.values())
        total_compliant = sum(p["compliant"] for p in dora_pillars.values())
        compliance_score = total_compliant / total_requirements if total_requirements > 0 else 0

        return {
            "pillars": dora_pillars,
            "total_requirements": total_requirements,
            "compliant_requirements": total_compliant,
            "compliance_score": compliance_score,
            "overall_status": "compliant" if compliance_score >= 0.7 else "needs_improvement",
            "regulation": "EU DORA (Regulation 2022/2554)",
            "effective_date": "January 17, 2025",
            "recommendation": "Document operational resilience procedures for DORA compliance"
        }

    def _generate_compliance_report(self, contract_path: str,
                                   findings: List[Dict[str, Any]],
                                   all_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate comprehensive compliance report covering all standards

        Returns:
            Complete compliance report
        """
        iso_status = all_results.get("iso27001_status", {})
        nist_status = all_results.get("nist_ssdf_status", {})
        owasp_coverage = all_results.get("owasp_coverage", {})
        swc_classification = all_results.get("swc_classification", {})
        dasp_coverage = all_results.get("dasp_coverage", {})
        scsvs_status = all_results.get("scsvs_status", {})
        ccss_status = all_results.get("ccss_status", {})
        defi_risk = all_results.get("defi_risk_assessment", {})
        mica_compliance = all_results.get("mica_compliance", {})
        dora_resilience = all_results.get("dora_resilience", {})
        audit_checklist = all_results.get("audit_checklist", {})

        return {
            "contract": contract_path,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "agent": "PolicyAgent",
            "version": "2.2.0",
            "summary": {
                "total_findings": len(findings),
                "critical_findings": len([f for f in findings if f.get("severity") == "Critical"]),
                "high_findings": len([f for f in findings if f.get("severity") == "High"]),
                "medium_findings": len([f for f in findings if f.get("severity") == "Medium"]),
                "low_findings": len([f for f in findings if f.get("severity") == "Low"])
            },
            "standards_compliance": {
                "ISO_IEC_27001_2022": {
                    "score": iso_status.get("compliance_score", 0),
                    "status": iso_status.get("overall_status", "unknown"),
                    "compliant_controls": iso_status.get("compliant_controls", 0),
                    "total_controls": iso_status.get("total_controls", 0)
                },
                "NIST_SSDF": {
                    "score": nist_status.get("compliance_score", 0),
                    "status": nist_status.get("overall_status", "unknown"),
                    "compliant_practices": nist_status.get("compliant_practices", 0),
                    "total_practices": nist_status.get("total_practices", 0)
                },
                "OWASP_SC_Top10": {
                    "score": owasp_coverage.get("coverage_score", 0),
                    "status": owasp_coverage.get("overall_status", "unknown"),
                    "covered_categories": owasp_coverage.get("covered_categories", 0),
                    "total_categories": owasp_coverage.get("total_categories", 0)
                },
                "OWASP_SCSVS": {
                    "achieved_level": scsvs_status.get("achieved_level", "None"),
                    "l1_score": scsvs_status.get("l1_score", 0),
                    "l2_score": scsvs_status.get("l2_score", 0),
                    "l3_score": scsvs_status.get("l3_score", 0)
                },
                "CCSS_v9": {
                    "score": ccss_status.get("compliance_score", 0),
                    "status": ccss_status.get("overall_status", "unknown"),
                    "compliant_aspects": ccss_status.get("compliant_aspects", 0),
                    "total_aspects": ccss_status.get("total_aspects", 0)
                },
                "EU_MiCA": {
                    "score": mica_compliance.get("high_priority_compliance", 0),
                    "status": mica_compliance.get("overall_status", "unknown"),
                    "regulation": "Regulation 2023/1114",
                    "effective_date": "December 30, 2024"
                },
                "EU_DORA": {
                    "score": dora_resilience.get("compliance_score", 0),
                    "status": dora_resilience.get("overall_status", "unknown"),
                    "regulation": "Regulation 2022/2554",
                    "effective_date": "January 17, 2025"
                }
            },
            "vulnerability_classification": {
                "SWC_Registry": {
                    "total_swc_types": swc_classification.get("total_swc_types", 0),
                    "total_classified": swc_classification.get("total_classified", 0),
                    "coverage_score": swc_classification.get("coverage_score", 0),
                    "most_common": swc_classification.get("most_common", [])
                },
                "DASP_Top10": {
                    "coverage_score": dasp_coverage.get("coverage_score", 0),
                    "status": dasp_coverage.get("overall_status", "unknown"),
                    "covered_categories": dasp_coverage.get("covered_categories", 0),
                    "critical_areas": dasp_coverage.get("critical_areas", [])
                }
            },
            # [LAYER 7 - AUDIT READINESS] Trail of Bits checklist and audit assessment
            "audit_assessment": {
                "trail_of_bits_checklist": {
                    "completion_score": audit_checklist.get("completion_score", 0),
                    "readiness": audit_checklist.get("audit_readiness", "unknown"),
                    "items_checked": audit_checklist.get("items_checked", 0),
                    "total_items": audit_checklist.get("total_items", 0)
                },
                "consensys_practices": {
                    "compliance_score": audit_checklist.get("compliance_score", 0),
                    "status": audit_checklist.get("overall_status", "unknown")
                }
            },
            "risk_assessment": {
                "defi_risks": {
                    "overall_risk_level": defi_risk.get("overall_risk_level", "unknown"),
                    "critical_findings": defi_risk.get("critical_findings", 0),
                    "high_findings": defi_risk.get("high_findings", 0),
                    "framework": "EEA DeFi Risk Assessment Guidelines v1.0"
                }
            },
            "overall_compliance_index": self._calculate_overall_compliance(all_results),
            "recommendations": self._generate_recommendations(findings, all_results),
            "audit_readiness": self._assess_audit_readiness(findings)
        }

    def _calculate_overall_compliance(self, all_results: Dict[str, Any]) -> float:
        """Calculate overall compliance index across all standards"""
        scores = []

        # Traditional standards
        if "iso27001_status" in all_results:
            scores.append(all_results["iso27001_status"].get("compliance_score", 0))
        if "nist_ssdf_status" in all_results:
            scores.append(all_results["nist_ssdf_status"].get("compliance_score", 0))
        if "owasp_coverage" in all_results:
            scores.append(all_results["owasp_coverage"].get("coverage_score", 0))

        # New standards
        if "scsvs_status" in all_results:
            scores.append(all_results["scsvs_status"].get("l1_score", 0))
        if "ccss_status" in all_results:
            scores.append(all_results["ccss_status"].get("compliance_score", 0))
        if "dasp_coverage" in all_results:
            scores.append(all_results["dasp_coverage"].get("coverage_score", 0))
        if "mica_compliance" in all_results:
            scores.append(all_results["mica_compliance"].get("high_priority_compliance", 0))
        if "dora_resilience" in all_results:
            scores.append(all_results["dora_resilience"].get("compliance_score", 0))

        return sum(scores) / len(scores) if scores else 0.0

    def _generate_recommendations(self, findings: List[Dict[str, Any]],
                                 all_results: Dict[str, Any]) -> List[str]:
        """
        Generate comprehensive compliance recommendations across all standards

        Returns:
            List of recommendation strings
        """
        recommendations = []

        # Critical vulnerabilities
        critical_count = len([f for f in findings if f.get("severity") == "Critical"])
        if critical_count > 0:
            recommendations.append(
                f"CRITICAL: Address {critical_count} critical vulnerabilities before production deployment"
            )

        # High severity findings
        high_count = len([f for f in findings if f.get("severity") == "High"])
        if high_count > 3:
            recommendations.append(
                f"HIGH: Resolve {high_count} high-severity findings to improve security posture"
            )

        # OWASP SC Top 10 gaps
        owasp_coverage = all_results.get("owasp_coverage", {})
        if owasp_coverage:
            uncovered = [
                cat for cat, data in owasp_coverage.get("categories", {}).items()
                if data.get("detected", 0) == 0
            ]
            if uncovered:
                recommendations.append(
                    f"OWASP: Enhance testing coverage for {', '.join(uncovered[:3])}"
                )

        # SCSVS level advancement
        scsvs_status = all_results.get("scsvs_status", {})
        if scsvs_status:
            achieved = scsvs_status.get("achieved_level", "None")
            if achieved != "L3":
                recommendations.append(
                    f"SCSVS: {scsvs_status.get('recommendation', '')}"
                )

        # DeFi risk assessment
        defi_risk = all_results.get("defi_risk_assessment", {})
        if defi_risk:
            risk_level = defi_risk.get("overall_risk_level", "unknown")
            if risk_level in ["high", "critical"]:
                recommendations.append(
                    f"DeFi RISK: {defi_risk.get('recommendation', '')}"
                )

        # EU MiCA compliance
        mica_compliance = all_results.get("mica_compliance", {})
        if mica_compliance:
            if mica_compliance.get("overall_status") == "non_compliant":
                recommendations.append(
                    "MiCA: Address non-compliant requirements for EU market readiness"
                )

        # DORA operational resilience
        dora_resilience = all_results.get("dora_resilience", {})
        if dora_resilience:
            if dora_resilience.get("overall_status") == "needs_improvement":
                recommendations.append(
                    "DORA: Strengthen operational resilience procedures and documentation"
                )

        # Trail of Bits audit checklist
        audit_checklist = all_results.get("audit_checklist", {})
        if audit_checklist:
            completion = audit_checklist.get("completion_score", 0)
            if completion < 0.7:
                recommendations.append(
                    f"AUDIT: Complete remaining checklist items ({int(completion * 100)}% done)"
                )

        # SWC classification
        swc_classification = all_results.get("swc_classification", {})
        if swc_classification:
            unclassified = swc_classification.get("unclassified_count", 0)
            if unclassified > 0:
                recommendations.append(
                    f"SWC: {unclassified} findings lack SWC classification - review for proper categorization"
                )

        # ISO 27001
        iso_status = all_results.get("iso27001_status", {})
        if iso_status and iso_status.get("compliance_score", 1.0) < 1.0:
            recommendations.append(
                "ISO 27001: Complete documentation for all information security controls"
            )

        # General recommendation
        recommendations.append(
            "EVIDENCE: Maintain complete audit trail via MCP Context Bus for compliance evidence"
        )

        # Prioritize recommendations
        return recommendations[:10]  # Limit to top 10 most important

    def _comprehensive_audit_readiness_assessment(
        self,
        findings: List[Dict[str, Any]],
        contract_path: str = None,
        project_root: str = None
    ) -> Dict[str, Any]:
        """
        [LAYER 7 - AUDIT READINESS - COMPREHENSIVE]
        Comprehensive audit readiness assessment per OpenZeppelin Guide

        Evaluates 4 dimensions:
        1. Documentation (NatSpec 90%, README quality)
        2. Testing (Code coverage 90%, property tests)
        3. Code Maturity (Git history, stability)
        4. Security Practices (OpenZeppelin patterns)

        Plus severity-based findings analysis (legacy method)

        Args:
            findings: List of vulnerability findings
            contract_path: Path to Solidity contract (optional)
            project_root: Path to project root (optional)

        Returns:
            {
                'documentation': {...},
                'testing': {...},
                'maturity': {...},
                'security_practices': {...},
                'findings_severity': {...},
                'overall_score': float (0-1),
                'readiness_status': str,
                'openzeppelin_compliance': float (0-100),
                'recommendations': List[str]
            }
        """
        logger.info("Running comprehensive audit readiness assessment")

        result = {
            'documentation': None,
            'testing': None,
            'maturity': None,
            'security_practices': None,
            'findings_severity': {},
            'overall_score': 0.0,
            'readiness_status': 'not_ready',
            'openzeppelin_compliance': 0.0,
            'recommendations': []
        }

        # 1. Documentation Analysis
        if self.documentation_analyzer and contract_path:
            try:
                logger.info("Analyzing documentation quality")
                doc_result = self.documentation_analyzer.analyze_all(
                    contract_path,
                    project_root
                )
                result['documentation'] = doc_result

                if not doc_result.get('passes_audit_readiness', False):
                    if doc_result.get('natspec', {}).get('coverage_percentage', 0) < 90:
                        result['recommendations'].append(
                            f"Increase NatSpec coverage to 90% (current: {doc_result.get('natspec', {}).get('coverage_percentage', 0)}%)"
                        )
                    if not doc_result.get('readme', {}).get('passes_threshold', False):
                        missing = doc_result.get('readme', {}).get('sections_missing', [])
                        if missing:
                            result['recommendations'].append(
                                f"Add missing README sections: {', '.join(missing)}"
                            )
            except Exception as e:
                logger.warning(f"Documentation analysis failed: {e}")
                result['documentation'] = {'error': str(e), 'passes_audit_readiness': False}

        # 2. Testing Analysis
        if self.testing_analyzer and project_root:
            try:
                logger.info("Analyzing test coverage and quality")
                testing_result = self.testing_analyzer.analyze_all(project_root)
                result['testing'] = testing_result

                if not testing_result.get('passes_audit_readiness', False):
                    coverage = testing_result.get('coverage', {}).get('line_coverage', 0)
                    if coverage < 90:
                        result['recommendations'].append(
                            f"Increase code coverage to 90% (current: {coverage}%)"
                        )
                    if not testing_result.get('property_tests', {}).get('passes_threshold', False):
                        result['recommendations'].append(
                            "Add property-based tests (Echidna/Medusa)"
                        )
            except Exception as e:
                logger.warning(f"Testing analysis failed: {e}")
                result['testing'] = {'error': str(e), 'passes_audit_readiness': False}

        # 3. Code Maturity Analysis
        if self.maturity_analyzer and project_root:
            try:
                logger.info("Analyzing code maturity")
                maturity_result = self.maturity_analyzer.analyze_all(project_root)
                result['maturity'] = maturity_result

                if not maturity_result.get('passes_audit_readiness', False):
                    score = maturity_result.get('maturity', {}).get('maturity_score', 0)
                    level = maturity_result.get('maturity', {}).get('maturity_level', 'unknown')
                    result['recommendations'].append(
                        f"Code maturity is {level} (score: {score:.2f}). Consider more development time."
                    )
            except Exception as e:
                logger.warning(f"Maturity analysis failed: {e}")
                result['maturity'] = {'error': str(e), 'passes_audit_readiness': False}

        # 4. Security Practices Analysis
        if self.security_practices_analyzer and contract_path:
            try:
                logger.info("Analyzing security practices")
                security_result = self.security_practices_analyzer.analyze_all(contract_path)
                result['security_practices'] = security_result

                if not security_result.get('passes_audit_readiness', False):
                    recommendations = security_result.get('practices', {}).get('recommendations', [])
                    result['recommendations'].extend(recommendations)
            except Exception as e:
                logger.warning(f"Security practices analysis failed: {e}")
                result['security_practices'] = {'error': str(e), 'passes_audit_readiness': False}

        # 5. Findings Severity Analysis (Legacy)
        critical = len([f for f in findings if f.get("severity") == "Critical"])
        high = len([f for f in findings if f.get("severity") == "High"])
        medium = len([f for f in findings if f.get("severity") == "Medium"])
        low = len([f for f in findings if f.get("severity") == "Low"])

        result['findings_severity'] = {
            'critical': critical,
            'high': high,
            'medium': medium,
            'low': low,
            'total': len(findings)
        }

        if critical > 0:
            result['recommendations'].append(
                f"Fix {critical} critical severity issue(s) before audit"
            )
        if high > 5:
            result['recommendations'].append(
                f"Reduce high severity issues from {high} to 5"
            )

        # Calculate Overall Score
        scores = []
        weights = []

        if result['documentation']:
            scores.append(result['documentation'].get('overall_score', 0))
            weights.append(0.25)  # 25% weight
        if result['testing']:
            scores.append(result['testing'].get('overall_score', 0))
            weights.append(0.30)  # 30% weight (most important per OpenZeppelin)
        if result['maturity']:
            scores.append(result['maturity'].get('overall_score', 0))
            weights.append(0.20)  # 20% weight
        if result['security_practices']:
            scores.append(result['security_practices'].get('overall_score', 0))
            weights.append(0.25)  # 25% weight

        if scores:
            result['overall_score'] = sum(s * w for s, w in zip(scores, weights)) / sum(weights)
        else:
            result['overall_score'] = 0.0

        # Penalize for critical/high findings
        severity_penalty = 0
        if critical > 0:
            severity_penalty = 0.5  # 50% penalty for ANY critical
        elif high > 5:
            severity_penalty = 0.3  # 30% penalty for >5 high
        elif high > 0:
            severity_penalty = 0.1  # 10% penalty for any high

        result['overall_score'] = max(0, result['overall_score'] * (1 - severity_penalty))

        # OpenZeppelin Compliance Percentage
        result['openzeppelin_compliance'] = result['overall_score'] * 100

        # Determine Readiness Status
        if result['overall_score'] >= 0.9 and critical == 0:
            result['readiness_status'] = 'ready'
        elif result['overall_score'] >= 0.75 and critical == 0 and high <= 2:
            result['readiness_status'] = 'ready_with_notes'
        elif result['overall_score'] >= 0.5 and critical == 0:
            result['readiness_status'] = 'needs_review'
        else:
            result['readiness_status'] = 'not_ready'

        logger.info(f"Audit readiness: {result['readiness_status']} (score: {result['overall_score']:.2f}, OpenZeppelin compliance: {result['openzeppelin_compliance']:.1f}%)")

        # Add disclaimer: This measures PRE-AUDIT MATURITY, not a replacement for professional audits
        result['disclaimer'] = (
            " IMPORTANT: This assessment measures PRE-AUDIT MATURITY, NOT security certification. "
            "It evaluates the contract's readiness level before undergoing professional audit. "
            "The compliance score indicates how well documentation, testing, and security practices "
            "align with OpenZeppelin Audit Readiness Guide requirements. "
            "This tool is COMPLEMENTARY and does NOT replace professional security audits. "
            "Professional audits remain MANDATORY regardless of compliance score."
        )

        return result

    def _assess_audit_readiness(self, findings: List[Dict[str, Any]]) -> str:
        """
        [LAYER 7 - AUDIT READINESS - LEGACY]
        Assess readiness for external audit based on vulnerability severity

        This is the legacy simple method. Use _comprehensive_audit_readiness_assessment()
        for full OpenZeppelin Guide compliance.

        Returns:
            Readiness status string: "ready", "ready_with_notes",
            "needs_review", or "not_ready"
        """
        critical = len([f for f in findings if f.get("severity") == "Critical"])
        high = len([f for f in findings if f.get("severity") == "High"])

        if critical > 0:
            return "not_ready"
        elif high > 5:
            return "needs_review"
        elif high > 0:
            return "ready_with_notes"
        else:
            return "ready"
