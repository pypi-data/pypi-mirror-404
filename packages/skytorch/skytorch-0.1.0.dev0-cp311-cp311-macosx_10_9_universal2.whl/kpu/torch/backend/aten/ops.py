"""Generated ATen operator registrations for KPU backend.

This file is auto-generated by hack/gen-aten-ops.py.
Do not edit manually.
"""

from typing import Any, Callable

import torch

from .dispatch import _kpu_kernel_fallback


def _kpu_kernel_fallback_wrapper(
    op: torch._ops.OpOverload | torch._ops.OpOverloadPacket,
) -> Callable[..., Any]:
    """Create a wrapper that calls _kpu_kernel_fallback with the specified op."""

    def wrapper(*args: Any, **kwargs: Any) -> Any:
        return _kpu_kernel_fallback(op, *args, **kwargs)

    return wrapper


# Register operators with KPU backend
_kpu_lib_aten = torch.library.Library("aten", "IMPL")

_kpu_lib_aten.impl(
    "_adaptive_avg_pool2d",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._adaptive_avg_pool2d.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_adaptive_avg_pool2d.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._adaptive_avg_pool2d.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_adaptive_avg_pool2d_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._adaptive_avg_pool2d_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_adaptive_avg_pool2d_backward.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._adaptive_avg_pool2d_backward.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_log_softmax",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._log_softmax.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_log_softmax.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._log_softmax.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_log_softmax_backward_data",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._log_softmax_backward_data.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_log_softmax_backward_data.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._log_softmax_backward_data.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_native_batch_norm_legit",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._native_batch_norm_legit.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_native_batch_norm_legit.no_stats",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._native_batch_norm_legit.no_stats),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_native_batch_norm_legit.no_stats_out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._native_batch_norm_legit.no_stats_out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_native_batch_norm_legit.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._native_batch_norm_legit.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_native_batch_norm_legit_no_training",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._native_batch_norm_legit_no_training.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_native_batch_norm_legit_no_training.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._native_batch_norm_legit_no_training.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_softmax",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._softmax.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_softmax.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._softmax.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_softmax_backward_data",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._softmax_backward_data.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "_softmax_backward_data.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten._softmax_backward_data.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "abs",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.abs.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "abs.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.abs.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "abs_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.abs_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "add.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.add.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "add.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.add.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "add.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.add.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "add_.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.add_.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "add_.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.add_.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "addmm",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.addmm.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "addmm.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.addmm.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "addmm_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.addmm_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "argmax",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.argmax.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "argmax.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.argmax.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "avg_pool2d",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.avg_pool2d.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "avg_pool2d.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.avg_pool2d.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "avg_pool2d_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.avg_pool2d_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "avg_pool2d_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.avg_pool2d_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "bmm",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.bmm.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "bmm.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.bmm.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "cat",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.cat.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "cat.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.cat.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "clone",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.clone.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "contiguous",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.contiguous.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "convolution",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.convolution.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "convolution.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.convolution.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "convolution_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.convolution_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "convolution_backward.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.convolution_backward.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div.Scalar_mode",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div.Scalar_mode),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div.Tensor_mode",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div.Tensor_mode),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div_.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div_.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "div_.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.div_.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "embedding",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.embedding.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "embedding_dense_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.embedding_dense_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "eq.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.eq.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "eq.Scalar_out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.eq.Scalar_out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "eq.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.eq.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "eq.Tensor_out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.eq.Tensor_out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "exp",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.exp.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "exp.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.exp.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "exp_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.exp_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "expand",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.expand.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "fill_.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.fill_.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "fill_.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.fill_.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "flatten.using_ints",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.flatten.using_ints),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "full",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.full.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "full.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.full.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "ge.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.ge.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "ge.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.ge.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gelu",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gelu.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gelu.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gelu.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gelu_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gelu_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gelu_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gelu_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gelu_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gelu_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gt.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gt.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "gt.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.gt.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "index.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.index.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "index.Tensor_out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.index.Tensor_out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "le.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.le.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "le.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.le.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "log",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.log.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "log.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.log.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "log_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.log_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "lt.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.lt.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "lt.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.lt.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max.dim",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max.dim),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max.dim_max",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max.dim_max),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max_pool2d_with_indices",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max_pool2d_with_indices.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max_pool2d_with_indices.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max_pool2d_with_indices.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max_pool2d_with_indices_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max_pool2d_with_indices_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "max_pool2d_with_indices_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.max_pool2d_with_indices_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mean",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mean.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mean.dim",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mean.dim),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mean.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mean.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mm",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mm.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mm.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mm.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mul.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mul.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mul.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mul.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mul.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mul.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mul_.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mul_.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "mul_.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.mul_.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "native_batch_norm_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.native_batch_norm_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "native_dropout",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.native_dropout.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "native_dropout.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.native_dropout.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "native_dropout_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.native_dropout_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "native_dropout_backward.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.native_dropout_backward.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "ne.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.ne.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "ne.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.ne.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "neg",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.neg.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "neg.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.neg.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "neg_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.neg_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss2d_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss2d_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss2d_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss2d_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss2d_forward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss2d_forward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss2d_forward.output",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss2d_forward.output),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss_forward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss_forward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "nll_loss_forward.output",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.nll_loss_forward.output),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "ones",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.ones.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "ones.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.ones.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "permute",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.permute.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "pow.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.pow.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "pow.Tensor_Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.pow.Tensor_Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "pow.Tensor_Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.pow.Tensor_Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "relu",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.relu.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "relu.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.relu.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "relu_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.relu_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "reshape",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.reshape.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "rsqrt",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.rsqrt.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "rsqrt.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.rsqrt.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "rsqrt_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.rsqrt_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "select.int",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.select.int),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sigmoid",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sigmoid.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sigmoid.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sigmoid.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sigmoid_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sigmoid_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sigmoid_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sigmoid_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sigmoid_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sigmoid_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "slice.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.slice.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sqrt",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sqrt.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sqrt.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sqrt.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sqrt_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sqrt_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "squeeze.dim",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.squeeze.dim),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "squeeze.dims",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.squeeze.dims),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sub.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sub.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sub.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sub.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sub.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sub.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sub_.Scalar",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sub_.Scalar),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sub_.Tensor",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sub_.Tensor),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sum",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sum.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sum.dim_IntList",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sum.dim_IntList),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "sum.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.sum.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "t",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.t.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "tanh",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.tanh.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "tanh.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.tanh.out),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "tanh_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.tanh_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "tanh_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.tanh_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "tanh_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.tanh_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "threshold_backward",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.threshold_backward.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "threshold_backward.grad_input",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.threshold_backward.grad_input),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "transpose.int",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.transpose.int),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "unsqueeze",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.unsqueeze.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "zero_",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.zero_.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "zeros",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.zeros.default),
    dispatch_key="PrivateUse1",
)

_kpu_lib_aten.impl(
    "zeros.out",
    _kpu_kernel_fallback_wrapper(torch.ops.aten.zeros.out),
    dispatch_key="PrivateUse1",
)
