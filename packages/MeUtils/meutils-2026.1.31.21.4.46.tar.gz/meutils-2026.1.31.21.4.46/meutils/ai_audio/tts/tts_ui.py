#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : tts
# @Time         : 2023/10/25 18:21
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  : https://www.qianduan.shop/blogs/detail/140
# https://baijiahao.baidu.com/s?id=1762431177147996323&wfr=spider&for=pc
# https://github.com/pndurette/gTTS
# https://github.com/ycyy/edge-tts-webui

from meutils.pipe import *
import gradio as gr
import edge_tts
import asyncio
import os

# https://speech.platform.bing.com/consumer/speech/synthesize/readaloud/voices/list?trustedclienttoken=6A5AA1D4EAFF4E9FB37E23D68491D6F4
SUPPORTED_VOICES = {
    'Xiaoxiao-æ™“æ™“': 'zh-CN-XiaoxiaoNeural',
    'Xiaoyi-æ™“ä¼Š': 'zh-CN-XiaoyiNeural',
    'Yunjian-äº‘å¥': 'zh-CN-YunjianNeural',
    'Yunxi-äº‘å¸Œ': 'zh-CN-YunxiNeural',
    'Yunxia-äº‘å¤': 'zh-CN-YunxiaNeural',
    'Yunyang-äº‘æ‰¬': 'zh-CN-YunyangNeural',
    'liaoning-Xiaobei-æ™“åŒ—è¾½å®': 'zh-CN-liaoning-XiaobeiNeural',
    'shaanxi-Xiaoni-é™•è¥¿æ™“å¦®': 'zh-CN-shaanxi-XiaoniNeural'
}


# å‘éŸ³åˆ‡æ¢
def changeVoice(voices):
    example = SUPPORTED_VOICES[voices]
    example_file = os.path.join(os.path.dirname(__file__), "example/" + example + ".wav")
    return example_file


# æ–‡æœ¬è½¬è¯­éŸ³
async def textToSpeech(text, voices, rate, volume):
    output_file = "output.mp3"
    voices = SUPPORTED_VOICES[voices]
    if (rate >= 0):
        rates = rate = "+" + str(rate) + "%"
    else:
        rates = str(rate) + "%"
    if (volume >= 0):
        volumes = "+" + str(volume) + "%"
    else:
        volumes = str(volume) + "%"
    communicate = edge_tts.Communicate(text,
                                       voices,
                                       rate=rates,
                                       volume=volumes,
                                       proxy=None)
    await communicate.save(output_file)
    audio_file = os.path.join(os.path.dirname(__file__), "output.mp3")
    if (os.path.exists(audio_file)):
        return audio_file
    else:
        raise gr.Error("è½¬æ¢å¤±è´¥ï¼")
        return FileNotFoundError


# æ¸…é™¤è½¬æ¢ç»“æœ
def clearSpeech():
    output_file = os.path.join(os.path.dirname(__file__), "output.mp3")
    if (os.path.exists(output_file)):
        os.remove(output_file)
    return None, None


with gr.Blocks(css="style.css", title="æ–‡æœ¬è½¬è¯­éŸ³") as demo:
    gr.Markdown("""
    # ğŸ”¥ChatLLM è¯­éŸ³åˆæˆç³»ç»Ÿ`TTS`
    """)
    with gr.Row():
        with gr.Column():
            text = gr.TextArea(label="æ–‡æœ¬", elem_classes="text-area")
            btn = gr.Button("ç”Ÿæˆ", elem_id="submit-btn")
        with gr.Column():
            voices = gr.Dropdown(choices=[
                "Xiaoxiao-æ™“æ™“", "Xiaoyi-æ™“ä¼Š", "Yunjian-äº‘å¥", "Yunxi-äº‘å¸Œ",
                "Yunxia-äº‘å¤", "Yunyang-äº‘æ‰¬", "liaoning-Xiaobei-æ™“åŒ—è¾½å®",
                "shaanxi-Xiaoni-é™•è¥¿æ™“å¦®"
            ],
                value="Xiaoxiao-æ™“æ™“",
                label="å‘éŸ³",
                info="è¯·é€‰æ‹©å‘éŸ³äºº",
                interactive=True)

            example = gr.Audio(label="è¯•å¬",
                               value="example/zh-CN-XiaoxiaoNeural.wav",
                               interactive=False,
                               elem_classes="example")

            voices.change(fn=changeVoice, inputs=voices, outputs=example)
            rate = gr.Slider(-100,
                             100,
                             step=1,
                             value=0,
                             label="è¯­é€Ÿå¢å‡",
                             info="åŠ å¿«æˆ–å‡æ…¢è¯­é€Ÿ",
                             interactive=True)

            volume = gr.Slider(-100,
                               100,
                               step=1,
                               value=0,
                               label="éŸ³è°ƒå¢å‡",
                               info="åŠ å¤§æˆ–å‡å°éŸ³è°ƒ",
                               interactive=True)
            audio = gr.Audio(label="è¾“å‡º",
                             interactive=False,
                             elem_classes="audio")
            clear = gr.Button("æ¸…é™¤", elem_id="clear-btn")
            btn.click(fn=textToSpeech,
                      inputs=[text, voices, rate, volume],
                      outputs=[audio])
            clear.click(fn=clearSpeech, outputs=[text, audio])

if __name__ == "__main__":
    import uvicorn
    from fastapi import FastAPI

    app = FastAPI()

    app = gr.mount_gradio_app(app, demo, path="/web/tts")
    uvicorn.run(app, host="0.0.0.0", port=39999)
