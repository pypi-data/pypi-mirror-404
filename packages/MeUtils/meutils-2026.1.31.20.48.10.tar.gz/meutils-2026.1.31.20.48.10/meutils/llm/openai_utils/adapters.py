#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : AI.  @by PyCharm
# @File         : adapters
# @Time         : 2025/5/30 16:38
# @Author       : betterme
# @WeChat       : meutils
# @Software     : PyCharm
# @Description  :
import shortuuid
from aiostream import stream

from meutils.pipe import *
from meutils.io.files_utils import to_url, to_url_fal
from meutils.str_utils.json_utils import json_path
from meutils.llm.openai_utils import create_chat_completion
from meutils.schemas.openai_types import CompletionRequest, ChatCompletion
from meutils.schemas.image_types import ImageRequest, ImagesResponse
from meutils.llm.openai_utils import chat_completion, chat_completion_chunk, create_chat_completion_chunk
from meutils.str_utils import parse_url, parse_command_string


async def stream_to_nostream(
        request: CompletionRequest,
):
    pass


async def chat_for_image(
        generate: Optional[Callable],
        request: CompletionRequest,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        http_url: Optional[Any] = None,
):
    generate = generate and partial(generate, api_key=api_key, base_url=base_url, http_url=http_url)

    image = None
    prompt = request.last_user_content
    if image_urls := request.last_urls.get("image_url"):  # image_url
        if request.model.startswith('fal'):
            urls = await to_url_fal(image_urls, content_type="image/png")  # å›½å¤–å‹å¥½
            image = urls

        elif request.model.startswith("doubao-seed"):
            image = image_urls  # b64

        else:
            urls = await to_url(image_urls, ".png", content_type="image/png")  # b64 è½¬ url
            image = urls

    image_request = ImageRequest(
        model=request.model,
        prompt=prompt,
        image=image
    )
    if not image_request.image:
        image_request.image, image_request.prompt = image_request.image_and_prompt

    if '--' in image_request.prompt:
        prompt_dict = parse_command_string(image_request.prompt)
        # ç¼©å†™è¡¥å……
        prompt_dict['aspect_ratio'] = prompt_dict.get('aspect_ratio') or prompt_dict.get('ar')

        data = {
            **image_request.model_dump(exclude_none=True, exclude={"extra_fields", "aspect_ratio"}),
            **prompt_dict
        }
        image_request = ImageRequest(**data)
        logger.debug(image_request)

    # éæµå¼
    if not request.stream:
        if request.last_user_content.startswith(  # è·³è¿‡nextchat
                (
                        "hi",
                        "ä½¿ç”¨å››åˆ°äº”ä¸ªå­—ç›´æ¥è¿”å›è¿™å¥è¯çš„ç®€è¦ä¸»é¢˜",
                        "ç®€è¦æ€»ç»“ä¸€ä¸‹å¯¹è¯å†…å®¹ï¼Œç”¨ä½œåç»­çš„ä¸Šä¸‹æ–‡æç¤º promptï¼Œæ§åˆ¶åœ¨ 200 å­—ä»¥å†…"
                )):
            return chat_completion

        response = await generate(image_request)  # None

        if not response:
            raise Exception(f"image generate error: {str(request)[:1000]}")

        if not isinstance(response, dict):
            response = response.model_dump()

        content = ""
        for image in response['data']:
            content += f"""![{image.get("revised_prompt")}]({image['url']})\n\n"""

        chat_completion.choices[0].message.content = content
        chat_completion.usage = image_request.usage
        return chat_completion

    # æµå¼
    if not generate: return

    future_task = asyncio.create_task(generate(image_request))  # å¼‚æ­¥æ‰§è¡Œ

    async def gen():
        exclude = None
        if len(str(image_request.image)) > 1000:
            exclude = {"image"}

        text = image_request.model_dump_json(exclude_none=True, exclude=exclude).replace("free", "")
        for i in f"""> ğŸ–Œï¸æ­£åœ¨ç»˜ç”»\n\n```json\n{text}\n```\n\n""":
            await asyncio.sleep(0.05)
            yield i

        try:
            response = await future_task
            # response = await response  # æ³¨æ„

            if not isinstance(response, dict):
                response = response.model_dump()

            for image in response['data']:
                yield f"""![{image.get("revised_prompt")}]({image['url']})\n\n"""


        except Exception as e:
            # yield f"```error\n{e}\n```\n"
            raise e

    chunks = create_chat_completion_chunk(gen(), redirect_model=request.model)
    return chunks


async def chat_for_video(
        get_task: Callable,  # response
        taskid: str,
):
    """å¼‚æ­¥ä»»åŠ¡"""

    async def gen():

        # è·å–ä»»åŠ¡
        for i in f"""> VideoTask(id={taskid})\n""":
            await asyncio.sleep(0.03)
            yield i

        yield f"[ğŸ¤« ä»»åŠ¡è¿›åº¦]("
        for i in range(60):
            await asyncio.sleep(3)
            response = await get_task(taskid)  # åŒ…å«  "status"

            logger.debug(response)
            if response.get("status", "").lower().startswith(("succ", "fail")):

                yield ")ğŸ‰ğŸ‰ğŸ‰\n\n"

                yield f"""```json\n{json.dumps(response, indent=4, ensure_ascii=False)}\n```"""

                if urls := json_path(response, expr='$..[url,image_url,video_url]'):  # æ‰€æœ‰url
                    for i, url in enumerate(urls, 1):
                        yield f"\n\n[ä¸‹è½½é“¾æ¥{i}]({url})\n\n"

                break

            else:
                yield "ğŸš€"

    chunks = create_chat_completion_chunk(gen(), chat_id=taskid)
    return chunks


if __name__ == '__main__':
    from meutils.apis.images.generations import generate

    request = CompletionRequest(
        model="deepseek-r1-Distill-Qwen-1.5B",
        messages=[
            {"role": "user", "content": "``hi --a 1"}
        ],
        stream=True,
    )
    arun(chat_for_image(None, request))

    request = CompletionRequest(
        model="gemini-2.5-flash-image-preview",
        messages=[
            {"role": "user", "content": "ç”»æ¡ç‹—"}
        ],
        # stream=True,
    )
    api_key = "sk-MAZ6SELJVtGNX6jgIcZBKuttsRibaDlAskFAnR7WD6PBSN6M-openai"
    base_url = "https://new.yunai.link/v1"
    arun(chat_for_image(generate, request, api_key, base_url))
