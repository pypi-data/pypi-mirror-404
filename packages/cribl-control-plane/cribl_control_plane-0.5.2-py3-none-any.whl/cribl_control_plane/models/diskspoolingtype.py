"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .compressionoptionspersistence import CompressionOptionsPersistence
from cribl_control_plane import models
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import field_serializer, model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class DiskSpoolingTypeTypedDict(TypedDict):
    enable: NotRequired[bool]
    r"""Spool events on disk for Cribl Edge and Search. Default is disabled."""
    time_window: NotRequired[str]
    r"""Time period for grouping spooled events. Default is 10m."""
    max_data_size: NotRequired[str]
    r"""Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB."""
    max_data_time: NotRequired[str]
    r"""Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h."""
    compress: NotRequired[CompressionOptionsPersistence]
    r"""Data compression format. Default is gzip."""


class DiskSpoolingType(BaseModel):
    enable: Optional[bool] = None
    r"""Spool events on disk for Cribl Edge and Search. Default is disabled."""

    time_window: Annotated[Optional[str], pydantic.Field(alias="timeWindow")] = None
    r"""Time period for grouping spooled events. Default is 10m."""

    max_data_size: Annotated[Optional[str], pydantic.Field(alias="maxDataSize")] = None
    r"""Maximum disk space that can be consumed before older buckets are deleted. Examples: 420MB, 4GB. Default is 1GB."""

    max_data_time: Annotated[Optional[str], pydantic.Field(alias="maxDataTime")] = None
    r"""Maximum amount of time to retain data before older buckets are deleted. Examples: 2h, 4d. Default is 24h."""

    compress: Optional[CompressionOptionsPersistence] = None
    r"""Data compression format. Default is gzip."""

    @field_serializer("compress")
    def serialize_compress(self, value):
        if isinstance(value, str):
            try:
                return models.CompressionOptionsPersistence(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["enable", "timeWindow", "maxDataSize", "maxDataTime", "compress"]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
