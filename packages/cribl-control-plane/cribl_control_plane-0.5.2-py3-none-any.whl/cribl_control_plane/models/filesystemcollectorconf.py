"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
import pydantic
from pydantic import model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class FilesystemCollectorConfExtractorTypedDict(TypedDict):
    key: str
    r"""A token from the template directory, such as epoch"""
    expression: str
    r"""JavaScript expression that receives token under \"value\" variable, and evaluates to populate event fields, such as {date: new Date(+value*1000)}"""


class FilesystemCollectorConfExtractor(BaseModel):
    key: str
    r"""A token from the template directory, such as epoch"""

    expression: str
    r"""JavaScript expression that receives token under \"value\" variable, and evaluates to populate event fields, such as {date: new Date(+value*1000)}"""


class FilesystemCollectorConfTypedDict(TypedDict):
    path: str
    r"""The directory from which to collect data. Templating is supported, such as /myDir/${datacenter}/${host}/${app}/. Time-based tokens are also supported, such as /myOtherDir/${_time:%Y}/${_time:%m}/${_time:%d}/."""
    output_name: NotRequired[str]
    r"""Select a predefined configuration (a Destination) to auto-populate Collector settings"""
    extractors: NotRequired[List[FilesystemCollectorConfExtractorTypedDict]]
    r"""Allows using template tokens as context for expressions that enrich discovery results. For example, given a template /path/${epoch}, an extractor under key \"epoch\" with an expression {date: new Date(+value*1000)}, will enrich discovery results with a human readable \"date\" field."""
    recurse: NotRequired[bool]
    r"""Recurse through subdirectories"""
    max_batch_size: NotRequired[float]
    r"""Maximum number of metadata files to batch before recording as results"""


class FilesystemCollectorConf(BaseModel):
    path: str
    r"""The directory from which to collect data. Templating is supported, such as /myDir/${datacenter}/${host}/${app}/. Time-based tokens are also supported, such as /myOtherDir/${_time:%Y}/${_time:%m}/${_time:%d}/."""

    output_name: Annotated[Optional[str], pydantic.Field(alias="outputName")] = None
    r"""Select a predefined configuration (a Destination) to auto-populate Collector settings"""

    extractors: Optional[List[FilesystemCollectorConfExtractor]] = None
    r"""Allows using template tokens as context for expressions that enrich discovery results. For example, given a template /path/${epoch}, an extractor under key \"epoch\" with an expression {date: new Date(+value*1000)}, will enrich discovery results with a human readable \"date\" field."""

    recurse: Optional[bool] = None
    r"""Recurse through subdirectories"""

    max_batch_size: Annotated[Optional[float], pydantic.Field(alias="maxBatchSize")] = (
        None
    )
    r"""Maximum number of metadata files to batch before recording as results"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["outputName", "extractors", "recurse", "maxBatchSize"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
