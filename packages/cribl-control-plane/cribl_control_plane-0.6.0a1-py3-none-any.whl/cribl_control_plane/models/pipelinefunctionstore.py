"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from enum import Enum
import pydantic
from pydantic import model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class PipelineFunctionStoreID(str, Enum):
    r"""Function ID"""

    STORE = "store"


class MappingOfFieldNamesTypedDict(TypedDict):
    r"""Mapping event property names to output field names"""


class MappingOfFieldNames(BaseModel):
    r"""Mapping event property names to output field names"""


class StoreFunctionConfigurationTypedDict(TypedDict):
    type: str
    r"""The type of knowledge object, generated by the function (i.e., 'lookup')"""
    destination: NotRequired[str]
    r"""Configures where and how the data should be stored"""
    description: NotRequired[str]
    r"""The knowledge object's description"""
    field_mapping: NotRequired[MappingOfFieldNamesTypedDict]
    r"""Mapping event property names to output field names"""
    separator: NotRequired[str]
    r"""Character to be used as value delimiter in output"""
    overwrite: NotRequired[bool]
    r"""For existing files, an error is thrown if overwrite is false or the file is replaced if overwrite is true"""
    compress: NotRequired[str]
    r"""True will compress output, false leaves it as it is and auto decides based on size"""
    tee: NotRequired[bool]
    r"""Tee results to the next operator"""
    max_events: NotRequired[float]
    r"""Limits how many events can be stored"""
    suppress_previews: NotRequired[bool]
    r"""Suppresses the timer-based export stats generating"""


class StoreFunctionConfiguration(BaseModel):
    type: str
    r"""The type of knowledge object, generated by the function (i.e., 'lookup')"""

    destination: Optional[str] = None
    r"""Configures where and how the data should be stored"""

    description: Optional[str] = None
    r"""The knowledge object's description"""

    field_mapping: Annotated[
        Optional[MappingOfFieldNames], pydantic.Field(alias="fieldMapping")
    ] = None
    r"""Mapping event property names to output field names"""

    separator: Optional[str] = None
    r"""Character to be used as value delimiter in output"""

    overwrite: Optional[bool] = None
    r"""For existing files, an error is thrown if overwrite is false or the file is replaced if overwrite is true"""

    compress: Optional[str] = None
    r"""True will compress output, false leaves it as it is and auto decides based on size"""

    tee: Optional[bool] = None
    r"""Tee results to the next operator"""

    max_events: Annotated[Optional[float], pydantic.Field(alias="maxEvents")] = None
    r"""Limits how many events can be stored"""

    suppress_previews: Annotated[
        Optional[bool], pydantic.Field(alias="suppressPreviews")
    ] = None
    r"""Suppresses the timer-based export stats generating"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "destination",
                "description",
                "fieldMapping",
                "separator",
                "overwrite",
                "compress",
                "tee",
                "maxEvents",
                "suppressPreviews",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class PipelineFunctionStoreTypedDict(TypedDict):
    id: PipelineFunctionStoreID
    r"""Function ID"""
    conf: StoreFunctionConfigurationTypedDict
    filter_: NotRequired[str]
    r"""Filter that selects data to be fed through this Function"""
    description: NotRequired[str]
    r"""Simple description of this step"""
    disabled: NotRequired[bool]
    r"""If true, data will not be pushed through this function"""
    final: NotRequired[bool]
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""
    group_id: NotRequired[str]
    r"""Group ID"""


class PipelineFunctionStore(BaseModel):
    id: PipelineFunctionStoreID
    r"""Function ID"""

    conf: StoreFunctionConfiguration

    filter_: Annotated[Optional[str], pydantic.Field(alias="filter")] = None
    r"""Filter that selects data to be fed through this Function"""

    description: Optional[str] = None
    r"""Simple description of this step"""

    disabled: Optional[bool] = None
    r"""If true, data will not be pushed through this function"""

    final: Optional[bool] = None
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""

    group_id: Annotated[Optional[str], pydantic.Field(alias="groupId")] = None
    r"""Group ID"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["filter", "description", "disabled", "final", "groupId"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
