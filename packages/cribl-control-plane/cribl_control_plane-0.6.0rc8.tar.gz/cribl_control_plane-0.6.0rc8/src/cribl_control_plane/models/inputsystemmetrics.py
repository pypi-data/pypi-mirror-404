"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .datacompressionformatoptionspersistence import (
    DataCompressionFormatOptionsPersistence,
)
from .itemstypeconnectionsoptional import (
    ItemsTypeConnectionsOptional,
    ItemsTypeConnectionsOptionalTypedDict,
)
from .itemstypemetadata import ItemsTypeMetadata, ItemsTypeMetadataTypedDict
from .modeoptionshost import ModeOptionsHost
from .pqtype import PqType, PqTypeTypedDict
from .processtype import ProcessType, ProcessTypeTypedDict
from cribl_control_plane import models, utils
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from enum import Enum
import pydantic
from pydantic import field_serializer, model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class InputSystemMetricsType(str, Enum):
    SYSTEM_METRICS = "system_metrics"


class InputSystemMetricsSystemMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Select the level of detail for system metrics"""

    # Basic
    BASIC = "basic"
    # All
    ALL = "all"
    # Custom
    CUSTOM = "custom"
    # Disabled
    DISABLED = "disabled"


class InputSystemMetricsSystemTypedDict(TypedDict):
    mode: NotRequired[InputSystemMetricsSystemMode]
    r"""Select the level of detail for system metrics"""
    processes: NotRequired[bool]
    r"""Generate metrics for the numbers of processes in various states"""


class InputSystemMetricsSystem(BaseModel):
    mode: Optional[InputSystemMetricsSystemMode] = None
    r"""Select the level of detail for system metrics"""

    processes: Optional[bool] = None
    r"""Generate metrics for the numbers of processes in various states"""

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemMetricsSystemMode(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["mode", "processes"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsCPUMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Select the level of detail for CPU metrics"""

    # Basic
    BASIC = "basic"
    # All
    ALL = "all"
    # Custom
    CUSTOM = "custom"
    # Disabled
    DISABLED = "disabled"


class InputSystemMetricsCPUTypedDict(TypedDict):
    mode: NotRequired[InputSystemMetricsCPUMode]
    r"""Select the level of detail for CPU metrics"""
    per_cpu: NotRequired[bool]
    r"""Generate metrics for each CPU"""
    detail: NotRequired[bool]
    r"""Generate metrics for all CPU states"""
    time: NotRequired[bool]
    r"""Generate raw, monotonic CPU time counters"""


class InputSystemMetricsCPU(BaseModel):
    mode: Optional[InputSystemMetricsCPUMode] = None
    r"""Select the level of detail for CPU metrics"""

    per_cpu: Annotated[Optional[bool], pydantic.Field(alias="perCpu")] = None
    r"""Generate metrics for each CPU"""

    detail: Optional[bool] = None
    r"""Generate metrics for all CPU states"""

    time: Optional[bool] = None
    r"""Generate raw, monotonic CPU time counters"""

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemMetricsCPUMode(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["mode", "perCpu", "detail", "time"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsMemoryMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Select the level of detail for memory metrics"""

    # Basic
    BASIC = "basic"
    # All
    ALL = "all"
    # Custom
    CUSTOM = "custom"
    # Disabled
    DISABLED = "disabled"


class InputSystemMetricsMemoryTypedDict(TypedDict):
    mode: NotRequired[InputSystemMetricsMemoryMode]
    r"""Select the level of detail for memory metrics"""
    detail: NotRequired[bool]
    r"""Generate metrics for all memory states"""


class InputSystemMetricsMemory(BaseModel):
    mode: Optional[InputSystemMetricsMemoryMode] = None
    r"""Select the level of detail for memory metrics"""

    detail: Optional[bool] = None
    r"""Generate metrics for all memory states"""

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemMetricsMemoryMode(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["mode", "detail"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsNetworkMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Select the level of detail for network metrics"""

    # Basic
    BASIC = "basic"
    # All
    ALL = "all"
    # Custom
    CUSTOM = "custom"
    # Disabled
    DISABLED = "disabled"


class InputSystemMetricsNetworkTypedDict(TypedDict):
    mode: NotRequired[InputSystemMetricsNetworkMode]
    r"""Select the level of detail for network metrics"""
    detail: NotRequired[bool]
    r"""Generate full network metrics"""
    protocols: NotRequired[bool]
    r"""Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite"""
    devices: NotRequired[List[str]]
    r"""Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty."""
    per_interface: NotRequired[bool]
    r"""Generate separate metrics for each interface"""


class InputSystemMetricsNetwork(BaseModel):
    mode: Optional[InputSystemMetricsNetworkMode] = None
    r"""Select the level of detail for network metrics"""

    detail: Optional[bool] = None
    r"""Generate full network metrics"""

    protocols: Optional[bool] = None
    r"""Generate protocol metrics for ICMP, ICMPMsg, IP, TCP, UDP and UDPLite"""

    devices: Optional[List[str]] = None
    r"""Network interfaces to include/exclude. Examples: eth0, !lo. All interfaces are included if this list is empty."""

    per_interface: Annotated[Optional[bool], pydantic.Field(alias="perInterface")] = (
        None
    )
    r"""Generate separate metrics for each interface"""

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemMetricsNetworkMode(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            ["mode", "detail", "protocols", "devices", "perInterface"]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsDiskMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Select the level of detail for disk metrics"""

    # Basic
    BASIC = "basic"
    # All
    ALL = "all"
    # Custom
    CUSTOM = "custom"
    # Disabled
    DISABLED = "disabled"


class InputSystemMetricsDiskTypedDict(TypedDict):
    mode: NotRequired[InputSystemMetricsDiskMode]
    r"""Select the level of detail for disk metrics"""
    detail: NotRequired[bool]
    r"""Generate full disk metrics"""
    inodes: NotRequired[bool]
    r"""Generate filesystem inode metrics"""
    devices: NotRequired[List[str]]
    r"""Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty."""
    mountpoints: NotRequired[List[str]]
    r"""Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty."""
    fstypes: NotRequired[List[str]]
    r"""Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty."""
    per_device: NotRequired[bool]
    r"""Generate separate metrics for each device"""


class InputSystemMetricsDisk(BaseModel):
    mode: Optional[InputSystemMetricsDiskMode] = None
    r"""Select the level of detail for disk metrics"""

    detail: Optional[bool] = None
    r"""Generate full disk metrics"""

    inodes: Optional[bool] = None
    r"""Generate filesystem inode metrics"""

    devices: Optional[List[str]] = None
    r"""Block devices to include/exclude. Examples: sda*, !loop*. Wildcards and ! (not) operators are supported. All devices are included if this list is empty."""

    mountpoints: Optional[List[str]] = None
    r"""Filesystem mountpoints to include/exclude. Examples: /, /home, !/proc*, !/tmp. Wildcards and ! (not) operators are supported. All mountpoints are included if this list is empty."""

    fstypes: Optional[List[str]] = None
    r"""Filesystem types to include/exclude. Examples: ext4, !*tmpfs, !squashfs. Wildcards and ! (not) operators are supported. All types are included if this list is empty."""

    per_device: Annotated[Optional[bool], pydantic.Field(alias="perDevice")] = None
    r"""Generate separate metrics for each device"""

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemMetricsDiskMode(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "mode",
                "detail",
                "inodes",
                "devices",
                "mountpoints",
                "fstypes",
                "perDevice",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsCustomTypedDict(TypedDict):
    system: NotRequired[InputSystemMetricsSystemTypedDict]
    cpu: NotRequired[InputSystemMetricsCPUTypedDict]
    memory: NotRequired[InputSystemMetricsMemoryTypedDict]
    network: NotRequired[InputSystemMetricsNetworkTypedDict]
    disk: NotRequired[InputSystemMetricsDiskTypedDict]


class InputSystemMetricsCustom(BaseModel):
    system: Optional[InputSystemMetricsSystem] = None

    cpu: Optional[InputSystemMetricsCPU] = None

    memory: Optional[InputSystemMetricsMemory] = None

    network: Optional[InputSystemMetricsNetwork] = None

    disk: Optional[InputSystemMetricsDisk] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["system", "cpu", "memory", "network", "disk"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsHostTypedDict(TypedDict):
    mode: NotRequired[ModeOptionsHost]
    r"""Select level of detail for host metrics"""
    custom: NotRequired[InputSystemMetricsCustomTypedDict]


class InputSystemMetricsHost(BaseModel):
    mode: Optional[ModeOptionsHost] = None
    r"""Select level of detail for host metrics"""

    custom: Optional[InputSystemMetricsCustom] = None

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.ModeOptionsHost(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["mode", "custom"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsContainerMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Select the level of detail for container metrics"""

    # Basic
    BASIC = "basic"
    # All
    ALL = "all"
    # Custom
    CUSTOM = "custom"
    # Disabled
    DISABLED = "disabled"


class InputSystemMetricsFilterTypedDict(TypedDict):
    expr: str


class InputSystemMetricsFilter(BaseModel):
    expr: str


class ContainerTypedDict(TypedDict):
    mode: NotRequired[InputSystemMetricsContainerMode]
    r"""Select the level of detail for container metrics"""
    docker_socket: NotRequired[List[str]]
    r"""Full paths for Docker's UNIX-domain socket"""
    docker_timeout: NotRequired[float]
    r"""Timeout, in seconds, for the Docker API"""
    filters: NotRequired[List[InputSystemMetricsFilterTypedDict]]
    r"""Containers matching any of these will be included. All are included if no filters are added."""
    all_containers: NotRequired[bool]
    r"""Include stopped and paused containers"""
    per_device: NotRequired[bool]
    r"""Generate separate metrics for each device"""
    detail: NotRequired[bool]
    r"""Generate full container metrics"""


class Container(BaseModel):
    mode: Optional[InputSystemMetricsContainerMode] = None
    r"""Select the level of detail for container metrics"""

    docker_socket: Annotated[
        Optional[List[str]], pydantic.Field(alias="dockerSocket")
    ] = None
    r"""Full paths for Docker's UNIX-domain socket"""

    docker_timeout: Annotated[
        Optional[float], pydantic.Field(alias="dockerTimeout")
    ] = None
    r"""Timeout, in seconds, for the Docker API"""

    filters: Optional[List[InputSystemMetricsFilter]] = None
    r"""Containers matching any of these will be included. All are included if no filters are added."""

    all_containers: Annotated[Optional[bool], pydantic.Field(alias="allContainers")] = (
        None
    )
    r"""Include stopped and paused containers"""

    per_device: Annotated[Optional[bool], pydantic.Field(alias="perDevice")] = None
    r"""Generate separate metrics for each device"""

    detail: Optional[bool] = None
    r"""Generate full container metrics"""

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemMetricsContainerMode(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "mode",
                "dockerSocket",
                "dockerTimeout",
                "filters",
                "allContainers",
                "perDevice",
                "detail",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsPersistenceTypedDict(TypedDict):
    enable: NotRequired[bool]
    r"""Spool metrics to disk for Cribl Edge and Search"""
    time_window: NotRequired[str]
    r"""Time span for each file bucket"""
    max_data_size: NotRequired[str]
    r"""Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted."""
    max_data_time: NotRequired[str]
    r"""Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted."""
    compress: NotRequired[DataCompressionFormatOptionsPersistence]
    dest_path: NotRequired[str]
    r"""Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics"""


class InputSystemMetricsPersistence(BaseModel):
    enable: Optional[bool] = None
    r"""Spool metrics to disk for Cribl Edge and Search"""

    time_window: Annotated[Optional[str], pydantic.Field(alias="timeWindow")] = None
    r"""Time span for each file bucket"""

    max_data_size: Annotated[Optional[str], pydantic.Field(alias="maxDataSize")] = None
    r"""Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted."""

    max_data_time: Annotated[Optional[str], pydantic.Field(alias="maxDataTime")] = None
    r"""Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted."""

    compress: Optional[DataCompressionFormatOptionsPersistence] = None

    dest_path: Annotated[Optional[str], pydantic.Field(alias="destPath")] = None
    r"""Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_metrics"""

    @field_serializer("compress")
    def serialize_compress(self, value):
        if isinstance(value, str):
            try:
                return models.DataCompressionFormatOptionsPersistence(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "enable",
                "timeWindow",
                "maxDataSize",
                "maxDataTime",
                "compress",
                "destPath",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class InputSystemMetricsTypedDict(TypedDict):
    type: InputSystemMetricsType
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ItemsTypeConnectionsOptionalTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    interval: NotRequired[float]
    r"""Time, in seconds, between consecutive metric collections. Default is 10 seconds."""
    host: NotRequired[InputSystemMetricsHostTypedDict]
    process: NotRequired[ProcessTypeTypedDict]
    container: NotRequired[ContainerTypedDict]
    metadata: NotRequired[List[ItemsTypeMetadataTypedDict]]
    r"""Fields to add to events from this input"""
    persistence: NotRequired[InputSystemMetricsPersistenceTypedDict]
    description: NotRequired[str]


class InputSystemMetrics(BaseModel):
    type: InputSystemMetricsType

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = None

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        None
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = None
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ItemsTypeConnectionsOptional]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    interval: Optional[float] = None
    r"""Time, in seconds, between consecutive metric collections. Default is 10 seconds."""

    host: Optional[InputSystemMetricsHost] = None

    process: Optional[ProcessType] = None

    container: Optional[Container] = None

    metadata: Optional[List[ItemsTypeMetadata]] = None
    r"""Fields to add to events from this input"""

    persistence: Optional[InputSystemMetricsPersistence] = None

    description: Optional[str] = None

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "id",
                "disabled",
                "pipeline",
                "sendToRoutes",
                "environment",
                "pqEnabled",
                "streamtags",
                "connections",
                "pq",
                "interval",
                "host",
                "process",
                "container",
                "metadata",
                "persistence",
                "description",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
