"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from enum import Enum
import pydantic
from pydantic import model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class PipelineFunctionLakeExportID(str, Enum):
    r"""Function ID"""

    LAKE_EXPORT = "lake_export"


class LakeExportConfigurationTypedDict(TypedDict):
    search_job_id: str
    r"""Id of the search job this function is running on."""
    dataset: str
    r"""Name of the dataset"""
    lake: NotRequired[str]
    r"""Name of the lake"""
    tee: NotRequired[bool]
    r"""Tee results to search. When set to true results will be shipped instead of stats"""
    flush_ms: NotRequired[float]
    r"""How often are stats flushed in ms"""
    suppress_previews: NotRequired[bool]
    r"""Disables generation of intermediate stats. When true stats will be emitted only on end"""


class LakeExportConfiguration(BaseModel):
    search_job_id: Annotated[str, pydantic.Field(alias="searchJobId")]
    r"""Id of the search job this function is running on."""

    dataset: str
    r"""Name of the dataset"""

    lake: Optional[str] = None
    r"""Name of the lake"""

    tee: Optional[bool] = None
    r"""Tee results to search. When set to true results will be shipped instead of stats"""

    flush_ms: Annotated[Optional[float], pydantic.Field(alias="flushMs")] = None
    r"""How often are stats flushed in ms"""

    suppress_previews: Annotated[
        Optional[bool], pydantic.Field(alias="suppressPreviews")
    ] = None
    r"""Disables generation of intermediate stats. When true stats will be emitted only on end"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["lake", "tee", "flushMs", "suppressPreviews"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class PipelineFunctionLakeExportTypedDict(TypedDict):
    id: PipelineFunctionLakeExportID
    r"""Function ID"""
    conf: LakeExportConfigurationTypedDict
    filter_: NotRequired[str]
    r"""Filter that selects data to be fed through this Function"""
    description: NotRequired[str]
    r"""Simple description of this step"""
    disabled: NotRequired[bool]
    r"""If true, data will not be pushed through this function"""
    final: NotRequired[bool]
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""
    group_id: NotRequired[str]
    r"""Group ID"""


class PipelineFunctionLakeExport(BaseModel):
    id: PipelineFunctionLakeExportID
    r"""Function ID"""

    conf: LakeExportConfiguration

    filter_: Annotated[Optional[str], pydantic.Field(alias="filter")] = None
    r"""Filter that selects data to be fed through this Function"""

    description: Optional[str] = None
    r"""Simple description of this step"""

    disabled: Optional[bool] = None
    r"""If true, data will not be pushed through this function"""

    final: Optional[bool] = None
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""

    group_id: Annotated[Optional[str], pydantic.Field(alias="groupId")] = None
    r"""Group ID"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["filter", "description", "disabled", "final", "groupId"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
