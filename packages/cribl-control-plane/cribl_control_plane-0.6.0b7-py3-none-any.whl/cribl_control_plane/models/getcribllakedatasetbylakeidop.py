"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from cribl_control_plane.utils import (
    FieldMetadata,
    PathParamMetadata,
    QueryParamMetadata,
)
import pydantic
from pydantic import model_serializer
from typing import Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class GetCriblLakeDatasetByLakeIDRequestTypedDict(TypedDict):
    lake_id: str
    r"""The <code>id</code> of the Lake that contains the Lake Datasets to list."""
    storage_location_id: NotRequired[str]
    r"""Filter datasets by storage location ID. Use <code>default</code> for default storage location."""
    format_: NotRequired[str]
    r"""Filter datasets by format. Set to <code>ddss</code> to return only DDSS datasets."""
    exclude_ddss: NotRequired[bool]
    r"""Exclude DDSS format datasets from the response."""
    exclude_deleted: NotRequired[bool]
    r"""Exclude deleted datasets from the response."""
    exclude_internal: NotRequired[bool]
    r"""Exclude internal datasets (those with IDs starting with <code>cribl_</code>) from the response."""
    exclude_byos: NotRequired[bool]
    r"""Exclude BYOS (Bring Your Own Storage) datasets from the response."""


class GetCriblLakeDatasetByLakeIDRequest(BaseModel):
    lake_id: Annotated[
        str,
        pydantic.Field(alias="lakeId"),
        FieldMetadata(path=PathParamMetadata(style="simple", explode=False)),
    ]
    r"""The <code>id</code> of the Lake that contains the Lake Datasets to list."""

    storage_location_id: Annotated[
        Optional[str],
        pydantic.Field(alias="storageLocationId"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None
    r"""Filter datasets by storage location ID. Use <code>default</code> for default storage location."""

    format_: Annotated[
        Optional[str],
        pydantic.Field(alias="format"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None
    r"""Filter datasets by format. Set to <code>ddss</code> to return only DDSS datasets."""

    exclude_ddss: Annotated[
        Optional[bool],
        pydantic.Field(alias="excludeDDSS"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None
    r"""Exclude DDSS format datasets from the response."""

    exclude_deleted: Annotated[
        Optional[bool],
        pydantic.Field(alias="excludeDeleted"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None
    r"""Exclude deleted datasets from the response."""

    exclude_internal: Annotated[
        Optional[bool],
        pydantic.Field(alias="excludeInternal"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None
    r"""Exclude internal datasets (those with IDs starting with <code>cribl_</code>) from the response."""

    exclude_byos: Annotated[
        Optional[bool],
        pydantic.Field(alias="excludeBYOS"),
        FieldMetadata(query=QueryParamMetadata(style="form", explode=True)),
    ] = None
    r"""Exclude BYOS (Bring Your Own Storage) datasets from the response."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "storageLocationId",
                "format",
                "excludeDDSS",
                "excludeDeleted",
                "excludeInternal",
                "excludeBYOS",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
