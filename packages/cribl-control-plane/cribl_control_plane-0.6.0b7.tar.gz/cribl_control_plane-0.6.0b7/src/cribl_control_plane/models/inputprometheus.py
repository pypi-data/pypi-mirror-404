"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .authenticationmethodoptionss3collectorconf import (
    AuthenticationMethodOptionsS3CollectorConf,
)
from .authenticationmethodoptionssasl import AuthenticationMethodOptionsSasl
from .itemstypeconnectionsoptional import (
    ItemsTypeConnectionsOptional,
    ItemsTypeConnectionsOptionalTypedDict,
)
from .itemstypemetadata import ItemsTypeMetadata, ItemsTypeMetadataTypedDict
from .itemstypesearchfilter import ItemsTypeSearchFilter, ItemsTypeSearchFilterTypedDict
from .pqtype import PqType, PqTypeTypedDict
from .recordtypeoptions import RecordTypeOptions
from .signatureversionoptions1 import SignatureVersionOptions1
from cribl_control_plane import models, utils
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from enum import Enum
import pydantic
from pydantic import field_serializer, model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class InputPrometheusType(str, Enum):
    PROMETHEUS = "prometheus"


class InputPrometheusDiscoveryType(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Target discovery mechanism. Use static to manually enter a list of targets."""

    # Static
    STATIC = "static"
    # DNS
    DNS = "dns"
    # AWS EC2
    EC2 = "ec2"


class InputPrometheusLogLevel(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Collector runtime log level"""

    ERROR = "error"
    WARN = "warn"
    INFO = "info"
    DEBUG = "debug"


class MetricsProtocol(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Protocol to use when collecting metrics"""

    HTTP = "http"
    HTTPS = "https"


class InputPrometheusTypedDict(TypedDict):
    type: InputPrometheusType
    interval: float
    r"""How often, in minutes, to scrape targets for metrics. Maximum of 60 minutes. 60 must be evenly divisible by the value you enter."""
    log_level: InputPrometheusLogLevel
    r"""Collector runtime log level"""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ItemsTypeConnectionsOptionalTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    dimension_list: NotRequired[List[str]]
    r"""Other dimensions to include in events"""
    discovery_type: NotRequired[InputPrometheusDiscoveryType]
    r"""Target discovery mechanism. Use static to manually enter a list of targets."""
    reject_unauthorized: NotRequired[bool]
    r"""Reject certificates that cannot be verified against a valid CA, such as self-signed certificates"""
    timeout: NotRequired[float]
    r"""Time, in seconds, before aborting HTTP connection attempts; use 0 for no timeout"""
    keep_alive_time: NotRequired[float]
    r"""How often workers should check in with the scheduler to keep job subscription alive"""
    job_timeout: NotRequired[str]
    r"""Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time."""
    max_missed_keep_alives: NotRequired[float]
    r"""The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked."""
    ttl: NotRequired[str]
    r"""Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector."""
    ignore_group_jobs_limit: NotRequired[bool]
    r"""When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live."""
    metadata: NotRequired[List[ItemsTypeMetadataTypedDict]]
    r"""Fields to add to events from this input"""
    auth_type: NotRequired[AuthenticationMethodOptionsSasl]
    r"""Enter credentials directly, or select a stored secret"""
    description: NotRequired[str]
    target_list: NotRequired[List[str]]
    r"""List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'."""
    record_type: NotRequired[RecordTypeOptions]
    r"""DNS record type to resolve"""
    scrape_port: NotRequired[float]
    r"""The port number in the metrics URL for discovered targets"""
    name_list: NotRequired[List[str]]
    r"""List of DNS names to resolve"""
    scrape_protocol: NotRequired[MetricsProtocol]
    r"""Protocol to use when collecting metrics"""
    scrape_path: NotRequired[str]
    r"""Path to use when collecting metrics from discovered targets"""
    aws_authentication_method: NotRequired[AuthenticationMethodOptionsS3CollectorConf]
    r"""AWS authentication method. Choose Auto to use IAM roles."""
    aws_api_key: NotRequired[str]
    aws_secret: NotRequired[str]
    r"""Select or create a stored secret that references your access key and secret key"""
    use_public_ip: NotRequired[bool]
    r"""Use public IP address for discovered targets. Disable to use the private IP address."""
    search_filter: NotRequired[List[ItemsTypeSearchFilterTypedDict]]
    r"""Filter to apply when searching for EC2 instances"""
    aws_secret_key: NotRequired[str]
    region: NotRequired[str]
    r"""Region where the EC2 is located"""
    endpoint: NotRequired[str]
    r"""EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint."""
    signature_version: NotRequired[SignatureVersionOptions1]
    r"""Signature version to use for signing EC2 requests"""
    reuse_connections: NotRequired[bool]
    r"""Reuse connections between requests, which can improve performance"""
    enable_assume_role: NotRequired[bool]
    r"""Use Assume Role credentials to access EC2"""
    assume_role_arn: NotRequired[str]
    r"""Amazon Resource Name (ARN) of the role to assume"""
    assume_role_external_id: NotRequired[str]
    r"""External ID to use when assuming role"""
    duration_seconds: NotRequired[float]
    r"""Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours)."""
    username: NotRequired[str]
    r"""Username for Prometheus Basic authentication"""
    password: NotRequired[str]
    r"""Password for Prometheus Basic authentication"""
    credentials_secret: NotRequired[str]
    r"""Select or create a secret that references your credentials"""
    template_log_level: NotRequired[str]
    r"""Binds 'logLevel' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'logLevel' at runtime."""
    template_aws_api_key: NotRequired[str]
    r"""Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime."""
    template_aws_secret_key: NotRequired[str]
    r"""Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime."""
    template_region: NotRequired[str]
    r"""Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime."""
    template_assume_role_arn: NotRequired[str]
    r"""Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime."""
    template_assume_role_external_id: NotRequired[str]
    r"""Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime."""


class InputPrometheus(BaseModel):
    type: InputPrometheusType

    interval: float
    r"""How often, in minutes, to scrape targets for metrics. Maximum of 60 minutes. 60 must be evenly divisible by the value you enter."""

    log_level: Annotated[InputPrometheusLogLevel, pydantic.Field(alias="logLevel")]
    r"""Collector runtime log level"""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = None

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        None
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = None
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ItemsTypeConnectionsOptional]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    dimension_list: Annotated[
        Optional[List[str]], pydantic.Field(alias="dimensionList")
    ] = None
    r"""Other dimensions to include in events"""

    discovery_type: Annotated[
        Optional[InputPrometheusDiscoveryType], pydantic.Field(alias="discoveryType")
    ] = None
    r"""Target discovery mechanism. Use static to manually enter a list of targets."""

    reject_unauthorized: Annotated[
        Optional[bool], pydantic.Field(alias="rejectUnauthorized")
    ] = None
    r"""Reject certificates that cannot be verified against a valid CA, such as self-signed certificates"""

    timeout: Optional[float] = None
    r"""Time, in seconds, before aborting HTTP connection attempts; use 0 for no timeout"""

    keep_alive_time: Annotated[
        Optional[float], pydantic.Field(alias="keepAliveTime")
    ] = None
    r"""How often workers should check in with the scheduler to keep job subscription alive"""

    job_timeout: Annotated[Optional[str], pydantic.Field(alias="jobTimeout")] = None
    r"""Maximum time the job is allowed to run (e.g., 30, 45s or 15m). Units are seconds, if not specified. Enter 0 for unlimited time."""

    max_missed_keep_alives: Annotated[
        Optional[float], pydantic.Field(alias="maxMissedKeepAlives")
    ] = None
    r"""The number of Keep Alive Time periods before an inactive worker will have its job subscription revoked."""

    ttl: Optional[str] = None
    r"""Time to keep the job's artifacts on disk after job completion. This also affects how long a job is listed in the Job Inspector."""

    ignore_group_jobs_limit: Annotated[
        Optional[bool], pydantic.Field(alias="ignoreGroupJobsLimit")
    ] = None
    r"""When enabled, this job's artifacts are not counted toward the Worker Group's finished job artifacts limit. Artifacts will be removed only after the Collector's configured time to live."""

    metadata: Optional[List[ItemsTypeMetadata]] = None
    r"""Fields to add to events from this input"""

    auth_type: Annotated[
        Optional[AuthenticationMethodOptionsSasl], pydantic.Field(alias="authType")
    ] = None
    r"""Enter credentials directly, or select a stored secret"""

    description: Optional[str] = None

    target_list: Annotated[Optional[List[str]], pydantic.Field(alias="targetList")] = (
        None
    )
    r"""List of Prometheus targets to pull metrics from. Values can be in URL or host[:port] format. For example: http://localhost:9090/metrics, localhost:9090, or localhost. In cases where just host[:port] is specified, the endpoint will resolve to 'http://host[:port]/metrics'."""

    record_type: Annotated[
        Optional[RecordTypeOptions], pydantic.Field(alias="recordType")
    ] = None
    r"""DNS record type to resolve"""

    scrape_port: Annotated[Optional[float], pydantic.Field(alias="scrapePort")] = None
    r"""The port number in the metrics URL for discovered targets"""

    name_list: Annotated[Optional[List[str]], pydantic.Field(alias="nameList")] = None
    r"""List of DNS names to resolve"""

    scrape_protocol: Annotated[
        Optional[MetricsProtocol], pydantic.Field(alias="scrapeProtocol")
    ] = None
    r"""Protocol to use when collecting metrics"""

    scrape_path: Annotated[Optional[str], pydantic.Field(alias="scrapePath")] = None
    r"""Path to use when collecting metrics from discovered targets"""

    aws_authentication_method: Annotated[
        Optional[AuthenticationMethodOptionsS3CollectorConf],
        pydantic.Field(alias="awsAuthenticationMethod"),
    ] = None
    r"""AWS authentication method. Choose Auto to use IAM roles."""

    aws_api_key: Annotated[Optional[str], pydantic.Field(alias="awsApiKey")] = None

    aws_secret: Annotated[Optional[str], pydantic.Field(alias="awsSecret")] = None
    r"""Select or create a stored secret that references your access key and secret key"""

    use_public_ip: Annotated[Optional[bool], pydantic.Field(alias="usePublicIp")] = None
    r"""Use public IP address for discovered targets. Disable to use the private IP address."""

    search_filter: Annotated[
        Optional[List[ItemsTypeSearchFilter]], pydantic.Field(alias="searchFilter")
    ] = None
    r"""Filter to apply when searching for EC2 instances"""

    aws_secret_key: Annotated[Optional[str], pydantic.Field(alias="awsSecretKey")] = (
        None
    )

    region: Optional[str] = None
    r"""Region where the EC2 is located"""

    endpoint: Optional[str] = None
    r"""EC2 service endpoint. If empty, defaults to the AWS Region-specific endpoint. Otherwise, it must point to EC2-compatible endpoint."""

    signature_version: Annotated[
        Optional[SignatureVersionOptions1], pydantic.Field(alias="signatureVersion")
    ] = None
    r"""Signature version to use for signing EC2 requests"""

    reuse_connections: Annotated[
        Optional[bool], pydantic.Field(alias="reuseConnections")
    ] = None
    r"""Reuse connections between requests, which can improve performance"""

    enable_assume_role: Annotated[
        Optional[bool], pydantic.Field(alias="enableAssumeRole")
    ] = None
    r"""Use Assume Role credentials to access EC2"""

    assume_role_arn: Annotated[Optional[str], pydantic.Field(alias="assumeRoleArn")] = (
        None
    )
    r"""Amazon Resource Name (ARN) of the role to assume"""

    assume_role_external_id: Annotated[
        Optional[str], pydantic.Field(alias="assumeRoleExternalId")
    ] = None
    r"""External ID to use when assuming role"""

    duration_seconds: Annotated[
        Optional[float], pydantic.Field(alias="durationSeconds")
    ] = None
    r"""Duration of the assumed role's session, in seconds. Minimum is 900 (15 minutes), default is 3600 (1 hour), and maximum is 43200 (12 hours)."""

    username: Optional[str] = None
    r"""Username for Prometheus Basic authentication"""

    password: Optional[str] = None
    r"""Password for Prometheus Basic authentication"""

    credentials_secret: Annotated[
        Optional[str], pydantic.Field(alias="credentialsSecret")
    ] = None
    r"""Select or create a secret that references your credentials"""

    template_log_level: Annotated[
        Optional[str], pydantic.Field(alias="__template_logLevel")
    ] = None
    r"""Binds 'logLevel' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'logLevel' at runtime."""

    template_aws_api_key: Annotated[
        Optional[str], pydantic.Field(alias="__template_awsApiKey")
    ] = None
    r"""Binds 'awsApiKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsApiKey' at runtime."""

    template_aws_secret_key: Annotated[
        Optional[str], pydantic.Field(alias="__template_awsSecretKey")
    ] = None
    r"""Binds 'awsSecretKey' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'awsSecretKey' at runtime."""

    template_region: Annotated[
        Optional[str], pydantic.Field(alias="__template_region")
    ] = None
    r"""Binds 'region' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'region' at runtime."""

    template_assume_role_arn: Annotated[
        Optional[str], pydantic.Field(alias="__template_assumeRoleArn")
    ] = None
    r"""Binds 'assumeRoleArn' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleArn' at runtime."""

    template_assume_role_external_id: Annotated[
        Optional[str], pydantic.Field(alias="__template_assumeRoleExternalId")
    ] = None
    r"""Binds 'assumeRoleExternalId' to a variable for dynamic value resolution. Set to variable ID (pack-scoped) or 'cribl.'/'edge.' prefixed ID (group-scoped). Variable value overrides 'assumeRoleExternalId' at runtime."""

    @field_serializer("discovery_type")
    def serialize_discovery_type(self, value):
        if isinstance(value, str):
            try:
                return models.InputPrometheusDiscoveryType(value)
            except ValueError:
                return value
        return value

    @field_serializer("log_level")
    def serialize_log_level(self, value):
        if isinstance(value, str):
            try:
                return models.InputPrometheusLogLevel(value)
            except ValueError:
                return value
        return value

    @field_serializer("auth_type")
    def serialize_auth_type(self, value):
        if isinstance(value, str):
            try:
                return models.AuthenticationMethodOptionsSasl(value)
            except ValueError:
                return value
        return value

    @field_serializer("record_type")
    def serialize_record_type(self, value):
        if isinstance(value, str):
            try:
                return models.RecordTypeOptions(value)
            except ValueError:
                return value
        return value

    @field_serializer("scrape_protocol")
    def serialize_scrape_protocol(self, value):
        if isinstance(value, str):
            try:
                return models.MetricsProtocol(value)
            except ValueError:
                return value
        return value

    @field_serializer("aws_authentication_method")
    def serialize_aws_authentication_method(self, value):
        if isinstance(value, str):
            try:
                return models.AuthenticationMethodOptionsS3CollectorConf(value)
            except ValueError:
                return value
        return value

    @field_serializer("signature_version")
    def serialize_signature_version(self, value):
        if isinstance(value, str):
            try:
                return models.SignatureVersionOptions1(value)
            except ValueError:
                return value
        return value

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(
            [
                "id",
                "disabled",
                "pipeline",
                "sendToRoutes",
                "environment",
                "pqEnabled",
                "streamtags",
                "connections",
                "pq",
                "dimensionList",
                "discoveryType",
                "rejectUnauthorized",
                "timeout",
                "keepAliveTime",
                "jobTimeout",
                "maxMissedKeepAlives",
                "ttl",
                "ignoreGroupJobsLimit",
                "metadata",
                "authType",
                "description",
                "targetList",
                "recordType",
                "scrapePort",
                "nameList",
                "scrapeProtocol",
                "scrapePath",
                "awsAuthenticationMethod",
                "awsApiKey",
                "awsSecret",
                "usePublicIp",
                "searchFilter",
                "awsSecretKey",
                "region",
                "endpoint",
                "signatureVersion",
                "reuseConnections",
                "enableAssumeRole",
                "assumeRoleArn",
                "assumeRoleExternalId",
                "durationSeconds",
                "username",
                "password",
                "credentialsSecret",
                "__template_logLevel",
                "__template_awsApiKey",
                "__template_awsSecretKey",
                "__template_region",
                "__template_assumeRoleArn",
                "__template_assumeRoleExternalId",
            ]
        )
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
