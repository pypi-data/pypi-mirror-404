"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel, UNSET_SENTINEL
from enum import Enum
import pydantic
from pydantic import model_serializer
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class PipelineFunctionEventstatsID(str, Enum):
    r"""Function ID"""

    EVENTSTATS = "eventstats"


class EventstatsConfigurationTypedDict(TypedDict):
    aggregations: List[str]
    r"""Aggregate function(s) to perform on events. E.g., sum(bytes).where(action=='REJECT').as(TotalBytes)"""
    group_bys: NotRequired[List[str]]
    r"""Fields to group aggregates by, supports wildcard expressions."""
    max_events: NotRequired[float]
    r"""Specifies how many events are at max kept in memory to be enriched with aggregations"""
    flush_on_input_close: NotRequired[bool]
    r"""Determines if aggregations should flush when an input stream is closed. If disabled, time window settings will control flush behavior."""


class EventstatsConfiguration(BaseModel):
    aggregations: List[str]
    r"""Aggregate function(s) to perform on events. E.g., sum(bytes).where(action=='REJECT').as(TotalBytes)"""

    group_bys: Annotated[Optional[List[str]], pydantic.Field(alias="groupBys")] = None
    r"""Fields to group aggregates by, supports wildcard expressions."""

    max_events: Annotated[Optional[float], pydantic.Field(alias="maxEvents")] = None
    r"""Specifies how many events are at max kept in memory to be enriched with aggregations"""

    flush_on_input_close: Annotated[
        Optional[bool], pydantic.Field(alias="flushOnInputClose")
    ] = None
    r"""Determines if aggregations should flush when an input stream is closed. If disabled, time window settings will control flush behavior."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["groupBys", "maxEvents", "flushOnInputClose"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m


class PipelineFunctionEventstatsTypedDict(TypedDict):
    id: PipelineFunctionEventstatsID
    r"""Function ID"""
    conf: EventstatsConfigurationTypedDict
    filter_: NotRequired[str]
    r"""Filter that selects data to be fed through this Function"""
    description: NotRequired[str]
    r"""Simple description of this step"""
    disabled: NotRequired[bool]
    r"""If true, data will not be pushed through this function"""
    final: NotRequired[bool]
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""
    group_id: NotRequired[str]
    r"""Group ID"""


class PipelineFunctionEventstats(BaseModel):
    id: PipelineFunctionEventstatsID
    r"""Function ID"""

    conf: EventstatsConfiguration

    filter_: Annotated[Optional[str], pydantic.Field(alias="filter")] = None
    r"""Filter that selects data to be fed through this Function"""

    description: Optional[str] = None
    r"""Simple description of this step"""

    disabled: Optional[bool] = None
    r"""If true, data will not be pushed through this function"""

    final: Optional[bool] = None
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""

    group_id: Annotated[Optional[str], pydantic.Field(alias="groupId")] = None
    r"""Group ID"""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = set(["filter", "description", "disabled", "final", "groupId"])
        serialized = handler(self)
        m = {}

        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)

            if val != UNSET_SENTINEL:
                if val is not None or k not in optional_fields:
                    m[k] = val

        return m
