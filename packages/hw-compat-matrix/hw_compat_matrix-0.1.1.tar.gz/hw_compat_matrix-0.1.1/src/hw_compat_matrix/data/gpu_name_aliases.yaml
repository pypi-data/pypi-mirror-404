# GPU Name Aliases by Cloud Provider
# Normalizes provider-specific GPU names to canonical names
schema_version: 1
canonical_gpus:
  # Blackwell
  - canonical_name: "B100"
    sm: "100"
    architecture: "Blackwell"
    aliases:
      vastai: ["B100"]
      aws: ["NVIDIA B100"]
      azure: ["B100"]
      lambda: ["B100"]
      runpod: ["B100"]

  - canonical_name: "B200"
    sm: "100"
    architecture: "Blackwell"
    aliases:
      vastai: ["B200"]
      aws: ["NVIDIA B200"]
      azure: ["B200"]
      lambda: ["B200"]
      runpod: ["B200"]

  - canonical_name: "RTX 5090"
    sm: "120"
    architecture: "Blackwell"
    aliases:
      vastai: ["RTX_5090", "RTX5090", "NVIDIA RTX 5090"]
      aws: ["NVIDIA GeForce RTX 5090"]
      lambda: ["RTX 5090"]
      runpod: ["RTX5090"]

  # Hopper
  - canonical_name: "H100"
    sm: "90"
    architecture: "Hopper"
    aliases:
      vastai: ["H100_SXM", "H100_PCIe", "H100_SXM5", "H100_PCIE", "H100 SXM5 80GB", "H100 PCIe"]
      aws: ["NVIDIA H100 80GB HBM3", "NVIDIA H100 Tensor Core GPU"]
      azure: ["Standard_NC40ads_H100_v5", "H100 80GB", "NVIDIA H100 80GB PCIe"]
      gcp: ["nvidia-h100-80gb"]
      lambda: ["gpu_1x_h100_pcie", "gpu_1x_h100_sxm5", "H100 PCIe", "H100 SXM5"]
      runpod: ["H100", "H100 PCIe", "H100 SXM5"]
      coreweave: ["H100_PCIE", "H100_SXM5"]

  - canonical_name: "H200"
    sm: "90"
    architecture: "Hopper"
    aliases:
      vastai: ["H200", "H200_SXM"]
      aws: ["NVIDIA H200"]
      azure: ["H200"]
      lambda: ["H200"]
      runpod: ["H200"]

  # Ada Lovelace
  - canonical_name: "RTX 4090"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["RTX_4090", "RTX4090", "NVIDIA RTX 4090", "GeForce RTX 4090"]
      aws: ["NVIDIA GeForce RTX 4090"]
      azure: ["RTX 4090"]
      lambda: ["gpu_1x_rtx4090", "RTX 4090"]
      runpod: ["RTX4090", "RTX 4090"]
      coreweave: ["RTX_A4090"]

  - canonical_name: "RTX 4080"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["RTX_4080", "RTX4080", "NVIDIA RTX 4080", "GeForce RTX 4080"]
      aws: ["NVIDIA GeForce RTX 4080"]
      lambda: ["RTX 4080"]
      runpod: ["RTX4080", "RTX 4080"]

  - canonical_name: "RTX 4080 Super"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["RTX_4080_Super", "RTX4080_Super", "RTX 4080 Super"]
      lambda: ["RTX 4080 Super"]
      runpod: ["RTX 4080 Super"]

  - canonical_name: "RTX 4070 Ti"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["RTX_4070_Ti", "RTX4070Ti", "RTX 4070 Ti"]
      lambda: ["RTX 4070 Ti"]
      runpod: ["RTX4070Ti", "RTX 4070 Ti"]

  - canonical_name: "RTX 4070"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["RTX_4070", "RTX4070", "RTX 4070"]
      lambda: ["RTX 4070"]
      runpod: ["RTX4070", "RTX 4070"]

  - canonical_name: "L40"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["L40", "NVIDIA L40"]
      aws: ["NVIDIA L40"]
      azure: ["Standard_NC24ads_L40_v3", "NVIDIA L40"]
      gcp: ["nvidia-l40"]
      lambda: ["gpu_1x_l40", "L40"]
      runpod: ["L40"]
      coreweave: ["L40"]

  - canonical_name: "L40S"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["L40S", "NVIDIA L40S"]
      aws: ["NVIDIA L40S"]
      azure: ["NVIDIA L40S"]
      lambda: ["L40S"]
      runpod: ["L40S"]
      coreweave: ["L40S"]

  - canonical_name: "L4"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["L4", "NVIDIA L4"]
      aws: ["NVIDIA L4"]
      gcp: ["nvidia-l4", "NVIDIA L4"]
      lambda: ["L4"]
      runpod: ["L4"]

  - canonical_name: "RTX 6000 Ada"
    sm: "89"
    architecture: "Ada Lovelace"
    aliases:
      vastai: ["RTX_6000_Ada", "RTX6000_Ada", "NVIDIA RTX 6000 Ada Generation"]
      lambda: ["RTX 6000 Ada"]
      runpod: ["RTX 6000 Ada"]

  # Ampere
  - canonical_name: "A100"
    sm: "80"
    architecture: "Ampere"
    aliases:
      vastai: ["A100_SXM4", "A100_PCIe", "A100_SXM", "A100_PCIE", "A100 40GB", "A100 80GB", "A100-SXM4-40GB", "A100-SXM4-80GB", "A100-PCIE-40GB", "A100-PCIE-80GB"]
      aws: ["NVIDIA A100-SXM4-40GB", "NVIDIA A100-SXM4-80GB", "NVIDIA A100 Tensor Core GPU"]
      azure: ["Standard_NC24ads_A100_v4", "NVIDIA A100 80GB PCIe", "NVIDIA A100 40GB"]
      gcp: ["nvidia-tesla-a100", "nvidia-a100-80gb"]
      lambda: ["gpu_1x_a100", "gpu_1x_a100_sxm4", "A100 40GB", "A100 80GB", "A100 PCIe", "A100 SXM4"]
      runpod: ["A100", "A100 40GB", "A100 80GB", "A100 PCIe", "A100 SXM"]
      coreweave: ["A100_PCIE_40GB", "A100_PCIE_80GB", "A100_SXM4_80GB"]

  - canonical_name: "A40"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["A40", "NVIDIA A40"]
      aws: ["NVIDIA A40"]
      azure: ["NVIDIA A40"]
      lambda: ["gpu_1x_a40", "A40"]
      runpod: ["A40"]
      coreweave: ["A40"]

  - canonical_name: "A10"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["A10", "NVIDIA A10"]
      aws: ["NVIDIA A10G"]
      gcp: ["nvidia-tesla-a10g"]
      lambda: ["A10"]
      runpod: ["A10"]

  - canonical_name: "A10G"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["A10G", "NVIDIA A10G"]
      aws: ["NVIDIA A10G"]
      gcp: ["nvidia-tesla-a10g"]
      lambda: ["A10G"]
      runpod: ["A10G"]

  - canonical_name: "RTX 3090"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_3090", "RTX3090", "NVIDIA RTX 3090", "GeForce RTX 3090"]
      aws: ["NVIDIA GeForce RTX 3090"]
      lambda: ["gpu_1x_rtx3090", "RTX 3090"]
      runpod: ["RTX3090", "RTX 3090"]

  - canonical_name: "RTX 3090 Ti"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_3090_Ti", "RTX3090Ti", "RTX 3090 Ti"]
      lambda: ["RTX 3090 Ti"]
      runpod: ["RTX 3090 Ti"]

  - canonical_name: "RTX 3080"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_3080", "RTX3080", "NVIDIA RTX 3080", "GeForce RTX 3080", "RTX_3080_10GB", "RTX_3080_12GB"]
      lambda: ["RTX 3080"]
      runpod: ["RTX3080", "RTX 3080"]

  - canonical_name: "RTX 3080 Ti"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_3080_Ti", "RTX3080Ti", "RTX 3080 Ti"]
      lambda: ["RTX 3080 Ti"]
      runpod: ["RTX 3080 Ti"]

  - canonical_name: "RTX 3070"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_3070", "RTX3070", "NVIDIA RTX 3070", "GeForce RTX 3070"]
      lambda: ["RTX 3070"]
      runpod: ["RTX3070", "RTX 3070"]

  - canonical_name: "RTX 3060"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_3060", "RTX3060", "NVIDIA RTX 3060", "GeForce RTX 3060"]
      lambda: ["RTX 3060"]
      runpod: ["RTX3060", "RTX 3060"]

  - canonical_name: "RTX A6000"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_A6000", "RTXA6000", "NVIDIA RTX A6000"]
      aws: ["NVIDIA RTX A6000"]
      lambda: ["gpu_1x_a6000", "RTX A6000"]
      runpod: ["RTX A6000"]
      coreweave: ["RTX_A6000"]

  - canonical_name: "RTX A5000"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_A5000", "RTXA5000", "NVIDIA RTX A5000"]
      lambda: ["RTX A5000"]
      runpod: ["RTX A5000"]

  - canonical_name: "RTX A4000"
    sm: "86"
    architecture: "Ampere"
    aliases:
      vastai: ["RTX_A4000", "RTXA4000", "NVIDIA RTX A4000"]
      lambda: ["RTX A4000"]
      runpod: ["RTX A4000"]

  # Turing
  - canonical_name: "T4"
    sm: "75"
    architecture: "Turing"
    aliases:
      vastai: ["T4", "Tesla_T4", "NVIDIA T4"]
      aws: ["Tesla T4", "NVIDIA T4 Tensor Core GPU"]
      azure: ["Standard_NC4as_T4_v3", "NVIDIA Tesla T4"]
      gcp: ["nvidia-tesla-t4"]
      lambda: ["T4"]
      runpod: ["T4"]

  - canonical_name: "RTX 2080 Ti"
    sm: "75"
    architecture: "Turing"
    aliases:
      vastai: ["RTX_2080_Ti", "RTX2080Ti", "NVIDIA RTX 2080 Ti", "GeForce RTX 2080 Ti"]
      lambda: ["RTX 2080 Ti"]
      runpod: ["RTX 2080 Ti"]

  - canonical_name: "RTX 2080"
    sm: "75"
    architecture: "Turing"
    aliases:
      vastai: ["RTX_2080", "RTX2080", "NVIDIA RTX 2080", "GeForce RTX 2080"]
      lambda: ["RTX 2080"]
      runpod: ["RTX 2080"]

  - canonical_name: "Quadro RTX 8000"
    sm: "75"
    architecture: "Turing"
    aliases:
      vastai: ["Quadro_RTX_8000", "QuadroRTX8000", "NVIDIA Quadro RTX 8000"]
      lambda: ["Quadro RTX 8000"]
      runpod: ["Quadro RTX 8000"]

  - canonical_name: "Quadro RTX 6000"
    sm: "75"
    architecture: "Turing"
    aliases:
      vastai: ["Quadro_RTX_6000", "QuadroRTX6000", "NVIDIA Quadro RTX 6000"]
      lambda: ["Quadro RTX 6000"]
      runpod: ["Quadro RTX 6000"]

  # Volta
  - canonical_name: "V100"
    sm: "70"
    architecture: "Volta"
    aliases:
      vastai: ["V100", "Tesla_V100", "V100_SXM2", "V100_PCIe", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-32GB", "Tesla V100-PCIE-16GB", "Tesla V100-PCIE-32GB"]
      aws: ["Tesla V100", "NVIDIA V100 Tensor Core GPU"]
      azure: ["Standard_NC6s_v3", "NVIDIA Tesla V100"]
      gcp: ["nvidia-tesla-v100"]
      lambda: ["V100"]
      runpod: ["V100"]

  # Pascal
  - canonical_name: "P100"
    sm: "60"
    architecture: "Pascal"
    aliases:
      vastai: ["P100", "Tesla_P100", "Tesla P100-PCIE-16GB"]
      aws: ["Tesla P100"]
      gcp: ["nvidia-tesla-p100"]
      lambda: ["P100"]
      runpod: ["P100"]

  - canonical_name: "P40"
    sm: "61"
    architecture: "Pascal"
    aliases:
      vastai: ["P40", "Tesla_P40", "Tesla P40"]
      aws: ["Tesla P40"]
      lambda: ["P40"]
      runpod: ["P40"]

  - canonical_name: "GTX 1080 Ti"
    sm: "61"
    architecture: "Pascal"
    aliases:
      vastai: ["GTX_1080_Ti", "GTX1080Ti", "NVIDIA GTX 1080 Ti", "GeForce GTX 1080 Ti"]
      lambda: ["GTX 1080 Ti"]
      runpod: ["GTX 1080 Ti"]

  - canonical_name: "GTX 1080"
    sm: "61"
    architecture: "Pascal"
    aliases:
      vastai: ["GTX_1080", "GTX1080", "NVIDIA GTX 1080", "GeForce GTX 1080"]
      lambda: ["GTX 1080"]
      runpod: ["GTX 1080"]
