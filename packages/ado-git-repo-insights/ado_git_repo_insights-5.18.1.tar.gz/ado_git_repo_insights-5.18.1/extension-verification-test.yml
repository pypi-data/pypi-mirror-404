# Extension Verification Test Pipeline
# Purpose: Test the ADO extension task (not just CLI)
# Uses: ExtractPullRequests@1 task from the installed extension
# Cross-platform: Uses pwsh (PowerShell Core) which works on Windows, Linux, Mac

trigger: none  # Manual only

pool:
  name: 'Default'  # Self-hosted agent

variables:
  - group: ado-insights-secrets  # Contains PAT_SECRET
  - name: ARTIFACT_NAME
    value: 'ado-insights-db-ext-test'

stages:
  - stage: Extract
    displayName: 'Extract via Extension'
    jobs:
      - job: ExtractPRs
        displayName: 'Run Extension Task'
        steps:
          # Step 1: Create directories FIRST (before download attempt)
          - pwsh: |
              New-Item -ItemType Directory -Force -Path "$(Pipeline.Workspace)/data" | Out-Null
              New-Item -ItemType Directory -Force -Path "$(Pipeline.Workspace)/csv_output" | Out-Null
              New-Item -ItemType Directory -Force -Path "$(Pipeline.Workspace)/run_artifacts" | Out-Null
              New-Item -ItemType Directory -Force -Path "$(Pipeline.Workspace)/aggregates" | Out-Null
              Write-Host "##[section]Directories created"
            displayName: 'Create Directories'

          # Step 1.5: Ensure Node.js is available (required for extension task)
          - task: UseNode@1
            displayName: 'Install Node.js 22'
            inputs:
              version: '22.x'

          # Step 2: Download previous DB (branch-isolated, first run will fail - OK)
          - task: DownloadPipelineArtifact@2
            displayName: 'Download Previous Database (Golden)'
            continueOnError: true
            inputs:
              buildType: 'specific'
              project: '$(System.TeamProjectId)'
              definition: '$(System.DefinitionId)'
              runVersion: 'latestFromBranch'
              runBranch: '$(Build.SourceBranch)'
              allowPartiallySucceededBuilds: true
              allowFailedBuilds: false
              artifactName: '$(ARTIFACT_NAME)'
              targetPath: '$(Pipeline.Workspace)/data'

          # Step 3: Check DB status (defensive - don't assume download succeeded)
          - pwsh: |
              $dbPath = "$(Pipeline.Workspace)/data/ado-insights.sqlite"
              if (Test-Path $dbPath) {
                Write-Host "##[section]Found existing database - incremental run"
                Get-ChildItem "$(Pipeline.Workspace)/data"
              } else {
                Write-Host "##[warning]No database found - first run (new DB will be created)"
              }
            displayName: 'Check Database Status'

          # Step 4: Run the extension task
          # Task Major version: 2 (update only on BREAKING TASK CHANGE)
          # generateAggregates defaults to true in v2.7.0+
          - task: ExtractPullRequests@2
            displayName: 'Extract PR Metrics'
            inputs:
              organization: 'oddessentials'
              projects: |
                marketing
                engineering
                hospitality
              pat: '$(PAT_SECRET)'
              database: '$(Pipeline.Workspace)/data/ado-insights.sqlite'
              outputDir: '$(Pipeline.Workspace)/csv_output'
              # CRITICAL: Write to run_artifacts so manifest is at artifact root
              # This prevents aggregates/aggregates double-nesting on download
              aggregatesDir: '$(Pipeline.Workspace)/run_artifacts'

          # Step 5: Publish Golden DB (only on success)
          - task: PublishPipelineArtifact@1
            displayName: 'Publish Golden DB'
            condition: succeeded()
            inputs:
              targetPath: '$(Pipeline.Workspace)/data'
              artifact: '$(ARTIFACT_NAME)'

          # Step 5b: Publish Aggregates (enables dashboard auto-discovery)
          # CRITICAL: Publish from run_artifacts (manifest at root, data in aggregates/)
          # This produces correct flat layout on download - no double-nesting
          - task: PublishPipelineArtifact@1
            displayName: 'Publish Aggregates'
            condition: succeeded()
            inputs:
              targetPath: '$(Pipeline.Workspace)/run_artifacts'
              artifact: 'aggregates'

          # Step 6: Publish Candidate DB (forensic - always)
          - task: PublishPipelineArtifact@1
            displayName: 'Publish Candidate DB (forensic)'
            condition: always()
            inputs:
              targetPath: '$(Pipeline.Workspace)/data'
              artifact: 'ado-insights-db-candidate-$(Build.BuildId)'

          # Step 7: Publish CSVs
          - task: PublishPipelineArtifact@1
            displayName: 'Publish CSVs'
            condition: always()
            inputs:
              targetPath: '$(Pipeline.Workspace)/csv_output'
              artifact: 'csv-output'

          # Step 8: Publish Run Artifacts
          - task: PublishPipelineArtifact@1
            displayName: 'Publish Run Artifacts'
            condition: always()
            continueOnError: true
            inputs:
              targetPath: '$(Pipeline.Workspace)/run_artifacts'
              artifact: 'run-artifacts'
