# aury-ai-model

> ç»Ÿä¸€ã€é«˜å¯é çš„ LLM è°ƒç”¨å±‚ï¼šç»Ÿä¸€æ¶ˆæ¯/äº‹ä»¶æ¨¡å‹ï¼Œå¤š Provider é€‚é…ï¼ˆOpenAI / OpenRouter / Doubaoï¼‰ï¼Œç»“æ„åŒ–è¾“å‡ºç®¡çº¿ï¼ˆStrict + Repairï¼‰ï¼Œå·¥å…·å£°æ˜ä¸è§£æï¼ˆå« MCPï¼‰ï¼Œä¸Šä¸‹æ–‡ä¸å¯è§‚æµ‹æ€§ï¼ˆusage/metricsï¼‰ï¼Œä»¥åŠåŸºäº tenacity çš„ with_retry é‡è¯•å°è£…ã€‚é¢å‘ç”Ÿäº§è°ƒç”¨ç¨³å®šæ€§ä¸ç±»å‹å®‰å…¨ï¼Œä¸å†…ç½® Agent/å·¥å…·æ‰§è¡Œã€‚

- Python: 3.12+
- ä¾èµ–: Pydantic v2ã€contextvarsã€openai>=1.0ã€tenacityã€json-repairã€python-dotenvï¼ˆå¼€å‘ï¼‰
- Provider é€‚é…ï¼š
  - OpenAIï¼ˆChat/Responsesï¼‰
  - OpenRouterï¼ˆOpenAI å…¼å®¹ï¼Œæ‰©å±• reasoning / images / provider è·¯ç”±ï¼‰
  - Doubao/ç«å±±æ–¹èˆŸ Arkï¼ˆChatCompletions é£æ ¼ï¼ŒResponses ç±»ç‰¹æ€§ï¼‰
- äº‹ä»¶ï¼š`content` / `thinking` / `tool_call` / `usage` / `completed` / `error`
- æ¶ˆæ¯ï¼šparts-onlyï¼ˆ`Text` / `Image` / `Thinking` / `FileRef`ï¼‰ï¼Œå¤šæ¨¡æ€ä¸€è‡´
- ç»“æ„åŒ–è¾“å‡ºï¼šStrict ä¼˜å…ˆï¼ŒRepair/Extract å…œåº•ï¼ˆè¯¦è§â€œç»“æ„åŒ–è¾“å‡ºâ€ï¼‰
- å·¥å…·ï¼šMCP/function/builtin å£°æ˜ä¸è§£æï¼ˆä¸æ‰§è¡Œï¼‰ï¼Œå¤šè½®å·¥å…·é“¾è·¯ï¼ˆå« reasoning_details é€ä¼ ï¼‰
- é‡è¯•ï¼š`client.with_retry(...)`ï¼ˆtenacity.AsyncRetryingï¼‰ï¼Œéæµå¼/æµå¼ç»Ÿä¸€
- å¯è§‚æµ‹ï¼šä¸Šä¸‹æ–‡ï¼ˆcontextvarsï¼‰ã€instrumentation sinkã€usage èšåˆ

æœ¬ README ä»¥â€œå°½å¯èƒ½è¯¦ç»†â€ä¸ºåŸåˆ™ï¼Œè¦†ç›–è®¾è®¡ã€APIã€Provider å·®å¼‚ã€æµ‹è¯•å¯¹åº”å…³ç³»ã€è¿ç§»æ¸…å•ã€‚è‹¥åªéœ€å…¥é—¨ï¼Œç›´æ¥è·³åˆ°â€œå¿«é€Ÿä¸Šæ‰‹â€ã€‚

---

## å®‰è£…ä¸å‡†å¤‡

```bash
pip install pydantic==2.* openai>=1.0 json-repair tenacity python-dotenv
# Doubao / Arkï¼ˆå¯é€‰ï¼‰
pip install 'volcengine-python-sdk[ark]'
```

- å»ºè®®ä½¿ç”¨ .env ç®¡ç†å¯†é’¥ï¼š
  - `OPENROUTER_API_KEY`
  - `OPENAI_API_KEY`ï¼ˆå¦‚ç›´æ¥èµ° OpenAIï¼‰
  - `ARK_API_KEY`ï¼ˆDoubao/æ–¹èˆŸï¼‰
  - å¯é€‰ï¼š`GEMINI_IMAGE_MODEL=google/gemini-3-pro-image-preview`

---

## å¿«é€Ÿä¸Šæ‰‹ï¼ˆè¦†ç›–å¸¸è§èƒ½åŠ›ï¼‰

### åˆå§‹åŒ–æ–¹å¼

ç›´æ¥åˆå§‹åŒ–ï¼ˆæ¨èï¼‰ï¼š
```python
from aury.ai.model import ModelClient, msg

client = ModelClient(
    provider="openrouter",
    model="openai/gpt-4o-mini",
    api_key="${OPENROUTER_API_KEY}"
)
```

æˆ–ä½¿ç”¨ `bind()` åˆ›å»ºé…ç½®å˜ä½“ï¼ˆé€‚åˆå¤ç”¨åŸºç¡€é…ç½®ï¼‰ï¼š
```python
base = ModelClient(provider="openrouter", api_key="${OPENROUTER_API_KEY}")
client_a = base.bind(model="openai/gpt-4o-mini")
client_b = base.bind(model="anthropic/claude-3-opus")
```

### éæµå¼è°ƒç”¨ + usage
```python
resp = await client.ainvoke([msg.user("Hello")])
print(resp.parts)
print(client.last_usage())  # input/output/reasoning/total
```

è°ƒç”¨æ—¶å¯è¦†ç›– provider/modelï¼š
```python
resp = await client.ainvoke([msg.user("Hello")], provider="doubao", model="doubao-seed-1-6-251015")
```

### æµå¼è°ƒç”¨
æœ€ç»ˆä» `last_usage()` å–ç”¨é‡ï¼›å¦‚éœ€äº‹ä»¶ä¸­å¸¦ usageï¼š`yield_usage_event=True`
```python
async for ev in client.astream([msg.user("è®²ä¸ªç¬‘è¯")], yield_usage_event=True):
    if ev.type == "content":
        print(ev.delta, end="")
    elif ev.type == "usage":
        print(f"ç”¨é‡: {ev.usage}")
print(client.last_usage())
```

### æµå¼ Thinkingï¼ˆæ¨ç†è¿‡ç¨‹ï¼‰
```python
async for ev in client.astream([msg.user("æ·±å…¥åˆ†æè¿™ä¸ªé—®é¢˜")], return_thinking=True):
    if ev.type == "thinking":
        print(f"ğŸ’­ {ev.delta}", end="")
    elif ev.type == "content":
        print(ev.delta, end="")
```

### å¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾ç‰‡ï¼‰
```python
# URL æˆ– base64 data:URL
image_url = "https://example.com/image.jpg"
# æˆ– image_url = "data:image/png;base64,..."

resp = await client.ainvoke([
    msg.user("æè¿°è¿™å¼ å›¾ç‰‡", images=[image_url])
])
```

### ä¸¥æ ¼ç»“æ„åŒ–è¾“å‡º
Responses/Doubao å»ºè®®é…åˆ `text_format`ï¼š
```python
from pydantic import BaseModel

class Weather(BaseModel):
    city: str
    temp_c: float

client = ModelClient(provider="openai", model="gpt-4.1-mini", api_key="${OPENAI_API_KEY}", transport="responses")
result = await client.with_structured_output(Weather).ainvoke(
    [msg.user("è¯·ä»¥JSONè¿”å›åŒ—äº¬å¤©æ°”ï¼ŒåŒ…å« city å’Œ temp_c")],
    text_format={"type":"json_object"},
    expect_strict=True,
)
```

### é‡è¯•ï¼ˆwith_retryï¼‰
```python
retrying = client.with_retry(max_attempts=4, base_delay=0.2)
res = await retrying.ainvoke([msg.user("ç¨³å®šè¿”å›ä¸€å¥è¯")])
```

### å¤šå›¾è¾“å‡ºï¼ˆOpenRouter x Geminiï¼‰
```python
client = ModelClient(provider="openrouter", model="${GEMINI_IMAGE_MODEL}", api_key="${OPENROUTER_API_KEY}")
res = await client.ainvoke([msg.user("Create two icon variations")])
# OpenRouterAdapter ä¼šæŠŠ message.images â†’ å¤šä¸ª Image(url=...) part
```

---

## å†å²è®°å½•ç®¡ç†

`ModelClient` ä¸å†…ç½®å¯¹è¯çŠ¶æ€ï¼Œå†å²ç”±è°ƒç”¨æ–¹ç®¡ç†ã€‚æ¯æ¬¡è°ƒç”¨éœ€ä¼ å…¥å®Œæ•´æ¶ˆæ¯åˆ—è¡¨ã€‚

### åŸºæœ¬å¤šè½®å¯¹è¯
```python
from aury.ai.model import ModelClient, msg, Message, Role

client = ModelClient(provider="openrouter", model="openai/gpt-4o-mini", api_key="...")
history: list[Message] = []

# ç¬¬ä¸€è½®
history.append(msg.user("æˆ‘å«å°æ˜"))
resp = await client.ainvoke(history)
history.append(resp)

# ç¬¬äºŒè½®ï¼ˆæ¨¡å‹è®°ä½ä¸Šä¸‹æ–‡ï¼‰
history.append(msg.user("æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"))
resp = await client.ainvoke(history)
history.append(resp)
```

### å·¥å…·è°ƒç”¨å¤šè½®é“¾è·¯
```python
history = [msg.system("ä½ æ˜¯åŠ©æ‰‹"), msg.user("æŸ¥è¯¢åŒ—äº¬å¤©æ°”")]

for _ in range(5):  # æœ€å¤š5è½®å·¥å…·è°ƒç”¨
    resp = await client.ainvoke(history, tools=TOOLS)
    history.append(resp)  # assistant æ¶ˆæ¯ï¼ˆå« tool_callsï¼‰
    
    if not resp.tool_calls:
        break  # æ— å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
    
    # æ‰§è¡Œå·¥å…·ï¼ŒæŠŠç»“æœåŠ å…¥å†å²
    for tc in resp.tool_calls:
        result = run_tool(tc.name, tc.arguments_json)
        history.append(msg.tool(result, tool_call_id=tc.id))
```

### æµå¼å†å²ç®¡ç†
æµå¼è¿”å› `StreamEvent`ï¼Œç”¨ `StreamCollector` èšåˆï¼š
```python
from aury.ai.model import StreamCollector

history = [msg.user("ä½ å¥½")]
collector = StreamCollector()

async for ev in client.astream(history):
    collector.feed(ev)
    if ev.type == "content":
        print(ev.delta, end="")

# èšåˆç»“æœ
collector.content           # str - èšåˆæ–‡æœ¬
collector.thinking          # str - èšåˆæ€è€ƒ
collector.tool_calls        # list[ToolCall]
collector.usage             # Usage | None
collector.thinking_message  # Message | None - ä»…å« thinking
collector.content_message   # Message | None - ä»…å« content
collector.message           # Message - å®Œæ•´æ¶ˆæ¯

# åŠ å…¥å†å²
history.append(collector.message)
```

æµå¼å·¥å…·è°ƒç”¨ï¼š
```python
for _ in range(5):
    collector = StreamCollector()
    async for ev in client.astream(history, tools=TOOLS):
        collector.feed(ev)
        if ev.type == "content":
            print(ev.delta, end="")
    
    resp = collector.to_message()
    history.append(resp)
    
    if not resp.tool_calls:
        break
    for tc in resp.tool_calls:
        history.append(msg.tool(run_tool(tc.name, tc.arguments_json), tool_call_id=tc.id))
```

### msg ä¾¿æ·æ„é€ å™¨
```python
msg.system("ä½ æ˜¯åŠ©æ‰‹")                           # system æ¶ˆæ¯
msg.user("ä½ å¥½", images=["url"])                   # user æ¶ˆæ¯ï¼ˆå¯å¸¦å›¾ç‰‡ï¼‰
msg.assistant("OK", thinking="...")                # assistant æ¶ˆæ¯
msg.tool(result_json, tool_call_id=tc.id)          # tool ç»“æœæ¶ˆæ¯
```

### Role æšä¸¾
```python
Role.system    # "system"
Role.user      # "user"
Role.assistant # "assistant"
Role.tool      # "tool"

# å­—ç¬¦ä¸²å…¼å®¹ï¼ˆStrEnum è‡ªåŠ¨è½¬æ¢ï¼‰
Message(role="tool", ...)  # ç­‰åŒäº Message(role=Role.tool, ...)
```

---

## æ ¸å¿ƒæ¦‚å¿µ

- Message / Partï¼ˆå¼ºç±»å‹ï¼‰ï¼š
  - `Text(text: str)`ã€`Image(url: str)`ã€`Thinking(text: str)`ã€`FileRef(id: str)`
  - `Message.parts` ä»…åŒ…å«è¿™äº› Partï¼Œé¿å…å­—ç¬¦ä¸²/åˆ—è¡¨äºŒä¹‰æ€§ï¼›å¤šæ¨¡æ€ä¸€è‡´
  - `Message.tool_calls`ï¼šè§£æåçš„å·¥å…·è°ƒç”¨ï¼ˆ`ToolCall{id,name,arguments_json,mcp_server_id}`ï¼‰
  - `Message.reasoning_details`ï¼šä¾› OpenRouter Gemini/DeepSeek å·¥å…·é“¾è·¯çš„å¤šè½®é€ä¼ 
  - `Message.role`ï¼šä½¿ç”¨ `Role` æšä¸¾ï¼ˆ`system`/`user`/`assistant`/`tool`ï¼‰
- äº‹ä»¶ï¼ˆ`StreamEvent`ï¼‰ï¼š`content` æ–‡æœ¬å¢é‡ã€`thinking` æ€è€ƒå¢é‡ã€`tool_call`ã€`usage`ã€`completed`ã€`error`
- Usageï¼š`input_tokens` / `output_tokens` / `reasoning_tokens` / `total_tokens`
- ä¸Šä¸‹æ–‡ï¼š`model_ctx`ï¼ˆwith/async with/è£…é¥°å™¨ï¼‰ï¼Œtrace_id/user_id/provider/model/extra_headers
- å¯è§‚æµ‹ï¼šinstrument sinkï¼ˆon_request_start/endã€on_stream_eventã€on_errorï¼‰ï¼Œ`client.last_usage()`

---

## API å‚è€ƒï¼ˆModelClientï¼‰

- `bind(**updates) -> ModelClient`ï¼šä¸å¯å˜é…ç½®ï¼Œå®‰å…¨å¤ç”¨
- `ainvoke(messages, **kw) -> Message`
- `astream(messages, **kw) -> AsyncIterator[StreamEvent]`
- `with_structured_output(schema) -> StructuredView`
- `with_retry(...) -> RetryView`
- `last_usage() -> Usage | None`

é€šç”¨è°ƒç”¨å‚æ•°ï¼š
- ç”Ÿæˆï¼š`max_tokens`ã€`max_completion_tokens`ã€`temperature`ã€`top_p`ã€`stop`ã€`seed`
- æ¨ç†ï¼š`return_thinking`ã€`reasoning_effort`ï¼ˆlow/medium/highï¼‰
- ç»“æ„åŒ–ï¼š`response_format`ï¼ˆChatï¼‰ã€`text_format`ï¼ˆResponses/Doubaoï¼‰
- å·¥å…·ï¼š`tools=[ToolSpec(...)]`ï¼ˆå« MCP é™çº§ç¼–ç ï¼›è¯¦è§â€œå·¥å…·ä¸ MCPâ€ï¼‰
- é€ä¼ ï¼š`extra_body={...}`ï¼ˆProvider ç‰¹å®šå‚æ•°åŸæ ·ä¼ é€’ï¼‰
- ç»‘å®šé»˜è®¤å€¼ï¼š`default_max_tokens`ã€`default_temperature`ã€`default_top_p`ã€`default_reasoning_effort`

Provider é€‰æ‹©ä¸ transportï¼š
- OpenAI é»˜è®¤ Chatï¼›`transport="responses"` ä½¿ç”¨ Responses
- OpenRouter é»˜è®¤ Chatï¼ˆå…¼å®¹ OpenAI Chatï¼‰
- Doubao å›ºå®š ChatCompletions é£æ ¼ï¼ˆå†…éƒ¨å¤„ç†å…¼å®¹ Responses ç‰¹æ€§ï¼‰

---

## ç»“æ„åŒ–è¾“å‡ºï¼ˆStrict + Repairï¼‰

`client.with_structured_output(Schema).ainvoke(messages, ...)` â†’ `Schema` å®ä¾‹ã€‚ç­–ç•¥ç®¡çº¿ï¼š
1) StrictSchemaStepï¼ˆ`expect_strict=True`ï¼‰ï¼šç›´æ¥æŒ‰ JSON/format ä¸¥æ ¼æ ¡éªŒï¼›
2) RepairExtractStepï¼šå…ˆå°è¯• JSON è§£æï¼Œå…¶æ¬¡ `json_repair` ä¿®å¤ï¼Œå†ä» markdown ä»£ç å—æˆ–æœ€å¤§èŠ±æ‹¬å·æå–å¹¶æ ¡éªŒã€‚

è¦ç‚¹ï¼š
- Chat API ç”¨ `response_format={"type":"json_object"}`ï¼›Responses/Doubao ç”¨ `text_format={"type":"json_object"}`
- æç¤ºè¯å°½é‡æ˜ç¡®å­—æ®µä¸æ‰å¹³ç»“æ„ï¼Œé¿å…å¤šåŒ…ä¸€å±‚ï¼ˆå¦‚ `{"company":{...}}`ï¼‰
- Pydantic v2 æ”¯æŒ `validation_alias` ä¸ `field_validator`ï¼ˆæ”¯æŒå­—æ®µåˆ«åä¸å®¹é”™æ ¡éªŒï¼‰
- å¤±è´¥æŠ›å‡º `ValueError: structured parse failed: ...`

---

## å·¥å…·ä¸ MCP

ç±»å‹ï¼š`ToolSpec(kind=function|mcp|builtin)`ï¼›MCP ç”¨ `MCPToolSpec(server_id,name,input_schema,...)`ã€‚

ç¼–ç /è§£ç ï¼š
- ä¸æ”¯æŒ MCP åŸç”Ÿçš„åç«¯ï¼šç¼–ç ä¸º `function.name = "mcp::{server}::{name}"`
- è§£æï¼š`decode_maybe_mcp` / `normalize_tool_call` è¿˜åŸ `mcp_server_id` ä¸ `name`

å¤šè½®å·¥å…·é“¾è·¯ï¼š
- ç¬¬ 1 è½® assistant äº§å‡º `tool_calls`ï¼ˆä»¥åŠ OpenRouter çš„ `reasoning_details`ï¼‰
- ç¬¬ 2 è½®å°†ä¸Šä¸€è½® assistant æ¶ˆæ¯åŸæ ·å›ä¼ ï¼Œå¹¶é™„å¸¦æ¯ä¸ª tool çš„ `tool` æ¶ˆæ¯ï¼ˆå¸¦ `tool_call_id`ï¼‰

---

## Reasoning / reasoning_detailsï¼ˆå¤šè½®ä¼ é€’ï¼‰

- OpenRouterAdapterï¼š
  - éæµå¼ï¼šä»åŸå§‹ JSON `choices[0].message.reasoning_details` æŠ½å–å¹¶æŒ‚åˆ°è¿”å› `Message`
  - æµå¼ï¼šç´¯ç§¯ chunk.delta é‡Œçš„ `reasoning_details`ï¼Œåœ¨ `completed` äº‹ä»¶å›ä¼ èšåˆåˆ—è¡¨
- Doubao/OpenAIï¼šæŒ‰å„è‡ªå­—æ®µï¼ˆå¦‚ `reasoning_content`ï¼‰å®æ—¶/æœ€ç»ˆæ˜ å°„åˆ° `thinking` äº‹ä»¶æˆ– `Thinking` part

ç”¨é€”ï¼šå½“æ¨¡å‹ä½¿ç”¨å‡½æ•°è°ƒç”¨ï¼ˆå·¥å…·è°ƒç”¨ï¼‰æ—¶ï¼Œå°† `reasoning_details` ä¸ `tool_calls` ä¸€èµ·éš assistant å›ä¼ ï¼Œä»¥ä¾›ä¸‹ä¸€è½®æ¨ç†ã€‚

---

## å¤šå›¾è¾“å‡ºï¼ˆOpenRouter / Geminiï¼‰

- éæµå¼ï¼šOpenRouter è¿”å› `choices[0].message.images`ï¼›é€‚é…å™¨ä¼šæ˜ å°„ä¸ºå¤šä¸ª `Image(url=...)` partï¼ˆæ”¯æŒ data:URL / httpsï¼‰
- æµå¼ï¼šç›®å‰ä»¥æ–‡æœ¬/å·¥å…·/usage ä¸ºä¸»ï¼Œæœ€ç»ˆå¤šå›¾å»ºè®®èµ°éæµå¼è·å–
- å¯é€šè¿‡ prompt æˆ– `extra_body`ï¼ˆè‹¥åç«¯æ”¯æŒï¼Œå¦‚ `n: 2`ï¼‰æç¤ºå¤šå›¾

---

## extra_body é€ä¼ ï¼ˆProvider ç‰¹å®šå‚æ•°ï¼‰

- OpenRouterï¼š`provider.order`ã€`transforms`ã€`models` å¤‡é€‰ç­‰
- Doubao/Arkï¼š`previous_response_id`ã€`caching`ã€å…¶å®ƒå¼€å…³
- OpenAIï¼šResponses/Chat å…¼å®¹çš„æ‰©å±•å‚æ•°

---

## é‡è¯•ï¼ˆwith_retry, tenacityï¼‰

- ä½¿ç”¨ï¼š`client.with_retry(max_attempts=3, base_delay=0.5, max_delay=5.0, backoff_factor=2.0, retry_on=..., predicate=...)`
- é»˜è®¤é‡è¯•ï¼š`ModelTimeoutError`ã€`RateLimitError`ã€`ModelOverloadedError`ã€`TransportError`
- ä¸é‡è¯•ï¼š`InvalidRequestError`
- é€‚ç”¨äºï¼š`ainvoke` ä¸ `astream`

---

## ä¸Šä¸‹æ–‡ä¸å¯è§‚æµ‹æ€§

- `model_ctx`ï¼šåŒæ­¥/å¼‚æ­¥/è£…é¥°å™¨ä¸‰ç”¨ï¼›åµŒå¥—ç»§æ‰¿ç­–ç•¥ï¼ˆå†…å±‚è¦†ç›–æœªæ˜¾å¼å­—æ®µç»§æ‰¿å¤–å±‚ï¼‰
- instrumentationï¼š
  - `emit_start(provider, model)` / `emit_event(type,payload)` / `emit_end(metrics, usage|error)`
  - sink æ¥å£ï¼š`on_request_start`ã€`on_stream_event`ã€`on_request_end`ã€`on_error`
- usage èšåˆï¼š
  - æµå¼é»˜è®¤ä¸å‘ usage äº‹ä»¶ï¼›æœ€ç»ˆä½¿ç”¨ `client.last_usage()` è¯»å–
  - éœ€è¦äº‹ä»¶ï¼š`yield_usage_event=True`

è‡ªå®šä¹‰ InstrumentSink ç¤ºä¾‹ï¼š
```python
from aury.ai.model.instrumentation import InstrumentSink, RequestMetrics, register_sink

class UsageTracker(InstrumentSink):
    def __init__(self):
        self.total_tokens = 0

    def on_request_start(self, metrics: RequestMetrics):
        print(f"è¯·æ±‚å¼€å§‹: {metrics.provider}/{metrics.model}")

    def on_request_end(self, metrics: RequestMetrics):
        if metrics.total_tokens:
            self.total_tokens += metrics.total_tokens
        print(f"è¯·æ±‚ç»“æŸ: å»¶è¿Ÿ={metrics.latency_ms}ms")

    def on_stream_event(self, event_type: str, payload: dict):
        pass  # æŒ‰éœ€å¤„ç†æµå¼äº‹ä»¶

    def on_error(self, metrics: RequestMetrics):
        print(f"è¯·æ±‚é”™è¯¯: {metrics.error}")

tracker = UsageTracker()
register_sink(tracker)
```

---

## é”™è¯¯æ¨¡å‹ï¼ˆç»Ÿä¸€å¼‚å¸¸ï¼‰

- åŸºç±»ï¼š`ModelError`
- å¯é‡è¯•ï¼š`ModelTimeoutError`ã€`RateLimitError`ã€`ModelOverloadedError`ã€`TransportError`
- ä¸å»ºè®®é‡è¯•ï¼š`InvalidRequestError`ã€`SchemaMismatchError`ã€`ProviderNotInstalledError`ã€`StreamBrokenError`
- Provider é€‚é…å™¨å°† HTTP/SDK å¼‚å¸¸å½’ä¸€ä¸ºä»¥ä¸Šç±»å‹ï¼ˆå…·ä½“è§å„é€‚é…å™¨ `except` åˆ†æ”¯ï¼‰

---

---

## è¿ç§»æ¸…å•ï¼ˆChecklistï¼‰

1) Provider é€‰æ‹©ä¸å¯†é’¥ï¼šOpenRouterï¼ˆæ¨èï¼‰/OpenAI/Doubaoï¼Œå¹¶åœ¨ .env é…ç½® API Keyã€‚
2) æ¶ˆæ¯æ”¹é€ ï¼šä½¿ç”¨ `msg.system/user(...)` ä¸ `Message.parts`ï¼ˆText/Imageï¼‰ã€‚
3) ç»“æ„åŒ–è¾“å‡ºï¼šä¼˜å…ˆ strictï¼ˆResponses/Doubao çš„ `text_format`ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ Repair å…œåº•ï¼›å®Œå–„ Schemaï¼ˆåˆ«å/å®¹é”™æ ¡éªŒï¼‰ã€‚
4) å·¥å…·ï¼šä»¥ `ToolSpec` å£°æ˜ï¼›å°†ç¬¬ä¸€è½® assistant çš„ `tool_calls` +ï¼ˆOpenRouter çš„ï¼‰`reasoning_details` ä¸€å¹¶å›ä¼ ç¬¬äºŒè½®ï¼›å·¥å…·æ‰§è¡Œåœ¨ä¸šåŠ¡å±‚å®Œæˆã€‚
5) å¤šå›¾ï¼šå¦‚éœ€å¤šå›¾ï¼Œä½¿ç”¨ OpenRouter x Geminiï¼Œè¯»å–è¿”å› `Image` partsï¼›ä¿å­˜ data:URLã€‚
6) å¯è§‚æµ‹ï¼šæ³¨å†Œ sink / ä½¿ç”¨ `client.last_usage()`ï¼›è‹¥éœ€è¦æµå¼ usage äº‹ä»¶ï¼Œ`yield_usage_event=True`ã€‚
7) ç¨³å®šæ€§ï¼šå¯ç”¨ `with_retry`ï¼ˆé»˜è®¤é‡è¯•é™æµ/è¶…æ—¶/è¿‡è½½/ä¼ è¾“é”™è¯¯ï¼›ä¸é‡è¯•æ— æ•ˆè¯·æ±‚ï¼‰ã€‚
8) å‚æ•°ï¼šå°†ä¸ä¸šåŠ¡ç›¸å…³çš„ provider ç‰¹å®šå‚æ•°æ”¾åˆ° `extra_body`ï¼Œä¾‹å¦‚ OpenRouter çš„ provider è·¯ç”±ä¸ transformsã€‚

---

## ç›®å½•ç»“æ„
```
aury/
  ai/
    model/
      __init__.py
      README.md
      client.py
      context.py
      errors.py
      instrumentation.py
      retry.py
      structured.py
      tools.py
      types.py
      providers/
        base.py
        registry.py
        openai.py
        openrouter.py
        doubao.py
```

ç°ä»£åŒ–ï¼ˆPython 3.12+ï¼‰æ¨¡å‹è°ƒç”¨å±‚ï¼šç»Ÿä¸€æ¶ˆæ¯/äº‹ä»¶æ¨¡å‹ï¼Œå¤š Provider é€‚é…ï¼Œä¸¥æ ¼è€Œç¨³å¥çš„ç»“æ„åŒ–è¾“å‡ºï¼ŒMCP å·¥å…·å£°æ˜ä¸è§£æï¼Œå¯æ’æ‹”å¯è§‚æµ‹æ€§ï¼Œä»¥åŠå†…ç½®é‡è¯• with_retryï¼ˆtenacityï¼‰ã€‚ä¸å†…ç½® Agent/å·¥å…·æ‰§è¡Œï¼Œä»…ä¸“æ³¨â€œè°ƒç”¨ç¨³å®š + ç±»å‹å‹å¥½â€ã€‚

- Python: 3.12+
- ä¾èµ–: Pydantic v2ã€contextvarsã€openai SDKï¼ˆå…¼å®¹ OpenRouterï¼‰ã€å¯é€‰ volcengine-python-sdk[ark]
- Provider: OpenAIï¼ˆChat/Responsesï¼‰ã€OpenRouterï¼ˆOpenAI å…¼å®¹ï¼‰ã€Doubao/ç«å±±æ–¹èˆŸï¼ˆArk Chatï¼‰
- äº‹ä»¶ï¼š`content` / `thinking` / `tool_call` / `usage` / `completed` / `error`
- æ¶ˆæ¯ï¼šparts-onlyï¼ˆ`Text`/`Image`/`Thinking`/`FileRef`ï¼‰
- ç»“æ„åŒ–è¾“å‡ºï¼šStrict ä¼˜å…ˆï¼ŒRepair/Extract å…œåº•
- å·¥å…·ï¼šMCP/function/builtin å£°æ˜ä¸è§£æï¼ˆä¸æ‰§è¡Œï¼‰
- å¯è§‚æµ‹ï¼šä¸Šä¸‹æ–‡/æŒ‡æ ‡ sink + usage èšåˆ
- é‡è¯•ï¼šclient.with_retry(...)ï¼ˆtenacityï¼‰


---

## å®‰è£…

```bash
pip install pydantic==2.* openai>=1.0 json-repair tenacity python-dotenv
# Doubao / Ark å¯é€‰
pip install 'volcengine-python-sdk[ark]'
```

æºç æ–¹å¼å¼•å…¥ï¼ˆæ­¤ä»“åº“ä¸­çš„ `aury/ai/model/` ç›®å½•ï¼‰ã€‚

---

## å¿«é€Ÿä¸Šæ‰‹

### åˆå§‹åŒ–
ç›´æ¥åˆå§‹åŒ–ï¼ˆæ¨èï¼‰ï¼š
```python
from aury.ai.model import ModelClient, msg

client = ModelClient(
    provider="openrouter",
    model="openai/gpt-4o-mini",
    api_key="${OPENROUTER_API_KEY}"
)
```

ä½¿ç”¨ `bind()` å¤ç”¨é…ç½®ï¼š
```python
base = ModelClient(provider="openrouter", api_key="${OPENROUTER_API_KEY}")
client = base.bind(model="openai/gpt-4o-mini")
```

### éæµå¼ + usage
```python
m = await client.ainvoke([msg.user("Hello")])
print(m.parts)
print(client.last_usage())
```

### æµå¼ï¼ˆæœ€ç»ˆä» last_usage å–ç”¨é‡ï¼‰
```python
async for ev in client.astream([msg.user("è®²ä¸ªç¬‘è¯")]):
    if ev.type == "content":
        print(ev.delta, end="")
print(client.last_usage())
```

### æµå¼ Thinking
```python
async for ev in client.astream([msg.user("æ·±å…¥åˆ†æ")], return_thinking=True):
    if ev.type == "thinking":
        print(f"ğŸ’­ {ev.delta}", end="")
    elif ev.type == "content":
        print(ev.delta, end="")
```

### å¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾ç‰‡ï¼‰
```python
resp = await client.ainvoke([
    msg.user("æè¿°è¿™å¼ å›¾ç‰‡", images=["https://example.com/img.jpg"])
])
```

### ä¸¥æ ¼ç»“æ„åŒ–ï¼ˆResponses/Doubao å»ºè®®é…åˆ `text_format`ï¼‰
```python
from pydantic import BaseModel

class Weather(BaseModel):
    city: str
    temp_c: float

client = ModelClient(provider="openai", model="gpt-4.1-mini", api_key="${OPENAI_API_KEY}", transport="responses")
result = await client.with_structured_output(Weather).ainvoke(
    [msg.user("è¯·ä»¥JSONè¿”å›åŒ—äº¬å¤©æ°”ï¼ŒåŒ…å« city å’Œ temp_c")],
    text_format={"type":"json_object"},
    expect_strict=True,
)
```

### with_retryï¼ˆtenacityï¼‰
```python
retrying = client.with_retry(max_attempts=4, base_delay=0.2)
res = await retrying.ainvoke([msg.user("ç¨³å®šè¿”å›ä¸€å¥è¯")])
```

---

## è®¾è®¡è¦ç‚¹
- parts-only å¼ºç±»å‹æ¶ˆæ¯ï¼›å¤šæ¨¡æ€ä¸€è‡´ï¼ŒThinking ä¸ºä¸€ç­‰å…¬æ°‘ã€‚
- Provider Adapter å†…éƒ¨è·¯ç”±ä¸å‚æ•°æ˜ å°„ï¼ˆChat/Responsesã€usageã€reasoningã€toolsã€å¤šå›¾ç­‰ï¼‰ã€‚
- ç»“æ„åŒ–è¾“å‡ºç­–ç•¥ï¼šStrictSchemaï¼ˆå¯é€‰ï¼‰â†’ Repair/Extractï¼ˆjson_repair + ä»£ç å—/æœ€å¤§èŠ±æ‹¬å·æå–ï¼‰ã€‚
- å·¥å…·ï¼šå£°æ˜ä¸è§£æï¼ˆå« MCP åç§°ç¼–ç /è§£ç ï¼‰ï¼Œæ‰§è¡Œç•™ç»™ä¸Šå±‚ã€‚
- å¯è§‚æµ‹ï¼šrequest start/endã€stream eventã€usage èšåˆï¼›ä¸ä¸Šä¸‹æ–‡ï¼ˆtrace_idã€headersï¼‰åä½œã€‚
- é‡è¯•ï¼štenacity.AsyncRetrying å°è£…ï¼Œéæµå¼ä¸æµå¼ä¸€è‡´ã€‚

---

## æ¶ˆæ¯ä¸äº‹ä»¶ï¼ˆæ‘˜è¦ï¼‰
```python
from aury.ai.model.types import Message, Text, Image, Thinking, ToolCall, StreamEvent, Evt
# msg.system(...) / msg.user(text, images=[...]) æä¾›ä¾¿æ·æ„é€ 
```
äº‹ä»¶æµï¼š`content` æ–‡æœ¬å¢é‡ã€`thinking` æ€è€ƒå¢é‡ã€`tool_call` å·¥å…·è°ƒç”¨ã€`usage` ç”¨é‡ã€`completed` ç»“æŸã€‚

å¤šæ¨¡æ€ï¼š`Image(url=...)`ã€‚OpenRouter é€‚é…å™¨ä¼šæŠŠ `message.images` ä¸­çš„å¤šå¼ å›¾ç‰‡æ˜ å°„åˆ° `Message.parts`ï¼ˆæ”¯æŒ data:URL / httpsï¼‰ã€‚

---

## ModelClient
- `bind(...)` ç”Ÿæˆæ–°å®ä¾‹ï¼ˆä¸å¯å˜é…ç½®ï¼Œçº¿ç¨‹/åç¨‹å®‰å…¨ï¼‰ã€‚
- `ainvoke(messages, **kw)` / `astream(messages, **kw)`
- `with_structured_output(schema)` â†’ `StructuredView`
- `with_retry(...)` â†’ RetryViewï¼ˆè§â€œé‡è¯•â€ï¼‰
- `last_usage()` è¯»å–æœ€è¿‘ä¸€æ¬¡ç”¨é‡ï¼ˆå« reasoning_tokensï¼‰ã€‚

å¸¸ç”¨è°ƒç”¨å‚æ•°ï¼š
- é€šç”¨ç”Ÿæˆï¼š`max_tokens`ã€`max_completion_tokens`ã€`temperature`ã€`top_p`ã€`stop`ã€`seed`ã€‚
- æ¨ç†ï¼š`return_thinking`ã€`reasoning_effort`ï¼ˆlow/medium/highï¼‰ã€‚
- ç»“æ„åŒ–ï¼š`response_format`ï¼ˆChatï¼‰ã€`text_format`ï¼ˆResponses/Doubaoï¼‰ã€‚
- å·¥å…·ï¼š`tools`ï¼ˆæ”¯æŒ MCP é™çº§ç¼–ç ï¼‰ã€‚
- é€ä¼ ï¼š`extra_body`ï¼ˆProvider ç‰¹å®šå‚æ•°ï¼ŒåŸæ ·ä¼ ç»™åç«¯ï¼‰ã€‚
- Doubao/Responses ç‰¹æ€§ï¼š`previous_response_id`ã€`caching` ç­‰ã€‚

---

## ç»“æ„åŒ–è¾“å‡ºï¼ˆwith_structured_outputï¼‰
- `expect_strict=True` æ—¶ä¼˜å…ˆä¸¥æ ¼æ ¡éªŒï¼›å¦åˆ™èµ° Repair/Extract å…œåº•ã€‚
- å¤±è´¥ä¼šæŠ›å‡º `ValueError: structured parse failed: ...`ã€‚

---

## å·¥å…·ï¼ˆMCP / Function / Builtinï¼‰
- å£°æ˜ï¼š`ToolSpec(kind=..., ...)`ï¼›
- ç¼–ç ï¼š`to_openai_tools` ä¼šå°† MCP å·¥å…·ç¼–ç ä¸º `mcp::{server}::{name}`ï¼›
- è§£æï¼š`normalize_tool_call` ä¼šè¿˜åŸå¹¶å¡«å…… `mcp_server_id`ï¼›

---

## Reasoning / reasoning_detailsï¼ˆå¤šè½®ä¼ é€’ï¼‰
- OpenRouter DeepSeek/Gemini ç­‰ï¼šé€‚é…å™¨åœ¨éæµå¼ä»åŸå§‹ JSON ä¸­æå– `reasoning_details`ï¼Œåœ¨æµå¼äº `completed` äº‹ä»¶èšåˆåå›ä¼ ï¼Œä¾¿äºå°†å…¶éš assistant tool_calls ä¸€å¹¶å¸¦å›ç¬¬äºŒè½®ã€‚

---

## å¤šå›¾è¾“å‡ºï¼ˆOpenRouter / Geminiï¼‰
- éæµå¼ï¼šOpenRouter è¿”å›çš„ `choices[0].message.images` ä¼šè¢«æ˜ å°„åˆ°å¤šä¸ª `Image` partã€‚
- å¯ç”¨ `extra_body`ï¼ˆå¦‚åç«¯æ”¯æŒï¼‰è¯·æ±‚å¤šå›¾ï¼Œå¦åˆ™é€šè¿‡ prompt æç¤ºç”Ÿæˆå¤šå¼ å›¾ã€‚

---

## extra_body é€ä¼ 
- é€šè¿‡ `extra_body={...}` ä¼ å…¥ Provider ç‰¹å®šå‚æ•°ï¼Œå¦‚ OpenRouter çš„ `provider.order`ã€`transforms`ã€‚

---

## é‡è¯•ï¼ˆwith_retry, tenacityï¼‰
- `client.with_retry(max_attempts=3, base_delay=0.5, max_delay=5.0, backoff_factor=2.0)` è¿”å› RetryViewï¼›
- é»˜è®¤é‡è¯•é”™è¯¯ï¼š`ModelTimeoutError`ã€`RateLimitError`ã€`ModelOverloadedError`ã€`TransportError`ï¼›ä¸é‡è¯• `InvalidRequestError`ï¼›
- æ”¯æŒè‡ªå®šä¹‰ `retry_on`/`predicate`ï¼›

---

## ä¸Šä¸‹æ–‡ä¸å¯è§‚æµ‹æ€§
- `model_ctx`ï¼šä¸Šä¸‹æ–‡ç®¡ç†å™¨/è£…é¥°å™¨ï¼ˆtrace_id/request_id/provider/model/extra_headersï¼‰ã€‚
- instrumentationï¼š`emit_*` + sink æ³¨å†Œï¼›`client.last_usage()` èšåˆè¯»æ•°ã€‚

---

## é”™è¯¯ç±»å‹
- `ModelTimeoutError` / `RateLimitError` / `ModelOverloadedError`
- `InvalidRequestError` / `TransportError` / `StreamBrokenError`
- `SchemaMismatchError` / `ProviderNotInstalledError`

---

---

## ç›®å½•
```
aury/
  ai/
    model/
      __init__.py
      README.md
      client.py
      context.py
      errors.py
      instrumentation.py
      retry.py
      structured.py
      tools.py
      types.py
      providers/
        base.py
        registry.py
        openai.py
        openrouter.py
        doubao.py
```

---

## è¿ç§»æç¤º
- `ModelClient`/`Message`/`StreamEvent`/`ToolSpec` ä¸ºæ ¸å¿ƒ APIï¼›
- è‹¥å·²æœ‰ OpenAI å…¼å®¹è°ƒç”¨ï¼Œå¯ç›´æ¥åˆ‡æ¢ provider="openrouter"ï¼›
- å¯¹å·¥å…·é“¾è·¯ï¼šä¿è¯å°†ä¸Šä¸€è½® assistantï¼ˆå« tool_calls ä¸ reasoning_detailsï¼‰åŸæ ·ä¼ å›ç¬¬äºŒè½®ï¼›
- å¯¹ç»“æ„åŒ–è¾“å‡ºï¼šä¼˜å…ˆå°è¯•ä¸¥æ ¼æ¨¡å¼ï¼ˆResponses/Doubao çš„ `text_format`ï¼‰ï¼Œå¦åˆ™ä¾èµ– Repair/Extract å…œåº•ï¼›
- å¯ç”¨ with_retry æå‡ç¨³å®šæ€§ï¼ˆé¢‘æ§/ç¬æ—¶ç½‘ç»œï¼‰ã€‚
