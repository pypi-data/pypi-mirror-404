[build-system]
requires = ["maturin>=1.10,<2.0"]
build-backend = "maturin"

[project]
name = "metadata-crawler"
authors = [{name = "DKRZ, Clint", email = "freva@dkrz.de"}]
readme = "README.md"
license = {file = "LICENSE"}
classifiers = [
               "Development Status :: 4 - Beta",
               "Environment :: Console",
               "Intended Audience :: Developers",
               "Intended Audience :: Science/Research",
               "License :: OSI Approved :: BSD License",
               "Operating System :: POSIX :: Linux",
               "Programming Language :: Rust",
               "Programming Language :: Python :: 3",
               "Programming Language :: Python :: 3.11",
               "Programming Language :: Python :: 3.12",
               "Programming Language :: Python :: 3.13",
               "Programming Language :: Python :: 3.14",
]
version = "2602.0.0"
description="Crawl, extract and push climate metadata for indexing."
requires-python = ">=3.11"
dependencies = [
        "aiohttp",
        "appdirs",
        "ciso8601",
        "fsspec",
        "diskcache",
        "s3fs",
        "jinja2",
        "ipython",
        "intake",
        "intake-xarray",
        "intake-esm",
        "pandas",
        "python-dateutil",
        "numpy",
        "orjson",
        "pyarrow",
        "h5netcdf",
        "h5py",
        "pydantic",
        "pyarrow",
        "rich",
        "rich-argparse",
        "rtoml",
        "tomlkit",
        "typing_extensions",
        "zarr",
        "xarray",
        "httpx",
        "uvloop ; sys_platform != 'win32'",
        "motor",
]
[project.optional-dependencies]
dev = ["maturin", "tox"]
mkdoc = [
  "mkdocs",
  "mkdocs-material",
  "mkdocstrings[python]",
  "mkdocs-macros-plugin",
  "mkdocs-minify-plugin",
  "mkdocs-redirects",
  #"mkdocs-open-graph-plugin",
  "mike",
]
doc = [
    "codespell",
    "blacken-docs",
    "numpydoc",
    "sphinx",
    "sphinxcontrib_github_alt",
    "sphinx-execute-code-python3",
    "sphinx-copybutton",
    "sphinx-sitemap",
    "sphinx-togglebutton",
    "sphinxext-opengraph[social-cards]",
    "pydata-sphinx-theme",
    "myst-parser",
]
tests = [
    "codespell",
    "pydocstyle",
    "types-appdirs",
    "black",
    "isort",
    "mock",
    "mypy",
    "netcdf4",
    "pandas",
    "intake-parquet",
    "pytest-asyncio",
    "pytest-cov",
    "pytest-env",
    "requests",
    "pre-commit",
    "toml",
]

[project.urls]
Documentation = "https://metadata-crawler.readthedocs.io"
Issues = "https://github.com/freva-org/metadata-crawler/issues"
Source = "https://github.com/freva-org/metadata-crawler"
Home = "https://github.com/freva-org/metadata-crawler"

[project.scripts]
metadata-crawler = "metadata_crawler.cli:cli"
mdc = "metadata_crawler.cli:cli"

[project.entry-points."metadata_crawler.ingester"]
solr = "metadata_crawler.ingester.solr:SolrIndex"
mongo = "metadata_crawler.ingester.mongo:MongoIndex"

[project.entry-points."metadata_crawler.storage"]
posix = "metadata_crawler.backends.posix:PosixPath"
swift = "metadata_crawler.backends.swift:SwiftPath"
s3 = "metadata_crawler.backends.s3:S3Path"
intake = "metadata_crawler.backends.intake:IntakePath"

[package-data]
metadata_crawler = ["py.typed", "*.toml", "_helper.pyi", "__init__.pyi"]

[tool.maturin]
bindings = "pyo3"
python-source = "src"
module-name = "metadata_crawler._helper"
python-packages = ["metadata_crawler"]


[tool.pytest.ini_options]
env = ["MDC_LOG_INTERVAL=1", "RICH_TERMINAL_WIDTH=120"]

[tool.coverage.run]
branch = false
omit = [
  ".converage*",
  "*/tests/*",
  "*/__main__.py",
]

[tool.coverage.report]
fail_under = 95
ignore_errors = false
exclude_lines = [
  "pragma: no cover",
  "noqa",
  "def __call__",
  "def __repr__",
  "if self\\.debug",
  "def _post_url\\(self\\)",
  "raise AssertionError",
  "raise NotImplementedError",
  "except KeyboardInterrupt:",
  "except ImportError:",
  "except RuntimeError",
  "raise SystemExit",
  "except OSError:",
  "except Exception as error:",
  "except errors.BulkWriteError as bwe:",
  "except Exception:",
  "class Completer",
  "if 0:",
  "if perf_file *:",
  "p_col = *",
  "f_col = *",
  "q_col = *",
  "if __name__ == .__main__.:",
]


[tool.flake8]
ignore = ["F405", "F403", "E704", "E203", "W503", "C901"]

[tool.isort]
known_first_party = ["metadata_crawler"]
sections = ["FUTURE", "STDLIB", "THIRDPARTY", "FIRSTPARTY", "LOCALFOLDER"]

[tool.mypy]
files = "src"
strict = true
warn_unused_ignores = true
warn_unreachable = true
show_error_codes = true
install_types = true
non_interactive = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
warn_redundant_casts = true
ignore_missing_imports = true
allow_untyped_calls = true

[tool.codespell]
skip = ".git,.tox,build,dist,*.svg,*.min.js,*.lock,*.ico,.mypy_cache,.ruff_cache,.venv"
ignore-words-list = "te,nd,fo,ist"
ignore-words = ".codespellignorewords.txt"
check-filenames = true
check-hidden = true
exclude-file = "src/metadata_crawler/api/mixin/lookup_tables.py"

[tool.pydocstyle]
convention = "numpy"
add-ignore = "D407, D105"

[tool.tox]
legacy_tox_ini = """
[tox]
min_version = 4.0
env_list = types, lint, docs
[testenv]
parallel_show_output = false
[testenv:test]
deps = -e .[tests]

commands =
    pytest -vv --cov=metadata_crawler --cov-report=html:coverage_report --junitxml report.xml --cov-report xml tests/
    python3 -m coverage report --fail-under=95 --precision=2

[testenv:docs]
deps = -e .[doc]
setenv =
    LC_ALL = C
    LANG = C
allowlist_externals = make
commands =
           codespell {posargs: --quiet-level=2} docs/source/
           make -C docs clean
           make -C docs html
[testenv:lint]
deps = black
       isort
       flake8
       codespell
       pydocstyle
       bandit[toml]
skip_install = true
allowlist_externals =
    codespell
    cargo
setenv =
    CARGO_TARGET_DIR = {toxworkdir}/cargo-target
commands =
    ; --- Python linting -----
    python3 -m isort --check --profile black -t py313 -l 79 src
    python3 -m flake8 src --count --max-complexity=10 --ignore=E203,F405,F403,E704,W503,C901 --max-line-length=88 --statistics --show-source
    codespell {posargs: --quiet-level=2} src/metadata_crawler
    python3 -m pydocstyle src/metadata_crawler
    bandit -r src/metadata_crawler --skip B110 --severity-level medium --confidence-level high
    ; --- Rust linting -----
    cargo fmt -p metadata_crawler -- --check
[testenv:types]
deps = .
       mypy
       types-toml
       pytest-stub
       pydantic
commands = mypy --install-types --non-interactive
[testenv:release]
deps = git-python
       packaging
       tomli
       requests
allowlist_externals = rm
                      curl
commands_pre = curl -H 'Cache-Control: no-cache' -Ls -o bump.py https://raw.githubusercontent.com/freva-org/freva-admin/main/release.py
commands = python3 bump.py tag metadata-crawler
commands_post = rm bump.py
       """
