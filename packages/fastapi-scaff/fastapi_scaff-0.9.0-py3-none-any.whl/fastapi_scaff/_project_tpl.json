{
    ".dockerignore": "# Python \u5b57\u8282\u7801\u548c\u7f13\u5b58\u6587\u4ef6\n__pycache__/\n#*.py[cod]\n#*.so\n.Python\n*.pth\n\n# \u865a\u62df\u73af\u5883\u6587\u4ef6\nvenv/\nenv/\n.venv/\n\n# \u65e5\u5fd7\u6587\u4ef6\nlogs/\n*.log\n\n# \u7248\u672c\u63a7\u5236\u7cfb\u7edf\u6587\u4ef6\n.git/\n.gitignore\n.gitattributes\n\n# IDE \u548c\u7f16\u8f91\u5668\u914d\u7f6e\u6587\u4ef6\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# \u6d4b\u8bd5\u6587\u4ef6\ntests/\ntest/\ntesting/\n.tox/\n.coverage\n.pytest_cache/\n\n# \u6784\u5efa\u4ea7\u7269\u548c\u5206\u53d1\u6587\u4ef6\nbuild/\ndist/\n*.egg-info/\n\n# \u6587\u6863\u6587\u4ef6\nREADME.md\nLICENSE\ndocs/\n\n# \u64cd\u4f5c\u7cfb\u7edf\u751f\u6210\u7684\u6587\u4ef6\n.DS_Store\nThumbs.db\n\n# \u5176\u4ed6\n.dockerignore\nDockerfile\nDockerfile-slim\ndocker-compose.yml\ndocker-compose.yaml\ndocker-compose.swarm.yml\ndocker-compose.swarm.yaml\nbuild.sh\nconfig/.env\n*.sqlite3\n*.sqlite\n*.db\ncelerybeat-schedule*\n",
    ".gitignore": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n#.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# Append\n.idea\n.vscode\n*.sqlite3\n*.sqlite\n*.db\ncelerybeat-schedule*\n",
    ".python-version": "3.12\n",
    "build.sh": "#!/bin/bash\n\n# =================== Configuration Variables ===================\nIMAGE_NAME=\"fastapi-scaff\"\nIMAGE_DEFAULT_TAG=\"latest\"\n\n# Dockerfile and build context\nDOCKERFILE_PATH=\"./Dockerfile\"\nDOCKERFILE_CONTEXT=\"./\"\n\n# ================ User Input for Tag ==================\necho \"Current image name: $IMAGE_NAME\"\nread -p \"Please enter the image tag to build [default: $IMAGE_DEFAULT_TAG]: \" IMAGE_TAG_INPUT\n\nif [ -z \"$IMAGE_TAG_INPUT\" ]; then\n    IMAGE_TAG=\"$IMAGE_DEFAULT_TAG\"\nelse\n    IMAGE_TAG=\"$IMAGE_TAG_INPUT\"\nfi\n\n# ================ Build Image ==================\necho \"=> Building image: $IMAGE_NAME:$IMAGE_TAG using Dockerfile: $DOCKERFILE_PATH\"\n\ndocker build -f \"$DOCKERFILE_PATH\" -t \"$IMAGE_NAME:$IMAGE_TAG\" \"$DOCKERFILE_CONTEXT\"\n\nif [ $? -ne 0 ]; then\n    echo \"Docker build failed!\"\n    exit 1\nfi\n\necho \"Image built successfully: $IMAGE_NAME:$IMAGE_TAG\"\n",
    "BuyMeaCoffee.jpg": "/9j/4AAQSkZJRgABAQEAkACQAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCADOAXUDAREAAhEBAxEB/8QAHQAAAgMBAQEBAQAAAAAAAAAAAAcFBggEAwIBCf/EAFUQAAEDAwMDAgMEAwkNBQYHAQECAwQFBhEABxITITEiQQgUURUjMmFxgZEWFzNCVnOUodIYJDY3UlVydJKVsbPRNVNUYrI0oqW00+ElJjiEk6TB4v/EABsBAQADAQADAAAAAAAAAAAAAAABAwQCBQYH/8QAKREBAQACAQMDBAEFAQAAAAAAAAECEQMSITEEMkEFEyJRgQYUM2Fx0f/aAAwDAQACEQMRAD8A1QnQfugNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0ANBVt0K/Ktawa5W6ehlyXCjF1tLwJQSCPIBBx3+ugzbSd+t2KxE+apFoRJ0XkUdWNTZDiMjyMpWRnQdv78u9P8AIH/4PK/taDnn75bv06G7Ln2UzFitDk489S5KEIH1JK8DQM20NyrouLYyo3ZFpsWTcDLjiGIkZhxaF8VpH4AoqJwSex9tAnqt8Se4tHmKiVagUmDKSAosyYbzawD4OC4D30Hux8Q+50ikOVZi2ac5S2shcxEB8soxjOV88DyPf30DMtHeeXXNpplWL1GVeQLqYtKZUSt5SSAgBnmVqJGfHnQLR74htz2awiku2xT26ovHCGqA+HlZGRhHPJyO/jQSn78u9P8AIH/4PK/taB47Y3ZVqnt+muX7FZoctDjgfQ82qMhtCVYSohw5AP1J0EfuNuvQqLZVWqNu1+gTqtHaCo8f5tDvUVyAxxSoE9ifGgRLfxD7nO0dyrNWzTl0pskLmJgPllODjuvngdyB50Fk233xvu4K5THa3RKfFtV10plVRMR5DLKQDkl1SyhPfAydB4bsfEXWbcveZTbV+wKlSW0NKak4U9yKkAqHJCwDgkjQNLZHdKPe9rwna5UKPHuCQ862IDDoQshJOCG1KKvAzoIWs7q1yF8QsKxWo1PNIeU0FOqbUXhyZ5nB5Y8/l40F+3buWZaG3VZr1NbYcmQ20LbQ+klBJcSnuAQfCj76DO1K343aq8NMulWdFmxFEhL0amSXEEg4ICgvHbQdf78u9P8AIH/4PK/taDmqO+m71MhOzKlZbESI0AXHn6XJQhAJwMqK8DuQNA+dj7wqF9beQa7V2ozUt9x1CkR0lKAELKRgEk+B9dBftAaAyProDI+ugMj66AyNAZxoDI+ugMj66AyProDI+ugM6A0BkaAyProDOdAZGgMjQGR9dAZH10BkfXQGgNAaAGgX+/3+Jy7P9SV/xGgUuzFwzLU+F+s1umJZVMhSX3Gw8kqQTybHcAj6n30C+PxSX3n/ANkoP9Gc/wDqaBsTbwqV9fCxcNcrKIyJjrLzakx0FKMJdAHYknx+eg7vhYqEOlbIibUpTMSGzNkKceeWEIQOSRkk9h3I0Cx3Vt+LfO+DNXWp5+yHUMty61EUDGaSlGFEvYKE4OAc+NB+XkK7SLcn2PtXTXrisiY2FLqDLCpa+qogrSHW8J7FKe2O2dAvNn6RUaJvhakOswZMGWJraizJaLawCDg4PfvoNYVe07Fk7yQq9Nr3Su5stFqn/ONp5EIIT90RyOU9/Ogqu+O5u4dlXHKFvUJmRbrEdt1c5+E64hKj+LLgUE+cD9eg97Q3Gt/cnaiRD3DuCjUuXUC6w+yzJRHWlAV6SAskjOPJ0Cv3F252ko9lVafbV2ibWGGgqNH+02HeauQGOKUgnsT40C5t2/rokWI7tzR4EeZCnrUQ21HW5JUSoLIThX/l+njOg6JF/Xda1iS9u6jTGIUJ1Ki4iVGWiSkLVzz3UMfl28aDsp1pWK9slJr8muhF4ICyin/ONjOHeI+6xy/B38/noGN8Llq2Q8qh1+TXOF4NyHw1T/m2xyACkj7rHI+kk+dA1N09vmYdVn7kUBmoTbwhNoXEiJ+8ZcUkBvBbA5H0knsrzoIG8q3cdwfDBcc68ad9m1ZQ4Kj/AC6mcJD7YSeKiT3Gg4NpLhmWp8Ksmt0xLKpkJUhxsPJKkE9fHcAj6n30CzPxSX3k/wB6UH+jOf8A1NAzbgvCpX18J1erlZRGRMdPTUI6ClGEyUAdiSf69BbfhP8A8StJ/n5P/NVoHDoOeorU3BkLQeK0tqUD9CAdBiuwbr3sv1M1VsVuTLEMoD3JUdvjyzj8QGfwnQW37H+JD/xz39JiaA+x/iQ/8c9/SYmgmPhivi77jvuv0q7au/NEKKr7paUYQ4l1KScpAz7jQNPe2Ne8q2YiNt3lNVUS0l4pcbRlngrPdzt+Lj+egT/w+3vfNS3eqNuXlWH5IhRZAdjrDeEuoWhPlI74yffGg5N7avvDaVWrVaYqj8S1vnenEUhbCsIUfQOOCr9ugjLbc+IG5KHDq9Iqb70CWjqNOF6KkqGSPBGR3B0EEi796l34bNTXJP7oAeJj8o+M8Op+PHH8PfzoHXau7sGyaIxQt2Kw83d8cqVLT0C7hKlFTfqbTxPoKfH69AxoG4duT7IkXbFmrXQmAsuP9BYI4nB9JHLz+WgQs/eaZcO/FtQrPr8hdsSnozLzHQCErUVHmPUnl3GNBa/iAO6kKsPVWyJrse24lP60gocZHFaSsrPFY5H08fGg6vhnvmrV7bmvVq76m7MMGY5l5aBlDSWULIASBnyT9dBH3Dd12bh16mTtnKm89QIiktVPshn1lfLw6Ao+j6aDi+Km+bptSuW3FtarPQBMad6iG0oPNQWkJzyB+uggPsf4kP8Axz39JiaA+x/iQ/8AHPf0mJoKtflyb4WJFiyLmrUiK1KWptopXHc5KAyfwg47aDYtryHZdt0qRIWXHnYjLi1nypRQCT+06CT0BoAaBf7/AH+Jy7P9SV/xGgS+2lPmVX4Srhg0yK9LmPvvpbZZQVLWebZwAPOgQ52svzP+CFe/oS/+mg0RR6PUqF8Iddg1mDJgTENyFKZkNlCwC8CDg/XQSXw823Eu74d5NCqLj7USbLfbcWwQFgBaVdiQR5A9tBxvWzX6HVE7V0mjT5G3s4gSauthSnmw56l4dGGxhQA7pOgdG29k06wLbFFpD0p6KHlvcpKkqXlWM90gDHb6aDPG91FvOLvyxdFrW1PqaYbcdxpxMVbrKlpSQQSnz5+ugjbTp1/3Lv5QLqum051PCXkJecRCcbZQlLZSCSrOPb30GhNz6rZdQotQtS7LlhUszGUh1CpSGnkpyFAgKz5x9NBj++9rJAuF397WFVbjt3gjp1COj5hC149aeaEhJwe2gqdV29u+k096dU7Zq8SGynk489FWhCBnGSSO3kaBl7Q0mhU21Y920OomXuNEec+RofVSvr9+P8CAFq9ClK7KHjOghNw7d3Lvu5367VrKqjMt1CG1IjQHUowlPEYByfb66Ba1qkVGh1ByBWYUiDNbAK2JDZQtIIyMg/UHOg0V8LtrWS9IoVek3AW7wbkPBqmfMtjmOKkj7vjyPpJPn20DOrG6tbhfEJCsVqNTzSXi0FOqQvrDkzzODyx5/LQWL4j/APEldH8w3/zm9ArNv6fMq3wgVKDTIr0uY98wltllBUtZ64OAB58aDPp2svvJ/wDyhXv6Ev8A6aB/NUepUL4Oa3BrMGTBmIWpSmZDZQsAykEHB+ugYPwn/wCJWk/z8n/mq0Dh0HLVf+zZf8yv/wBJ0GYPghOIl5EeR8sf6ndArpO/+5CJDqU3D2Sogf3oz9f9DQOz4Wtx7pvit1xi56n841GjtuNJ6KEcVFZBPpA9tBXvhZ/x031/Nv8A/wAyNB3XJL+IVNxVQUdh80wSnRFIRE/guZ4ee/4cee+gQLV3XdZ24FXqglGHcynXmZq1NtrPNS8uDGCn8Q9tBr9ypW7cOxVAqW6shLkCWyw9IdUFoCnjnicNDI9/HbQX7b5NBRZtLTaBCqCGj8oQVHKOR/y/V5z50CErtv1S1/iTmbgV2IqHZ7KwXKkpSVJSFRw0PSklfdZCfGgu9y23tLeNKlbhVltEuA4kB6oB2QhJCCGh6Bg9iAPGgTO4argatWrM7WpUvaboetaAgp5dur3c+9/H/wDbtoFZaFr3lHpove3ae58lSnC/88FNkNKbwSeKjk47ex0GiNqt6qDWtv6lA3WuJpc2U66wptUdSSqOpCRjLScDyr89BFv9Rh1DWy2XNtV/4QLR6khXh/Je+8H3HH8P6u+gcmyzVgNUmojbNaFwS+PmSlTp+849v4Tv4+mgTHxkf4ZWV/oOf81GgtnxVbhXNYr1uJtio/JCWl8vfcoc5cSjj+IHH4j40CD/ALoHcr+UP/8AUZ/saBu/GM6t+x7NedPJxx1a1HGMkspJ0GibN/wSov8AqLH/AC06CY0BoAaCj73QpVS2puaHT4z0qU9DUltllBWtZyOwA7k6DMe3lzbvWFboo1FsiU5EDy3uUmkyFL5KxnuCO3b6aCzfvt74fyEP+5pP9rQRF3X3vLdVt1CiVKxn0Q5rfScUzSJCVgZB7EqI9vpoGFtGi6bM+HWoOQ6JKFxR33nWIMmKsrXlaB/B9lEYye300EtSt0q4rbOY9VmqfF3CAc+Woa21IedPIcMMFXUOU5Pbz7aDib3hq1P2mqtSuc0qlXswVqYpUlJZWtHJISeipXMggq7g98aCWsjcO5rl2OqF0sQY0i4G+umPGjMLUhxSFAJHAKKj2J8HQRo3gqNO2kqFSuRyk0y+GErU3SZILKyOYCPuVK5nKTnz386BSVlij7s2RPuyqT21bhqBjxaPAeSOslCgE8WDyWo8So9j7aBm7Zyq3t58M9Qnu09yHVoBkPojz2VJ8uDBUk4OCDoOh64K5uX8MVYqD8JL9XmIdaTHgMqPLg+AAlOSScDQUDbjbCdbG3hvyNSqwL6prriotNfZPBfqCBlriFn0KUex9s6Bi/vwVCnbRz6lcblJpl8sJWpFJkgsrI5gIyypXPuk589/OgWV02zC3D2dqm69cW+3cikFJaiqCI33boZT6CCr8I7+rzoK7tyxa1rbdJv2JWmP3eU5xwxqa/KQULyvp92eyz6FKPYjxnQXuIgVmxHt8pWU3hDClNsN9oZ6a+inKPxfhPf1ef2aCzSLiru5/wAMNcnPQUyKvJKmUR4DKjyCH0Y4pySTgE/q0CysC694LGtpih0ex5LkNla1pVIpMhS8qVk5IIHk/TQWP99vfD+Qh/3NJ/taCEvW9t47wtefQapY8hEKYlKXFMUiQlYAUFDBJI8pHtoHp8M1LqFG2jpkKrwpMGYh6QVMyGi2tILqiMpPfuNA1dBy1X/s2X/Mr/8ASdBmD4IgTDvIDyflv+DugTUnZvcJch1SbUqWCskelP1/ToHr8Jtj3LaVer71x0aVT2n4zSGlPAAKIWSQMHQRPws/46b6/m3/AP5kaCYsPfCWjdW5qXfNbgxKFDXJai82Eo9aHglI5JGT6eXnQXiRsltzdz7lxfKyJf2qozeu3McCXOp6uQGewOdBM31bVkU3bSLQ7qdMO2Iimmmy4+tJBTngCodz76D622uywURqdatm1yLJ6DSkx4yXFLXxGVHuR39zoEl8TVV3ILlywVwl/uECmcP/AC6MY+7P4/xfwnb+rQTuwlVs249m6ZYNcqbKp05byFwEuKQ6r75TgwQO3YA+fGgcdP25t2BYki0Y0Z4USQFhbRfUVHkcn1+fOgQlyLNn7nUvamhfc2ZWSyJkZz7xxYfJS5h0+pOQkeD20FP352XlW9XlP2VQZyrejwA/If6hcShYKyskqOeyQDoK5trVNx4dg12PZ0Jb9uuKd+fcEdCwkloBfqV3Howe2gk9gqruRBZdasWEuRSHJrfzq0x0OcTgA91dx6fpoL78ZH+GNlf6Dn/NRoLF8W9l3Hdz9sm26RJqIjJkB4sgHhyLeM5Pvg/s0Gef3mdw/wCSdS/2U/8AXQPH4xG1s2NZjbqSlxDikqSfYhlII0GirN/wSov+osf8tOgmNAaAGgNBW9xajWKVZdWnWzEMysMtcozAaLvNXIDHEHJ7E6BaUjdCu/vczfttMGJuLhz5SiraKHnTkdPDBVyVkZ8edBQv30N9/wCRSv8Ac7/9rQXmm7oXH+9tN+1WoUfcfkr5SiKZUh51PJPEhgq5qynke30/LQV+0RbdSuGBeu6tVZt+/IzoJgPSExEpQgYbUWl5VgpOc576BN/FFWaZXt0VzKJUItQifJMoD0ZwOI5DlkZHvoPna3eC9bZpcS2LUhQZnN5SmWlRVuurWs5IGFDP7NAx74sZy7NrK1uJfUKfT7xaZIMYJLDQShQQgltQKu6fz76BA7d1Gs0m9aXOtiJ87WWXCY0fpF3mriQRxHc9ifGgdt13jvXdFuT6LUrKfEOa10nC1SXkr45B7EqOPH00EVa957tbZWYILNquRqPCK3VPzaa76OaskqVyAxk6BrWtvTUa7tLJmx5VJkX8pxaYlKYTlx3CxjDPLkfRyPY+2fbQIGqyJd470Qjuu19hmSW25uUmJ0mw2eKvXnjnA7nQaIvak29RPhgrsGzp/wBoUZDSi1I66XuRMhJUOSQAcHI0GYtsLHNcrNOnXLEnRLMU4tMuqgdNloBJAy6QUp9fEd/rjQbBplsWIzsvKokSthyzVhfUn/OIPHLvJX3uOPZXbx+WgVdqbjUvb/cim2TbVYpTthci67UJDocUlS0KUodYEJHqAHj30GmKJWKdXaeidRp0edDWSlL8dwLQSDggEfQ6BJ3VvHU7e39atSfIpcS2R0y9IkJKVoCmefdZVgerA8e+gtt67o039y879wFZpNZufin5KBHdEhbyuQ5ANpOVYTyPb6Z0E7tLV7irlkxJ14wDT6ytxwOsFhTPFIWQk8VEkZGDoLloOapJUuBJShJUpTSgAPc8ToMRbas7u7donpt20aiBOKC78xTVufg5Yx4x+I6C6/vi79/yRe/3Ov8A66A/fF37/kk9/udf/XQSHws2zdFK3BuOqXPQ59OE2KpXUfjqaQpxTyVEDP6zjQQFmbMv3Ru/dZvSi1iJRXHpUiNJCSylxZf9OFEHIKSToGFZF2XHZ94y6FdjCKPt/TEOQ6dUJzBaDgQoJZBeJwolAJ/PBOghbirs+9rmqNLvwIibWreU7Dq6EdBt3j/A4fOUqCu/6dBSNloNGpvxQGHbEoSqM0mQmM8HQ6Fp6BOeQ8986C93ddNRvTfGftXWuibWkLCVhlHB/CWQ8MOZP8cD28dtBVom3p25+ISDUY0CfFsqnLStdUl5LLYUwQSp3AGOauP6e2gY9U3NuNW5UR2j/KSdtgW/mawhjmw2OP3mX88RhXb8tAtr3rlLuD4qrQm0SoRahE6sJHWjOBaeQWrIyPfuNBed7b9rMXdWkWG0Y32DXGWI8sFrLvB5xTa+K89jx8dux0FZvVxW0d2Urb60sC37jDapwlDqvZecLC+C+3H0JGOxwe+g9rxmvbD3TRbdsPiKfWVIflfPDrr5dQN+k9sDjoOz4tLWuOvXBbEm3KLPqQitO81RmFOBCuaSAcfo0ER++Lv5/JJ7/c6/+ugP3xd+/wCSL3+51/8AXQU/cg7wbhQ4ca4bRqBaiLU438vTFoOSMHPnOg2ZajLke2aSy+2pt1uGyhaFDBSoISCD+edBK6A0ANBXdwalVaPZtXqFvxPnKrHYK47HSU51F5HbinuffsNBlasfEfuVRZnylYoVKgyuIX0ZMF5tfE+DguZxoGBthS6VuA3C3bvGWafV4T5SrouJZiJSz6UlQXkjz39X7NA27sud4bfVSt2OqNWpbLRMVMf++EOrCgCnCDlXv2B0GYrcmXhWN86FeV90CRRYkZQTJluQ3I8ZlCUKSCpS+ye6gMk+SNBH/ERRKreO5cqr2lTZlbpS47LaZlOZVIZUpKcKAWgEZB7Ee2gtOzvw80m5LOTPvFqv0yqmQ42WMpZ9AxxPFaCe+T30C53JpTGze8cX9yxckfZyWZbXz5DmVlJJCuPHt+zQaYsyutbpbFypl9SI1NizeqzKejKDCG0JcABBWVAeB3OgRlrUC3bc+J22YFn1P7TpQUlYkfMIeystL5DkgAdtAxN4t5rytXcxdsWvTKfOBaZUy2uM468tS05IASsZ/ZoFne28O49zw5ll1e3YrMqoIDaorUF5Ekg4WOKSonuBnx40F9+H/aukUGiwL6u1dSotWp8h0qRNWmOyhPdCSpK0ggEK85840Hl8QdB24uCDXbsi3ZGk3CmMgMRY9RZUhZTxSAEAFR7fQ6CHoVx0Rr4RJ9Hcq9PTVlJe4wlSEB45lBQwjOfHfx40Ckh7n1uJtlJsVpiAaPIUVLcU2rrd1hfZXLHkD20GlNk6XSK18MIp9xzfkaTIXITIkdVLXTT1855KBA7gedBVL02Fs5G3dUrtiT6tXJrKR8siPIbkocVzSlQwhGTgE9gfbQc2xd135ZiqRb1bt1VMtNt9a5VQnwXWuilWVEqdUQhI5YGSPfQW3fHbC371oVcvu3ZU6r1hbTYjt091DzLqkFLZCUpSScAHOD5Ggo1l2CbB2sXuY9FqMS76S4tTUOcjizhTgaBU2Uhf4Vk/iHfGg0Nsdd9QvnbuDXau3GbmPuPIUmOgpQAhZSMAknwProL9oA6BIfEdunXNt5FvooTMBxM/rdUym1LxwKMYwoY/EdAw2dwrQUy2pd00ILKQSPnm+xx+nQUzZa9r1umvVpi7aKmnwI6AqI8mG4yHcrI/EokK9OD20HBYG51xu3jW4m4cSFQKGx1EwZcllUUPqDmAAtxWFHhk4H0zoIjbXfR6t7lV+kXHOoMKhROv8pK5dLq8XQlHrUvCspJPbzoGBeMKy92aSLdXcEaUEOiX06bNbU76ARn+N29X0+mgRhrMGr3ZM2iumbFp1lUda2mJinAzIPR/gwpxR4knJz6Rn8tB7V2j2HtJTV3dt3ckeqXFFUlpmNInNSEKS4eCyUICVHCST57aDpUwlmwRvugn92SxzLB/9jyV/Lfg/F+Dv+Lz3/LQR1E3Ju7c1hmkXpTI8Gx6kS3Nq0eM4yhpKTkEPKUUJ9aUp7/XGgaFZtak0z4d7gotiSXq1DUw90VNOJkLcWpYKkgoHfB9gNBmbay07hoe49t1Ss0OpwKbEntPSJUmKttplCVZKlqUAEgfU6C0/EtdcQbz0WvW5Ng1D5CLHdQtpwOt9RDq1BKuJ/RkZ99AxNrKWxvupq9bxU5Hq1FmoixkU49NpSG+Lw5JVyJPJZ8EdsaBmbrbYUi8ZceuznKh9o0phRitx1gJWpJK0hQKST6sDsRoK5tbulWp1Lqy9yWqfb89BT8gzJbVEMgcTnCXFZV6uI7fXQKasfEHuhQ1MCt29T6f1s9P5qnvNc8YzjksZxkaBsbsbp1qFDpK9r2qfcj7nMzkRW1TOgMJ4ZDavTklXnzj8tA5qe449BjuPo4OrbSpacYwogEjH6dB0aA0BoAaCq7p16Xa+39crVNDRmQoxdaDqSpHIEeQCM+froMbRhV9276gXJfMF2LbiiI02pxGlMx2UIB7lxXJKTkgEk+40Fpv6o1i1rSq1rbdRPtjbtyOVO1YNGSEqXgujrowgYIHt299BU9rt472tqlQ7XtSBAmZdWWWlRVuvLUolRA4qGff20Gm6HKmXtszURu20aCl9a25RKDE6bQWkpV95nGT7nzoEvL3JqW3VebsnaFUCvUbs5GUUmY6464OS0hTagDg+wGg0Vs7XLmuCzkzb1ppp1WL7iCwY6mPQMcTxUSe+T30Cl+Ji1LDlCuVupV0M3c1CQWIBmtp5lIwj7sjkcjPvoO3Y2nUeq/DM5BuSX8nR3nJKZMjqhvpo6vnkQQO4HnQfu3m320VIvSlzrZuxM2ssOFUaOKoy7zVxII4pTk9ifGgjrutiuyPiso1Zj0eoOUhpUbnNQwospw2QcrxjsdAu9/7im2n8RrtbpiWVTITUdxsPJKkZ6AHcAj6n30F1ru60a9Phwrv7oKrR2rkkZbTBZcCFqSl5GMNlRV4BOgg9n9nbJuTa1m6brnzoRDjweeTKQ0yhKV8QTySce3voKYixbRqG/kC1KHUXZ9syVISJLElDi1fclasLCcdlDHjQT9y7MU6h7usQJcerxrBShCpVXfUEttZbJ7vceA9fFPce+NBHbmX2i1aXUtubJl0+o2attPCUVB91RWQ4sBxJCey8j8PbxoGxsnU61R/hjkT7Xh/O1lmQ8Y8cMqd5kvJBHFJBPYk9vpoGFacerbkbTPQtxYL9NmTy4zIYaaVHWlAX6SAvJGQB5zoFzbFyztvt5qXtTQksKtlDgIckoK5P3jReV6wQPxHt6fGg4Pijui+W01yhRqIV2c5HYLtQ+TcPEkpUfvc8R6wB4/LQMD4T/8AErSP5+T/AM1WgcOg8ZrqmIjzqQCUIUoA/kCdBgPci/bl3hcp6nqEnFM5jNNYdcx1OP4u6sfg7fr0Daa2A20U2grvp1KyBkfOxex/ZoK8v4obmpy1Qo9HojjMY9FCz1SVJT2B7Lx4GgnItal75BNK3LjotalQ0ibFltJVH67h9PHk9lJHFRPbv20Ct23sG2rk3IuCg1quqg0qB1/l5YfaQXeDoQn1K9Jykk9v+Ggar1r0fZpP7ptt6mboraz8mqCtxEgBpfdS+LOFdihIz476DOV8VabXbuq1UqsUQ50uQp16OEqT01E9xhXcfr0HCukVJunJnuU+YmCrGJJYUGzk4Hqxjz286Bju7h3QrZNNoqoCBbwSAKj0Hc463P8AHnh+Lt/99BObP3nMuejUzaKZHjtUSorcbcmNcvmEjkp7tk8fxJx3HjQNi3KxVdqb2p239NpxftFLqXXqxNaWFNh0clEuJw2AD276Bgbt16j1PbK54VNq0CXNkU95tmOxJQ444sp7JSkEkk/QaDLtl7T0eqbcVir3BUJ1NuSN1/lKYsobW/xbCkYbWOauSiR284wO+gltiLwvWxVMW/FtR5yDUKk2t9+TDfCmwrghRBGAAAM99BtUd9Apd7bBtq7Z1LnXBXVU2XAacMZkPtI63cK8L7nuAO310GZd27ovfc5ylqq9pyYnyHUCPlYT/q58c55Z/wAkaDTm2G3ls7QmZITXXEmqobSRUnmmx6Mn09hn8ffz7aBKzvioudibIZaotCWhtxSUqw6cgEgH8eg1pQZi6jRKfNdSlLkiO28pKfAKkgkD8u+g79AaAGgh7vt+LdNt1CiVBbzcSa0WnFMkBYBIPYkEZ7fTQZkuSRAsO5G9oXJbceyKkhL0yfLWBJa6mVHDnZAGUJAyk+ToKfuBfkezaNUdvbFlwKtakljkqa4rrPc3O6wFpIT2IH8XQem0lGtuHakW6aTVDI3GiuuLg0XrJUH1hWEjpAc1ZSSeyhoHvQa+3uFZT9pbmPR6HcdTWpo01o9CQWwQpCkoXyPfie/5aCsXDsxbu1tFmXvb0qpv1WiI+bjNzHULZUsdsLCUJJHf2I0E7bm69dqWwVZvZ+PT01WGtxLbaG1BkhKkAZHLP8Y++gXttUuy97no9avmvpgXbMcMVNOgSENBSUdkYQsKVkj89BerzpNuWltJWtuLcqhmVp5lRjU515K5bqnFheAlIGe2SO3jQZ2s2zNyLSuiBXabZtVclwllxtL8JwoJKSO4GD4P10GjVbxzqTthUJl0qpVLvphC1t0iQlTalDkOH3RVy7p7+e+gzlSprm829NM/dQlEf7TcSw98gOGEobOOPLlg+kfXQX3eDabbeyrcqvyVxyzcsdpDjECTLaKl8lJ/iBAJ9JJ8+2grmzd6VGuRKbtXLaipt6qPLZffbQRJSFErPFRJSDkDyk9tA6rQ2p21szcmmiFcss3NFXzZp8iW0VKKmz5QEAn0knzoKv8AEhfl0TrqqW2tFpsabFnR2SlLTK1yVHAcPHCsfxfp4zoM+1bbu8KRTn59UtqrRIbA5OvPRlJQgZxkk+POg0ltJcky0PhWm12mNsOTIT7y20vpKkEl5Ke4BB8KPvoIrav4hbsuzcGiUOowqM3Emv8ATcUyy4FgcSexKyPb6aDn3dot8U/4gnbttS2ZtSEZLCmHBFW4ys9AII9JGcZPv5Gg5r2uvee8LWn0Cp2GtuHMSlLimKc8lYCVBQwSsjyke2gdfw10eo0HaamQKzCkQZrbz5Uy+goWAXFEEg/UaBpaDylMh+O60SQFpKSR7ZGNAutntqIW2TVWbgVSVNFQ6fLrISjhwCsYx/pf1aDLvxB7SwdtGKPIg1OTNVUXHgoPNpSEcQk9sf6WgU4o1TIBFOmEHuD0F/8ATQM3cjcG4r5tGjUGXba4rNMUhSHW0OqUvi3w7gjA+ugZdE+GmgSrapVUqNzTYa5kZp5SHG20hCloCin1fTJ/PtoFja1Sqm0e59Zk0Olu1hiOX4DTjjawlxHMYXlAwc8R47d9Bf7Y2Yc3ZVIvuuVf7Jbqsh912EywStlSVlOOSz49Oe40DMr220uftg1YcW5KQ3SWeAbkuoUp/CV8/UAsJ89u3tqOqJ1XpC22lr2rasCoXFSlUdKeKpUdCg+fveqMBSynz2/R+em4aquWJsBFs3cSmXDDupiRDhLKxHdaAcVlBSfUFY8nPjTcNUz9yKTUbsoFUocWrUWLT5zHRLjoUt1HjJ7LCT403DVK3b74eaXbNepdam3YmTNgSkyUoZbQhtQSQQDlROm4aqY3osBUvcG3b/8AtVhuLAlU+OYym+6sygOXUzgD7zPj21KDpRV6ataUoqERSlHAAkJJJ+nnQSA0GUPjJIF42WTjHBzOf51Gg06qtUsAkVGHn/WEf9dBnCAxL+I956Lc8V23kUE82Fxmyrr9U4OeoPbpjx9dBl2sUuTTJjzb7EhttLi20LdbKeWCR7jQf0rs3/BKi/6ix/y06CY0BoAaDmqU+JTIL02oyWYsRlPNx55YQhA+pJ7AaDK241pt7ob80uTBal1K0n2Wo8iqU31soKUrKh1QCkEHjnP10E3f3w22zSrNq063vt+ZVmI5XGY6qXOovtgcUoBP6BoM42yzc9nbg0ww6NJFxRnQ4xBkxllayUnGW+yjkEntoH0lx6ot/u5raPld3Inpg0DHT6yU+lB+WP3isoUs9le2fbQe9LubdK/agxa16Wm9BtyqK+XmyWaY8ytts98haiUp7gdyDoKfvPWZO2EeobY26lp23ZcdEhxyYkuSApw5VhYIGPQMenQLXZadFpu6tszKhJZixGZiVuvPLCEIGD3JPYDQXjeu92oG/Yui1ZkCo/KtsLZdSrrMqUG+JB4nvjJ99AxdoN6b+vG6oDVQplMRb3W6cya1GWhLXpJA5qXxBzjt386i2Q1tYd+NsLduuHWbmgy5Uq5BGQmPGjymy2tScADhjJ7Z99OqftOqS2yNj3JRN1bdqNWpEmJBjyCp193ilCBwUMk5+pGnVP2aq/7m7fv338REMvwpz1syGWmpE6FgpRxaV/HAIT6gB3GksvhGnfW9trK24mLn2fVZMu+qeA9T6TIlturecI7DopSFqykk4BHjUix2Na0WpOw91dx/maFczC1F9p0iNGaSjLSCpCwSMpx/G7k6CpVlaJXxM029Yyg9Z8dCUu1pB5Q2yGFIIU9+EeohPnyQNBZbrr9fv++DacCCmftvUwhl6sQGFLwAjkri+CUAhaePg48aCQ3Ps6m2L8N9yUWjLkriIQHQZKwteVPtk9wB/wANBnj4dbYrr25VsVpmj1BykIlq5TUx1FlOEqByvGOx7aB93RvFUrf38atOc7SYltDpl6TISULQFMc+6yriPVgeNBZNy94KBR7Gqk+1rioE6tMoQY8f5lDvMlaQfQlQJ9JJ7fTQTGxl3VG+NuoFcrCIyJj7ryFCOgoRhKykYBJPgfXQMDQGgU2+W68nbR+ioi0VNTFQ6vIl4t9PgU/RJznl/VoPfeHbGPuvBo6HKwad8iXHPu2Q9y6gT2/EMY46BiwizEhsR/mEK6SEt8ioDOBjPnQLDandqTfN7V2hP0VMFumpWpL4fK+rxdCPBSMZznzoM/fEVuzJvBEq2HqGmG1TKo4Uyg+Vlzp82/wlIxnOfJ0DO+GzeBy4X6ZZjtJais06lgCX8ySV9IISPSUgDOc+dBfd1In2TtzPRHkqdTJqJfUR27OOlZT28gZx+eNZ/U38F3B7yTpVAkVeJIdiONhxpQAaUMc+2ex9tY8OK5S2NWXJMLqvuE2poqadBbUn0qSRgg/mNIjKuxzjhOOKu3c6WOpNPj5Zb622mkha3FYSMeTqJju6LdPS5aS1SXo7KFlS1NBSz2xyyc4/LXXJh0XRx5dU2mb7W4/8K1XTlbhTKbSkecASEdh+WtfpvYyc8/NlGizXKLXadUFMFaokhuQG1ZTz4KCsZ9s4xnWhS3rsXua7udRqlOepaKcYkgMBCHy7yynlnJAxoOPezaGLuZPpciVXVUswm3GwkMBznyIOe6hjGNBl/e7adnbZ+jJhVZyrCd1Cr+9wjp8Cn6KOc8v6tBvFhxDcVnqLCcoH4jj20GF9+N2ZO4TUSnSKImnIp0l1SXQ+pzqduPgpGPGdBtmzf8EqL/qLH/LToJjQGgBoIm66DDue3p9FqRdEOa2WnekrirGQexwceNBQaxS2Nmtm62q0CtRhJVKa+dPV9alJBzjGRjQVKzd6Jdd2qlyjPpLl9KLqIdMaT63lAjgA1y5KJGfB76DP9ZuS/H95YVZnUYt3i2W+jC+TUkqwghP3ecnKe/nQOSZTat+42Zu3dMCRT79pIwxHdaLTHBKghJU0e5yFq/jaD92k3V3RvC46OqVRWXLbkSOlImsQFhCUjOfXyIGDoPLdzbioXn8QtNMyk1Ry23mGWpM2O2QhACV59eCB3xoE3vPt/HtvdD9zFpx5srqMsqZZUeq6ta0kkDAGf2aCx03bG3httJRVVTY+5OF/L0VTwQ84eXowwU8jlPfz386CXoVIk0O2rVplywZMJSEvLejvoLa0hUhfqIPcZSE9/oBrF6jV5JL4auHfRdLbCtha3HfssokRR3bUryfy7ef06p6e/ZZbe3UklWRLbS2ucGm2VKGcEZP5DPvqZx35LnNdkZTZdUotxVl+1ISlVJqK+YsQNKX1FADCeA7q+uNd8P8Al7OeXvx90VU58CPTH9wLtlM0zdeCnmzSnlhkHieDeY59Ryg5/F3863sa7WvuNbG4u0ioG41xUmBNnlxuUw1ITHWlKXcowFE4yEpOgr1KpMidVGdvLXjv1LaaaSX6qwkuqC8FxQEgekYcSkfh/LQX6oTaRtfY0u07EnsybljJLkKlyHQ/JdW4oLI6YwVekkjHtoFom6dxLqUKLunQ1Uay5fpqM8wlxQygepJ6qiQnKwgdx7499BfYVyWtZe28mhbWV2BV6w2Frp8IyUynnnFLyUhKcFXbkcD6aCKoO0UTc+mt3TuVDqlPueWVIkR2VfLpSlB4Iw2pJIylKT57+dBn7eDb1qgbqu2rZ8WdMJaaWywT1XVqLfJWMAZ9z49tBrL4aaRUaFtLTIFZgyIM1t58qYkNlC0guEgkH6jQNPQeUt7oRnXccumgqxnzgZ0Cv2V3WRuozWMUc035Dpp9T/W58wr/AMoxjj/XoPLZPaNzbSfWpK6yKl9ohsBIjlvp8VKP+Uc55f1aBZzvhUekzZD/AO69Keq4pfH5EnGSTj+E/PQfKfiZatofYf7llSFUwfJF4TQnqdL0cscDjPHOM6CU+LCoisbK2vVAz0fnZceT0854c2Fqxn3xnQU6z/hkduG1qTWU3SmP8/Fbk9L5Iq4c0g8c8xnGdA07htE2HsRFt5yb88YssHrhvp8ubqleMnGM486z+p9i7g95cWlVH4UxxlhtbocGcJ+o1l487jLGrPCZLy1GiJQqp1UMsKSAVrdI9P5Z9zrrHG5VxlZE5a9JodbbemQHIctkrwVI74P0IPcHXf2nP3L8OK7KlbdqVGJTZj4blSE82kIQCUpzjOdT0Sd4jrt7Kve9Mkl0VBKg7HKQnIGCkfnqnklvdbhZOxg7d1oULbOLLVH64dqjcXhy446r6G+Xj25Zx741r9N7Gbn95MfFvTvtbeG1KalwM/OQ2Y/U45485C05x74zq9Semx+2StsaPUoKqoKl83ID/MMdLjhPHGORzoIvfHZ5zc6fSpLdbFNEFpxspMcu8+RBz+IY8aBZoc/uYMtvj9032/6gR/e3Q6P6efLPU/LGNB+uSj8UGIzINtfYH3hUo/NdfrdsduHHHT/POdB1/GZGESzrRj5Ci0+43yAxnDSRn+rQaHs3/BKi/wCosf8ALToJjQGgBoDQVrceBRqnZVWh3PMMKjPNcZMgOBBbTyHfkQQO+PbQKSytp9sKIYt70W4Jr8KmOl4SlzG1MJKex5EIHYZ+ug475XY1Uuhy87OuBqq34whH2dTmZCXG33EJ4hPTA5K9OTgKGgp943NvbdltT6HU7I4QpiA24pmnuJWAFA9iVkeQPbQU23t1r82kpiLVVSYMQsqU/wBOfFX1R1DyycLHb6dtA+rb3Vr9S+H+s3rIZp4q8RbiW0IaUGfSpAGU8s/xj76Di2ft6Hue/Tdz7iU81cTEktpbhqCI+GvSnKCCfB7+rQUjcaowqP8AF3TJ1TktRYTHyynXnVcUoHRPcnQW7cWoUu8dxLf+yZzEunyIeRIZUFIVwcXyH59xjWPnx6s408OWsVnuGg0ZFDUaqZa4sRsyyIhWlfox4CCCfPjU4Y99S6Rll82IGq1q2aqqEic/UK2GHW1RIrbDhdQ6SE5UrIH7fz139r/bq5fjLMf5MVmiRYt7UmexhLoDzKh/lDpkj9mNMcNZyq7nvGwh967DkVvfZVSr8KdGs0tsJmVRA4NtIDWCeZBA9WB41oUrXQfh22zr9MbqFFrNYnQnCQh5iY2pCiDg4PT9iNAyLEas/b/5axKXWkGfzU63ElPpVIUV5X4AHbAJ8eNAg9+Id2W3vZLvujUV96DT22HEy3WSqPkNBB5EEe5x586CjXnv/d13WzOoVUjUdEOYkIcUxHWlYAUFdiVkDuke2gtO2lnU2h7O/vpw1yVXJS1OusNOLBjEpc6Y5IwFHso/xh30Fx233k3BrM+nVO46TTodlLcUJVVTFWhttIyM8ysgesBPjQem6NcsCJVpe41tXNDnXnDbbESH8ylbDhwGzlsAKPoUo9lDuM6Bs7G3dUb426gVysIjImPuvIUmOgpRhKykYBJPgfXQX/QctV/7Nl/zK/8A0nQYJ2T2vqe4rNYcplbTSxALQWChaupzCsfhI8cT+3QLp2oVBt1aPnpJ4qKc9ZXt+vQMvY3dlO3dTqkqpxZlUTLZQ2hKZHHgQonPqzoGqr4nrcUolVlukk5JLrXf/wB3QLfejb2fSbcjXq9V0PQa7LD7EDioGOHkqdSnJPE8R6ewGgd3w47uRLjapNmM0qQw/TqWkKkqeSpK+kEpOEgZGc6Cy70VhudtrNf6am0s1T5UgnOS26pBP68ao9RN4LuC6yL7a6hKqEdc4KAQtWE5HkDWTHCtNzMudbUSZETTpzbbzEk9NSFDIPbOrphdyRV1TVtRVMtagUpUpq35MCJISnouNsuEJCh3AUMkA+fz1ZeDK+aYc2MvePKbS6LFiCp3o9SQ6yQlK1JDykpyDjPnyfA1H2L+3XJy8fV+E7LnMo0KdTuASlTLiOxA7EEdjplx/CmZ3atfJGn7G3fFX3VHjz8H6YQSD+RHnOu+Cax0jmu8ts1bSbO1TdGiSay1X24hiyjFAfbW6rISleQQe34tXKjMiT3tiWnbQrLztclXF62pbThbTHCh0u4Vknv37HQco+Gy44JEtd5NuJY+9KA276gnvj8X5aBbb97rRN0HaIqJTH6f8gHQrrOpXy58PGAMY4/16DSfw/7SS9s3aw/LqjE8VFtkJDTKkcOBUe+T3/F/VoJHfrbGVubTKVFh1FmAYTy3Sp1pSwrkkDAwR9NAxqHCVTqNAhLWFqjR22SoDAUUpCc/1aDu0BoAaA0Fc3Dp9HqlmVWFc0v5OjvNcZL/AFQ3wTyBzyOQO4GgyTet1O0NMrbLbB2NW7cqDQCFo/vmQtxzutKVpIGcjxjQLW2o102fuFTBEo8lNyR3EuMQZEdRWolJx6OxOQSdBq6m7nXGNtpiaq1CjbjlSvlKIpgoedTyTxIYKuRynme30/LQQkTbem7gUB29d30TqHWBluSlKxEabaQeKFFKwojI986Ba3xcSqM3J2x2udj123ai2FBTf99SFurPJaUrQQO3AdsaDqsCuby2NbrdFotmSlQ0OLdBfpTq15UcnuCNAyqDtMxunT0XRuZDqlNuV8lp6OwflkJQg8UHgpKiMj89BT79sxu0tx7YoFsypLMODAMkOvqDixyfcJz2AOSceNZua6y21cWvt2GzalRkOVmKiQtKm1NOJwB2JwNccOe8+6MsfxXmPEiIWHGo7aVjuCE62aZrvwom4lQr9LqzMu34xly2oclUSOGy5zfCR2KR3PpJ/ZqmyzkkWSTotdVGfl3dszM/fYbNDMgONzcp+U6TYcHFXrzxzgdz9dXK1l2ppVvUWyokKzp/2hRkLcLUjrpe5ErJUOSQAcHI0GZ97KlW6T8TrU61YfztaZYZMaP0i7zJYIPpBBPpJP6tA8qS9Ju/ZWV++y39hmSFonZT8p0mw76D688c4T3PnOgzOmxbNqW/dLtagVF2fbUoDlIYlJcWVdJSiAsJx2IHtoNUO2Datt7UTrXmTZEW2ilRfkSJCUrQFLCiSvjgd8e2g4afbNiNbLSaJGrQXZqgvnP+cQcZd5K+9xx/H28floMr7g7XvruV47Z02qV62+COlOjJMpC149Y5oGDg9se2g1T8NNIqNC2lpkCswZMGa28+VMSGyhaQXCRkH6jQNPQeM1ovxHmkkArQpIJ9sgjQZKgfDHeVPCxBuyBGC8c+it9HLH1wO+g9aTRYvw6rdlXtFjXEit4bjpitBRZLXdRPVA89QePpoCl0mHsQ87X7uiRa7Dr44RmIzSSpgg9T1dQAeFAdvpoPSrSqR8QrKKDZdLYt+XTlfPOvymUJS4jHDiOkCc5UD37dtAy9qb8otz1D97+TSFuy7eidF56QhtbLimCllSkA5Iye4yPGg+NvdoKhau8Nbu1c2nqp075gNRWEKSpsOLCkjGOIwBjtoJL4k1NxNr5CkpShJmMqISAMkqOT+nVPP7V3Bj1ZaLvZG5WJFGMQcUusLI457kHvnVWM3Nrc/wAbo1fn0rqVNKV9w+nt+3THczji98aqVS2qW1V5s6i1SfFEt5TqkMOBIAUe6SO2R3Uc5/LWqxVjcZfym45mNo/tCUh2tTZr+V83FPPEk5xkYycn2z2//wA1En7WcnLhl2wx1/OzYfSlhkBtBDbaAAEgnAA8f1ajJVL+i4vGuCmbP1GtS2XywxWWX3WMcVONCU3yRg/VORg9jnvqOLw65PJDXPuREvDda05FqRZlEgJfjMPRkqDSXF9fJUUtnByCB379tWK2j919x7es66aJTK3QV1GXOSCy8G21dIFzj5V389+2gj9/duLhvd6ny6BXEUxmDHdDzanHU9TJB/idj2B86DNexe49vWEzWU3FQl1VUwtFkpbaV0+PPP4/ryHj6aD62ltK69z5VWRSbnegiCG1qEiS8eQWVYA4k+OOgZH9zruB/Lhn+kSdBqOiRXYNHgxJDnVeYYbaWvJPJSUgE9+/cjQdugNADQclVqMOk09+dUpLUWGwnm686rilA+pOgyP8Ru8sqfPqFt23UKXPtuZEbDjrKOorkTlQC8/kPbQKzYb/ABw2n/r6P+B0Di3qt++I++4ui0renTvlW2FMPJjF1oqDfEjt5xk6CjXNL3SjXi1uFW7bkRJlOQnL7kFSGEJAKQVDP/m+ug0PYdxNbj7FTJ+4MliNDkl5mW8z9wlDaVgA5749u+gz3dlvqsi82bt2qjv1O3KY2l0VJX98sJdwUrCljA7ch2/PQWWwfiNumoXlSIlxyqPFo7r4TKeMfp8Ee55cu2gv696J9Q35pVtW9Ppc62Za2kF5lHNRJbJUAvP1H00HFvau+29xXXbftH7cp4itBl9yGtfTOCVpStCknGe5Bz38Y1zlhMvLqZWeE3TplXouy1Su2s0Bmm3NBbeWiM6h1LYAUEpJQV5wQfrrmcWON3Im8mVmq47U3gXWtrXJkR2kPX84XExqQzyKnVBzCQGuXI+jJ86s8OL3cdi3NuvXNwKC3c1qGl0pL6lSZDUBbfp6auxUpSuIJ45xjPbUa77N/Dx3f3BkL3YcsC4ZUKLZkxtlMx5SeDiEKb5k9TPb1Ae2pF1kz6Vt/sHUJ+281mbCgJU5FfcX8wgqU8AvJGM91KGgzdTalubdN6xNxaVb706c1920/HhFTB4oLZGM9yAT7+dBbrsuLfC6bdnUWqWlI+SmI6bvSpikqxkHsc9vGgTNOfuHbO9Ik16CuDWoX3qGZrJ7BSSMlP0wToNobZzXt39lz+68pP2ip1h/5QdL0oc7Y84PYaD4v2wW6FsHW7VtGLMl/dHoMZ6rq1KeStWMAZ99Aqdkq1uBYTtMpNz0ddHspl11yXNmxC2GgoKIKnCcDKykDt740GoqDWqbX6a3Po01idCcJSl9hfJCiDggH8joJHQGg+H+zSyO3pP/AA0GAbLsy794p9Tjs13r/ZZC8VSW6sJ5lQ9HZWPwd/HtoN0O2/TZ9Lgxa3ToNQ+WbSlIkMJdSlQSASOQ7eNBnivSIW58+Tbu0UVNrVulPLcmyggQkvNJJbKAtnKlesg4IA7Z86Dpo299hWS59nSrfm/uggo+RnzosRnlIdR6XFdTkFKClpKsq7nye+gl/wC6psv/ADZX/wD+Fr/6mg8t7buhXv8AD01cFKakMxJM5pKESEgLHFxSTkAkeQffVfJ4X+n95f7YW43ApzU55ShNeGc+OA+g1kyzs8LsrumXFK0VKmOFxZCJKM5P56548r1zZZOimy27nXkp3ZLi6oyA4olRAQBlR/LUOL28lxcG58huYtmgsMIioJSHnUlRcx7gZGBrLn6i7/F6Z67+puSZ3H00mp835dUCsC8qO7Sb5pMddHnYbDq/u0uKyCkAE5JzjBT4Ou+Pkt90eQ+l/WOfm1/dYdMvjLxu/rV8/wAFQil23tHIqFk1aCip1muPKdotREZtSoyXR0mua1YUhSXEk5Tn6jv21e9kK7cCz7ps++7ZjXlWRVpL7jbjLgkuP8EB0AjKwCO/ftoNKb/2LeV2PU+VaNdFLixI7wktmW6z1ckEdkAg9gR30Gbdir5s6zma0m86CasqV0vlyIjT/T48uX4yMZyPH00Hd8O+6VF23n3C9Wos95uoBoNCIhCuPArJzyUP8oaDw27g3/ufW6u1bt2z4ojffkS6i+gcVKIAHHOg3NRI78SjwY8tzqyWmG23V5J5KCQCcnuckHQdugNADQL/AH+/xO3Z/qSv+I0H8+KRS5taqjFPpUZ2VNkK4tMtjKlnGcAfoB0F7pVnbgWFUGLpNszWBSlfM9WSxlpGPdWCO3fQaLtHeuTXtr3XmpdKev8AdLiYlLabOXVBfpAbzk5Tk+dBWn7l3IuNpVJ3RoLdHsuV6KlPRFUyWW/IIWVKCfUEjwfOgpV2XY9TkSdsNrnI9atye2EtL4l6Qtxz1LSlYKR2I/ydBf8AbQ25Q9n5lj7nVFNAmy3nVuxX3Ok+GlFJSodjgHjoM9bs0u2aPeDsWyKgqoUcMtqS+p0OErI9Q5ADwfy0HrsnU4VH3UtyoVSS3FhR5PN1504SgcVdydB/Qe3K9SrkpqZ9DnMToZUUB5lWU8h5GdAgPiXuHcBhFepNPoiHbNXER1pxjElIIBX6+WBg/loKv8M1vWA6u36tMra27zTJd6cD5gAKIKgn0cc909/Ogvu9+4O5Fm1ya9b1EjO2zGYacVNfiqWlKjgKyoLHuQPGgibI28o2+FvtXveS5jdZlrWw4mA4GmuLR4JwlSVEHA799Be2qDYNPtxe0pra0qkZHyipA+aPNXW7Hjj8/HjQcc2ZStrrOlWdt/MRNupr76FTJSus86pagpXpHHI4clfoGgtNiXNVW9uk1zcllmizWlOGUFtlpDaAvigkEnGRj399BmHdGdaF6fEPGcn1lk2w+y0iRNYd4pTxaV/GIOPUAPHvoLpGrd6Wk0KTstSU1+zGvXHnLYMgrcV3cHMKSDhWR40DWgXBfrmzEiryqKhF6pC+nA+XIBw7gejln8HfzoIC5E3neXw51pmvUVbdzyTwEJhkoUUpfQQQkk/xQT59tBYPhvolSt/aim06twn4U5t59SmXk4UAXCR2/MaBoaA0HysgIUT3AHfQZZnLa3DcLOwif3NS4KiqqrSPkOulXZsZRnngpX58Z/PQNDeS2b5r1v0KPZNZNPnR1Ey3BMWx1BwA8pHq75OgVrykXm2iibRJ+w7yp3qrM5I+UMlKfQsdVGSvLuFdx386CQ2c2Iq1JvCoVLcWJRqvEkx19nF/MKL6lpVzIUnzjl3/AD0HtX742QoVcn0mbZrBlQn1x3enSGinkk4ODnuMjQW9FmRL62Yap9DLNNp8yYqpQG+nxQhovKWhCkj8PpPgZwdc5Tc07wy6bt80za2sRGUo+chdhjs4sj9nHWa+nt+Vs5Yl02DVk9E/MQ8tuJX+JXgHP01E9PlLvbq8+OtaXRFLkp8qb/2j/wBNapNKOqOtuEsx32XSkJdQUZSc4yMa6vdVyY9eNx/ZGJlS7OkzqZMgxJLqVJW0p9AWltXgOJ/SPb8tYd3jtxsfOJy8v0vPPg5MJlfM331/uf8AY9LbgVe7bjjyZC33m23ErdkLHpQkHOB7e3YDTCZcmW3XoeD1X1P1WPJnbZLN34n/AD/yJG59zdr5e4cel1WliqV2LJbhszBCQ8ltzmMBLhOQErV7eDnW59HR3xF7VXPf1y0Wo205CbTCjltSn3y2oL5lQIwD+3QJPcYbrWLOp8C4LvnrcqSVdMMVNxxOAQk8s4x+LQWq1raoGywko3ho8GqrqvEwDHYTL6Ybz1M8uPHPNHjzj8tBSt9bpsC449HTt/RE0xxhTplEQkR+YITx/CTnGFft0Hv8Nm4tE27rFalXAmYpuXHQ238s0FnIUSc5IxoN0U2W3UIEaYxy6MhpLqOQweKgCMj64Og6NAaAGgibroMO57en0apdX5Oa0WnekrirGQex9vGgzRA2kk2f8Q1uuW3SKq7bjBQ65MdBcQlRQvllYAH00F13bqt0SLzct6o08tbcSmW0VGp/LlIZbUPWetnCcEDvjtoM8VtmHau80IbSu/bIYLbkLCvmuo6UHkntjPv20Fv3DvbeGpWXVYdz2yqJRnWwmS+aatvgnkCDyKu3fGgsvw5WDajdmU7cKtyZEWbAkuuKeXICGEBCuIKgR47/AF0EhvZSNvb9bqFVoFcbqt4rjoZgwoUxKy8pJ7ANgZUcFR8+2gqlA2GTJ2cqNWqVIrTV4Nh3oQyeJVhQ4fd8cnIz76CxbSfDxRaxZceZecGtQKyp1xLjJd6OEhWEniUnyNA25NuP7Z7U1OFt3GkzJzGX4rL4+YWtalp5DAxntntoE4Lq3MuJX2TuVQVUuz5f3dTmmCqP0WfdXUJIT3A740CsqrUa1d6Yv70jn2yI5bXCwr5rquFs8x2xyxlXb8tBoqn3dTLm24lUHeWpQqFWJaimRDWsRHUtBYUhQSrJGceffQWClMxLV2Ym/vSO/bIjhxcLCvmuo4XByHbHLGT20Cfq1SgQKW/f9zy2afu3EHJFKeX009j00Zjnv3aOfxfnoE5M3SuCVuNGvZ0QvtmOkJQAzhrAQUd05+hPvoGZaO7dybp3HBsm5xBFFrCyxJ+VYLTvEAr9KsnByke2gjqztfb8T4jKZZTXzv2NIQhS+TwLuSypfZWPqB7aDXVh2jTbJtxmi0brmG0ta09dfNWVHJ74HvoFFdm8FSt3f5u16hKpkS109MvPPt8VICmOfdecD1Y9vfQOJm7redtxyvN1iCuitnC5odHSSeQT3V48kD9eg7qFWabXqc3Pos2POhLJSl5hYWhRBwcEfQ6CQ0HjMS4qK8lg4dKCEHOMHBx/XoFdsZRdwKU3WRuPUFTer0vlOUlL3HHPn4HbOU6CD3M21rtLbgr2XjxqE+6pz7RVGeDBeSMdPOc5wSv9ugS24dQ3l2/iQ5Nx3NLbalOKba6MxLhJAycgDtoGPY+7m0ltNNzosZ6NWpEdKJslqCvk6s4UvJz3yoZ0E/8AEvelSpe11Brtp1KVAM6W0tLrXoUppbK1gEHx7HH5aBOWVaSaBJbv/d6KxUbcq7HNLij8w4t97C0KUhOCDgLyfbQOTeG5k0fYGn1fb6S9Soa1xhEUwOmpDKifTg+P0aBa2bNu8UWDdm6VVkVLb19BU6yqR1VKUSUtktpwrsvHvoKrudadUlw6lftoExrFcKFRUiSptaRlLSvuycj7wK/46C67XbiibtBFsa3ajNbv2SXUxVkFKQovFz+FOQPuwf8AhoGhaVC/cnZhuvdNv5u4qapb704OF9wNg4RjiQDgHGMaDqi33U7shmqbb2tCq1OccLb0qoShFUpxIHp4FJJwCO5Oo1HH2sN26ndT9zp+8z9r1NTFNolBpbEdbr64csLfDaUkqCVHxkA+AD+epdSSdogvhFs63q9aU+qVmkRJdRiVX7iQ6nK2+Lbahg59iSdEtLXC8tigVJ5hZQ63GdWhSfIIQSDoM4/Dey3ujArEzcJIuCVTnmkRHJ3rLIUkqUE+PJA/ZoGTvfWNvKU7SBuLTUzVupd+UJiqe4gcefgjGcp0CLtKzaBtY7Lkby0mJIjVPiKaGk/NcSjJczxI49lo8+f1aDn+Fq1rdu267obrNKiz4bTSXI6H0HCAXD479u2NBs2Kw1FjNMR0JbZaQEIQnwlIGAB+rQeugNADQV7cGXWINm1aTbLBkVlpgqitBvqcl5Hbj7++gX+3+6Ig0ANbr1KBRLk6qyYkhPQX0u3BXHv2PfvoLdXKnad4bfVR6TVY71tvNLaky2XuKUpBHL1e2O2gyhU7KqlF3Dj1/Zuly6xRYhQ5FmIT8y0p0JwsZ7ZwSRjQOO6qldFV+GW55N8wjCrPFSS0WOl6A63xPHJ/PQVeyP8A9G9e/wBGV/zRoKvtha1OpGzM3cqGl4XNSX3VRlrc5MgpUlI5I9+yz76Bk2XvPLru1kpf2nTXb9cLqIVPbbAW6oEcAG/fIz76BjbdXJWW9uhWdykIpM1lbhkF5roJbQFYSSO+O2NB5X9frDO01bumzahDmmIj7p9P3rfMLSkgj37K0GZ6/uVurd+3tTel0xt22X21NyJbMEJQlIIB9We2DoLDtFt+y3tGzf1uQ5cq9Yq3lRG0q5tqWlwo/g/f0k++giYNiXvuNutTZ249uVGPAfwzKeZY6CUoShXHv3x3xoLvcKNyNt6o5be19BkyrXYSlxl12J8worWOS/XkZ9RPtoEnuhQNxK1UJ913fbs2NhCOu/8ALdJtCUgIBxnt7aCG2at2Bde5dDolXS6qDLcWl0Nr4KwG1qGD7dwNBqq2tt9q7Q3GpzMCpuNXRGcC2Ibs7ksqUgkejHfKTnQS91sbaUndRm5LgrrMK54qEFLbsvikJ4FKSUY/ySffQMGPd9vyLacr7FXhroreecwOfdpweJyf09tBiTfd5u+t7Jv7kFisfNoYQx8p6+opLKeQH1xg/s0DKpTa4fw51Db6Skt3tIWpTVFV2lLBfS4CEf6CSr9A0Df+G6i1K39qKbT61CfhTW3n1KZfTxUAXCR2/MaBoaD4ecSy0txw4QhJUT+Q0Cl/uiNtv89vf0J7+zoD+6I22/z49/Qnv7OgzAV7hb2T5UGLLdrTFOWp9tt5xpkNpWSkEZ457DQdW8i9umrUpEC0IzbNyxXg1UuLbo7pbKVjkr0n1j20Dx3VsyuXzsPZFOtqImVLaahvrQp1LeECMRnKiB5UNAjtzKBurQbChQ70cWm2ozrTDDPXZWEKCVBAHH1dgDoL0utwNxdjaDt/aTxmXVHZYcciKQWgA1kr9asJ7ZHvoIfaJNfmbhxdrr8cVJoURt1LtKWpJbSpCC4n1I7nBwfOgfgqG2zsz96XooJSeP2X0nemMDr/AI//AHvxaD3k2Ntxt0wq7DRI9PFM+8+ab6q1N8vRkJyc/ix499BY6TU7c3Ms51yLio0KbzYWlxC2wvicEEHB8jQSNrW1R7Upf2db8FuDC6inek2SRyOMnuSfYaBB74XZXGN77dtNmoupt6qtxmZsIBPB5DrqkOAnGe6e3Y6Cvb1y6rtlfFHtna19VEiVNhDqoscgpdkLdU2FEuZwSEoHnHbQXG0b9n2HS51L33qbqZ88lcVBQH+THHiruyMDvnz30Ctvnci37YqdMRstUHKVTXvVU0ssLT1FBQ4k9UEn0lXjQNW8dztkrxMZVyvCoKihQYLkOQOHLGcYA84H7NAgIrG4u9jjsdmQ5Wm6SeSUvONNdIOdhjPHOeH9Wgtl+3xa9o02njZ6Wqk1tRLNVUwysFYSkYBLgIPrz40GwrXkOy7bpUiQsuPOxGXFrPlSigEn9p0EnoDQA0Fe3Bm1enWbVpdtxjLq7LBVGZDZc5ryO3EeffQJu3drU7q0/wDdHulBqVOuIrMcsMf3snpI/AeBCj3ye+dBVdyKJe9pQKjYNgW9PqFoSWMqfVFU+4Vud1gODA7EfTtoLxtXDuq0Ph2kpiUeSi5Y6n3GIT8cqWpRc7ejsT2JOgU+4l77wVOy6rDue2FQ6K62EyXzTVt8E8gQeRVgdwNBL7e1umTPhmqVqxZ8Z65JnzCI9MQ4DIdUpwEBKPJyAToGJsbYj8rY2Xa93wJ1PEyS8HWljpO8CUEEZHbxoK3X9ubE2+nLkWpUX3r7hJEim0x+Wl1bzp/COkEgqyM9gdAwqI/MurZmb++y0aL8wHG5uU/K9JoLHFXqzxzgd9AnYdTpKr0hbSWtPYqFhVUgvvtuB1/mpJWoJdHYYUhP8XQRe6NQrFm1CZtJZUUS6PMZQUNONF6UtTo5qAUMe47dtAWLWt6LKttiiUazpJhMrWtPXpbi1ZUoqOTke50Fr293f3Cm7sUW1bvp0OniUs9ZlUJTToT01KBGVds4HtoNBv3Zb7FwN0J+rwEVlzARCU8A6rIyMJ89x30Crv8AN4XNuS9ZcujPK2+nBtEiczFUFAdMLOHskD1gDx+WgULdEt/a/wCKGjxGpZiUaIkOrfmvA8CuOvyrAHkgfr0DX3LpNuCn1LeC15/z1ZgtpXGdQ+HIqlIw1gpA79iffzoM23DDv7depKuj9z0yb1UhjrQIiukeHbA89/roJ16Xuhbe1M+2JtsSYttcFl9+RAWFIClhRJXnA749tBevhktuwXk29WZdZCL0S+8UQfnEgkgrSn7vGfwd/P56B4XFY9qU+9U7jVmY9DlwkpCnnZARHQOPSHIEf+bHnydBc6FWKbXac3Oos2POhLJSl6OsLQSDg4I+h0EjoPKX0vlnev8AwXA8/wDRx3/q0GYPlvhr/wC+a/25ugPlvhr/AO+Z/wBuboLLZF4bGWPKlSLZqrMJ2SgNuq4ynOSQcgeoHHfQfttWdsfuBWpyaFHRUahhUqQEvSm+yld1eogeVeB9dBM7SR9xYF81Wn3KytqzIrTjNKSoMkBCXEpaGU+s/dj+N+vvoIpu17zvTcSs0nceC5L2/S889BQVNtjkleGTybIc/CVef16Cu3DR7Ut6pS6fse2G9x4rhZUylbi1JaH8KPvvuz2x75+mgX8Sxt7ol6u3YxSHkV50qK5POKc8k8T6eXHx28aBlWjW7CtysRa1ubMRD3RY5faC1h0lKiClPpbBa/gijx9froKDu3uRcW4d71C0bDqn2nb9TS22xFQyhHVKUJWsclpCh6kk9yPGgj9u71u/am8aRad2TTR6Ey+HpkZbTbvFtwFRPJIUrv28HQTe8m/1aReONvLkSqifLN90xEkdXvy/hEcvp+WgnrEZRfu19c3EuofPXfRev8hPz0+j0Ww416E4QrC1E9wc++gSUa867e25lqzrmm/OSmZsZhC+khGEdYKxhIA8qOgb/wAXjDUrcyzY76eTLrIQtOcZSX8EfsOgu13be7H2fMhxbjhIgvzMlhCn5S+YBAP4ScdyPOgU/wAVFgW3Yz1tptenfJfOB/rffLc58Sjj+InH4j40DM+E+wbmsyVcbtzUpcBEtuOGCpxC+fErJ/CTj8Q8/XQLq1tvqJateq8ze+mmBS5ilCnOOPLPNzmSrHRJP4SPOg2JRhEFJhCmnMLoN9A9/wCD4jj57+MedB2aA0ANBU91q5MtrbyvVmmFsTYcYutFxPJOQR5Hv50GbLf3Y3ruKnidQ6K3OhlZb6zFN5J5DyM8tBJfu73/AP5LL/3X/wD9aDkq25m+dIp0ifU7fEWEwnm687TMJQPqTy0DKsS42dx9iahO3HlsR4L7rjMp5n7hKG0rTx798d8aBHW9TbYpXxL21FsiYJlGEhlSHQ91crKDyHLA99Bp7c2+G6NS51Lt6dEdvNTKVQacfW66okeEe/pCj+rQZxpcO/Je8FFvbcChyadDhvNqlzFxuiyy0gEcldzgd/OgfO8VbplwbD3RPok1idDVFKUvMK5JJC0gjP5aBDbZ2vTqJsxK3NgpdFz0p50x1LXyZ7LSjuj37LPvoLja1Ll3tZC91URnZd/xlLERuMPuVqaVwQOl7+kn30EVbO998U/cem0TcMwKPCLg+cD8QMqbQUEgk57Z7ft0Deeo+39Trze6f2slZhAI+eRK/vZPEdPuMf8Amx+k6Cubk0u2H6VUt3LXmfO1qntBcaQ291I5U3hvBRjv2J9/Ogh6fvx1NkpNVk1qkJvZIX04fEAnD2B93/od/OgV901C1b620qV3XLVY43CUA23EZe6YUlDiUp+67/xMnz+egocPc64Ye3b1lMqifYjoUFAs5c9S+Z9WfroNHbJza5TvhjkS7TjGVW25DxjMhrqcj1kg+n39JVoJa6qjctV+GS4ZV7QzDrSmXA4yWelhIdSEnjk+2gzNtrbt9xKjTrrtC35szoOLVHfTG6jSiOSFfpxkjQMy76zvhdltzaHVrVkGDLSlLoap3BWAoKGDnt3SNA9PhtotSt/aemU+tQn4M1t59S2X08VAFwkHH5g6Bo6Dlqv/AGbL/mV/+k6DGHwwbb21fzFxLueK8+YRY6JbfU3xCgvlnj5/CNBdVWv8O6VEGsNAg4P9/v6CctTavZO7ZD7NuOqqDrCQt1LM57KQTgE5x76Co/CXFag7uXlEjApYYjutNgnJCUyAB3/QNBpOh3tbddrkuj0irxpVTic+vHbJ5N8VcVZ7exIGgoW6e4cx+E/SNrZzFQu+LL4yITTQdW20nkHCQoY7K4j9eg8LTt23bOhxNxL35Uq55jWKi/IdUEB538Q6YykZx4A0F2t7cqzrjqjdNodfhTZziVKQy0VciEjJ8j2A0GV9w4tuTPioqrF6PBigqcT8wsuKbAxFSU909x6uOg/LIiWzC+KWiMWQ+l+gpdHQWHFOAkxlFXdXf8WdA0d/rYsSu1GrNpc6+4j0ZtEOGiQsLcXgcAEfhPp0EXs38P1GqFnda/6HOj1n5lxPBUlTZ6eBxOEnH10FZ3dlVTbaujbjbtHTo9aipK4jiA+466+VNqCVq7jISkAZ7aDu2r2aRTLCrlfvGizIVyUtbsuAXHSkANtBaFFIOFDmD58+NAmq/uFWr1uyiVG65bLioTraUuIZS2Eo6gUchI7++g1LfVd2YvidAl3DcUR5+DkMluQ62BlQJyAO/cDQKf4s7zt67ZFrqtyrRqgIwf63RJ9HIt4zkDzg/s0Fz3t33FLgUIbb3BAkOq6gmBLId4gBHD8Q7fxvGgpNmX9Sdz5EmLvZVoyYEJAdg8R8t94o4V3bGT2A7HQbEoyIrdJhIp6uUNLDYYVnOW+I4nPv2xoOzQGgBoF/v9/icuz/AFJX/EaBR7N1+Za3wu1mt0wMmbDkvuNdVHJOeTY7jIz2J0C5PxOX5/3dF/oiv7egbkq7ale/wrXBW60I4musvNq6DfBOEugDtk6CA21pc6tfCTXKdSYzkqdIfeS0y2MqWeq2e36gdAh7fpl22buRS2I1IdRczDqXY8N9vkVKIOMpz3yM++g0hHtO5qxQ3txqzR5TW5MAlEKChASytKcJTlrJJ7KX/GHjQed27huyNlLhpG4MiFS7yfjupTTeBbWUkjpkJyfIz76CJ2buexXtiTat33BGgmU4+l9rqlDoSXOQIODjwNBF02r0d68IW01qTmp9g1Y5ffSrnI5qBWoJcwAMKQn+LoLLRrhm7b7xUbbG3QybaddbWoyk9R/LqStXrBA8+O2g/fiBs6zK/WauuLPff3CdYaTGpjT/AHcUEp4gI4/5GT50CZZq+4FLoDm0/wBjJQqdlfyi2P75VyPU7Hlj+Jnx4Gg0ns3Yb7+xP7lLvhy4KpK30vtZCHAkucgQe+PA0HL/AHMVhf8AeVr+lp/saCmbw7C2haO21brlKXVDNhtoU2HpIUjJcSk5HEZ7KOgodF2vt+Z8Oc29njN+2mQ6UhLwDXpe4DKeP0/PQRe0+6980OFDtOzoUGYpbri2WVxi44tRypXfkPoToLhuLd28s+yatFue2WotFdZxKeEPgUJ5Dvnmcd8e2gYvws3lbrG3dDt16rRE1xb0jjCKj1Dlxah2x9O+gaNw7jWhblTXTq3XoEKahKVKZdUQoAjIPj3GgnLdrtMuKlt1GhzGZsFwqSh5o5SSDg/sOgk9By1X/s2X/Mr/APSdBmD4I/8A2K8//wBt/wAHdBlqYf77e/01f8dBpH4Iv8JLm/1Rn/mHQd3ws/46b6/m3/8A5kaBvxLRsfa+4p93SqkqnSaotxpxydKAaUpxXUISCB3yn9g0Cg26Qq3N9bjvKvA0+1KiZXydVkeiM/1HEqb4LPY8kgkfUDQNS/bn2uvm31Uat3dTPk1OJdPQnJQrknx37/XQR1m7e7aWH8pfNLqzjcNCFJamyJoUwQvKPOBnyR+nQZZ3+qkGtbu3DUKTLZmQnltFt9lXJC8NIBwf0gj9Wgq1oXFOtS5IVcpXS+dhqK2uqjmnJSU9x79idBrLaynUa8qXC3bvaSY1ZiPKK3kO9GMhLR4JJR39vPfQSle3MuJe4FPftn5Sbt2ktfP1ZtjqNMgE9XLoOE8Rg/lnQLDftypV7ceBe9hxzWaXSIrTip8VHWjtOsrW4Qsjt2BSSPodB62huhunuAExEUhqZQZT4gz34kA4bbXgOevPpIQrOfbzoKtv9t1bthXnbtPpapTcCY2HJKpD3IgdXiSDgY7aC/SNvtiSw4I11JW/xPTSKqklSsdh+H66BGHai/fe0a1/RVaCd2Nt+xa5JrKNxKqKalhLXyvKUGOZJVzHcHOMJ/boKZSbVq1xVSfHtamTKmmOokiM2XClHIhJOProP6PWqy7HtmksvtqbebhsoWhQwUqCEgg/r0EroDQA0C/3+/xOXZ/qSv8AiNAmNsabNrHwl3DApcV2XNfffS0y0nkpZ5tnAH6joEYdpb+z/gjWf6MdBoSlUWp2/wDCLXoFbgyIM1DchSmX0cVAF4EHH56D22Mm1unfDTPl2tGMqtNSnzGZDXU5q6iARx9+xOgQd43heVP3SYuO44LcG5YgbWll2NwSAEkJJRn6H66BqbS783ldG4tColTVTfkpj/Td6UXirHEnsc9vGgZe/G0NKuimVq440WoyrkTECY7LDvpWpPZI4Y7/ALdBky2rYZp241Mou4LT9HhKcHzYfV0VNtlJIJPtntoL9SxZVofETb71uVhldtR+Li5jskOISotrCsrwPfA/XoNLQbMsy8bvh7g0ya5OmsqSGn40nLBU2OOMY749++gibqhbZUzdVFyXBcDMK54vTV0XZoQlIDfFOUY90n66CH3OhW2aRUN3rUmpnVqmtoTGfQ91I3IENEFGO/pWffzoJnY7dqDdlt05q4azS0XNJecbENohtagFHjhH5gZ0DDeu+32bkRb7tYhJrS8BMIuDqnKeQ9P6O+gS241zVC4t7G9rqiWTa1Tab64bRxf/AIIu9nM9vUge3jtoFXvVcc7b5dV2vt/pC1+i2rD6Oo/94Euq+87fxj9PGguXw32VacGy4G4tbkuxJsCS9yfckcWEDPTHJOP/ADY8+ToIne7dStXTctQsuynYFYotRZbabEVnqOOKKQpQSoHyCD7aBP2tDu2z9x6e1T6S+i6Iy+bMJ5gqWSpBPdHv6SToG5d9AjXpbE6oXQl5vdx5KUM0ZpXSWtCVAJIY7n+CClefbOgeXw20apUDaemU+tQn4M1t58qZfTxUAXCRkfmNA0dBy1X/ALNl/wAyv/0nQZN+Dq4KLRI91prdWgU7rmOG/mpCWueA5nHIjOMj9ugm3NoNlVuKWq+BlRJP/wCLx/7Ogum2FG2u24nTZVBvKE65MbS04JVUYUAEnIxjGgXXwputv7x3u6ytLjS2nlJWk5CgZIIIP00EFvhWtyr3fm0CXaUtVJhVJxyM9Gpr3JxKStCCVdwQUnPYd9B1bYVSo7quxtr7zjiFSqRE6iflmyzJS4xhtKVlWR4WcjiO/wBNAltyqHFtq/a7RoCnVRYMtbDRdIKikHtkgDvoGXtlfCbwplM22vKTAptooaUVS0qDLwLeXEZcUSnurA8d9Bad1dlLJt/auo3VbFUnzi0Gyw78y26yvLqUHulPfyfB8jQV23dnqbW/h/cu+EiqyrjIc6UWOQtCyl/h2QElR9OT50FSVuDdlq2HM2+nUxmHDfSvqJlxlokAOHlnuRj8u2gam1FXpy/hnuShJnxFVuX82iPADqTIeUpKQkIbzyUSfAA76Cy/DxGgQdq6paF5SRRqhVZTzSYUtwR5K23W0ICkIX3OTkA4PcaD7XBuDZy6qRbG3lImVO3am81JnS5MZb6mlqc6awFowlICEJPcds50Fx3jsOxbvrdMcvKvKps5tksx2UzG2S4kr8gKBJ7nHbQUqt7DbZW0ptc+4ZsOYUl2O1KnsoLqk+MApBPfA7fXQWPafdGtz2ar++m1AtpaOHyQlNqh9fIVzx1FerHp8eM/noMY06g1evy5YodLnVHpKy58owp3gCTjPEHGcHQPus1Oh7IU6FUdtKtDqlUqiehPYlyESOiEpCuyUcSk8iR3/RoNY29McqFCp0x8JDsiM08sJGBlSATj8u+gkNAaAGgpW89NmVja65KfTIzkqbIiFDTLYypasjsNBmWxV722RQhSKDbMlEMOqew7BStXJWM9yfy0Fh/dl8QX8nF/7tR/10EZc9W32uWgTaNVLafVCmN9N0IgJSojIPY57eNA6PhloNVtzbBqBXYD8GYJbyyy8nCuJIwdAlfiV27u24905dQodvz5sJUZhCXmW8pJCMEedBdvh12ZiUynQLhual1CDc0SW4ptDrpSAkDCSUeD2J0Dsv8Ak1iFZtWkWyyX6y2wVRWwgL5LyMDifPvoFFbe00fcalouLdOmzo90PKU28htwxwEIPFHoGQPTjQSv9zXt7/4Wo/01X/TQWeVbj23u1tSp+3cZ92bHQt2Gy59+pTilAkd/Pv20FEtzaWLuLSm7i3Rp06PdMhSm30NuGOkIQeKPQMgekDQMWHthbsTb6VZrLUr7EkKKloL5K8lQUcK8+UjQZpvLa66LH3VbqG2dvVGRBght2M8tPXSVlHqzk9+5OgYTFnV+Zai9xp9JljdNnJZYCcIJSrpJ+58fwXfz+egqVgUDcas79UK6ryt+XHCCUPSPlw22lIZWlOQD+YGgZO/ez9LuWlVy44ECdLulTDYYbZeOFFPFIwjx+HOgRkOi7wRNvpNmM2vMFEfJK0GIkud1hZ9ec+QNBBWtt5udbFwQqzS7UqKZsRfUaLkcLSDgjuM9/OgnpVH3hk7hNXo7a8w1xriUrENIb7I4D0Zx+HQfcml7xydwo96O2vL+22EhKFCGkN4CCj8GceCdBqzaSdctRsmJJvaKYlbU44HWi0GsJCyE+kfljQXPQeclkPsONKJCVpKSR+YxoM9/3KVp/wCe67/tM/2NAf3KVp/57rv+0z/Y0B/cpWn/AJ7rv+0z/Y0F42o2Zou2tXmVCkVCoynZTHy6kyigpA5BWRxSO/bQNDGgXFrbS0i3NxqreUWdPdn1HrdRl0o6SeqsKOMJB7EdsnQVS7vhwtq57mqVbmVesNSJz6n3ENKa4JJ9hlBONBE/3KVp/wCe67/tM/2NAxnNrKSvaZNgGbOFMACfmAUdb+F6n+Tx89vHjQTm3VoQ7FtOJQKbIkSIsZTikuSCnmeayo5wAPJ+mgou5OwtAv26Xq7U6nVY8l1tDZbjqbCAEjA/Ekn+vQRlqfDbbVtXLTK1Eq9YdkQJCJDaHVNcVKScgHCAcaC13htJSLp3BpN3TZ09qdTuj02Wijpq6aysZyknye+DoGRoFxuRtLSL9uKk1ipzp8d+mpCW0RyjirC+fq5JJ8/TQG6G0tI3EqlKnVWdPjOU4KDaYxQArKgrvySfp7aD93b2mpO5q6YqsTp8UwA4G/lSgcufHOeST/kjQfO0m0lI2yeqblHnVCUZ6W0uCUUHjwKiMcUj/KOgokv4WbVkynn11quBTq1LICmcAk5/yNA+aVCRTqbEhNKUpuOyhlKleSEpABP59tB1aA0ANAaAwPoNAYH0GgMD6DQGNAYH00BjQc9RmMU+C/LlqKI7KC44oJKsJHk4AJP6hoFne28FIo0OnO0dxMtb9QYjOoejPthLSyQpYPDyOxx3z9NBaaXf1Bqlaj0uA/KdkPpUpKjDeQ2OPsVqSACe+B+X6NBz3Jd0in35b1uwI8d75xt2VOcdWU/LR04CVD2ypZwAfODoPK6b6Zod32xSuUBUGqCSZElySECOGkJUDnx3yR3xoJG4r4otv1mDS6g7IVMmMrkNojR1vngggEkIBIBKuxxjsdBWLf3Qack1pu4afPiMRJChElt0yVwkR8cgsgoJQUjsrPbIyO2gu1p3FT7qoMar0dTi4UgEoLrSm1djjuk99BMYH00BoDA+g0BgfQaAwPoNAYH0GgMaA0BoDQGgNAaA0Cy3ZuyrW1UKS5EUqNTwtXIpZ66576kL6cZCB6gn0lS1juBxx76BQR94L0dhVGFKalQJk6Ww5CeVEWVxw48gFptCkfeJ4BzGQT50D5p+4VEm2LULqZck/ZUJDqlOvsKZLvT8lIV5CiMD8+3nQKgXzdzNgwG5VTpsWvTUoqkWbKqLaE9Na+QbU108lAGUHvntnPjQM2wb3m3W5VSiDALEJKUpXFn9YrdxkpOUJAB7YUCR5z40FX3bve6aZYNTlRaJIo8pos8ZYqEZxTRLqB+AE5yDjx76C3Uu5rjm1CEwm1wmJ1AiZINTYWpkccghCM5PcEjt28aCG3Sut+Dd1p2/Tak5BefeXUZy2W+qv5RlJJQEAEq5ntgDPpOgitx9z2Ycq1FUKVVGUO1ZDcxH2W8C6x01lSAFt+okgYCe+gbVJntVOmxpsdLqGpDYcSl5strSCPCknuD+R0HXoDQGgNAaA0BoAaA0BoDQGgNAaA0AdAhN4ozFErLci7q5cTtvOkTKemO4jLVQaUVoZHoz6gRwJ7ApOfbQMjaen16BZsY3ZUJMyryVKkuh9YUWOZyGgQPCRj9ecdtAtBbU2o73VFFwGK7Oq1vPOoZdbD7EUJkBLKOKuy+IAUfqoq8aDkTQoNQvDa8Vyz6XSZkr7SbnwUxkdNxTbYAVjHdJxyTnxnQNO+LfhluJPhUmpu1BgCMldGkJiyEs4PoKypOWwf4ufODjQI9qruS51yUWvx7wnB+qKp8OG7XQygjpoUWFrLmCvCiQO/IdhnvoNO01lMeBGZQlaEttpSEuHKgAPBP10HToDQGgNAaA0BoDQGgNAaA0BoDQJbfCmst3fZdZqUxaojc1xj5dXpaab+XeW4o/UninufAT299Ak0mXEYalTqcftoQINQpZZjlrMhXr6fHup1RAxgdkgrJx4IOiBRKPVfhviMNTUzosCkuyVBlz0OPpaWrDg8+lZzxOPUBnxoK99qSgbMpDNSRT212tFl9WRWXILRUDxIASCCo9j+rQXfY6a9Km3ey9JEr5Wc211kVFyahwllKiUrX+kDtgdvHbJCE3vYt2gXBTK59iUys1V/qMyaMWQt+agjKXUpAJ5IUkeojHEqGc40Er8Pqbcp9pqeg1akP1apvGVORFWlAacV4aDZwUhAPEAgaDlrtvtU/fe0Jzz7kqbVBUlPOLHHi0llCW2kgeEpBP6SSfJ0Edc9PqVGkWJS6xVm6kqPd6PlFlfJ5EUtOFtLpPcqAOM+4xoHuNB+6A0BoDQGgNAaAGgNAaA0BoDQGgNBy1JqS/CdbgyUxZKhhDymuoEH68cjP7dBTk7Z0ifKcmXY9JuWattTQXUSC20lXkNtJAQjP1Az+eg87c22btytsSaTctxIpTOSmkuzC7HHbAA5AqCR9M6Ccctdpe4DV0mU51m6aacI/EceJc5lWfOfbQRr9hof3Cp90P1iovJgpd6EB1YU00txISpSDjIGB+HuP0aCUrlAm1KcH49yVemt8AnoRejwyP43rbUc/rx20FPk7OwJKZqZFw11xMyaiovBSmPVITji5/B9iOI8YGgvttUldEpDEBdRnVLpZxInOBx5QJz6lADONBKaA0BoDQGgNAaA0BoDQGgNAaA0EPcVtUi4xETW4LU1EV3rNIdyUpXxKc48HsSO+g/WLcpTNacq6YaFVFaA2H1krU2gDHFGT6E/knA0H43bVGZp1Sgx6bGjxakXDLQygN9YuDCyrGO5B86Dxj2hQGHIjiaTEU5EiJgsLcbCyhhJyEDlntnQdES3aVCbqCIENuH8+rlIVG+6UtXHjyynBBwAMjGg8KBadDoDzr1KprLMl7+FkHK3nP9JxRKj+s6Dmm2Ha02usVqTQKcuqsrDiJPRAXyHgkjyf050EnModPm1qnVaTGS5UKelxMZ4k5bDgAXgeO4A0HFULNt+oXJBr8ulRnKxCJLMrjhY7Y7kfix7Zzj20FgGgNAaA0BoDQGgNADQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0BoDQGgNAaA0H/2Q==",
    "docker-compose.swarm.yaml": "services:\n\n  backend:\n#    build:\n#      context: .\n#      dockerfile: Dockerfile\n    image: fastapi-scaff:v1.0.0  # \u5f3a\u70c8\u5efa\u8bae\u4e0d\u8981\u7528 :latest\n    environment:\n      app_env: prod\n    volumes:\n      - ./config:/backend/config\n      - ./logs:/backend/logs\n    command: \"uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 5 --log-level info\"\n#    command: \"gunicorn app.main:app -c config/gunicorn.conf.py\"  # \u8ffd\u52a0\u5b89\u88c5 gunicorn\n    healthcheck:\n      test: [ \"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/ping\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 60s\n    deploy:\n      mode: replicated\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first  # \u5148\u542f\u52a8\u65b0\u526f\u672c\uff0c\u518d\u505c\u6b62\u65e7\u7684\uff08\u96f6\u505c\u673a\uff09\n        failure_action: rollback\n        monitor: 60s\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 180s\n      resources:\n        limits:\n          memory: 1G\n          cpus: '1.0'\n        reservations:\n          memory: 256M\n          cpus: '0.25'\n    networks:\n      app-network:\n        aliases:\n          - backend\n\n  nginx:\n    image: nginx:1.29.3\n    ports:\n      - target: 80\n        published: 8000\n        protocol: tcp\n        mode: ingress  # ingress | host\n    volumes:\n      - ./config/nginx.conf:/etc/nginx/conf.d/default.conf:ro\n    deploy:\n      mode: replicated\n      replicas: 1\n      update_config:\n        parallelism: 1\n        delay: 10s\n        order: start-first\n        failure_action: rollback\n        monitor: 60s\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 15\n        window: 180s\n      resources:\n        limits:\n          memory: 256M\n          cpus: '0.3'\n        reservations:\n          memory: 64M\n          cpus: '0.1'\n    networks:\n      - app-network\n    depends_on:  # \u636e\u8bf4 swarm \u6a21\u5f0f\u4e0b\u65e0\u6548\n      - backend\n\nnetworks:\n  app-network:\n    driver: overlay\n    attachable: true\n\n\n# =============================================================================\n# \u90e8\u7f72\u6267\u884c\u6b65\u9aa4\uff08\u8bf7\u6309\u987a\u5e8f\u64cd\u4f5c\uff09\n# =============================================================================\n\n# 1\ufe0f\u3002\u3010\u524d\u63d0\u3011\u786e\u4fdd\u5df2\u5728\u76ee\u6807\u673a\u5668\u4e0a\u5b89\u88c5 Docker Engine \u5e76\u542f\u7528 Swarm \u6a21\u5f0f\n#    - \u5b89\u88c5 Docker\uff1ahttps://docs.docker.com/engine/install/\n#    - \u521d\u59cb\u5316 Swarm\uff08\u4ec5\u9996\u6b21\u6267\u884c\u4e00\u6b21\uff09\uff1a\n#        docker swarm init --advertise-addr \u672c\u673aIP\n#    - \u5176\u4ed6\u8282\u70b9\u82e5\u52a0\u5165 Swarm \u96c6\u7fa4\uff0c\u53ef\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u83b7\u53d6\u52a0\u5165\u547d\u4ee4\uff1a\n#        - \u83b7\u53d6 manager \u52a0\u5165\u547d\u4ee4\uff1adocker swarm join-token manager\n#        - \u83b7\u53d6 worker \u52a0\u5165\u547d\u4ee4\uff1adocker swarm join-token worker\n\n# 2\ufe0f\u3002\u3010\u51c6\u5907\u3011\u5728\u90e8\u7f72\u76ee\u5f55\u4e0b\u521b\u5efa\u5fc5\u8981\u672c\u5730\u76ee\u5f55\uff08\u4e0e volumes \u5bf9\u5e94\uff09\n#    mkdir -p ./config ./logs\n#    - \u5c06\u9879\u76ee\u914d\u7f6e\u6587\u4ef6\u653e\u5165 ./config/\n#    - \u786e\u4fdd ./config/nginx.conf \u5b58\u5728\uff08\u5185\u5bb9\u53c2\u8003\u6807\u51c6 Nginx \u53cd\u5411\u4ee3\u7406\u914d\u7f6e\uff09\n\n# 3\ufe0f\u3002\u3010\u955c\u50cf\u51c6\u5907\u3011\u786e\u4fdd\u6240\u6709\u8282\u70b9\u80fd\u62c9\u53d6\u6240\u9700\u955c\u50cf\n#    - \u65b9\u5f0f A\uff08\u63a8\u8350\uff09\uff1a\u5c06\u955c\u50cf\u63a8\u9001\u5230\u79c1\u6709/\u516c\u5171\u955c\u50cf\u4ed3\u5e93\uff08\u5982 Harbor\u3001Docker Hub\uff09\n#        docker tag fastapi-scaff:v1.0.0 your-registry/fastapi-scaff:v1.0.0\n#        docker push your-registry/fastapi-scaff:v1.0.0\n#        \uff08\u7136\u540e\u5c06 compose \u6587\u4ef6\u4e2d\u7684 image \u6539\u4e3a\u5b8c\u6574\u8def\u5f84\uff09\n#    - \u65b9\u5f0f B\uff08\u5355\u8282\u70b9\u6d4b\u8bd5\uff09\uff1a\u5728\u90e8\u7f72\u8282\u70b9\u672c\u5730\u6784\u5efa\u5e76\u52a0\u8f7d\u955c\u50cf\n#        \uff08\u4e5f\u53ef\u4f7f\u7528\u811a\u672c build.sh \u7f16\u8bd1\uff09\n#        docker build -t fastapi-scaff:v1.0.0 .\n\n# 4\ufe0f\u3002\u3010\u90e8\u7f72\u3011\u4f7f\u7528 docker stack deploy \u542f\u52a8\u670d\u52a1\u6808\n#    - \u542f\u52a8 docker-compose.swarm.yaml\n#        docker stack deploy -c docker-compose.swarm.yaml fastapi-scaff-prod\n#    - \u6808\u540d \"fastapi-scaff-prod\" \u53ef\u81ea\u5b9a\u4e49\uff0c\u670d\u52a1\u540d\u5c06\u53d8\u4e3a fastapi-scaff-prod_backend \u548c fastapi-scaff-prod_nginx\n#        - \u786e\u4fdd nginx.conf \u914d\u7f6e\u6b63\u786e\uff1a\n#            upstream backend_upstream {\n#              server fastapi-scaff-prod_backend:8000;\n#              keepalive 32;\n#            }\n\n# 5\ufe0f\u3002\u3010\u9a8c\u8bc1\u3011\u68c0\u67e5\u670d\u52a1\u72b6\u6001\n#    - \u67e5\u770b\u670d\u52a1\u5217\u8868\uff1a\n#        docker service ls\n#    - \u67e5\u770b backend \u526f\u672c\u8fd0\u884c\u60c5\u51b5\uff1a\n#        docker service ps fastapi-scaff-prod_backend\n#    - \u67e5\u770b\u65e5\u5fd7\uff08\u4f8b\u5982\u67e5\u770b\u4e00\u4e2a backend \u5b9e\u4f8b\uff09\uff1a\n#        docker service logs fastapi-scaff-prod_backend --follow\n\n# 6\u3002\u3010\u8bbf\u95ee\u3011\u6d4b\u8bd5 API \u662f\u5426\u53ef\u7528\n#    - \u5728\u90e8\u7f72\u8282\u70b9\uff08\u6216\u4efb\u610f Swarm \u8282\u70b9\uff0c\u82e5 ports \u4f7f\u7528 ingress \u6a21\u5f0f\uff09\u8bbf\u95ee\uff1a\n#        curl http://localhost:8000/api/ping\n#    - \u5e94\u8fd4\u56de\u63a5\u53e3\u5b9a\u4e49\u7684\u54cd\u5e94\n\n# 7\ufe0f\u3002\u3010\u66f4\u65b0\u3011\u6eda\u52a8\u5347\u7ea7\u5e94\u7528\uff08\u4f8b\u5982\u5347\u7ea7\u5230 v1.0.1\uff09\n#    - \u4fee\u6539 image \u4e3a fastapi-scaff:v1.0.1\n#    - \u91cd\u65b0\u6267\u884c\u90e8\u7f72\u547d\u4ee4\uff08Swarm \u81ea\u52a8\u6267\u884c\u6eda\u52a8\u66f4\u65b0\uff09\uff1a\n#        docker stack deploy -c docker-compose.swarm.yaml fastapi-scaff-prod\n#    - \u89c2\u5bdf\u66f4\u65b0\u8fc7\u7a0b\uff1a\n#        watch docker service ps fastapi-scaff-prod_backend\n\n# 8\ufe0f\u3002\u3010\u6e05\u7406\u3011\uff08\u53ef\u9009\uff09\u5220\u9664\u6574\u4e2a\u5e94\u7528\u6808\n#        docker stack rm fastapi-scaff-prod\n\n# 9\u3002\u3010\u53c2\u8003\u3011\u5b98\u65b9\u6587\u6863\uff1ahttps://docs.docker.com/manuals/\n\n# 10\u3002\u3010\u6ce8\u610f\u3011\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\n",
    "docker-compose.yaml": "services:\n\n  backend:\n#    build:\n#      context: .\n#      dockerfile: Dockerfile\n    image: fastapi-scaff:v1.0.0  # \u5f3a\u70c8\u5efa\u8bae\u4e0d\u8981\u7528 :latest\n    restart: unless-stopped\n    environment:\n      app_env: prod\n    volumes:\n      - /data/fastapi-scaff/logs:/backend/logs\n    ports:\n      - \"8000:8000\"\n    command: \"uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 5 --log-level info\"\n#    command: \"gunicorn app.main:app -c config/gunicorn.conf.py\"  # \u8ffd\u52a0\u5b89\u88c5 gunicorn\n",
    "Dockerfile": "FROM python:3.12-bullseye\n\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONPATH=/backend \\\n    TZ=Asia/Shanghai \\\n    app_env=prod\n\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n\nWORKDIR /backend\n\nCOPY requirements.txt .\nRUN pip install --upgrade pip && \\\n    pip install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/ && \\\n    rm requirements.txt\n\nCOPY config ./config\nCOPY app ./app\n",
    "Dockerfile-slim": "FROM python:3.12-slim\n\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONPATH=/backend \\\n    TZ=Asia/Shanghai \\\n    app_env=prod\n\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n\nWORKDIR /backend\n\n# \u5b89\u88c5\u4f9d\u8d56\u7f16\u8bd1\u6240\u9700\u7684\u57fa\u7840\u5de5\u5177\uff08\u5982\u9700\u8981\u7f16\u8bd1 C \u6269\u5c55\uff09\n# \u5982\u679c requirements.txt \u4e2d\u5168\u662f\u7eaf Python \u5305\uff08\u5982 fastapi, uvicorn\uff09\uff0c\u53ef\u7701\u7565\n# RUN apt-get update && apt-get install -y --no-install-recommends gcc musl-dev && rm -rf /var/lib/apt/lists/*\n\nCOPY requirements.txt .\nRUN pip install --upgrade pip && \\\n    pip install --no-cache-dir -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/ && \\\n    rm requirements.txt\n\nCOPY config ./config\nCOPY app ./app\n",
    "LICENSE": "Copyright (c) 2024 axiner\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n",
    "README.md": "# fastapi-scaff\n\n## What is this?\n\n- by: axiner\n- fastapi-scaff\n- This is a fastapi scaff.\n    - new project\n    - add api\n    - about project:\n        - auto init project (conf, db, log...)\n        - auto register router\n        - auto register middleware\n        - ...\n        - integrated api-key/jwt\n        - integrated sqlalchemy\n        - integrated migration\n        - integrated celery\n        - integrated docker deployment\n        - ...\n    - more documents: [\u8bf7\u70b9\u51fb\u94fe\u63a5](https://blog.csdn.net/atpuxiner/article/details/144291336?fromshare=blogdetail&sharetype=blogdetail&sharerId=144291336&sharerefer=PC&sharesource=atpuxiner&sharefrom=from_link)\n\n## Project template\n\n- Architecture: ASM\n    - A api\n    - S services(&schemas)\n    - M models(&repositories)\n- Flow: main.py(initializer) - (middleware) - api - services(&schemas) - (models&repositories)\n- Layout: (The naming has been finalized after multiple revisions, making it concise and easy to understand)\n  ```\n  \u2514\u2500\u2500 fastapi-scaff\n      \u251c\u2500\u2500 app                         (\u5e94\u7528)\n      \u2502   \u251c\u2500\u2500 api                     \u251c\u2500\u2500 (\u63a5\u53e3)\n      \u2502   \u2502   \u2514\u2500\u2500 v1                  \u2502   \u2514\u2500\u2500 (\u7248\u672c1)\n      \u2502   \u251c\u2500\u2500 initializer             \u251c\u2500\u2500 (\u521d\u59cb\u5316)\n      \u2502   \u2502   \u251c\u2500\u2500 conf                \u2502   \u251c\u2500\u2500 (\u914d\u7f6e)\n      \u2502   \u2502   \u251c\u2500\u2500 db                  \u2502   \u251c\u2500\u2500 (\u6570\u636e\u5e93)\n      \u2502   \u2502   \u251c\u2500\u2500 log                 \u2502   \u251c\u2500\u2500 (\u65e5\u5fd7)\n      \u2502   \u2502   \u2514\u2500\u2500 ...                 \u2502   \u2514\u2500\u2500 (...)\n      \u2502   \u251c\u2500\u2500 middleware              \u251c\u2500\u2500 (\u4e2d\u95f4\u4ef6)\n      \u2502   \u251c\u2500\u2500 migrations              \u251c\u2500\u2500 (\u6570\u636e\u5e93\u8fc1\u79fb)\n      \u2502   \u251c\u2500\u2500 models                  \u251c\u2500\u2500 (\u6570\u636e\u6a21\u578b)\n      \u2502   \u251c\u2500\u2500 repositories            \u251c\u2500\u2500 (\u6570\u636e\u4ed3\u5e93)\n      \u2502   \u251c\u2500\u2500 schemas                 \u251c\u2500\u2500 (\u6570\u636e\u7ed3\u6784)\n      \u2502   \u251c\u2500\u2500 services                \u251c\u2500\u2500 (\u4e1a\u52a1\u903b\u8f91)\n      \u2502   \u251c\u2500\u2500 utils                   \u251c\u2500\u2500 (\u5de5\u5177\u96c6)\n      \u2502   \u2514\u2500\u2500 main.py                 \u2514\u2500\u2500 (\u4e3b\u5165\u53e3)\n      \u251c\u2500\u2500 app_celery                  (\u5e94\u7528-\u5f02\u6b65\u4efb\u52a1)\n      \u251c\u2500\u2500 config                      (\u914d\u7f6e\u76ee\u5f55)\n      \u251c\u2500\u2500 docs                        (\u6587\u6863\u76ee\u5f55)\n      \u251c\u2500\u2500 logs                        (\u65e5\u5fd7\u76ee\u5f55)\n      \u251c\u2500\u2500 tests                       (\u6d4b\u8bd5\u76ee\u5f55)\n      \u251c\u2500\u2500 .dockerignore\n      \u251c\u2500\u2500 .gitignore\n      \u251c\u2500\u2500 .python-version\n      \u251c\u2500\u2500 build.sh\n      \u251c\u2500\u2500 docker-compose.yaml\n      \u251c\u2500\u2500 Dockerfile\n      \u251c\u2500\u2500 LICENSE\n      \u251c\u2500\u2500 README.md\n      \u251c\u2500\u2500 requirements.txt\n      \u2514\u2500\u2500 runserver.py\n  ```\n\n- \u3010Other\u3011\n    - light\uff1aPlease create and view (with `-t light`)\n    - tiny\uff1aPlease create and view (with `-t tiny`)\n    - single\uff1aPlease create and view (with `-t single`)\n\n- \u3010Tips\u3011Database, Redis, Snowflake and Celery can all be controlled through parameters to integrate or not, allowing you to flexibly customize the functional modules needed for your project.\n\n## Installation\n\nThis package can be installed using pip (Python>=3.11):\n> pip install fastapi-scaff\n\n## Scaff usage\n\n- 1\uff09help document\n    - `fastapi-scaff -h`\n- 2\uff09new project\n    - `fastapi-scaff new <myproj>`\n    - *light*: `fastapi-scaff new <myproj> -t light`\n    - *tiny*: `fastapi-scaff new <myproj> -t tiny`\n    - *single*: `fastapi-scaff new <myproj> -t single`\n- 3\uff09add api\n    - `cd to project root dir`\n    - `fastapi-scaff add <myapi>`\n- 4\uff09integrated celery\n    - M1\u3002`new` with `--celery`: `fastapi-scaff new <myproj> --celery`\n    - M2\u3002`add` with `--celery`: `fastapi-scaff add <mycelery> --celery`\n\n## Project run\n\n- 1\uff09cd to project root dir\n- 2\uff09modify the configuration, such as for the database\n- 3\uff09`pip install -r requirements.txt`\n- 4\uff09`python runserver.py`\n    - more parameters see:\n        - about uvicorn: [click here](https://www.uvicorn.org/)\n        - about gunicorn: [click here](https://docs.gunicorn.org/en/stable/)\n- x\uff09migration\n    - eg (Can be executed before runserver):\n        - generate: `python runmigration.py generate init`\n        - upgrade: `python runmigration.py upgrade`\n    - about alembic: [click here](https://alembic.sqlalchemy.org/en/latest/)\n- x\uff09docker, please see:\n    - project files:\n        - build.sh\n        - docker-compose.yaml | docker-compose.swarm.yaml[config/nginx.conf]\n        - Dockerfile | Dockerfile.slim\n    - about docker: [click here](https://docs.docker.com/)\n\n## License\n\nThis project is released under the MIT License (MIT). See [LICENSE](LICENSE)\n\n-----\n\n## \u2615 \u8bf7\u6211\u559d\u5496\u5561\n\n\u4eab\u53d7\u5f00\u6e90\uff0c\u4e5f\u611f\u8c22\u652f\u6301\u3002\n\n\u5982\u679c\u672c\u9879\u76ee\u5bf9\u60a8\u6709\u7528\uff0c\u53ef\u4ee5\u8003\u8651 Buy Me a Coffee :)\n\n![](BuyMeaCoffee.jpg)\n",
    "requirements.txt": "# -*- coding: utf-8 -*-\n# Python>=3.11\nfastapi-scaff==0.9.0\nfastapi==0.128.0\nuvicorn[standard]==0.40.0\ntoollib==2.0.6\ntzdata==2025.3\npython-dotenv==1.2.1\nPyYAML==6.0.3\norjson==3.11.5\nloguru==0.7.3\nPyJWT==2.10.1\nbcrypt==5.0.0\nSQLAlchemy==2.0.45\nalembic==1.17.2\naiosqlite==0.22.1\nredis==7.1.0\ncelery==5.6.2\n#gunicorn\n",
    "runcbeat.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2025/09/20 10:10\n@abstract runcbeat\uff08\u66f4\u591a\u53c2\u6570\u8bf7\u81ea\u884c\u6307\u5b9a\uff09\n@description\n@history\n\"\"\"\nimport argparse\nimport subprocess\n\n\ndef main(\n        loglevel: str = \"info\",\n        scheduler: str = None,\n        pidfile: str = None,\n        max_interval: int = 5,\n        celery_module: str = \"app_celery\",\n):\n    parser = argparse.ArgumentParser(description=\"CeleryBeat\u542f\u52a8\u5668\")\n    parser.add_argument(\"-l\", \"--loglevel\", type=str, default=\"info\", metavar=\"\", help=\"\u65e5\u5fd7\u7b49\u7ea7\")\n    parser.add_argument(\"-S\", \"--scheduler\", type=str, default=None, metavar=\"\", help=\"\u8c03\u5ea6\u5668\u7c7b\u578b\")\n    parser.add_argument(\"--pidfile\", type=str, default=None, metavar=\"\", help=\"pid\u6587\u4ef6\")\n    parser.add_argument(\"--max-interval\", type=int, default=5, metavar=\"\", help=\"\u68c0\u6d4b\u4efb\u52a1\u95f4\u9694\")\n    parser.add_argument(\"--celery-module\", type=str, default=\"app_celery\", metavar=\"\", help=\"celery\u6a21\u5757\")\n    args = parser.parse_args()\n    loglevel = args.loglevel or loglevel\n    scheduler = args.scheduler or scheduler\n    pidfile = args.pidfile or pidfile\n    max_interval = args.max_interval or max_interval\n    celery_module = args.celery_module or celery_module\n    command = [\n        \"celery\",\n        \"-A\",\n        f\"{celery_module}.consumer\",\n        \"beat\",\n        f\"--loglevel={loglevel}\",\n        f\"--max-interval={max_interval}\",\n    ]\n    if scheduler:\n        command.extend([\"--scheduler\", scheduler])\n    if pidfile:\n        command.extend([\"--pidfile\", pidfile])\n    subprocess.run(command, check=True)\n\n\nif __name__ == '__main__':\n    main()\n",
    "runcworker.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2025/09/20 10:10\n@abstract runcworker\uff08\u66f4\u591a\u53c2\u6570\u8bf7\u81ea\u884c\u6307\u5b9a\uff09\n@description\n@history\n\"\"\"\nimport argparse\nimport platform\nimport subprocess\nfrom os import cpu_count\n\n\ndef main(\n        name: str,  # `<celery_module>/consumer/workers`\u4e0b\u7684\u6a21\u5757\u540d\n        loglevel: str = \"info\",\n        concurrency: int = None,\n        pool: str = None,\n        celery_module: str = \"app_celery\",\n):\n    parser = argparse.ArgumentParser(description=\"CeleryWorker\u542f\u52a8\u5668\")\n    parser.add_argument(\"-n\", \"--name\", type=str, metavar=\"\", help=\"\u540d\u79f0\")\n    parser.add_argument(\"-l\", \"--loglevel\", type=str, default=\"info\", metavar=\"\", help=\"\u65e5\u5fd7\u7b49\u7ea7\")\n    parser.add_argument(\"-c\", \"--concurrency\", type=int, default=None, metavar=\"\", help=\"\u5e76\u53d1\u6570\")\n    parser.add_argument(\"-P\", \"--pool\", type=str, default=None, metavar=\"\", help=\"\u5e76\u53d1\u6a21\u578b\")\n    parser.add_argument(\"--celery-module\", type=str, default=\"app_celery\", metavar=\"\", help=\"celery\u6a21\u5757\")\n    args = parser.parse_args()\n    name = args.name or name\n    loglevel = args.loglevel or loglevel\n    concurrency = args.concurrency or concurrency\n    pool = args.pool or pool\n    celery_module = args.celery_module or celery_module\n    if pool is None:\n        if platform.system().lower().startswith(\"win\"):\n            pool = 'gevent'\n            if not concurrency:\n                concurrency = 100\n        else:\n            pool = 'prefork'\n            if not concurrency:\n                concurrency = cpu_count()\n    command = [\n        \"celery\",\n        \"-A\",\n        f\"{celery_module}.consumer.workers.{name}\",\n        \"worker\",\n        f\"--loglevel={loglevel}\",\n        f\"--concurrency={concurrency}\",\n        f\"--pool={pool}\",\n    ]\n    subprocess.run(\n        command,\n        check=True,\n    )\n\n\nif __name__ == '__main__':\n    main(\n        name=\"ping\",\n    )\n",
    "runmigration.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2025/09/20 10:10\n@abstract runmigration\uff08\u66f4\u591a\u53c2\u6570\u8bf7\u81ea\u884c\u6307\u5b9a\uff09\n@description\n@history\n\"\"\"\nimport argparse\nimport sys\nfrom pathlib import Path\n\nfrom alembic import command\nfrom alembic.config import Config\n\nwork_dir = Path(__file__).parent\nsys.path.insert(0, str(work_dir))\n\ncfg_path = work_dir / \"app/migrations/alembic.ini\"\nif not cfg_path.exists():\n    raise FileNotFoundError(f\"alembic.ini not found at {cfg_path}\")\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Manage database migrations.\")\n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Available commands\")\n\n    # generate\n    gen_parser = subparsers.add_parser(\"generate\", help=\"Autogenerate a new migration\")\n    gen_parser.add_argument(\"message\", help=\"Migration message (required)\")\n    gen_parser.add_argument(\"--autogenerate\", action=\"store_true\", default=True,\n                            help=\"Enable autogenerate (default: True)\")\n\n    # upgrade\n    upgrade_parser = subparsers.add_parser(\"upgrade\", help=\"Apply migrations up to head\")\n    upgrade_parser.add_argument(\"-m\", \"--message\", help=\"Optional log message\")\n    upgrade_parser.add_argument(\"--revision\", default=\"head\", help=\"Revision to upgrade to (default: head)\")\n\n    # stamp\n    stamp_parser = subparsers.add_parser(\"stamp\", help=\"Set current revision without running migrations\")\n    stamp_parser.add_argument(\"revision\", help=\"Revision to stamp\")\n\n    # current\n    subparsers.add_parser(\"current\", help=\"Show current revision\")\n\n    args = parser.parse_args()\n\n    alembic_cfg = Config(str(cfg_path))\n\n    try:\n        if args.command == \"generate\":\n            print(f\"Generating migration: {args.message}\")\n            command.revision(alembic_cfg, autogenerate=args.autogenerate, message=args.message)\n            print(\"Migration generated.\")\n\n        elif args.command == \"upgrade\":\n            if args.message:\n                print(f\"[INFO] Upgrade context: {args.message}\")\n            print(f\"Applying migrations to {args.revision}...\")\n            command.upgrade(alembic_cfg, args.revision)\n            print(f\"Upgraded to {args.revision}.\")\n\n        elif args.command == \"stamp\":\n            print(f\"Stamping revision: {args.revision}\")\n            command.stamp(alembic_cfg, args.revision)\n            print(\"Revision stamped.\")\n\n        elif args.command == \"current\":\n            print(\"Checking current revision...\")\n            command.current(alembic_cfg)\n\n        else:\n            parser.print_help()\n\n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "runserver.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2024/07/29 22:22\n@abstract runserver\uff08\u66f4\u591a\u53c2\u6570\u8bf7\u81ea\u884c\u6307\u5b9a\uff09\n@description\n@history\n\"\"\"\nimport argparse\nimport subprocess\nimport sys\n\nimport uvicorn\n\n\ndef run_by_unicorn(\n        host: str,\n        port: int,\n        workers: int,\n        log_level: str,\n        reload: bool,\n):\n    log_config = {\n        \"version\": 1,\n        \"disable_existing_loggers\": False,\n        \"formatters\": {\n            \"default\": {\n                \"()\": \"uvicorn.logging.DefaultFormatter\",\n                \"fmt\": \"%(asctime)s %(levelname)s %(filename)s:%(lineno)d %(message)s\",\n                \"use_colors\": None\n            },\n            \"access\": {\n                \"()\": \"uvicorn.logging.AccessFormatter\",\n                \"fmt\": \"%(asctime)s %(levelname)s %(client_addr)s - \\\"%(request_line)s\\\" %(status_code)s\"\n            }\n        },\n        \"handlers\": {\n            \"default\": {\n                \"formatter\": \"default\",\n                \"class\": \"logging.StreamHandler\",\n                \"stream\": \"ext://sys.stderr\"\n            },\n            \"access\": {\n                \"formatter\": \"access\",\n                \"class\": \"logging.StreamHandler\",\n                \"stream\": \"ext://sys.stdout\"\n            }\n        },\n        \"loggers\": {\n            \"uvicorn\": {\n                \"handlers\": [\n                    \"default\"\n                ],\n                \"level\": \"INFO\",\n                \"propagate\": False\n            },\n            \"uvicorn.error\": {\n                \"level\": \"INFO\"\n            },\n            \"uvicorn.access\": {\n                \"handlers\": [\n                    \"access\"\n                ],\n                \"level\": \"INFO\",\n                \"propagate\": False\n            }\n        }\n    }\n    uvicorn.run(\n        app=\"app.main:app\",\n        host=host,\n        port=port,\n        workers=workers,\n        log_level=log_level,\n        log_config=log_config,\n        reload=reload,\n    )\n\n\ndef run_by_gunicorn(\n        host: str,\n        port: int,\n        workers: int,\n        log_level: str,\n        reload: bool,\n):\n    cmd = (\n        \"gunicorn app.main:app \"\n        \"--worker-class=uvicorn.workers.UvicornWorker \"\n        \"--bind={host}:{port} \"\n        \"--workers={workers} \"\n        \"--log-level={log_level} \"\n        \"--access-logfile=- \"\n        \"--error-logfile=-\"\n        .format(\n            host=host,\n            port=port,\n            workers=workers,\n            log_level=log_level,\n        )\n    )\n    if reload:\n        cmd += f\" --reload\"\n    subprocess.run(cmd, shell=True)\n\n\ndef main(\n        host: str,\n        port: int,\n        workers: int,\n        log_level: str,\n        reload: bool,\n        gunicorn: bool,\n):\n    parser = argparse.ArgumentParser(description=\"App\u542f\u52a8\u5668\")\n    parser.add_argument(\"--host\", type=str, metavar=\"\", help=\"host\")\n    parser.add_argument(\"--port\", type=int, metavar=\"\", help=\"port\")\n    parser.add_argument(\"--workers\", type=int, metavar=\"\", help=\"\u8fdb\u7a0b\u6570\")\n    parser.add_argument(\"--log-level\", type=str, metavar=\"\", help=\"\u65e5\u5fd7\u7b49\u7ea7\")\n    parser.add_argument(\"--reload\", action=\"store_true\", help=\"\u662f\u5426reload\")\n    parser.add_argument(\"--gunicorn\", action=\"store_true\", help=\"\u662f\u5426gunicorn\")\n    args = parser.parse_args()\n    kwargs = {\n        \"host\": args.host or host,\n        \"port\": args.port or port,\n        \"workers\": args.workers or workers,\n        \"log_level\": args.log_level or log_level,\n        \"reload\": args.reload or reload,\n    }\n    if (args.gunicorn or gunicorn) and not sys.platform.lower().startswith(\"win\"):\n        try:\n            import gunicorn  # noqa\n        except ImportError:\n            sys.stderr.write(\"gunicorn\u672a\u627e\u5230\uff0c\u6b63\u5728\u5c1d\u8bd5\u81ea\u52a8\u5b89\u88c5...\\n\")\n            try:\n                subprocess.run(\n                    [\"pip\", \"install\", \"gunicorn\"],\n                    check=True,\n                    stdout=subprocess.PIPE,\n                    stderr=subprocess.PIPE)\n                sys.stderr.write(\"gunicorn\u5b89\u88c5\u6210\u529f\\n\")\n            except subprocess.CalledProcessError as e:\n                sys.stderr.write(f\"gunicorn\u5b89\u88c5\u5931\u8d25: {e.stderr.decode().strip()}\\n\")\n                raise\n        run_by_gunicorn(**kwargs)\n    else:\n        run_by_unicorn(**kwargs)\n\n\nif __name__ == '__main__':\n    main(\n        host=\"0.0.0.0\",\n        port=8000,\n        workers=1,\n        log_level=\"debug\",\n        reload=False,  # For development environment\n        gunicorn=False,  # Not supported on Windows\n    )\n",
    "app/main.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2024/07/29 22:22\n@abstract main\n@description\n@history\n\"\"\"\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom fastapi.responses import ORJSONResponse\nfrom loguru import logger\n\nfrom app import (\n    api,\n    middleware,\n)\nfrom app.initializer import g\n\ng.setup()\n# #\nopenapi_url = \"/openapi.json\"\ndocs_url = \"/docs\"\nredoc_url = \"/redoc\"\nif g.config.app_disable_docs is True:\n    openapi_url, docs_url, redoc_url = None, None, None\n\n\n@asynccontextmanager\nasync def lifespan(xapp: FastAPI):\n    logger.info(f\"Application env '{g.config.app_env}'\")\n    logger.info(f\"Application yaml '{g.config.yaml_path.name}'\")\n    logger.info(f\"Application title '{g.config.app_title}'\")\n    logger.info(f\"Application version '{g.config.app_version}'\")\n    # #\n    logger.info(\"Application server running\")\n    yield\n    logger.info(\"Application server shutdown\")\n\n\napp = FastAPI(\n    title=g.config.app_title,\n    summary=g.config.app_summary,\n    description=g.config.app_description,\n    version=g.config.app_version,\n    debug=g.config.app_debug,\n    openapi_url=openapi_url,\n    docs_url=docs_url,\n    redoc_url=redoc_url,\n    lifespan=lifespan,\n    default_response_class=ORJSONResponse,\n)\n# #\nmiddleware.register_middlewares(app)\napi.register_routers(app)\n",
    "app/__init__.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2024/07/29 22:22\n@abstract app\n@description\n@history\n\"\"\"\nfrom pathlib import Path\n\nAPP_DIR = Path(__file__).absolute().parent\n",
    "app_celery/conf.py": "import os\nfrom pathlib import Path\n\nfrom toollib.utils import ConfModel, FrozenVar\n\n_APP_DIR = Path(__file__).absolute().parent\n_CONFIG_DIR = _APP_DIR.parent.joinpath(\"config\")\n\ndotenv_path = _CONFIG_DIR.joinpath(\".env\")\nif os.environ.setdefault(\"app_env\", \"dev\") == \"prod\":  # \u751f\u4ea7\u73af\u5883\u4e0d\u52a0\u8f7d.env\uff08\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\uff09\n    dotenv_path = None\nyaml_path = _CONFIG_DIR.joinpath(f\"app_{os.environ.get('app_env', 'dev')}.yaml\")\n\n\nclass Config(ConfModel):\n    \"\"\"\u914d\u7f6e\"\"\"\n    app_dir: FrozenVar[Path] = _APP_DIR\n    # #\n    app_env: str = \"dev\"\n    yaml_path: Path = yaml_path\n    # #\n    celery_broker_url: str\n    celery_backend_url: str\n    celery_timezone: str = \"Asia/Shanghai\"\n    celery_enable_utc: bool = True\n    celery_task_serializer: str = \"json\"\n    celery_result_serializer: str = \"json\"\n    celery_accept_content: list = [\"json\"]\n    celery_task_ignore_result: bool = False\n    celery_result_expire: int = 86400\n    celery_task_track_started: bool = True\n    celery_worker_concurrency: int = 8\n    celery_worker_prefetch_multiplier: int = 2\n    celery_worker_max_tasks_per_child: int = 100\n    celery_broker_connection_retry_on_startup: bool = True\n    celery_task_reject_on_worker_lost: bool = True\n\n\nconfig = Config(\n    dotenv_path=dotenv_path,\n    yaml_path=yaml_path,\n)\n",
    "app_celery/README.md": "# app-celery\n\n## \u7b80\u4ecb\n\n### producer\uff1a\u751f\u4ea7\u8005\uff08\u53d1\u5e03\u4efb\u52a1\uff09\n\n- register\uff1a\u6ce8\u518c\u4e2d\u5fc3\n    - \u5c06`consumer`\u7684`tasks`\u6ce8\u518c\u5230`producer`\u7684`register`\u4e2d\n- publisher\uff1a\u53d1\u5e03\u8005\n    - \u9879\u76ee\u4e2d\u901a\u8fc7`publisher.publish`\u6765\u53d1\u5e03\u4efb\u52a1\n\n### consumer\uff1a\u6d88\u8d39\u8005\uff08\u6267\u884c\u4efb\u52a1\uff09\n\n- tasks: \u4efb\u52a1\n    - \u5b9a\u65f6\u4efb\u52a1\uff08beat_xxx\uff09\n        - 1\u3002\u521b\u5efa\u5b9a\u65f6\u4efb\u52a1\n        - 2\u3002\u53d1\u5e03\u5b9a\u65f6\u4efb\u52a1\uff08\u901a\u8fc7celery\u5185\u90e8\u7684`beat`\u8c03\u7528\uff09\n            - \u8fdb\u5165`app_celery`\u7236\u7ea7\u76ee\u5f55\uff0c\u5373\u5de5\u4f5c\u76ee\u5f55\n            - \u542f\u52a8\u547d\u4ee4\uff1a\uff08\u66f4\u591a\u53c2\u6570\u8bf7\u81ea\u884c\u6307\u5b9a\uff09\n                - \u65b9\u5f0f1\u3002\u76f4\u63a5\u6267\u884c\u811a\u672c: `python runcbeat.py --celery-module=app_celery`\n                - \u65b9\u5f0f2\u3002\u4f7f\u7528\u547d\u4ee4\u884c\uff1a`celery -A app_celery.consumer beat --loglevel=info --max-interval=5`\n        - 3\u3002\u542f\u52a8\u6d88\u8d39\u8005worker\n    - \u5f02\u6b65\u4efb\u52a1\uff08xxx)\n        - 1\u3002\u521b\u5efa\u5f02\u6b65\u4efb\u52a1\uff0c\u5e76\u6ce8\u518c\u5230`producer`\u7684`register`\uff0c\u6839\u636e\u6ce8\u518c\u7684\u89c4\u5219\u8fdb\u884c`\u4efb\u52a1\u8c03\u7528`\u548c`worker\u542f\u52a8`\n        - 2\u3002\u53d1\u5e03\u5f02\u6b65\u4efb\u52a1\uff08\u901a\u8fc7\u751f\u4ea7\u8005\u7684`publisher.publish`\u8c03\u7528\uff09\n        - 3\u3002\u542f\u52a8\u6d88\u8d39\u8005worker\n- workers: \u5de5\u4f5c\u8005\n    - 1\u3002\u521b\u5efaworker\u670d\u52a1\uff0c\u5b9a\u4e49\u961f\u5217\u7b49\u5c5e\u6027\uff08\u4e3a\u65b9\u4fbf\u6269\u5c55\u5efa\u8bae\u4e00\u7c7b\u4efb\u52a1\u4e00\u4e2a\u670d\u52a1\uff09\n    - 2\u3002\u542f\u52a8worker\u670d\u52a1\uff1a\n        - 1\u3002\u8fdb\u5165`app_celery`\u7236\u7ea7\u76ee\u5f55\uff0c\u5373\u5de5\u4f5c\u76ee\u5f55\n        - 2\u3002\u542f\u52a8\u547d\u4ee4\uff1a\uff08\u66f4\u591a\u53c2\u6570\u8bf7\u81ea\u884c\u6307\u5b9a\uff09\n            - \u65b9\u5f0f1\u3002\u76f4\u63a5\u6267\u884c\u811a\u672c: `python runcworker.py -n ping --celery-module=app_celery`\n            - \u65b9\u5f0f2\u3002\u4f7f\u7528\u547d\u4ee4\u884c\uff1a`celery -A app_celery.consumer.workers.ping worker --loglevel=info --concurrency=5`\n- yaml\u914d\u7f6e\n\n```yaml\ncelery_broker_url: redis://:<password>@<host>:<port>/<db>\ncelery_backend_url: redis://:<password>@<host>:<port>/<db>\ncelery_timezone: Asia/Shanghai\ncelery_enable_utc: true\ncelery_task_serializer: json\ncelery_result_serializer: json\ncelery_accept_content: [ json ]\ncelery_task_ignore_result: false\ncelery_result_expire: 86400\ncelery_task_track_started: true\ncelery_worker_concurrency: 8\ncelery_worker_prefetch_multiplier: 2\ncelery_worker_max_tasks_per_child: 100\ncelery_broker_connection_retry_on_startup: true\ncelery_task_reject_on_worker_lost: true\n```\n\n- \u6d88\u8d39\u7aef\u4f9d\u8d56\n\n```text\ncelery\nredis\n```\n\n### \u6ce8\u610f\uff1a\n\n- \u6700\u597d\u4e0e`app`\u89e3\u8026\uff0c\u5373\uff1a\n    - \u53ea`app`\u5355\u5411\u8c03\u7528`app_celery`\n    - \u4f46`app_celery`\u4e0d\u8c03\u7528`app`\n",
    "app_celery/requirements.txt": "# -*- coding: utf-8 -*-\n# Python>=3.11\ncelery==5.6.2\nredis==7.1.0\ngevent==25.9.1\ntoollib==2.0.6\npython-dotenv==1.2.1\nPyYAML==6.0.3\npydantic==2.12.5\n",
    "app_celery/__init__.py": "\"\"\"\n@author axiner\n@version v0.0.1\n@created 2025/09/20 10:10\n@abstract app-celery\n@description\n@history\n\"\"\"\nfrom celery import Celery\n\nfrom app_celery.conf import config\n\n\ndef make_celery(include: list = None, configs: dict = None):\n    app = Celery(\n        main=\"app_celery\",\n        broker=config.celery_broker_url,\n        backend=config.celery_backend_url,\n        include=include,\n    )\n    app.conf.update(\n        timezone=config.celery_timezone,\n        enable_utc=config.celery_enable_utc,\n        task_serializer=config.celery_task_serializer,\n        result_serializer=config.celery_result_serializer,\n        accept_content=config.celery_accept_content,\n        celery_task_ignore_result=config.celery_task_ignore_result,\n        celery_result_expire=config.celery_result_expire,\n        celery_task_track_started=config.celery_task_track_started,\n        worker_concurrency=config.celery_worker_concurrency,\n        worker_prefetch_multiplier=config.celery_worker_prefetch_multiplier,\n        worker_max_tasks_per_child=config.celery_worker_max_tasks_per_child,\n        broker_connection_retry_on_startup=config.celery_broker_connection_retry_on_startup,\n        task_reject_on_worker_lost=config.celery_task_reject_on_worker_lost,\n    )\n    if configs:\n        app.conf.update(configs)\n    return app\n",
    "config/.env": "# ------- \u5747\u53ef\u76f4\u63a5\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf -------\n# ------- \u5747\u53ef\u76f4\u63a5\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf -------\n# ------- \u5747\u53ef\u76f4\u63a5\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf -------\n# \u5e94\u7528\u73af\u5883\uff08\u5b9a\u4f4dyaml\u914d\u7f6e\uff09\napp_env=dev\n# \u5e94\u7528\u914d\u7f6e\uff08\u6307\u5b9ayaml\u914d\u7f6e\uff0c\u4f18\u4e8e`app_env`\u5b9a\u4f4d\uff09\nyaml_path=\n# ------- Config -------\n# api\u5bc6\u94a5\napi_keys=\n# jwt\u5bc6\u94a5\njwt_key=\n# \u96ea\u82b1\u7b97\u6cd5\u6570\u636e\u4e2d\u5fc3id\uff08\u53d6\u503c\uff1a0-31\uff0c\u5728\u5206\u5e03\u5f0f\u90e8\u7f72\u65f6\u9700\u786e\u4fdd\u6bcf\u4e2a\u8282\u70b9\u7684\u53d6\u503c\u4e0d\u540c\uff09\nsnow_datacenter_id=0\n",
    "config/app_dev.yaml": "# \u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\napp_title: xApp-dev\napp_summary: xxApp-dev\napp_description: xxxApp-dev\napp_version: 1.0.0\napp_debug: true\napp_log_serialize: false\napp_log_outdir: ./logs\napp_disable_docs: false\napp_allow_credentials: true\napp_allow_origins:\n  - '*'\napp_allow_methods:\n  - '*'\napp_allow_headers:\n  - '*'\n# #\ndb_drivername: sqlite\ndb_async_drivername: sqlite+aiosqlite\ndb_database: app_dev.sqlite\ndb_username:\ndb_password:\ndb_host:\ndb_port:\ndb_charset:\nredis_host: 127.0.0.1\nredis_port: 6379\nredis_db: 0\nredis_password:\nredis_max_connections:\n# #\ncelery_broker_url: redis://:<password>@<host>:<port>/<db>\ncelery_backend_url: redis://:<password>@<host>:<port>/<db>\ncelery_timezone: Asia/Shanghai\ncelery_enable_utc: true\ncelery_task_serializer: json\ncelery_result_serializer: json\ncelery_accept_content: [ json ]\ncelery_task_ignore_result: false\ncelery_result_expire: 86400\ncelery_task_track_started: true\ncelery_worker_concurrency: 8\ncelery_worker_prefetch_multiplier: 2\ncelery_worker_max_tasks_per_child: 100\ncelery_broker_connection_retry_on_startup: true\ncelery_task_reject_on_worker_lost: true\n",
    "config/app_prod.yaml": "# \u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\napp_title: xApp-prod\napp_summary: xxApp-prod\napp_description: xxxApp-prod\napp_version: 1.0.0\napp_debug: false\napp_log_serialize: false\napp_log_outdir: ./logs\napp_disable_docs: true\napp_allow_credentials: true\napp_allow_origins:\n  - '*'\napp_allow_methods:\n  - '*'\napp_allow_headers:\n  - '*'\n# #\ndb_drivername: sqlite\ndb_async_drivername: sqlite+aiosqlite\ndb_database: app_prod.sqlite\ndb_username:\ndb_password:\ndb_host:\ndb_port:\ndb_charset:\nredis_host: 127.0.0.1\nredis_port: 6379\nredis_db: 0\nredis_password:\nredis_max_connections:\n# #\ncelery_broker_url: redis://:<password>@<host>:<port>/<db>\ncelery_backend_url: redis://:<password>@<host>:<port>/<db>\ncelery_timezone: Asia/Shanghai\ncelery_enable_utc: true\ncelery_task_serializer: json\ncelery_result_serializer: json\ncelery_accept_content: [ json ]\ncelery_task_ignore_result: false\ncelery_result_expire: 86400\ncelery_task_track_started: true\ncelery_worker_concurrency: 8\ncelery_worker_prefetch_multiplier: 2\ncelery_worker_max_tasks_per_child: 100\ncelery_broker_connection_retry_on_startup: true\ncelery_task_reject_on_worker_lost: true\n",
    "config/app_test.yaml": "# \u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\napp_title: xApp-test\napp_summary: xxApp-test\napp_description: xxxApp-test\napp_version: 1.0.0\napp_debug: true\napp_log_serialize: false\napp_log_outdir: ./logs\napp_disable_docs: false\napp_allow_credentials: true\napp_allow_origins:\n  - '*'\napp_allow_methods:\n  - '*'\napp_allow_headers:\n  - '*'\n# #\ndb_drivername: sqlite\ndb_async_drivername: sqlite+aiosqlite\ndb_database: app_test.sqlite\ndb_username:\ndb_password:\ndb_host:\ndb_port:\ndb_charset:\nredis_host: 127.0.0.1\nredis_port: 6379\nredis_db: 0\nredis_password:\nredis_max_connections:\n# #\ncelery_broker_url: redis://:<password>@<host>:<port>/<db>\ncelery_backend_url: redis://:<password>@<host>:<port>/<db>\ncelery_timezone: Asia/Shanghai\ncelery_enable_utc: true\ncelery_task_serializer: json\ncelery_result_serializer: json\ncelery_accept_content: [ json ]\ncelery_task_ignore_result: false\ncelery_result_expire: 86400\ncelery_task_track_started: true\ncelery_worker_concurrency: 8\ncelery_worker_prefetch_multiplier: 2\ncelery_worker_max_tasks_per_child: 100\ncelery_broker_connection_retry_on_startup: true\ncelery_task_reject_on_worker_lost: true\n",
    "config/gunicorn.conf.py": "import multiprocessing\nimport os\n\n# ========================\n# \u7ed1\u5b9a\u914d\u7f6e\n# ========================\nbind = \"0.0.0.0:8000\"  # \u76d1\u542c\u5730\u5740\uff1b\u82e5\u7528 Unix Socket\uff1abind = \"unix:/tmp/gunicorn.sock\"\n\n# ========================\n# Worker \u914d\u7f6e\uff08\u6838\u5fc3\uff09\n# ========================\n# \u63a8\u8350\u516c\u5f0f\uff1aI/O \u5bc6\u96c6\u578b\u5e94\u7528\uff08\u5982 FastAPI\uff09\u2192 2 * CPU + 1\nworkers = int(os.getenv(\"WORKERS\", multiprocessing.cpu_count() * 2 + 1))\nworker_class = \"uvicorn.workers.UvicornWorker\"\nworker_connections = int(os.getenv(\"WORKER_CONNECTIONS\", \"1000\"))  # async worker \u8f6f\u9650\u5236\n\n# ========================\n# \u8d85\u65f6\u4e0e\u751f\u547d\u5468\u671f\n# ========================\ntimeout = 60  # \u8bf7\u6c42\u5904\u7406\u8d85\u65f6\uff08\u79d2\uff09\uff0c\u8d85\u8fc7\u5219 kill worker\nkeepalive = 5  # Keep-Alive \u8d85\u65f6\uff08\u79d2\uff09\ngraceful_timeout = 30  # SIGTERM \u540e\u7b49\u5f85\u65f6\u95f4\uff08\u79d2\uff09\nmax_requests = 1000  # \u6bcf\u4e2a worker \u5904\u7406 N \u4e2a\u8bf7\u6c42\u540e\u91cd\u542f\uff08\u9632\u5185\u5b58\u6cc4\u6f0f\uff09\nmax_requests_jitter = 50  # \u968f\u673a\u6296\u52a8\uff080~50\uff09\uff0c\u907f\u514d\u6240\u6709 worker \u540c\u65f6\u91cd\u542f\n\n# ========================\n# \u65e5\u5fd7\u914d\u7f6e\uff08\u5bb9\u5668\u53cb\u597d\uff1a\u8f93\u51fa\u5230 stdout/stderr\uff09\n# ========================\nloglevel = os.getenv(\"LOG_LEVEL\", \"info\")\naccesslog = \"-\"  # \u8bbf\u95ee\u65e5\u5fd7 \u2192 stdout\nerrorlog = \"-\"  # \u9519\u8bef\u65e5\u5fd7 \u2192 stderr\naccess_log_format = '%(h)s %(l)s %(u)s %(t)s \"%(r)s\" %(s)s %(b)s \"%(f)s\" \"%(a)s\" %(T)s %(D)s'\n\n# ========================\n# \u6027\u80fd\u4e0e\u5b89\u5168\n# ========================\npreload_app = True  # \u9884\u52a0\u8f7d\u5e94\u7528\uff0c\u51cf\u5c11\u5185\u5b58\u5360\u7528\uff08fork \u524d\u52a0\u8f7d\uff09\nforwarded_allow_ips = os.getenv(\n    \"FORWARDED_ALLOW_IPS\",\n    \"*\"\n)\nsecure_scheme_headers = {\"X-Forwarded-Proto\": \"https\"}  # \u8bc6\u522b HTTPS\n\n# ========================\n# \u8fdb\u7a0b\u4e0e\u8d44\u6e90\n# ========================\nproc_name = \"fastapi-app\"  # ps/top \u4e2d\u663e\u793a\u7684\u8fdb\u7a0b\u540d\n# pidfile = \"/var/run/fastapi.pid\"  # \u5bb9\u5668\u4e2d\u901a\u5e38\u4e0d\u9700\u8981\uff0c\u53ef\u6ce8\u91ca\nuser = None  # \u5bb9\u5668\u4e2d\u901a\u5e38\u4ee5\u975e root \u542f\u52a8\uff0c\u7531 Dockerfile \u63a7\u5236\ngroup = None\ntmp_upload_dir = None\n\n# ========================\n# \u5b89\u5168\u52a0\u56fa\uff08\u53ef\u9009\u4f46\u63a8\u8350\uff09\n# ========================\n# limit_request_line = 4096         # \u6700\u5927\u8bf7\u6c42\u884c\u957f\u5ea6\uff08\u9632 DoS\uff09\n# limit_request_fields = 100        # \u6700\u5927 header \u5b57\u6bb5\u6570\n# limit_request_field_size = 8190   # \u5355\u4e2a header \u6700\u5927\u5927\u5c0f\n",
    "config/nginx.conf": "upstream backend_upstream {\n    server backend:8000;\n    keepalive 32;\n}\n\nserver {\n    listen 80;\n\n    client_max_body_size 20M;\n    keepalive_timeout 30s;\n    keepalive_requests 1000;\n\n    # \u5b89\u5168\u5934\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-Frame-Options \"DENY\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n\n    location /api/ {\n        proxy_pass http://backend_upstream;  # \u6ce8\u610f\uff1a\u7ed3\u5c3e\u65e0 /\uff0clocation \u6709 /\n\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        proxy_connect_timeout 5s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n\n        proxy_buffering on;\n        proxy_buffers 8 16k;\n        proxy_buffer_size 32k;\n        proxy_busy_buffers_size 64k;\n\n        # gzip \u538b\u7f29\n        gzip on;\n        gzip_vary on;\n        gzip_min_length 1024;\n        gzip_types\n            application/json\n            application/javascript\n            text/css\n            text/plain;\n    }\n\n    # \u62d2\u7edd\u5176\u4ed6\u8def\u5f84\n    location / {\n        return 404;\n    }\n\n    # \u53ef\u9009\uff1a\u5065\u5eb7\u68c0\u67e5\u7aef\u70b9\uff08\u4f9b\u5916\u90e8 LB \u4f7f\u7528\uff09\n    location /healthz {\n        access_log off;\n        return 200 \"OK\\n\";\n    }\n}\n",
    "docs/.gitkeep": "",
    "logs/.gitkeep": "",
    "tests/__init__.py": "\"\"\"\n\u6d4b\u8bd5\n\"\"\"\n",
    "app_celery/consumer/__init__.py": "\"\"\"\n\u6d88\u8d39\u8005\n\"\"\"\nimport re\nfrom pathlib import Path\n\nfrom app_celery import make_celery\n\n\ndef autodiscover_task_modules(\n        task_name: str = \"tasks\",\n        task_module: str = \"app_celery.consumer.tasks\",\n) -> list:\n    \"\"\"\n    \u81ea\u52a8\u53d1\u73b0\u4efb\u52a1\u6a21\u5757\n    - \u53ef\u5728\u6a21\u5757\u4e2d\u52a0\u5165`_active = False`\u6765\u53d6\u6d88\u6fc0\u6d3b\n    \"\"\"\n    task_modules = []\n    active_pat = re.compile(r\"^_active\\s*=\\s*False\\s*(?:#.*)?$\", re.MULTILINE)\n    for p in Path(__file__).parent.joinpath(task_name).rglob(\"*.py\"):\n        if p.stem == \"__init__\":\n            continue\n        if active_pat.search(p.read_text(encoding=\"utf-8\")):\n            continue\n        task_modules.append(f\"{task_module}.{p.stem}\")\n    return task_modules\n\n\ncelery_app = make_celery(\n    include=autodiscover_task_modules()\n)\n",
    "app_celery/producer/publisher.py": "import logging\n\nfrom app_celery.producer import celery_app\nfrom app_celery.producer.registry import AllTasks\n\nlogger = logging.getLogger(__name__)\n\n\ndef publish(\n        task_label: str,\n        task_args: tuple = None,\n        task_kwargs: dict = None,\n        task_id: str = None,\n        **task_options,\n) -> str:\n    \"\"\"\u53d1\u5e03\u4efb\u52a1\"\"\"\n    if task_label not in AllTasks:\n        raise ValueError(f\"UNKNOWN TASK: {task_label}\")\n    task_params = AllTasks[task_label]\n    task_options_merged = task_params.options or {}\n    task_options_merged.update(task_options)\n    result = celery_app.send_task(\n        name=task_params.name,\n        args=task_args,\n        kwargs=task_kwargs,\n        task_id=task_id,\n        queue=task_params.queue,  # enforced queue consistency\n        **task_options_merged,\n    )\n    logger.info(f\"PUBLISH TASK: {task_params.name} | ID={result.id} | QUEUE={task_params.queue}\")\n    return result.id\n",
    "app_celery/producer/registry.py": "from pydantic import BaseModel\n\n\nclass TaskParams(BaseModel):\n    name: str\n    queue: str\n    options: dict = {}\n\n\nAllTasks: dict[str, TaskParams] = {  # label: TaskParams\n    \"ping\": TaskParams(\n        name=\"app_celery.consumer.tasks.ping.ping\",\n        queue=\"ping\"\n    ),\n}\n",
    "app_celery/producer/tests.py": "import unittest\n\nfrom app_celery.producer import publisher\n\n\nclass TestPublisher(unittest.TestCase):\n\n    def test_publish_ping(self):\n        publisher.publish(\"ping\")\n",
    "app_celery/producer/__init__.py": "\"\"\"\n\u751f\u4ea7\u8005\n\"\"\"\nfrom app_celery import make_celery\n\ncelery_app = make_celery()\n",
    "app_celery/consumer/tasks/beat_ping.py": "import logging\n\nfrom celery.schedules import crontab\n\nfrom app_celery.consumer import celery_app\n\nlogger = logging.getLogger(__name__)\n\ncelery_app.conf.beat_schedule.setdefault(\n    'beat_ping', {\n        'task': 'app_celery.consumer.tasks.beat_ping.ping',\n        'schedule': crontab(minute='*/2'),  # \u6bcfx\u5206\u949f\u6267\u884c\u4e00\u6b21\n        'options': {'queue': 'beat_ping'}\n    }\n)\n\n\n@celery_app.task(\n    bind=True,\n    autoretry_for=(Exception,),\n    max_retries=3,\n    retry_backoff=True,\n    retry_backoff_max=300,\n    retry_jitter=True,\n    time_limit=360,\n    soft_time_limit=300,\n    acks_late=True,\n)\ndef ping(self, text: str = \"\u8fd9\u662f\u4e00\u4e2a\u5b9a\u65f6\u4efb\u52a1\u6d4b\u8bd5\"):\n    logger.info(f\"pong: {text}\")\n",
    "app_celery/consumer/tasks/ping.py": "import logging\n\nfrom app_celery.consumer import celery_app\n\nlogger = logging.getLogger(__name__)\n\n\n@celery_app.task(\n    bind=True,\n    autoretry_for=(Exception,),\n    max_retries=3,\n    retry_backoff=True,\n    retry_backoff_max=300,\n    retry_jitter=True,\n    time_limit=360,\n    soft_time_limit=300,\n    acks_late=True,\n)\ndef ping(self, text: str = \"\u8fd9\u662f\u4e00\u4e2a\u5f02\u6b65\u4efb\u52a1\u6d4b\u8bd5\"):\n    logger.info(f\"pong: {text}\")\n",
    "app_celery/consumer/tasks/__init__.py": "\"\"\"\n\u4efb\u52a1\uff08\u5b9a\u65f6&\u5f02\u6b65\uff09\n\"\"\"\n",
    "app_celery/consumer/workers/beat_ping.py": "from app_celery.consumer import celery_app\n\ncelery_app.conf.update(\n    task_queues={\n        \"beat_ping\": {\n            \"exchange_type\": \"direct\",\n            \"exchange\": \"beat_ping\",\n            \"routing_key\": \"beat_ping\",\n        },\n    },\n    task_routes={\n        \"app_celery.consumer.tasks.beat_ping.ping\": {\"queue\": \"beat_ping\"},\n    }\n)\n",
    "app_celery/consumer/workers/ping.py": "from app_celery.consumer import celery_app\n\ncelery_app.conf.update(\n    task_queues={\n        \"ping\": {\n            \"exchange_type\": \"direct\",\n            \"exchange\": \"ping\",\n            \"routing_key\": \"ping\",\n        },\n    },\n    task_routes={\n        \"app_celery.consumer.tasks.ping.ping\": {\"queue\": \"ping\"},\n    }\n)\n",
    "app_celery/consumer/workers/__init__.py": "\"\"\"\n\u5de5\u4f5c\u8005\n\"\"\"",
    "app/api/dependencies.py": "from fastapi import Depends, Security\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials, APIKeyHeader\nfrom fastapi.security.utils import get_authorization_scheme_param\nfrom pydantic import BaseModel\nfrom sqlalchemy import text\nfrom sqlalchemy.sql.elements import quoted_name\nfrom starlette.requests import Request\n\nfrom app.api.exceptions import CustomException\nfrom app.api.status import Status\nfrom app.initializer import g\nfrom app.utils.jwt_util import verify_jwt\n\n\n# ======= jwt =======\n\nclass JWTUser(BaseModel):\n    # \u4e0e\u5b9e\u9645`user`\u5bf9\u9f50\n    id: str = None\n    phone: str = None\n    name: str = None\n    age: int = None\n    gender: int = None\n\n    @staticmethod\n    async def get_user_jwt_key(user_id: str) -> str:\n        if g.config.jwt_key:  # \u76f4\u63a5\u4ece\u73af\u5883\u4e2d\u83b7\u53d6\uff0c\u9002\u7528\u4e8e\u4e0d\u5b58\u6570\u636e\u5e93\u7684\u573a\u666f\n            return g.config.jwt_key\n        # \u5efa\u8bae\uff1ajwt_key\u8fdb\u884credis\u7f13\u5b58\n        table = quoted_name(\"user\", quote=True)\n        sql = f\"SELECT jwt_key FROM {table} WHERE id = :id\"  # noqa\n        async with g.db_async_session() as session:\n            result = await session.execute(text(sql), params={\"id\": user_id})\n            row = result.fetchone()\n            return row[0] if row else None\n\n\nclass JWTAuthorizationCredentials(HTTPAuthorizationCredentials):\n    jwt_user: JWTUser\n\n\nclass JWTBearer(HTTPBearer):\n\n    async def __call__(\n            self, request: Request\n    ) -> JWTAuthorizationCredentials | None:\n        authorization = request.headers.get(\"Authorization\")\n        scheme, credentials = get_authorization_scheme_param(authorization)\n        if not (authorization and scheme and credentials):\n            if self.auto_error:\n                raise CustomException(\n                    msg=\"Not authenticated\",\n                    status=Status.UNAUTHORIZED_ERROR,\n                )\n            else:\n                return None\n        if scheme.lower() != \"bearer\":\n            if self.auto_error:\n                raise CustomException(\n                    msg=\"Invalid authentication credentials\",\n                    status=Status.UNAUTHORIZED_ERROR,\n                )\n            else:\n                return None\n        jwt_user = await self.verify_credentials(credentials)\n        return JWTAuthorizationCredentials(scheme=scheme, credentials=credentials, jwt_user=jwt_user)\n\n    async def verify_credentials(self, credentials: str) -> JWTUser:\n        playload = await self._verify_jwt(credentials)\n        if playload is None:\n            raise CustomException(status=Status.UNAUTHORIZED_ERROR)\n        user_jwt_key = await JWTUser.get_user_jwt_key(playload.get(\"id\"))\n        if not user_jwt_key:\n            raise CustomException(status=Status.UNAUTHORIZED_ERROR)\n        await self._verify_jwt(credentials, jwt_key=user_jwt_key)\n        return JWTUser(**playload)\n\n    @staticmethod\n    async def _verify_jwt(token: str, jwt_key: str = None) -> dict:\n        try:\n            return verify_jwt(token=token, jwt_key=jwt_key)\n        except Exception as e:\n            raise CustomException(status=Status.UNAUTHORIZED_ERROR, msg=str(e))\n\n\nasync def get_current_user(\n        credentials: JWTAuthorizationCredentials | None = Depends(JWTBearer(auto_error=True))\n) -> JWTUser:\n    if not credentials:\n        return JWTUser()\n    return credentials.jwt_user\n\n\n# ======= api key =======\n\n_API_KEY_HEADER = APIKeyHeader(name=\"X-API-Key\", auto_error=False)\n\n\nasync def get_current_api_key(\n        api_key: str | None = Security(_API_KEY_HEADER)\n) -> str:\n    if not api_key:\n        raise CustomException(status=Status.UNAUTHORIZED_ERROR, msg=\"API key is required\")\n    if api_key not in g.config.api_keys:\n        raise CustomException(status=Status.UNAUTHORIZED_ERROR, msg=\"Invalid API key\")\n    return api_key\n",
    "app/api/exceptions.py": "from typing import Any\n\nfrom app.api.status import Status\n\n\nclass CustomException(Exception):\n\n    def __init__(\n            self,\n            msg: str = None,\n            code: int = None,\n            data: Any = None,\n            status: Status = Status.FAILURE,\n    ):\n        self.msg = msg or status.msg\n        self.code = code or status.code\n        self.data = data\n        self.status = status\n\n    def __str__(self) -> str:\n        return f\"{self.code} {self.msg}\"\n\n    def __repr__(self) -> str:\n        return f\"<{self.__class__.__name__}: ({self.code!r}, {self.msg!r})>\"\n",
    "app/api/responses.py": "import json\nfrom typing import Mapping, get_type_hints, Any\n\nfrom fastapi.encoders import jsonable_encoder\nfrom starlette.background import BackgroundTask\nfrom starlette.responses import JSONResponse, StreamingResponse, ContentStream\nfrom toollib.utils import map_jsontype\n\nfrom app.api.status import Status\nfrom app.initializer.context import request_id_var\n\n_EXPOSE_ERROR = True\n\n\nclass Responses:\n\n    @staticmethod\n    def success(\n            data: dict | list | str | None = None,\n            msg: str = None,\n            code: int = None,\n            status: Status = Status.SUCCESS,\n            is_encode_data: bool = False,\n            status_code: int = 200,\n            headers: Mapping[str, str] | None = None,\n            media_type: str | None = None,\n            background: BackgroundTask | None = None,\n    ) -> JSONResponse:\n        content = {\n            \"msg\": msg or status.msg,\n            \"code\": code or status.code,\n            \"data\": Responses.encode_data(data) if is_encode_data else data,\n            \"request_id\": request_id_var.get(),\n        }\n        return JSONResponse(\n            content=content,\n            status_code=status_code,\n            headers=headers,\n            media_type=media_type,\n            background=background,\n        )\n\n    @staticmethod\n    def failure(\n            msg: str = None,\n            code: int = None,\n            error: str | Exception | None = None,\n            data: dict | list | str | None = None,\n            status: Status = Status.FAILURE,\n            is_encode_data: bool = False,\n            status_code: int = 200,\n            headers: Mapping[str, str] | None = None,\n            media_type: str | None = None,\n            background: BackgroundTask | None = None,\n    ) -> JSONResponse:\n        content = {\n            \"msg\": msg or status.msg,\n            \"code\": code or status.code,\n            \"data\": Responses.encode_data(data) if is_encode_data else data,\n            \"request_id\": request_id_var.get(),\n        }\n        if _EXPOSE_ERROR:\n            content[\"error\"] = str(error) if error else None\n        return JSONResponse(\n            content=content,\n            status_code=status_code,\n            headers=headers,\n            media_type=media_type,\n            background=background,\n        )\n\n    @staticmethod\n    def encode_data(data: Any) -> Any:\n        if data is None or isinstance(data, (str, int, float, bool)):\n            return data\n        if isinstance(data, (dict, list)):\n            try:\n                json.dumps(data)\n                return data\n            except (TypeError, OverflowError):\n                pass\n        return jsonable_encoder(data)\n\n    @staticmethod\n    def stream(\n            content: ContentStream,\n            status_code: int = 200,\n            headers: Mapping[str, str] | None = None,\n            media_type: str | None = None,\n            background: BackgroundTask | None = None,\n    ) -> StreamingResponse:\n        return StreamingResponse(\n            content=content,\n            status_code=status_code,\n            headers=headers,\n            media_type=media_type,\n            background=background,\n        )\n\n\ndef response_docs(\n        model=None,  # \u6a21\u578b(BaseModel): \u81ea\u52a8\u4ece\u6a21\u578b\u4e2d\u89e3\u6790\u5b57\u6bb5\u4e0e\u7c7b\u578b\n        data: dict | str = None,  # \u6570\u636e(dict/str): \u76f4\u63a5\u7ed9\u5b9a\u5b57\u6bb5\u4e0e\u7c7b\u578b/\u7c7b\u578b\n        is_listwrap: bool = False,\n        listwrap_key: str = None,\n        listwrap_key_extra: dict = None,\n        docs_extra: dict = None,\n):\n    \"\"\"\u54cd\u5e94\u6587\u6863\"\"\"\n\n    def _data_from_model(model_, default: str = \"\u672a\u77e5\") -> dict:\n        \"\"\"\u6570\u636e\u6a21\u677f\"\"\"\n        data_ = {}\n        if hasattr(model_, \"response_fields\"):\n            all_fields = set(model_.response_fields())\n        else:\n            all_fields = set(model_.model_fields.keys())\n        type_hints = get_type_hints(model_)\n        for field_name in all_fields:\n            try:\n                t = type_hints.get(field_name)\n                t = str(t).replace(\"<class '\", \"\").replace(\"'>\", \"\") if t else default\n            except Exception:\n                t = default\n            data_[field_name] = t\n        return data_\n\n    final_data = {}\n    if model:\n        final_data = _data_from_model(model)\n    if data:\n        if isinstance(data, dict):\n            final_data.update(data)\n        else:\n            final_data = data\n    if is_listwrap:\n        final_data = [final_data] if not isinstance(final_data, list) else final_data\n        if listwrap_key:\n            final_data = {listwrap_key: final_data}\n            if listwrap_key_extra:\n                final_data.update(listwrap_key_extra)\n\n    def _format_value(value):\n        if isinstance(value, str):\n            _value = value.split(\"|\")\n            if len(_value) > 1:\n                return \" | \".join([map_jsontype(_v.strip(), is_keep_integer=True) for _v in _value])\n            return map_jsontype(value, is_keep_integer=True)\n        elif isinstance(value, dict):\n            return {k: _format_value(v) for k, v in value.items()}\n        elif isinstance(value, (list, tuple)):\n            return [_format_value(item) for item in value]\n        else:\n            return str(value)\n\n    format_data = _format_value(final_data)\n\n    docs = {\n        200: {\n            \"description\": \"\u64cd\u4f5c\u6210\u529f\u3010code\u4e3a0 & http\u72b6\u6001\u7801200\u3011\",\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"msg\": \"string\",\n                        \"code\": \"integer\",\n                        \"data\": format_data or \"object | array | ...\",\n                        \"request_id\": \"string\",\n                    }\n                }\n            }\n        },\n        422: {\n            \"description\": \"\u64cd\u4f5c\u5931\u8d25\u3010code\u975e0 & http\u72b6\u6001\u7801200\u3011\",\n            \"content\": {\n                \"application/json\": {\n                    \"example\": {\n                        \"msg\": \"string\",\n                        \"code\": \"integer\",\n                        \"error\": \"string\",\n                        \"data\": \"object | array | ...\",\n                        \"request_id\": \"string\",\n                    }\n                }\n            }\n        },\n    }\n    if docs_extra:\n        docs.update(docs_extra)\n    return docs\n",
    "app/api/status.py": "from enum import Enum\n\n\nclass Status(Enum):\n    SUCCESS = (0, '\u64cd\u4f5c\u6210\u529f')\n    FAILURE = (1, '\u64cd\u4f5c\u5931\u8d25')\n\n    PARAMS_ERROR = (400, '\u53c2\u6570\u9519\u8bef')\n    UNAUTHORIZED_ERROR = (401, '\u8ba4\u8bc1\u5931\u8d25')\n    INTERNAL_SERVER_ERROR = (500, '\u5185\u90e8\u670d\u52a1\u5668\u9519\u8bef')\n    # \u5efa\u8bae\uff1a\u4e1a\u52a1\u6a21\u5757\u9519\u8bef\u7801\u4ece10000\u5f00\u59cb\n    RECORD_NOT_EXIST_ERROR = (10000, '\u8bb0\u5f55\u4e0d\u5b58\u5728')\n    RECORD_EXISTS_ERROR = (10001, '\u8bb0\u5f55\u5df2\u5b58\u5728')\n    USER_OR_PASSWORD_ERROR = (10002, '\u7528\u6237\u540d\u6216\u5bc6\u7801\u9519\u8bef')\n\n    @property\n    def code(self):\n        return self.value[0]\n\n    @property\n    def msg(self):\n        return self.value[1]\n\n    @classmethod\n    def collect_status(cls):\n        text = \"\"\n        for s in cls:\n            text += f\"{s.code} {s.msg}\\n\"\n        return text\n\n\nif __name__ == '__main__':\n    print(Status.collect_status())\n",
    "app/api/__init__.py": "\"\"\"\napi\n\"\"\"\nimport importlib\nimport sys\nfrom pathlib import Path\n\nfrom fastapi import FastAPI, APIRouter\nfrom loguru import logger\n\nfrom app import APP_DIR\n\n_API_MOD_DIR = APP_DIR.joinpath(\"api\")\n_API_MOD_BASE = \"app.api\"\n\n\ndef register_routers(\n        app: FastAPI,\n        mod_dir: Path = _API_MOD_DIR,\n        mod_base: str = _API_MOD_BASE,\n        name: str = \"router\",\n        prefix: str = \"\",\n        depth: int = 0,\n        min_depth: int = 1,\n        max_depth: int = 2,\n):\n    \"\"\"\n    \u6ce8\u518c\u8def\u7531\n    \u8981\u6c42\uff1a\n        \u8def\u7531\u6a21\u5757\uff1a\u975e'__'\u5f00\u5934\u7684\u6a21\u5757\n        \u8def\u7531\u540d\u79f0\uff1a{name}\n    :param app: FastAPI\u5e94\u7528\n    :param mod_dir: api\u6a21\u5757\u76ee\u5f55\n    :param mod_base: api\u6a21\u5757\u57fa\u7840\n    :param name: \u8def\u7531\u540d\u79f0\n    :param prefix: url\u524d\u7f00\n    :param depth: \u5f53\u524d\u9012\u5f52\u6df1\u5ea6\n    :param min_depth: \u6700\u5c0f\u9012\u5f52\u6df1\u5ea6\n    :param max_depth: \u6700\u5927\u9012\u5f52\u6df1\u5ea6\n    \"\"\"\n    if depth > max_depth:\n        return\n    for item in mod_dir.iterdir():\n        if item.name.startswith(\"__\"):\n            continue\n        if item.is_dir():\n            new_mod_dir = item\n            new_mod_base = f\"{mod_base}.{item.name}\"\n            new_prefix = prefix\n            try:\n                mod = importlib.import_module(new_mod_base)\n                _prefix = getattr(mod, \"_prefix\", None)\n                if _prefix:\n                    new_prefix = f\"{new_prefix}/{_prefix}\"\n            except ImportError:\n                logger.error(f\"Register router failed to import module: {new_mod_base}\")\n                continue\n            register_routers(\n                app=app,\n                mod_dir=new_mod_dir,\n                mod_base=new_mod_base,\n                prefix=new_prefix,\n                name=name,\n                depth=depth + 1,\n                max_depth=max_depth\n            )\n        elif item.is_file() and item.suffix == \".py\" and depth >= min_depth:\n            mod_name = item.stem\n            final_mod = f\"{mod_base}.{mod_name}\"\n            try:\n                mod = importlib.import_module(final_mod)\n                if not getattr(mod, \"_active\", True):\n                    logger.info(f\"Register router skipping inactive module: {final_mod}\")\n                    sys.modules.pop(final_mod)\n                    continue\n                if router := getattr(mod, name, None):\n                    if isinstance(router, APIRouter):\n                        tag = getattr(mod, \"_tag\", None)\n                        if not tag:\n                            tag = item.parent.stem if depth > 1 else mod_name\n                        app.include_router(\n                            router=router,\n                            prefix=prefix.replace(\"//\", \"/\").rstrip(\"/\"),\n                            tags=[tag]\n                        )\n            except ImportError as e:\n                logger.error(f\"Register router failed to import module: {final_mod} ({e})\")\n                continue\n",
    "app/initializer/context.py": "from contextvars import ContextVar\n\nrequest_id_var: ContextVar[str] = ContextVar(\"request_id\", default=\"N/A\")\n",
    "app/initializer/_conf.py": "import os\nfrom pathlib import Path\n\nfrom toollib.utils import ConfModel, FrozenVar\n\nfrom app import APP_DIR\n\n_CONFIG_DIR = APP_DIR.parent.joinpath(\"config\")\n\ndotenv_path = _CONFIG_DIR.joinpath(\".env\")\nif os.environ.setdefault(\"app_env\", \"dev\") == \"prod\":  # \u751f\u4ea7\u73af\u5883\u4e0d\u52a0\u8f7d.env\uff08\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\uff09\n    dotenv_path = None\nyaml_path = _CONFIG_DIR.joinpath(f\"app_{os.environ.get('app_env', 'dev')}.yaml\")\n\n\nclass Config(ConfModel):\n    \"\"\"\u914d\u7f6e\"\"\"\n    app_dir: FrozenVar[Path] = APP_DIR\n    # #\n    app_env: str = \"dev\"\n    yaml_path: Path = yaml_path\n    api_keys: list = []\n    jwt_key: str = \"\"\n    snow_datacenter_id: int = None\n    # #\n    app_title: str = \"xApp\"\n    app_summary: str = \"xxApp\"\n    app_description: str = \"xxxApp\"\n    app_version: str = \"1.0.0\"\n    app_debug: bool = True\n    app_log_serialize: bool = False\n    app_log_outdir: str = \"./logs\"\n    app_disable_docs: bool = False\n    app_allow_credentials: bool = True\n    app_allow_origins: list = [\"*\"]\n    app_allow_methods: list = [\"*\"]\n    app_allow_headers: list = [\"*\"]\n    # #\n    db_drivername: str\n    db_async_drivername: str\n    db_database: str\n    db_username: str = None\n    db_password: str = None\n    db_host: str = None\n    db_port: int = None\n    db_charset: str = None\n    redis_host: str = None\n    redis_port: int = None\n    redis_db: int = None\n    redis_password: str = None\n    redis_max_connections: int = None\n\n\ndef init_config() -> Config:\n    return Config(\n        dotenv_path=dotenv_path,\n        yaml_path=yaml_path,\n    )\n",
    "app/initializer/_db.py": "import asyncio\nimport importlib\nimport re\n\nfrom sqlalchemy import URL, create_engine\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import sessionmaker, scoped_session\nfrom sqlalchemy.orm.decl_api import DeclarativeAttributeIntercept\n\nfrom app import APP_DIR\n\n_MODELS_MOD_DIR = APP_DIR.joinpath(\"models\")\n_MODELS_MOD_BASE = \"app.models\"\n_DECL_BASE_NAME = \"DeclBase\"\n_TABLES_CREATED = False\n\n\ndef init_db_session(\n        db_drivername: str,\n        db_database: str,\n        db_username: str,\n        db_password: str,\n        db_host: str,\n        db_port: int,\n        db_charset: str,\n        db_echo: bool,\n        db_pool_size: int = 10,\n        db_max_overflow: int = 5,\n        db_pool_recycle: int = 3600,\n        is_create_tables: bool = False,\n) -> scoped_session:\n    db_url = make_db_url(\n        drivername=db_drivername,\n        database=db_database,\n        username=db_username,\n        password=db_password,\n        host=db_host,\n        port=db_port,\n        query={\n            \"charset\": db_charset,\n        },\n    )\n    db_echo = db_echo or False\n    kwargs = {\n        \"pool_size\": db_pool_size,\n        \"max_overflow\": db_max_overflow,\n        \"pool_recycle\": db_pool_recycle,\n    }\n    if db_url.drivername.startswith(\"sqlite\"):\n        kwargs = {}\n    engine = create_engine(\n        url=db_url,\n        echo=db_echo,\n        pool_pre_ping=True,\n        **kwargs,\n    )\n    db_session = sessionmaker(engine, expire_on_commit=False)\n\n    def create_tables():\n        decl_base = import_tables()\n        if decl_base:\n            try:\n                decl_base.metadata.create_all(engine)  # noqa\n            except Exception as e:\n                if \"already exists\" not in str(e):\n                    raise\n\n    global _TABLES_CREATED\n    if is_create_tables and not _TABLES_CREATED:\n        create_tables()\n        _TABLES_CREATED = True\n\n    return scoped_session(db_session)\n\n\ndef init_db_async_session(\n        db_drivername: str,\n        db_database: str,\n        db_username: str,\n        db_password: str,\n        db_host: str,\n        db_port: int,\n        db_charset: str,\n        db_echo: bool,\n        db_pool_size: int = 10,\n        db_max_overflow: int = 5,\n        db_pool_recycle: int = 3600,\n        is_create_tables: bool = False,\n) -> sessionmaker:\n    db_url = make_db_url(\n        drivername=db_drivername,\n        database=db_database,\n        username=db_username,\n        password=db_password,\n        host=db_host,\n        port=db_port,\n        query={\n            \"charset\": db_charset,\n        },\n    )\n    db_echo = db_echo or False\n    kwargs = {\n        \"pool_size\": db_pool_size,\n        \"max_overflow\": db_max_overflow,\n        \"pool_recycle\": db_pool_recycle,\n    }\n    if db_url.drivername.startswith(\"sqlite\"):\n        kwargs = {}\n    async_engine = create_async_engine(\n        url=db_url,\n        echo=db_echo,\n        pool_pre_ping=True,\n        **kwargs,\n    )\n    db_async_session = sessionmaker(async_engine, class_=AsyncSession, expire_on_commit=False)  # noqa\n\n    async def create_tables():\n        decl_base = import_tables()\n        if decl_base:\n            async with async_engine.begin() as conn:\n                try:\n                    await conn.run_sync(decl_base.metadata.create_all)  # noqa\n                except Exception as e:\n                    if \"already exists\" not in str(e):\n                        raise\n\n    global _TABLES_CREATED\n    if is_create_tables and not _TABLES_CREATED:\n        try:\n            loop = asyncio.get_running_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n        task = loop.create_task(create_tables())\n        task.add_done_callback(lambda t: t.result() if not t.cancelled() else None)\n        if not loop.is_running():\n            loop.run_until_complete(task)\n        _TABLES_CREATED = True\n    return db_async_session\n\n\ndef make_db_url(\n        drivername: str,\n        database: str,\n        username: str = None,\n        password: str = None,\n        host: str = None,\n        port: int = None,\n        query: dict = None,\n) -> URL:\n    query = {k: v for k, v in query.items() if v} if query else {}\n    return URL.create(\n        drivername=drivername,\n        username=username,\n        password=password,\n        host=host,\n        port=port,\n        database=database,\n        query=query,\n    )\n\n\ndef import_tables() -> DeclarativeAttributeIntercept | None:\n    decl_base = getattr(importlib.import_module(_MODELS_MOD_BASE), _DECL_BASE_NAME, None)\n    if isinstance(decl_base, DeclarativeAttributeIntercept):\n        pat = re.compile(rf\"^\\s*class\\s+[A-Za-z_]\\w*\\s*\\(\\s*{_DECL_BASE_NAME}\\s*\\)\\s*:\", re.MULTILINE)\n        for f in _MODELS_MOD_DIR.rglob(\"*.py\"):\n            if f.name.startswith(\"__\"):\n                continue\n            if pat.search(f.read_text(\"utf-8\")):\n                rel = f.relative_to(_MODELS_MOD_DIR).with_suffix(\"\")\n                _ = importlib.import_module(f\"{_MODELS_MOD_BASE}.{'.'.join(rel.parts)}\")\n        return decl_base\n",
    "app/initializer/_log.py": "import os\n\nfrom loguru._logger import Logger  # noqa\nfrom toollib import logu\n\nfrom app.initializer.context import request_id_var\n\n\ndef init_logger(\n        level: str,\n        serialize: bool = False,\n        outdir: str = None,\n) -> Logger:\n    enable_console, enable_file = True, True\n    if os.getenv(\"app_env\") == \"prod\":\n        enable_console, enable_file = False, True  # \u6309\u9700\u8c03\u6574\n    _logger = logu.init_logger(\n        level=level,\n        request_id_var=request_id_var,\n        serialize=serialize,\n        enable_console=enable_console,\n        enable_file=enable_file,\n        outdir=outdir,\n    )\n    # _logger.add \u53ef\u6dfb\u52a0\u5176\u4ed6 handler\n    return _logger\n",
    "app/initializer/_redis.py": "from toollib.rediscli import RedisCli\n\n\ndef init_redis_cli(\n        host: str,\n        port: int,\n        db: int,\n        password: str = None,\n        max_connections: int = None,\n        **kwargs,\n) -> RedisCli:\n    return RedisCli(\n        host=host,\n        port=port,\n        db=db,\n        password=password,\n        max_connections=max_connections,\n        **kwargs,\n    )\n",
    "app/initializer/_snow.py": "import os\n\nfrom loguru import logger\nfrom toollib.guid import SnowFlake\nfrom toollib.utils import localip\n\n_CACHE_KEY_SNOW_WORKER_ID_INCR = \"config:snow_worker_id_incr\"\n_CACHE_KEY_SNOW_DATACENTER_ID_INCR = \"config:snow_datacenter_id_incr\"\n_CACHE_EXPIRE_SNOW = 120\n\n\ndef init_snow_cli(\n        redis_cli=None,  # `from toollib.rediscli import RedisCli` \u5b9e\u4f8b\n        datacenter_id: int = None,\n) -> SnowFlake:\n    # \u5efa\u8bae\uff1a\u91c7\u7528\u670d\u52a1\u7684\u65b9\u5f0f\u8c03\u7528api\u83b7\u53d6\n    if datacenter_id is None:\n        datacenter_id = _snow_incr(redis_cli, _CACHE_KEY_SNOW_DATACENTER_ID_INCR, _CACHE_EXPIRE_SNOW)\n        if datacenter_id is None:\n            local_ip = localip()\n            if local_ip:\n                ip_parts = list(map(int, local_ip.split('.')))\n                ip_int = (ip_parts[0] << 24) + (ip_parts[1] << 16) + (ip_parts[2] << 8) + ip_parts[3]\n                datacenter_id = ip_int % 32\n    worker_id = _snow_incr(redis_cli, _CACHE_KEY_SNOW_WORKER_ID_INCR, _CACHE_EXPIRE_SNOW)\n    if worker_id is None:\n        worker_id = os.getpid() % 32\n    return SnowFlake(worker_id=worker_id, datacenter_id=datacenter_id)\n\n\ndef _snow_incr(redis_cli, cache_key: str, cache_expire: int):\n    incr = None\n    if not redis_cli:\n        return incr\n    try:\n        with redis_cli.connection() as r:\n            resp = r.ping()\n            if resp:\n                lua_script = \"\"\"\n                    if redis.call('exists', KEYS[1]) == 1 then\n                        redis.call('expire', KEYS[1], ARGV[1])\n                        return redis.call('incr', KEYS[1])\n                    else\n                        redis.call('set', KEYS[1], 0)\n                        redis.call('expire', KEYS[1], ARGV[1])\n                        return 0\n                    end\n                    \"\"\"\n                incr = r.eval(lua_script, 1, cache_key, cache_expire)\n    except Exception as e:\n        logger.warning(f\"snow\u521d\u59cb\u5316id\u5c06\u91c7\u7528\u672c\u5730\u65b9\u5f0f\uff0c\u7531\u4e8e\uff08{e}\uff09\")\n    return incr\n",
    "app/initializer/__init__.py": "\"\"\"\n\u521d\u59cb\u5316\n\"\"\"\nimport threading\nfrom functools import cached_property\n\nfrom loguru import logger\nfrom loguru._logger import Logger  # noqa\nfrom sqlalchemy.orm import sessionmaker, scoped_session\nfrom toollib.guid import SnowFlake\nfrom toollib.rediscli import RedisCli\nfrom toollib.utils import Singleton\n\nfrom app.initializer._conf import Config, init_config\nfrom app.initializer._db import init_db_session, init_db_async_session\nfrom app.initializer._log import init_logger\nfrom app.initializer._redis import init_redis_cli\nfrom app.initializer._snow import init_snow_cli\n\n\nclass G(metaclass=Singleton):\n    \"\"\"\n    \u5168\u5c40\u53d8\u91cf\n    \"\"\"\n    _initialized = False\n    _init_lock = threading.Lock()\n    _init_properties = [\n        \"config\",\n        \"logger\",\n        \"redis_cli\",\n        \"snow_cli\",\n        # \"db_session\",\n        \"db_async_session\",\n    ]\n\n    def __init__(self):\n        self._initialized = False\n\n    @cached_property\n    def config(self) -> Config:\n        return init_config()\n\n    @cached_property\n    def logger(self) -> Logger:\n        return init_logger(\n            level=\"DEBUG\" if self.config.app_debug else \"INFO\",\n            serialize=self.config.app_log_serialize,\n            outdir=self.config.app_log_outdir,\n        )\n\n    @cached_property\n    def redis_cli(self) -> RedisCli:\n        return init_redis_cli(\n            host=self.config.redis_host,\n            port=self.config.redis_port,\n            db=self.config.redis_db,\n            password=self.config.redis_password,\n            max_connections=self.config.redis_max_connections,\n        )\n\n    @cached_property\n    def snow_cli(self) -> SnowFlake:\n        return init_snow_cli(\n            redis_cli=getattr(self, \"redis_cli\", None),\n            datacenter_id=self.config.snow_datacenter_id,\n        )\n\n    @cached_property\n    def db_session(self) -> scoped_session:\n        return init_db_session(\n            db_drivername=self.config.db_drivername,\n            db_database=self.config.db_database,\n            db_username=self.config.db_username,\n            db_password=self.config.db_password,\n            db_host=self.config.db_host,\n            db_port=self.config.db_port,\n            db_charset=self.config.db_charset,\n            db_echo=self.config.app_debug,\n            is_create_tables=True,  # \u53ef\u901a\u8fc7 alembic \u8fdb\u884c\u6570\u636e\u5e93\u8fc1\u79fb\n        )\n\n    @cached_property\n    def db_async_session(self) -> sessionmaker:\n        return init_db_async_session(\n            db_drivername=self.config.db_async_drivername,\n            db_database=self.config.db_database,\n            db_username=self.config.db_username,\n            db_password=self.config.db_password,\n            db_host=self.config.db_host,\n            db_port=self.config.db_port,\n            db_charset=self.config.db_charset,\n            db_echo=self.config.app_debug,\n            is_create_tables=True,  # \u53ef\u901a\u8fc7 alembic \u8fdb\u884c\u6570\u636e\u5e93\u8fc1\u79fb\n        )\n\n    def setup(self):\n        with self._init_lock:\n            if not self._initialized:\n                for prop_name in self._init_properties:\n                    if hasattr(self, prop_name):\n                        getattr(self, prop_name)\n                    else:\n                        logger.warning(f\"{prop_name} not found\")\n                self._initialized = True\n\n\ng = G()\n",
    "app/middleware/cors.py": "from starlette.middleware.cors import CORSMiddleware\n\nfrom app.initializer import g\n\n\nclass CorsMiddleware(CORSMiddleware):\n    def __init__(self, app, **kwargs):\n        super().__init__(\n            app,\n            allow_credentials=g.config.app_allow_credentials,\n            allow_origins=g.config.app_allow_origins,\n            allow_methods=g.config.app_allow_methods,\n            allow_headers=g.config.app_allow_headers,\n            **kwargs\n        )\n",
    "app/middleware/exceptions.py": "from fastapi.exceptions import RequestValidationError\nfrom loguru import logger\nfrom starlette.exceptions import HTTPException\nfrom starlette.requests import Request\nfrom starlette.responses import JSONResponse\n\nfrom app.api.exceptions import CustomException\nfrom app.api.responses import Responses\nfrom app.api.status import Status\n\n\nclass ExceptionsHandler:\n\n    @staticmethod\n    async def custom_exception_handler(\n            request: Request,\n            exc: CustomException,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {exc.code} {exc.msg}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            msg=exc.msg,\n            code=exc.code,\n            error=exc,\n            data=exc.data,\n        )\n\n    @staticmethod\n    async def request_validation_handler(\n            request: Request,\n            exc: RequestValidationError,\n            display_all: bool = False,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        if display_all:\n            msg = \" & \".join([\n                f\"{error['loc'][-1]} ({error['type']}) {error['msg'].replace('Value error, ', '').lower()}\"\n                for error in exc.errors()\n            ])\n        else:\n            error = exc.errors()[0]\n            msg = f\"{error['loc'][-1]} ({error['type']}) {error['msg'].replace('Value error, ', '').lower()}\"\n        lmsg = f'- \"{request.method} {request.url.path}\" {Status.PARAMS_ERROR.code} {msg}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            msg=msg,\n            error=exc,\n            status=Status.PARAMS_ERROR,\n        )\n\n    @staticmethod\n    async def http_exception_handler(\n            request: Request,\n            exc: HTTPException,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {exc.status_code} {exc.detail}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            msg=exc.detail,\n            code=exc.status_code,\n            error=exc,\n        )\n",
    "app/middleware/http.py": "import uuid\n\nfrom loguru import logger\nfrom starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\nfrom starlette.requests import Request\nfrom starlette.responses import Response, JSONResponse\n\nfrom app.api.responses import Responses\nfrom app.api.status import Status\nfrom app.initializer.context import request_id_var\n\n\nclass HttpMiddleware(BaseHTTPMiddleware):\n    _HEADERS = {\n        # \u53ef\u6dfb\u52a0\u76f8\u5173\u5934\n    }\n\n    async def dispatch(\n            self, request: Request,\n            call_next: RequestResponseEndpoint,\n    ) -> Response:\n        request_id = self._get_or_create_request_id(request)\n        request.state.request_id = request_id\n        token = request_id_var.set(request_id)\n        try:\n            response = await call_next(request)\n            response.headers[\"X-Request-ID\"] = request_id\n            for key, value in self._HEADERS.items():\n                if key not in response.headers:\n                    response.headers[key] = value\n            return response\n        except Exception as exc:\n            return await self.handle_exception(request, exc)\n        finally:\n            request_id_var.reset(token)\n\n    @staticmethod\n    def _get_or_create_request_id(request: Request, prefix: str = \"req-\") -> str:\n        request_id = request.headers.get(\"X-Request-ID\")\n        if not request_id:\n            request_id = f\"{prefix}{uuid.uuid4().hex}\"\n        return request_id\n\n    @staticmethod\n    async def handle_exception(\n            request: Request,\n            exc: Exception,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {Status.INTERNAL_SERVER_ERROR.code} {type(exc).__name__}: {exc}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            error=exc,\n            status=Status.INTERNAL_SERVER_ERROR,\n        )\n",
    "app/middleware/__init__.py": "\"\"\"\n\u4e2d\u95f4\u4ef6\n\"\"\"\nfrom fastapi import FastAPI\nfrom fastapi.exceptions import RequestValidationError\nfrom starlette.exceptions import HTTPException\n\nfrom app.api.exceptions import CustomException\nfrom app.middleware.cors import CorsMiddleware\nfrom app.middleware.exceptions import ExceptionsHandler\nfrom app.middleware.http import HttpMiddleware\n\n\ndef register_middlewares(app: FastAPI):\n    \"\"\"\u6ce8\u518c\u4e2d\u95f4\u4ef6 & \u9519\u8bef\u5904\u7406\"\"\"\n    app.add_middleware(CorsMiddleware)  # type: ignore\n    app.add_middleware(HttpMiddleware)  # type: ignore\n    # #\n    app.add_exception_handler(CustomException, ExceptionsHandler.custom_exception_handler)  # type: ignore\n    app.add_exception_handler(RequestValidationError, ExceptionsHandler.request_validation_handler)  # type: ignore\n    app.add_exception_handler(HTTPException, ExceptionsHandler.http_exception_handler)  # type: ignore\n",
    "app/migrations/alembic.ini": "# A generic, single database configuration.\n\n[alembic]\n# path to migration scripts.\n# this is typically a path given in POSIX (e.g. forward slashes)\n# format, relative to the token %(here)s which refers to the location of this\n# ini file\nscript_location = %(here)s/alembic\n\n# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s\n# Uncomment the line below if you want the files to be prepended with date and time\n# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file\n# for all available tokens\n# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s\n\n# sys.path path, will be prepended to sys.path if present.\n# defaults to the current working directory.  for multiple paths, the path separator\n# is defined by \"path_separator\" below.\nprepend_sys_path = .\n\n\n# timezone to use when rendering the date within the migration file\n# as well as the filename.\n# If specified, requires the tzdata library which can be installed by adding\n# `alembic[tz]` to the pip requirements.\n# string value is passed to ZoneInfo()\n# leave blank for localtime\n# timezone =\n\n# max length of characters to apply to the \"slug\" field\n# truncate_slug_length = 40\n\n# set to 'true' to run the environment during\n# the 'revision' command, regardless of autogenerate\n# revision_environment = false\n\n# set to 'true' to allow .pyc and .pyo files without\n# a source .py file to be detected as revisions in the\n# versions/ directory\n# sourceless = false\n\n# version location specification; This defaults\n# to <script_location>/versions.  When using multiple version\n# directories, initial revisions must be specified with --version-path.\n# The path separator used here should be the separator specified by \"path_separator\"\n# below.\n# version_locations = %(here)s/bar:%(here)s/bat:%(here)s/alembic/versions\n\n# path_separator; This indicates what character is used to split lists of file\n# paths, including version_locations and prepend_sys_path within configparser\n# files such as alembic.ini.\n# The default rendered in new alembic.ini files is \"os\", which uses os.pathsep\n# to provide os-dependent path splitting.\n#\n# Note that in order to support legacy alembic.ini files, this default does NOT\n# take place if path_separator is not present in alembic.ini.  If this\n# option is omitted entirely, fallback logic is as follows:\n#\n# 1. Parsing of the version_locations option falls back to using the legacy\n#    \"version_path_separator\" key, which if absent then falls back to the legacy\n#    behavior of splitting on spaces and/or commas.\n# 2. Parsing of the prepend_sys_path option falls back to the legacy\n#    behavior of splitting on spaces, commas, or colons.\n#\n# Valid values for path_separator are:\n#\n# path_separator = :\n# path_separator = ;\n# path_separator = space\n# path_separator = newline\n#\n# Use os.pathsep. Default configuration used for new projects.\npath_separator = os\n\n# set to 'true' to search source files recursively\n# in each \"version_locations\" directory\n# new in Alembic version 1.10\n# recursive_version_locations = false\n\n# the output encoding used when revision files\n# are written from script.py.mako\n# output_encoding = utf-8\n\n# database URL.  This is consumed by the user-maintained env.py script only.\n# other means of configuring database URLs may be customized within the env.py\n# file.\nsqlalchemy.url = driver://user:pass@localhost/dbname\n\n\n[post_write_hooks]\n# post_write_hooks defines scripts or Python functions that are run\n# on newly generated revision scripts.  See the documentation for further\n# detail and examples\n\n# format using \"black\" - use the console_scripts runner, against the \"black\" entrypoint\n# hooks = black\n# black.type = console_scripts\n# black.entrypoint = black\n# black.options = -l 79 REVISION_SCRIPT_FILENAME\n\n# lint with attempts to fix using \"ruff\" - use the module runner, against the \"ruff\" module\n# hooks = ruff\n# ruff.type = module\n# ruff.module = ruff\n# ruff.options = check --fix REVISION_SCRIPT_FILENAME\n\n# Alternatively, use the exec runner to execute a binary found on your PATH\n# hooks = ruff\n# ruff.type = exec\n# ruff.executable = ruff\n# ruff.options = check --fix REVISION_SCRIPT_FILENAME\n\n# Logging configuration.  This is also consumed by the user-maintained\n# env.py script only.\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARNING\nhandlers = console\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARNING\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_console]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S\n",
    "app/models/user.py": "from sqlalchemy import Column, BigInteger, Integer, String\n\nfrom app.models import DeclBase\nfrom app.utils.ext_util import gen_snow_id, now_timestamp\n\n\nclass User(DeclBase):\n    __tablename__ = \"user\"\n\n    id = Column(String(20), primary_key=True, default=gen_snow_id, comment=\"\u4e3b\u952e\")\n    phone = Column(String(11), unique=True, index=True, nullable=False, comment=\"\u624b\u673a\u53f7\")\n    password = Column(String(20), nullable=True, comment=\"\u5bc6\u7801\")\n    jwt_key = Column(String(64), nullable=True, comment=\"jwt\u5bc6\u94a5\")\n    name = Column(String(50), nullable=True, comment=\"\u540d\u79f0\")\n    age = Column(Integer, nullable=True, comment=\"\u5e74\u9f84\")\n    gender = Column(Integer, nullable=True, comment=\"\u6027\u522b\")\n    created_at = Column(BigInteger, default=now_timestamp, comment=\"\u521b\u5efa\u65f6\u95f4\")\n    updated_at = Column(BigInteger, default=now_timestamp, onupdate=now_timestamp, comment=\"\u66f4\u65b0\u65f6\u95f4\")\n",
    "app/models/__init__.py": "\"\"\"\n\u6570\u636e\u6a21\u578b\n\"\"\"\nfrom sqlalchemy.orm import DeclarativeBase\n\n\nclass DeclBase(DeclarativeBase):\n    pass\n\n\n# DeclBase \u4f7f\u7528\u793a\u4f8b\uff08\u5b98\u65b9\u6587\u6863\uff1ahttps://docs.sqlalchemy.org/en/latest/orm/quickstart.html#declare-models\uff09\n\"\"\"\nfrom sqlalchemy import Column, String\n\nfrom app.services import DeclBase\n\n\nclass User(DeclBase):\n    __tablename__ = \"user\"\n\n    id = Column(String(20), primary_key=True, comment=\"\u4e3b\u952e\")\n    name = Column(String(50), nullable=False, comment=\"\u540d\u79f0\")\n\"\"\"\n",
    "app/repositories/user.py": "from app.models.user import User\nfrom app.utils import db_util\n\n\nclass UserRepo:\n\n    def __init__(self, session, model=User):\n        self.session = session\n        self.model = model\n\n    async def get_user_detail(self, fields, filter_by: dict):\n        return await db_util.fetch_one(self.session, self.model, fields=fields, filter_by=filter_by)\n\n    async def get_user_lst(self, fields, page: int, size: int):\n        return await db_util.fetch_all(self.session, self.model, fields=fields, page=page, size=size)\n\n    async def get_user_total(self):\n        return await db_util.fetch_total(self.session, self.model)\n\n    async def create_user(self, data: dict, check_unique: dict = None):\n        return await db_util.create(self.session, self.model, data=data, check_unique=check_unique)\n\n    async def update_user(self, data: dict, filter_by: dict):\n        return await db_util.update(self.session, self.model, data=data, filter_by=filter_by)\n\n    async def delete_user(self, filter_by: dict):\n        return await db_util.delete(self.session, self.model, filter_by=filter_by)\n",
    "app/repositories/__init__.py": "\"\"\"\n\u6570\u636e\u4ed3\u5e93\n\"\"\"\n",
    "app/schemas/user.py": "import re\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field, field_validator\n\nfrom app.schemas import filter_fields\n\n\nclass UserDetail(BaseModel):\n    id: str = Field(...)\n    # #\n    phone: str = None\n    name: str = None\n    age: int = None\n    gender: int = None\n    created_at: int = None\n    updated_at: int = None\n\n    @classmethod\n    def response_fields(cls):\n        return filter_fields(\n            cls,\n            exclude=[]\n        )\n\n\nclass UserList(BaseModel):\n    page: int = Field(1, ge=1)\n    size: int = Field(10, ge=1)\n    # #\n    id: str = None\n    phone: str = None\n    name: str = None\n    age: int = None\n    gender: int = None\n    created_at: int = None\n    updated_at: int = None\n\n    @classmethod\n    def response_fields(cls):\n        return filter_fields(\n            cls,\n            exclude=[\n                \"page\",\n                \"size\",\n            ]\n        )\n\n\nclass UserCreate(BaseModel):\n    phone: str = Field(..., pattern=r\"^1[3-9]\\d{9}$\")\n    password: str = Field(...)\n    name: str | None = Field(None)\n    age: int | None = Field(None, ge=0, le=200)\n    gender: Literal[1, 2] | None = Field(None)\n\n    @field_validator(\"password\")\n    def validate_password(cls, v):\n        if not re.match(r\"^(?=.*[A-Za-z])(?=.*\\d)\\S{6,20}$\", v):\n            raise ValueError(\"\u5bc6\u7801\u5fc5\u987b\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u5b57\u6bcd\u548c\u4e00\u4e2a\u6570\u5b57\uff0c\u957f\u5ea6\u4e3a6-20\u4f4d\u7684\u975e\u7a7a\u767d\u5b57\u7b26\u7ec4\u5408\")\n        return v\n\n    @field_validator(\"name\")\n    def validate_name(cls, v, info):\n        if not v and (phone := info.data.get(\"phone\")):\n            return f\"\u7528\u6237{phone[-4:]}\"\n        if v and not re.match(r\"^[\\u4e00-\\u9fffA-Za-z0-9_\\-.]{1,50}$\", v):\n            raise ValueError(\"\u540d\u79f0\u4ec5\u96501-50\u4f4d\u7684\u4e2d\u6587\u3001\u82f1\u6587\u3001\u6570\u5b57\u3001_-.\u7ec4\u5408\")\n        return v\n\n\nclass UserUpdate(BaseModel):\n    name: str | None = Field(None)\n    age: int | None = Field(None, ge=0, le=200)\n    gender: Literal[1, 2] | None = Field(None)\n\n    @field_validator(\"name\")\n    def validate_name(cls, v):\n        if v and not re.match(r\"^[\\u4e00-\\u9fffA-Za-z0-9_\\-.]{1,50}$\", v):\n            raise ValueError(\"\u540d\u79f0\u4ec5\u96501-50\u4f4d\u7684\u4e2d\u6587\u3001\u82f1\u6587\u3001\u6570\u5b57\u3001_-.\u7ec4\u5408\")\n        return v\n\n\nclass UserDelete(BaseModel):\n    pass\n\n\nclass UserLogin(BaseModel):\n    phone: str = Field(...)\n    password: str = Field(...)\n\n\nclass UserToken(BaseModel):\n    id: str = Field(...)\n    exp_minutes: int = Field(24 * 60 * 30, ge=1)\n",
    "app/schemas/__init__.py": "\"\"\"\n\u6570\u636e\u7ed3\u6784\n\"\"\"\n\n\ndef filter_fields(\n        model,\n        exclude: list = None,\n):\n    if exclude:\n        return list(set(model.model_fields.keys()) - set(exclude))\n    return list(model.model_fields.keys())\n",
    "app/services/user.py": "from app.api.exceptions import CustomException\nfrom app.api.status import Status\nfrom app.initializer import g\nfrom app.repositories.user import UserRepo\nfrom app.schemas.user import (\n    UserDetail,\n    UserList,\n    UserCreate,\n    UserUpdate,\n    UserDelete,\n    UserLogin,\n    UserToken,\n)\nfrom app.utils import jwt_util\n\n\nclass UserDetailSvc(UserDetail):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserDetail\"\n        }\n    }\n\n    async def detail(self):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            data = await user_repo.get_user_detail(\n                fields=self.response_fields(),\n                filter_by={\"id\": self.id},\n            )\n            if not data:\n                raise CustomException(status=Status.RECORD_NOT_EXIST_ERROR)\n            return data\n\n\nclass UserListSvc(UserList):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserList\"\n        }\n    }\n\n    async def lst(self):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            data = await user_repo.get_user_lst(\n                fields=self.response_fields(),\n                page=self.page,\n                size=self.size,\n            )\n            total = await user_repo.get_user_total()\n            return data, total\n\n\nclass UserCreateSvc(UserCreate):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserCreate\"\n        }\n    }\n\n    async def create(self):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            user = await user_repo.create_user(\n                data={\n                    \"name\": self.name,\n                    \"phone\": self.phone,\n                    \"age\": self.age,\n                    \"gender\": self.gender,\n                    \"password\": jwt_util.hash_password(self.password),\n                    \"jwt_key\": jwt_util.gen_jwt_key(jwt_key=g.config.jwt_key),\n                },\n                check_unique={\"phone\": self.phone},\n            )\n            if not user:\n                raise CustomException(status=Status.RECORD_EXISTS_ERROR)\n            await session.commit()\n            return user.id\n\n\nclass UserUpdateSvc(UserUpdate):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserUpdate\"\n        }\n    }\n\n    async def update(self, user_id: str):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            rowcount = await user_repo.update_user(\n                data=self.model_dump(),\n                filter_by={\"id\": user_id},\n            )\n            if not rowcount:\n                raise CustomException(status=Status.RECORD_NOT_EXIST_ERROR)\n            await session.commit()\n            return user_id\n\n\nclass UserDeleteSvc(UserDelete):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserDelete\"\n        }\n    }\n\n    @staticmethod\n    async def delete(user_id: str):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            rowcount = await user_repo.delete_user(\n                filter_by={\"id\": user_id},\n            )\n            if not rowcount:\n                raise CustomException(status=Status.RECORD_NOT_EXIST_ERROR)\n            await session.commit()\n            return user_id\n\n\nclass UserLoginSvc(UserLogin):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserLogin\"\n        }\n    }\n\n    async def login(self):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            data = await user_repo.get_user_detail(\n                fields=(\"id\", \"phone\", \"name\", \"age\", \"gender\", \"password\"),\n                filter_by={\"phone\": self.phone},\n            )\n            if not data:\n                raise CustomException(status=Status.USER_OR_PASSWORD_ERROR)\n            stored_password = data[\"password\"]\n            payload = {\n                \"id\": data.get(\"id\"),\n                \"phone\": data.get(\"phone\"),\n                \"name\": data.get(\"name\"),\n                \"age\": data.get(\"age\"),\n                \"gender\": data.get(\"gender\"),\n            }\n\n        if not jwt_util.verify_password(self.password, stored_password):\n            raise CustomException(status=Status.USER_OR_PASSWORD_ERROR)\n        new_jwt_key = jwt_util.gen_jwt_key(jwt_key=g.config.jwt_key)\n        token = jwt_util.gen_jwt(\n            payload=payload,\n            jwt_key=new_jwt_key,\n            exp_minutes=24 * 60 * 30,\n        )\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            await user_repo.update_user(\n                data={\"jwt_key\": new_jwt_key},\n                filter_by={\"phone\": self.phone},\n            )\n            await session.commit()\n\n        return token\n\n\nclass UserTokenSvc(UserToken):\n    model_config = {\n        \"json_schema_extra\": {\n            \"title\": \"UserToken\"\n        }\n    }\n\n    async def token(self):\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            data = await user_repo.get_user_detail(\n                fields=(\"id\", \"phone\", \"name\", \"age\", \"gender\"),\n                filter_by={\"id\": self.id},\n            )\n            if not data:\n                raise CustomException(status=Status.RECORD_NOT_EXIST_ERROR)\n            payload = {\n                \"id\": data.get(\"id\"),\n                \"phone\": data.get(\"phone\"),\n                \"name\": data.get(\"name\"),\n                \"age\": data.get(\"age\"),\n                \"gender\": data.get(\"gender\"),\n            }\n\n        new_jwt_key = jwt_util.gen_jwt_key(jwt_key=g.config.jwt_key)\n        token = jwt_util.gen_jwt(\n            payload=payload,\n            jwt_key=new_jwt_key,\n            exp_minutes=self.exp_minutes,\n        )\n        async with g.db_async_session() as session:\n            user_repo = UserRepo(session)\n            await user_repo.update_user(\n                data={\"jwt_key\": new_jwt_key},\n                filter_by={\"id\": self.id},\n            )\n            await session.commit()\n\n        return token\n",
    "app/services/__init__.py": "\"\"\"\n\u4e1a\u52a1\u903b\u8f91\n\"\"\"\n",
    "app/utils/api_key_util.py": "import secrets\n\n_API_KEY_LENGTH = 45\n\n\ndef gen_api_key(prefix: str = \"\", length: int = _API_KEY_LENGTH) -> str:\n    api_key = secrets.token_urlsafe(length)[:length]\n    if prefix:\n        return f\"{prefix}_{api_key}\"\n    return api_key\n\n\nif __name__ == '__main__':\n    num = 2\n    print(\",\".join([gen_api_key() for _ in range(num)]))\n",
    "app/utils/db_util.py": "from sqlalchemy import (\n    select,\n    func,\n    text,\n    update as update_,\n    delete as delete_,\n)\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\n\ndef format_all(\n        rows,\n        fields: list[str] | tuple[str],\n) -> list[dict]:\n    if not rows:\n        return []\n    return [dict(zip(fields, row)) for row in rows]\n\n\ndef format_one(\n        row,\n        fields: list[str] | tuple[str],\n) -> dict:\n    if not row:\n        return {}\n    return dict(zip(fields, row))\n\n\ndef model_dict(\n        model,\n        fields: list[str] | tuple[str] | None = None,\n) -> dict:\n    if not model:\n        return {}\n    if fields is None:\n        fields = [field.name for field in model.__table__.columns]\n    return {field: getattr(model, field) for field in fields}\n\n\nasync def fetch_one(\n        session: AsyncSession,\n        model,\n        *,\n        fields: list[str] | tuple[str] | None = None,\n        filter_by: dict | None = None,\n) -> dict:\n    if fields is None:\n        fields = [field.name for field in model.__table__.columns]\n    cols = [getattr(model, field) for field in fields if hasattr(model, field)]\n    query = select(*cols).select_from(model)\n    if filter_by:\n        query = query.filter_by(**filter_by)\n    result = await session.execute(query)\n    return format_one(result.fetchone(), fields)\n\n\nasync def fetch_all(\n        session: AsyncSession,\n        model,\n        *,\n        fields: list[str] | tuple[str] | None = None,\n        filter_by: dict | None = None,\n        page: int | None = None,\n        size: int | None = None,\n) -> list[dict]:\n    if fields is None:\n        fields = [field.name for field in model.__table__.columns]\n    cols = [getattr(model, field) for field in fields if hasattr(model, field)]\n    query = select(*cols).select_from(model)\n    if filter_by:\n        query = query.filter_by(**filter_by)\n    if page is not None and size is not None:\n        query = query.offset((page - 1) * size).limit(size)\n    result = await session.execute(query)\n    return format_all(result.fetchall(), fields)\n\n\nasync def fetch_total(\n        session: AsyncSession,\n        model,\n        *,\n        filter_by: dict | None = None,\n) -> int:\n    query = select(func.count()).select_from(model)\n    if filter_by:\n        query = query.filter_by(**filter_by)\n    result = await session.execute(query)\n    return result.scalar() or 0\n\n\nasync def create(\n        session: AsyncSession,\n        model,\n        *,\n        data: dict,\n        check_unique: dict | None = None,\n        flush: bool = False,\n) -> object | None:\n    if check_unique:\n        exists = await fetch_one(session, model, filter_by=check_unique)\n        if exists:\n            return None\n    obj = model(**data)\n    session.add(obj)\n    if flush:\n        await session.flush()\n    return obj\n\n\nasync def update(\n        session: AsyncSession,\n        model,\n        *,\n        data: dict,\n        filter_by: dict,\n        is_exclude_none: bool = True,\n) -> int:\n    if not filter_by:\n        raise ValueError(\"update requires non-empty filter_by to avoid full-table update\")\n    if is_exclude_none:\n        data = {k: v for k, v in data.items() if v is not None}\n    stmt = update_(model).filter_by(**filter_by).values(**data)\n    result = await session.execute(stmt)\n    return result.rowcount  # noqa\n\n\nasync def delete(\n        session: AsyncSession,\n        model,\n        *,\n        filter_by: dict,\n) -> int:\n    if not filter_by:\n        raise ValueError(\"delete requires non-empty filter_by to avoid full-table delete\")\n    stmt = delete_(model).filter_by(**filter_by)\n    result = await session.execute(stmt)\n    return result.rowcount  # noqa\n\n\nasync def sqlfetch_one(\n        session: AsyncSession,\n        sql: str,\n        *,\n        params: dict | None = None,\n) -> dict:\n    result = await session.execute(text(sql), params)\n    row = result.fetchone()\n    return row._asdict() if row else {}  # noqa\n\n\nasync def sqlfetch_all(\n        session: AsyncSession,\n        sql: str,\n        *,\n        params: dict | None = None,\n) -> list[dict]:\n    result = await session.execute(text(sql), params)\n    rows = result.fetchall()\n    return [row._asdict() for row in rows]  # noqa\n",
    "app/utils/ext_util.py": "import uuid\nfrom toollib.utils import now2timestamp\n\nfrom app.initializer import g\n\n\ndef gen_uuid_hex() -> str:\n    return uuid.uuid4().hex\n\n\ndef gen_snow_id(to_str: bool = True):\n    return g.snow_cli.gen_uid(to_str=to_str)\n\n\ndef now_timestamp() -> int:\n    return now2timestamp()\n",
    "app/utils/jwt_util.py": "import secrets\nfrom datetime import datetime, timedelta\n\nimport bcrypt\nimport jwt\n\n_JWT_ALGORITHM = \"HS256\"\n\n\ndef gen_jwt(payload: dict, jwt_key: str, exp_minutes: int = 24 * 60 * 30, algorithm: str = _JWT_ALGORITHM):\n    payload.update({\"exp\": datetime.utcnow() + timedelta(minutes=exp_minutes)})\n    encoded_jwt = jwt.encode(payload=payload, key=jwt_key, algorithm=algorithm)\n    return encoded_jwt\n\n\ndef verify_jwt(token: str, jwt_key: str = None, algorithms: tuple = (_JWT_ALGORITHM,)) -> dict:\n    if not jwt_key:\n        return jwt.decode(jwt=token, options={\"verify_signature\": False})\n    return jwt.decode(jwt=token, key=jwt_key, algorithms=algorithms)\n\n\ndef gen_jwt_key(nbytes: int = 32, jwt_key: str = None):\n    if jwt_key:\n        return jwt_key\n    return secrets.token_hex(nbytes)\n\n\ndef hash_password(password: str) -> str:\n    salt = bcrypt.gensalt()\n    hashed_password = bcrypt.hashpw(password.encode('utf-8'), salt)\n    return hashed_password.decode('utf-8')\n\n\ndef verify_password(password: str, hashed_password: str) -> bool:\n    return bcrypt.checkpw(password.encode('utf-8'), hashed_password.encode('utf-8'))\n\n\nif __name__ == '__main__':\n    # jwt_key = gen_jwt_key()\n    # print(jwt_key)\n    jwt_key = \"da721f64779fd1d92de7abc2060eb62c7f61cf82942c052007486f759e185f6d\"\n    jwt_token = gen_jwt(\n        payload={\n            \"id\": \"1\",\n            \"phone\": \"18810000001\",\n            \"name\": \"admin\",\n            \"age\": 18,\n            \"gender\": 1\n        },\n        jwt_key=jwt_key\n    )\n    print(jwt_token)\n",
    "app/utils/__init__.py": "\"\"\"\nutils\n\"\"\"\n",
    "app/migrations/alembic/env.py": "from logging.config import fileConfig\nfrom urllib.parse import quote_plus\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config\nfrom sqlalchemy import pool\n\nfrom app.initializer import g\nfrom app.initializer._db import import_tables, make_db_url  # noqa\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# add your model's MetaData object here\ndecl_base = import_tables()\nif not decl_base:\n    raise RuntimeError(\"Failed to import DeclBase. Make sure your models are correctly defined and accessible.\")\ntarget_metadata = decl_base.metadata  # noqa\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\ndb_url = make_db_url(\n    drivername=g.config.db_drivername,\n    database=g.config.db_database,\n    username=g.config.db_username,\n    password=g.config.db_password,\n    host=g.config.db_host,\n    port=g.config.db_port,\n    query={\n        \"charset\": g.config.db_charset,\n    },\n)\ndb_password = quote_plus(db_url.password).replace(\"%\", \"%%\") if db_url.password else \"\"\ndb_url_str = str(db_url).replace(\"***\", db_password)\nconfig.set_main_option(\n    name=\"sqlalchemy.url\",\n    value=db_url_str,\n)\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n        render_as_batch=True,\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    connectable = engine_from_config(\n        config.get_section(config.config_ini_section, {}),\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n            compare_type=True,\n            compare_server_default=True,\n            render_as_batch=True,\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n",
    "app/migrations/alembic/README": "Generic single-database configuration.",
    "app/migrations/alembic/script.py.mako": "\"\"\"${message}\n\nRevision ID: ${up_revision}\nRevises: ${down_revision | comma,n}\nCreate Date: ${create_date}\n\n\"\"\"\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\n${imports if imports else \"\"}\n\n# revision identifiers, used by Alembic.\nrevision: str = ${repr(up_revision)}\ndown_revision: Union[str, Sequence[str], None] = ${repr(down_revision)}\nbranch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}\ndepends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}\n\n\ndef upgrade() -> None:\n    \"\"\"Upgrade schema.\"\"\"\n    ${upgrades if upgrades else \"pass\"}\n\n\ndef downgrade() -> None:\n    \"\"\"Downgrade schema.\"\"\"\n    ${downgrades if downgrades else \"pass\"}\n",
    "app/migrations/alembic/versions/.gitkeep": "",
    "app/api/default/aping.py": "from fastapi import APIRouter\n\nfrom app_celery.producer import publisher\n\nrouter = APIRouter()\n\n\n@router.get(\n    path=\"/aping\",\n    summary=\"aping\",\n)\nasync def ping():\n    task_id = publisher.publish(\"ping\")\n    return f\"pong > {task_id}\"\n",
    "app/api/default/ping.py": "from fastapi import APIRouter\n\nrouter = APIRouter()\n\n\n@router.get(\n    path=\"/ping\",\n    summary=\"ping\",\n)\nasync def ping():\n    return \"pong\"\n",
    "app/api/default/__init__.py": "\"\"\"\napi-default\n\"\"\"\n\n_prefix = \"/api\"\n",
    "app/api/v1/user.py": "from fastapi import APIRouter, Depends\nfrom loguru import logger\n\nfrom app.api.dependencies import JWTUser, get_current_user\nfrom app.api.responses import Responses, response_docs\nfrom app.services.user import (\n    UserDetailSvc,\n    UserListSvc,\n    UserCreateSvc,\n    UserUpdateSvc,\n    UserDeleteSvc,\n    UserLoginSvc,\n    UserTokenSvc,\n)\n\nrouter = APIRouter()\n_active = True  # \u6fc0\u6d3b\u72b6\u6001\uff08\u9ed8\u8ba4\u6fc0\u6d3b\uff09\n_tag = \"user\"  # \u6807\u7b7e\uff08\u9ed8\u8ba4\u6a21\u5757\u540d\uff09\n\n\n# \u6ce8\u610f\uff1a`user`\u4ec5\u4e3a\u6a21\u5757\u793a\u4f8b\uff0c\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\n# \u6ce8\u610f\uff1a`user`\u4ec5\u4e3a\u6a21\u5757\u793a\u4f8b\uff0c\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\n# \u6ce8\u610f\uff1a`user`\u4ec5\u4e3a\u6a21\u5757\u793a\u4f8b\uff0c\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\n\n\n@router.get(\n    path=\"/user/{user_id}\",\n    summary=\"userDetail\",\n    responses=response_docs(\n        model=UserDetailSvc,\n    ),\n)\nasync def detail(\n        user_id: str,\n        current_user: JWTUser = Depends(get_current_user),  # \u8ba4\u8bc1\n):\n    try:\n        user_svc = UserDetailSvc(id=user_id)\n        data = await user_svc.detail()\n    except Exception as e:\n        msg = \"userDetail\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data=data)\n\n\n@router.get(\n    path=\"/user\",\n    summary=\"userList\",\n    responses=response_docs(\n        model=UserListSvc,\n        is_listwrap=True,\n        listwrap_key=\"items\",\n        listwrap_key_extra={\n            \"total\": \"int\",\n        },\n    ),\n)\nasync def lst(\n        page: int = 1,\n        size: int = 10,\n        current_user: JWTUser = Depends(get_current_user),\n):\n    try:\n        user_svc = UserListSvc(page=page, size=size)\n        data, total = await user_svc.lst()\n    except Exception as e:\n        msg = \"userList\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data={\"items\": data, \"total\": total})\n\n\n@router.post(\n    path=\"/user\",\n    summary=\"userCreate\",\n    responses=response_docs(data={\n        \"id\": \"str\",\n    }),\n)\nasync def create(\n        user_svc: UserCreateSvc,\n):\n    try:\n        created_id = await user_svc.create()\n    except Exception as e:\n        msg = \"userCreate\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data={\"id\": created_id})\n\n\n@router.put(\n    path=\"/user/{user_id}\",\n    summary=\"userUpdate\",\n    responses=response_docs(data={\n        \"id\": \"str\",\n    }),\n)\nasync def update(\n        user_id: str,\n        user_svc: UserUpdateSvc,\n        current_user: JWTUser = Depends(get_current_user),\n):\n    try:\n        updated_id = await user_svc.update(user_id)\n    except Exception as e:\n        msg = \"userUpdate\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data={\"id\": updated_id})\n\n\n@router.delete(\n    path=\"/user/{user_id}\",\n    summary=\"userDelete\",\n    responses=response_docs(data={\n        \"id\": \"str\",\n    }),\n)\nasync def delete(\n        user_id: str,\n        current_user: JWTUser = Depends(get_current_user),\n):\n    try:\n        user_svc = UserDeleteSvc()\n        deleted_id = await user_svc.delete(user_id)\n    except Exception as e:\n        msg = \"userDelete\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data={\"id\": deleted_id})\n\n\n@router.post(\n    path=\"/user/login\",\n    summary=\"userLogin\",\n    responses=response_docs(data={\n        \"token\": \"str\",\n    }),\n)\nasync def login(\n        user_svc: UserLoginSvc,\n):\n    try:\n        data = await user_svc.login()\n    except Exception as e:\n        msg = \"userLogin\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data={\"token\": data})\n\n\n@router.post(\n    path=\"/user/token\",\n    summary=\"userToken\",\n    responses=response_docs(data={\n        \"token\": \"str\",\n    }),\n)\nasync def token(\n        user_svc: UserTokenSvc,\n        current_user: JWTUser = Depends(get_current_user),\n):\n    try:\n        data = await user_svc.token()\n    except Exception as e:\n        msg = \"userToken\u64cd\u4f5c\u5f02\u5e38\"\n        logger.exception(msg)\n        return Responses.failure(msg=msg, error=e)\n    return Responses.success(data={\"token\": data})\n",
    "app/api/v1/__init__.py": "\"\"\"\napi-v1\n\"\"\"\n\n_prefix = \"/api/v1\"\n",
    "tiny/app/initializer.py": "\"\"\"\n\u521d\u59cb\u5316\n\"\"\"\nimport os\nimport threading\nfrom contextvars import ContextVar\nfrom functools import cached_property\nfrom pathlib import Path\n\nfrom loguru import logger\nfrom loguru._logger import Logger  # noqa\nfrom sqlalchemy import URL, create_engine\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\nfrom sqlalchemy.orm import scoped_session, sessionmaker\nfrom toollib import logu\nfrom toollib.guid import SnowFlake\nfrom toollib.rediscli import RedisCli\nfrom toollib.utils import ConfModel, FrozenVar, Singleton, localip\n\nfrom app import APP_DIR\n\n__all__ = [\n    \"g\",\n    \"request_id_var\",\n]\n\n_CONFIG_DIR = APP_DIR.parent.joinpath(\"config\")\n\ndotenv_path = _CONFIG_DIR.joinpath(\".env\")\nif os.environ.setdefault(\"app_env\", \"dev\") == \"prod\":  # \u751f\u4ea7\u73af\u5883\u4e0d\u52a0\u8f7d.env\uff08\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\uff09\n    dotenv_path = None\nyaml_path = _CONFIG_DIR.joinpath(f\"app_{os.environ.get('app_env', 'dev')}.yaml\")\n\n\nclass Config(ConfModel):\n    \"\"\"\u914d\u7f6e\"\"\"\n    app_dir: FrozenVar[Path] = APP_DIR\n    # #\n    app_env: str = \"dev\"\n    yaml_path: Path = yaml_path\n    api_keys: list = []\n    jwt_key: str = \"\"\n    snow_datacenter_id: int = None\n    # #\n    app_title: str = \"xApp\"\n    app_summary: str = \"xxApp\"\n    app_description: str = \"xxxApp\"\n    app_version: str = \"1.0.0\"\n    app_debug: bool = True\n    app_log_serialize: bool = False\n    app_log_outdir: str = \"./logs\"\n    app_disable_docs: bool = False\n    app_allow_credentials: bool = True\n    app_allow_origins: list = [\"*\"]\n    app_allow_methods: list = [\"*\"]\n    app_allow_headers: list = [\"*\"]\n    # #\n    db_drivername: str\n    db_async_drivername: str\n    db_database: str\n    db_username: str = None\n    db_password: str = None\n    db_host: str = None\n    db_port: int = None\n    db_charset: str = None\n    redis_host: str = None\n    redis_port: int = None\n    redis_db: int = None\n    redis_password: str = None\n    redis_max_connections: int = None\n\n\ndef init_logger(\n        level: str,\n        serialize: bool = False,\n        outdir: str = None,\n) -> Logger:\n    enable_console, enable_file = True, True\n    if os.getenv(\"app_env\") == \"prod\":\n        enable_console, enable_file = False, True  # \u6309\u9700\u8c03\u6574\n    _logger = logu.init_logger(\n        level=level,\n        request_id_var=request_id_var,\n        serialize=serialize,\n        enable_console=enable_console,\n        enable_file=enable_file,\n        outdir=outdir,\n    )\n    # _logger.add \u53ef\u6dfb\u52a0\u5176\u4ed6 handler\n    return _logger\n\n\ndef init_redis_cli(\n        host: str,\n        port: int,\n        db: int,\n        password: str = None,\n        max_connections: int = None,\n        **kwargs,\n) -> RedisCli:\n    return RedisCli(\n        host=host,\n        port=port,\n        db=db,\n        password=password,\n        max_connections=max_connections,\n        **kwargs,\n    )\n\n\n_CACHE_KEY_SNOW_WORKER_ID_INCR = \"config:snow_worker_id_incr\"\n_CACHE_KEY_SNOW_DATACENTER_ID_INCR = \"config:snow_datacenter_id_incr\"\n_CACHE_EXPIRE_SNOW = 120\n\n\ndef init_snow_cli(\n        redis_cli=None,  # `from toollib.rediscli import RedisCli` \u5b9e\u4f8b\n        datacenter_id: int = None,\n) -> SnowFlake:\n    # \u5efa\u8bae\uff1a\u91c7\u7528\u670d\u52a1\u7684\u65b9\u5f0f\u8c03\u7528api\u83b7\u53d6\n    if datacenter_id is None:\n        datacenter_id = _snow_incr(redis_cli, _CACHE_KEY_SNOW_DATACENTER_ID_INCR, _CACHE_EXPIRE_SNOW)\n        if datacenter_id is None:\n            local_ip = localip()\n            if local_ip:\n                ip_parts = list(map(int, local_ip.split('.')))\n                ip_int = (ip_parts[0] << 24) + (ip_parts[1] << 16) + (ip_parts[2] << 8) + ip_parts[3]\n                datacenter_id = ip_int % 32\n    worker_id = _snow_incr(redis_cli, _CACHE_KEY_SNOW_WORKER_ID_INCR, _CACHE_EXPIRE_SNOW)\n    if worker_id is None:\n        worker_id = os.getpid() % 32\n    return SnowFlake(worker_id=worker_id, datacenter_id=datacenter_id)\n\n\ndef _snow_incr(redis_cli, cache_key: str, cache_expire: int):\n    incr = None\n    if not redis_cli:\n        return incr\n    try:\n        with redis_cli.connection() as r:\n            resp = r.ping()\n            if resp:\n                lua_script = \"\"\"\n                    if redis.call('exists', KEYS[1]) == 1 then\n                        redis.call('expire', KEYS[1], ARGV[1])\n                        return redis.call('incr', KEYS[1])\n                    else\n                        redis.call('set', KEYS[1], 0)\n                        redis.call('expire', KEYS[1], ARGV[1])\n                        return 0\n                    end\n                    \"\"\"\n                incr = r.eval(lua_script, 1, cache_key, cache_expire)\n    except Exception as e:\n        logger.warning(f\"snow\u521d\u59cb\u5316id\u5c06\u91c7\u7528\u672c\u5730\u65b9\u5f0f\uff0c\u7531\u4e8e\uff08{e}\uff09\")\n    return incr\n\n\ndef init_db_session(\n        db_drivername: str,\n        db_database: str,\n        db_username: str,\n        db_password: str,\n        db_host: str,\n        db_port: int,\n        db_charset: str,\n        db_echo: bool,\n        db_pool_size: int = 10,\n        db_max_overflow: int = 5,\n        db_pool_recycle: int = 3600,\n) -> scoped_session:\n    db_url = make_db_url(\n        drivername=db_drivername,\n        database=db_database,\n        username=db_username,\n        password=db_password,\n        host=db_host,\n        port=db_port,\n        query={\n            \"charset\": db_charset,\n        },\n    )\n    db_echo = db_echo or False\n    kwargs = {\n        \"pool_size\": db_pool_size,\n        \"max_overflow\": db_max_overflow,\n        \"pool_recycle\": db_pool_recycle,\n    }\n    if db_url.drivername.startswith(\"sqlite\"):\n        kwargs = {}\n    engine = create_engine(\n        url=db_url,\n        echo=db_echo,\n        pool_pre_ping=True,\n        **kwargs,\n    )\n    db_session = sessionmaker(engine, expire_on_commit=False)\n    return scoped_session(db_session)\n\n\ndef init_db_async_session(\n        db_drivername: str,\n        db_database: str,\n        db_username: str,\n        db_password: str,\n        db_host: str,\n        db_port: int,\n        db_charset: str,\n        db_echo: bool,\n        db_pool_size: int = 10,\n        db_max_overflow: int = 5,\n        db_pool_recycle: int = 3600,\n) -> sessionmaker:\n    db_url = make_db_url(\n        drivername=db_drivername,\n        database=db_database,\n        username=db_username,\n        password=db_password,\n        host=db_host,\n        port=db_port,\n        query={\n            \"charset\": db_charset,\n        },\n    )\n    db_echo = db_echo or False\n    kwargs = {\n        \"pool_size\": db_pool_size,\n        \"max_overflow\": db_max_overflow,\n        \"pool_recycle\": db_pool_recycle,\n    }\n    if db_url.drivername.startswith(\"sqlite\"):\n        kwargs = {}\n    async_engine = create_async_engine(\n        url=db_url,\n        echo=db_echo,\n        pool_pre_ping=True,\n        **kwargs,\n    )\n    db_async_session = sessionmaker(async_engine, class_=AsyncSession, expire_on_commit=False)  # noqa\n    return db_async_session\n\n\ndef make_db_url(\n        drivername: str,\n        database: str,\n        username: str = None,\n        password: str = None,\n        host: str = None,\n        port: int = None,\n        query: dict = None,\n) -> URL:\n    query = {k: v for k, v in query.items() if v} if query else {}\n    return URL.create(\n        drivername=drivername,\n        username=username,\n        password=password,\n        host=host,\n        port=port,\n        database=database,\n        query=query,\n    )\n\n\nclass G(metaclass=Singleton):\n    \"\"\"\n    \u5168\u5c40\u53d8\u91cf\n    \"\"\"\n    _initialized = False\n    _init_lock = threading.Lock()\n    _init_properties = [\n        \"config\",\n        \"logger\",\n        \"redis_cli\",\n        \"snow_cli\",\n        # \"db_session\",\n        \"db_async_session\",\n    ]\n\n    def __init__(self):\n        self._initialized = False\n\n    @cached_property\n    def config(self) -> Config:\n        return Config(\n            dotenv_path=dotenv_path,\n            yaml_path=yaml_path,\n        )\n\n    @cached_property\n    def logger(self) -> Logger:\n        return init_logger(\n            level=\"DEBUG\" if self.config.app_debug else \"INFO\",\n            serialize=self.config.app_log_serialize,\n            outdir=self.config.app_log_outdir,\n        )\n\n    @cached_property\n    def redis_cli(self) -> RedisCli:\n        return init_redis_cli(\n            host=self.config.redis_host,\n            port=self.config.redis_port,\n            db=self.config.redis_db,\n            password=self.config.redis_password,\n            max_connections=self.config.redis_max_connections,\n        )\n\n    @cached_property\n    def snow_cli(self) -> SnowFlake:\n        return init_snow_cli(\n            redis_cli=getattr(self, \"redis_cli\", None),\n            datacenter_id=self.config.snow_datacenter_id,\n        )\n\n    @cached_property\n    def db_session(self) -> scoped_session:\n        return init_db_session(\n            db_drivername=self.config.db_drivername,\n            db_database=self.config.db_database,\n            db_username=self.config.db_username,\n            db_password=self.config.db_password,\n            db_host=self.config.db_host,\n            db_port=self.config.db_port,\n            db_charset=self.config.db_charset,\n            db_echo=self.config.app_debug,\n        )\n\n    @cached_property\n    def db_async_session(self) -> sessionmaker:\n        return init_db_async_session(\n            db_drivername=self.config.db_async_drivername,\n            db_database=self.config.db_database,\n            db_username=self.config.db_username,\n            db_password=self.config.db_password,\n            db_host=self.config.db_host,\n            db_port=self.config.db_port,\n            db_charset=self.config.db_charset,\n            db_echo=self.config.app_debug,\n        )\n\n    def setup(self):\n        with self._init_lock:\n            if not self._initialized:\n                for prop_name in self._init_properties:\n                    if hasattr(self, prop_name):\n                        getattr(self, prop_name)\n                    else:\n                        logger.warning(f\"{prop_name} not found\")\n                self._initialized = True\n\n\ng = G()\nrequest_id_var: ContextVar[str] = ContextVar(\"request_id\", default=\"N/A\")\n",
    "tiny/app/middleware.py": "\"\"\"\n\u4e2d\u95f4\u4ef6\n\"\"\"\nimport uuid\n\nfrom fastapi import FastAPI\nfrom fastapi.exceptions import RequestValidationError\nfrom loguru import logger\nfrom starlette.exceptions import HTTPException\nfrom starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\nfrom starlette.middleware.cors import CORSMiddleware\nfrom starlette.requests import Request\nfrom starlette.responses import JSONResponse, Response\n\nfrom app.api.exceptions import CustomException\nfrom app.api.responses import Responses\nfrom app.api.status import Status\nfrom app.initializer import g, request_id_var\n\n__all__ = [\n    \"register_middlewares\",\n]\n\n\ndef register_middlewares(app: FastAPI):\n    \"\"\"\u6ce8\u518c\u4e2d\u95f4\u4ef6\"\"\"\n    app.add_middleware(CorsMiddleware)  # type: ignore\n    app.add_middleware(HttpMiddleware)  # type: ignore\n    # #\n    app.add_exception_handler(CustomException, ExceptionsHandler.custom_exception_handler)  # type: ignore\n    app.add_exception_handler(RequestValidationError, ExceptionsHandler.request_validation_handler)  # type: ignore\n    app.add_exception_handler(HTTPException, ExceptionsHandler.http_exception_handler)  # type: ignore\n\n\nclass CorsMiddleware(CORSMiddleware):\n    def __init__(self, app, **kwargs):\n        super().__init__(\n            app,\n            allow_credentials=g.config.app_allow_credentials,\n            allow_origins=g.config.app_allow_origins,\n            allow_methods=g.config.app_allow_methods,\n            allow_headers=g.config.app_allow_headers,\n            **kwargs\n        )\n\n\nclass HttpMiddleware(BaseHTTPMiddleware):\n    _HEADERS = {\n        # \u53ef\u6dfb\u52a0\u76f8\u5173\u5934\n    }\n\n    async def dispatch(\n            self, request: Request,\n            call_next: RequestResponseEndpoint,\n    ) -> Response:\n        request_id = self._get_or_create_request_id(request)\n        request.state.request_id = request_id\n        token = request_id_var.set(request_id)\n        try:\n            response = await call_next(request)\n            response.headers[\"X-Request-ID\"] = request_id\n            for key, value in self._HEADERS.items():\n                if key not in response.headers:\n                    response.headers[key] = value\n            return response\n        except Exception as exc:\n            return await self.handle_exception(request, exc)\n        finally:\n            request_id_var.reset(token)\n\n    @staticmethod\n    def _get_or_create_request_id(request: Request, prefix: str = \"req-\") -> str:\n        request_id = request.headers.get(\"X-Request-ID\")\n        if not request_id:\n            request_id = f\"{prefix}{uuid.uuid4().hex}\"\n        return request_id\n\n    @staticmethod\n    async def handle_exception(\n            request: Request,\n            exc: Exception,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {Status.INTERNAL_SERVER_ERROR.code} {type(exc).__name__}: {exc}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            error=exc,\n            status=Status.INTERNAL_SERVER_ERROR,\n        )\n\n\nclass ExceptionsHandler:\n\n    @staticmethod\n    async def custom_exception_handler(\n            request: Request,\n            exc: CustomException,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {exc.code} {exc.msg}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            msg=exc.msg,\n            code=exc.code,\n            error=exc,\n            data=exc.data,\n        )\n\n    @staticmethod\n    async def request_validation_handler(\n            request: Request,\n            exc: RequestValidationError,\n            display_all: bool = False,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        if display_all:\n            msg = \" & \".join([\n                f\"{error['loc'][-1]} ({error['type']}) {error['msg'].replace('Value error, ', '').lower()}\"\n                for error in exc.errors()\n            ])\n        else:\n            error = exc.errors()[0]\n            msg = f\"{error['loc'][-1]} ({error['type']}) {error['msg'].replace('Value error, ', '').lower()}\"\n        lmsg = f'- \"{request.method} {request.url.path}\" {Status.PARAMS_ERROR.code} {msg}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            msg=msg,\n            error=exc,\n            status=Status.PARAMS_ERROR,\n        )\n\n    @staticmethod\n    async def http_exception_handler(\n            request: Request,\n            exc: HTTPException,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {exc.status_code} {exc.detail}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        return Responses.failure(\n            msg=exc.detail,\n            code=exc.status_code,\n            error=exc,\n        )\n",
    "single/app/api.py": "from fastapi import APIRouter, Security\nfrom fastapi.security import APIKeyHeader\nfrom starlette.exceptions import HTTPException\nfrom starlette.status import HTTP_401_UNAUTHORIZED\n\nfrom app.core import config\n\nrouter = APIRouter()\n\n_API_KEY_HEADER = APIKeyHeader(name=\"X-API-Key\", auto_error=False)\n\n\nasync def get_current_api_key(\n        api_key: str | None = Security(_API_KEY_HEADER)\n) -> str:\n    if not api_key:\n        raise HTTPException(\n            status_code=HTTP_401_UNAUTHORIZED,\n            detail=\"API key is required\"\n        )\n    if api_key not in config.api_keys:\n        raise HTTPException(\n            status_code=HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid API key\"\n        )\n    return api_key\n\n\n@router.get(\n    path=\"/api/ping\",\n    summary=\"ping\",\n)\nasync def ping():\n    return \"pong\"\n",
    "single/app/core.py": "import os\nfrom contextvars import ContextVar\nfrom pathlib import Path\n\nfrom toollib.utils import ConfModel, FrozenVar\n\n_APP_DIR = Path(__file__).absolute().parent\n_CONFIG_DIR = _APP_DIR.parent.joinpath(\"config\")\n\ndotenv_path = _CONFIG_DIR.joinpath(\".env\")\nif os.environ.setdefault(\"app_env\", \"dev\") == \"prod\":  # \u751f\u4ea7\u73af\u5883\u4e0d\u52a0\u8f7d.env\uff08\u8bf7\u6839\u636e\u81ea\u8eab\u9700\u6c42\u4fee\u6539\uff09\n    dotenv_path = None\nyaml_path = _CONFIG_DIR.joinpath(f\"app_{os.environ.get('app_env', 'dev')}.yaml\")\n\n\nclass Config(ConfModel):\n    \"\"\"\u914d\u7f6e\"\"\"\n    app_dir: FrozenVar[Path] = _APP_DIR\n    # #\n    app_env: str = \"dev\"\n    yaml_path: Path = yaml_path\n    api_keys: list = []\n    # #\n    app_title: str = \"xApp\"\n    app_summary: str = \"xxApp\"\n    app_description: str = \"xxxApp\"\n    app_version: str = \"1.0.0\"\n    app_debug: bool = True\n    app_log_serialize: bool = False\n    app_log_outdir: str = \"./logs\"\n    app_disable_docs: bool = False\n    app_allow_credentials: bool = True\n    app_allow_origins: list = [\"*\"]\n    app_allow_methods: list = [\"*\"]\n    app_allow_headers: list = [\"*\"]\n\n\nconfig = Config(\n    dotenv_path=dotenv_path,\n    yaml_path=yaml_path,\n)\nrequest_id_var: ContextVar[str] = ContextVar(\"request_id\", default=\"N/A\")\n",
    "single/app/main.py": "import uuid\nfrom contextlib import asynccontextmanager\n\nfrom fastapi import FastAPI\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import ORJSONResponse\nfrom starlette.exceptions import HTTPException\nfrom starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\nfrom starlette.middleware.cors import CORSMiddleware\nfrom starlette.requests import Request\nfrom starlette.responses import Response, JSONResponse\nfrom toollib.logu import init_logger\n\nfrom app.api import router\nfrom app.core import config, request_id_var\n\n_EXPOSE_ERROR = True\n\nenable_console, enable_file = True, True\nif config.app_env == \"prod\":\n    enable_console, enable_file = False, True  # \u6309\u9700\u8c03\u6574\nlogger = init_logger(\n    __name__,\n    level=\"DEBUG\" if config.app_debug else \"INFO\",\n    request_id_var=request_id_var,\n    serialize=config.app_log_serialize,\n    enable_console=enable_console,\n    enable_file=enable_file,\n    outdir=config.app_log_outdir,\n)\n# logger.add \u53ef\u6dfb\u52a0\u5176\u4ed6 handler\n# #\nopenapi_url = \"/openapi.json\"\ndocs_url = \"/docs\"\nredoc_url = \"/redoc\"\nif config.app_disable_docs is True:\n    openapi_url, docs_url, redoc_url = None, None, None\n\n\n@asynccontextmanager\nasync def lifespan(xapp: FastAPI):\n    logger.info(f\"Application env '{config.app_env}'\")\n    logger.info(f\"Application yaml '{config.yaml_path.name}'\")\n    logger.info(f\"Application title '{config.app_title}'\")\n    logger.info(f\"Application version '{config.app_version}'\")\n    # #\n    logger.info(\"Application server running\")\n    yield\n    logger.info(\"Application server shutdown\")\n\n\nclass CorsMiddleware(CORSMiddleware):\n    def __init__(self, xapp, **kwargs):\n        super().__init__(\n            xapp,\n            allow_credentials=config.app_allow_credentials,\n            allow_origins=config.app_allow_origins,\n            allow_methods=config.app_allow_methods,\n            allow_headers=config.app_allow_headers,\n            **kwargs\n        )\n\n\nclass HttpMiddleware(BaseHTTPMiddleware):\n    _HEADERS = {\n        # \u53ef\u6dfb\u52a0\u76f8\u5173\u5934\n    }\n\n    async def dispatch(\n            self, request: Request,\n            call_next: RequestResponseEndpoint,\n    ) -> Response:\n        request_id = self._get_or_create_request_id(request)\n        request.state.request_id = request_id\n        token = request_id_var.set(request_id)\n        try:\n            response = await call_next(request)\n            response.headers[\"X-Request-ID\"] = request_id\n            for key, value in self._HEADERS.items():\n                if key not in response.headers:\n                    response.headers[key] = value\n            return response\n        except Exception as exc:\n            return await self.handle_exception(request, exc)\n        finally:\n            request_id_var.reset(token)\n\n    @staticmethod\n    def _get_or_create_request_id(request: Request, prefix: str = \"req-\") -> str:\n        request_id = request.headers.get(\"X-Request-ID\")\n        if not request_id:\n            request_id = f\"{prefix}{uuid.uuid4().hex}\"\n        return request_id\n\n    @staticmethod\n    async def handle_exception(\n            request: Request,\n            exc: Exception,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        msg = \"\u5185\u90e8\u670d\u52a1\u5668\u9519\u8bef\"\n        code = 500\n        lmsg = f'- \"{request.method} {request.url.path}\" {code} {type(exc).__name__}: {exc}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        content = {\n            \"msg\": msg,\n            \"code\": code,\n            \"request_id\": request.state.request_id,\n        }\n        if _EXPOSE_ERROR:\n            content[\"error\"] = str(exc)\n        return JSONResponse(\n            content=content,\n        )\n\n\nclass ExceptionsHandler:\n\n    @staticmethod\n    async def request_validation_handler(\n            request: Request,\n            exc: RequestValidationError,\n            display_all: bool = False,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        if display_all:\n            msg = \" & \".join([\n                f\"{error['loc'][-1]} ({error['type']}) {error['msg'].replace('Value error, ', '').lower()}\"\n                for error in exc.errors()\n            ])\n        else:\n            error = exc.errors()[0]\n            msg = f\"{error['loc'][-1]} ({error['type']}) {error['msg'].replace('Value error, ', '').lower()}\"\n        code = 400\n        lmsg = f'- \"{request.method} {request.url.path}\" {code} {msg}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        content = {\n            \"msg\": msg,\n            \"code\": code,\n            \"request_id\": request.state.request_id,\n        }\n        if _EXPOSE_ERROR:\n            content[\"error\"] = str(exc)\n        return JSONResponse(\n            content=content,\n        )\n\n    @staticmethod\n    async def http_exception_handler(\n            request: Request,\n            exc: HTTPException,\n            is_traceback: bool = True,\n    ) -> JSONResponse:\n        lmsg = f'- \"{request.method} {request.url.path}\" {exc.status_code} {exc.detail}'\n        if is_traceback:\n            logger.exception(lmsg)\n        else:\n            logger.error(lmsg)\n        content = {\n            \"msg\": exc.detail,\n            \"code\": exc.status_code,\n            \"request_id\": request.state.request_id,\n        }\n        if _EXPOSE_ERROR:\n            content[\"error\"] = str(exc)\n        return JSONResponse(\n            content=content,\n        )\n\n\napp = FastAPI(\n    title=config.app_title,\n    summary=config.app_summary,\n    description=config.app_description,\n    version=config.app_version,\n    debug=config.app_debug,\n    openapi_url=openapi_url,\n    docs_url=docs_url,\n    redoc_url=redoc_url,\n    lifespan=lifespan,\n    default_response_class=ORJSONResponse,\n)\n# #\napp.add_middleware(CorsMiddleware)  # type: ignore\napp.add_middleware(HttpMiddleware)  # type: ignore\napp.add_exception_handler(RequestValidationError, ExceptionsHandler.request_validation_handler)  # type: ignore\napp.add_exception_handler(HTTPException, ExceptionsHandler.http_exception_handler)  # type: ignore\napp.include_router(router)\n",
    "single/app/__init__.py": "\"\"\"\n@author axiner\n@version v1.0.0\n@created 2024/07/29 22:22\n@abstract app\n@description\n@history\n\"\"\"\n"
}