Metadata-Version: 2.4
Name: geronimo
Version: 0.3.0
Summary: ML deployment framework - from local development to production with one command
Project-URL: Homepage, https://geronimo.dev
Project-URL: Documentation, https://geronimo.dev/docs
Project-URL: Repository, https://github.com/geronimo-deploy-cloud/geronimo
Project-URL: Changelog, https://github.com/geronimo-deploy-cloud/geronimo/releases
Author-email: Chris Sweet <chris.sweet0320@gmail.com>
License: Apache-2.0
License-File: LICENSE
Keywords: ai-agents,deployment,machine-learning,mcp,mlops,model-serving
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.11
Requires-Dist: jinja2>=3.1.6
Requires-Dist: pandas>=2.0.0
Requires-Dist: pydantic>=2.12.5
Requires-Dist: pyyaml>=6.0.3
Requires-Dist: rich>=14.2.0
Requires-Dist: typer>=0.21.1
Provides-Extra: all
Requires-Dist: mlflow>=2.10.0; extra == 'all'
Requires-Dist: psycopg2-binary>=2.9.0; extra == 'all'
Requires-Dist: pulumi-aws>=6.0.0; extra == 'all'
Requires-Dist: pulumi-azure-native>=2.0.0; extra == 'all'
Requires-Dist: pulumi-gcp>=7.0.0; extra == 'all'
Requires-Dist: pulumi>=3.0.0; extra == 'all'
Requires-Dist: pyodbc>=5.0.0; extra == 'all'
Requires-Dist: snowflake-connector-python>=3.0.0; extra == 'all'
Provides-Extra: cloud
Requires-Dist: httpx>=0.25.0; extra == 'cloud'
Provides-Extra: databases
Requires-Dist: psycopg2-binary>=2.9.0; extra == 'databases'
Requires-Dist: pyodbc>=5.0.0; extra == 'databases'
Requires-Dist: snowflake-connector-python>=3.0.0; extra == 'databases'
Provides-Extra: mlflow
Requires-Dist: mlflow>=2.10.0; extra == 'mlflow'
Provides-Extra: pulumi
Requires-Dist: pulumi-aws>=6.0.0; extra == 'pulumi'
Requires-Dist: pulumi-azure-native>=2.0.0; extra == 'pulumi'
Requires-Dist: pulumi-gcp>=7.0.0; extra == 'pulumi'
Requires-Dist: pulumi>=3.0.0; extra == 'pulumi'
Description-Content-Type: text/markdown

# Geronimo: The Declarative ML Framework For AI

Build, train, and deploy ML models with production-ready infrastructure and Generative AI MCP support from the start.

Geronimo is like **dbt for AI**:

## Why Geronimo?

### ðŸš€ Ship Models Faster

Stop writing boilerplate. One command creates a runnable project with FastAPI endpoints, monitoring, and CI/CD ready to go.

```bash
geronimo init --name iris-realtime
cd iris-realtime && uv sync
uvicorn iris-realtime.app:app --reload  # API running in seconds
```

### ðŸ§© Simpler Development

Define your model's **what**, not the **how**. The SDK has 5 componentsâ€”each maps to one file:

| Component | File | Purpose |
|-----------|------|---------|
| **DataSource** | `data_sources.py` | Where your data comes from |
| **FeatureSet** | `features.py` | How to transform raw data |
| **Model** | `model.py` | Training and prediction logic |
| **Endpoint** | `endpoint.py` | Request/response handling (realtime) |
| **Pipeline** | `pipeline.py` | Batch job orchestration (batch) |

# data_sources.py â€” Declare your data
```
training_data = DataSource(name="training", source="snowflake", query=Query.from_file("train.sql"))
```

# features.py â€” Define transformations
```
class IrisFeatures(FeatureSet):
    sepal_length = Feature(dtype="numeric", transformer=StandardScaler())
    sepal_width = Feature(dtype="numeric", transformer=StandardScaler())
    petal_length = Feature(dtype="numeric", transformer=StandardScaler())
    petal_width = Feature(dtype="numeric", transformer=StandardScaler())
```

# model.py â€” Train and predict
```
class IrisModel(Model):
    name = "iris-realtime"
    features = IrisFeatures()
    
    def train(self, X, y, params): ...
    def predict(self, X): ...
```
# endpoint.py â€” Handle requests (realtime)
```
class PredictEndpoint(Endpoint):
    def preprocess(self, request): ...
    def postprocess(self, prediction): ...
```

# pipeline.py â€” Run batch jobs
```
class ScoringPipeline(BatchPipeline):
    schedule = Schedule.daily(hour=6)
    def run(self): ...
```


### ðŸ¤– GenAI Agent-Ready

Every project is automatically exposed as an [MCP tool](https://modelcontextprotocol.io). AI agents like Claude can call your models directlyâ€”no extra work required.

```json
{
  "mcpServers": {
    "iris-realtime": {
      "command": "uv",
      "args": ["run", "python", "-m", "iris-realtime.agent.server"]
    }
  }
}
```

> "Analyze this transaction for fraud risk"  
> â†’ Claude calls your model â†’ Returns risk score

---

## Getting Started

```bash
pip install geronimo
geronimo init --name my-model --template realtime
```

Choose your template:

| Template | Use Case | Output |
|----------|----------|--------|
| `realtime` | REST APIs, low-latency | FastAPI + monitoring |
| `batch` | Scheduled jobs, bulk scoring | Metaflow + drift detection |
| `both` | APIs + scheduled pipelines | Everything |

## What You Get

A complete, runnable project structure:

```
my-model/
â”œâ”€â”€ src/my_model/
â”‚   â”œâ”€â”€ sdk/                    # Define your model here
â”‚   â”‚   â”œâ”€â”€ model.py            # train() + predict()
â”‚   â”‚   â”œâ”€â”€ features.py         # Feature transformations
â”‚   â”‚   â”œâ”€â”€ endpoint.py         # Request/response handling
â”‚   â”‚   â””â”€â”€ monitoring_config.py
â”‚   â”œâ”€â”€ app.py                  # FastAPI (auto-generated)
â”‚   â””â”€â”€ train.py                # Training script
â”œâ”€â”€ geronimo.yaml               # Deployment config
â””â”€â”€ models/                     # Saved artifacts
```

**Focus on the `sdk/` folder.** Everything else is generated for you.

## Deploy to Production

```bash
geronimo generate all
```

Generates:
- **Terraform** â€” ECS Fargate infrastructure
- **Dockerfile** â€” Optimized for ML serving
- **CI/CD** â€” Azure DevOps / GitHub Actions pipelines

## Integrations

| Integration | Purpose |
|-------------|---------|
| **MLflow** | Experiment tracking, artifact store |
| **Snowflake/Postgres** | Data sources for training |
| **CloudWatch** | Production metrics |
| **Slack** | Alerts for drift/errors |
| **MCP** | AI agent tool exposure |

## Documentation

- [Getting Started: Realtime](docs/tutorials/getting_started_realtime.md)
- [Getting Started: Batch](docs/tutorials/getting_started_batch.md)
- [Monitoring & Drift Detection](docs/tutorials/monitoring.md)
- [MCP Integration](docs/tutorials/mcp_integration.md)
- [SDK Reference](docs/tutorials/sdk_reference.md)

## Installation

```bash
pip install geronimo                  # Core
pip install geronimo[mlflow]          # + MLflow
pip install geronimo[databases]       # + Snowflake, Postgres
pip install geronimo[all]             # Everything
```

---

**Apache 2.0 License** â€¢ [GitHub](https://github.com/geronimo-deploy-cloud/geronimo)
