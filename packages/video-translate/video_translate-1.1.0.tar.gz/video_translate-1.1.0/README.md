# ğŸ¬ Video Subtitle Translation Tool

Automatically transcribe video audio, translate to target language, and generate subtitle files or embed them into videos. **Supports translation between 18 languages**.

[ä¸­æ–‡æ–‡æ¡£](README.zh.md) | [æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](README.ja.md) | [í•œêµ­ì–´ ë¬¸ì„œ](README.ko.md)

## âœ¨ Features

- ğŸ¤ **Speech Recognition**: High-precision speech recognition using OpenAI Whisper
- ğŸŒ **Multi-language Translation**: Supports translation between 18 languages (Chinese, English, Japanese, Korean, French, German, Spanish, etc.)
- ğŸ¤– **Multiple Engine Support**: Supports DeepSeek, OpenAI, and other translation engines
- ğŸ“„ **Subtitle Generation**: Supports multiple subtitle formats including SRT, VTT, ASS
- ğŸ¥ **Subtitle Embedding**: Supports both soft and hard subtitle methods
- ğŸŒ **Bilingual Subtitles**: Optional bilingual subtitle generation
- ğŸ’° **Cost-Effective**: DeepSeek API offers affordable pricing with excellent translation quality
- ğŸ—ï¸ **Modular Design**: Easy to extend and maintain

## ğŸŒ Supported Languages

| Code | Language | Code | Language |
|------|----------|------|----------|
| `zh` | Chinese (ä¸­æ–‡) | `en` | English |
| `ja` | Japanese (æ—¥æœ¬èª) | `ko` | Korean (í•œêµ­ì–´) |
| `fr` | French (FranÃ§ais) | `de` | German (Deutsch) |
| `es` | Spanish (EspaÃ±ol) | `ru` | Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹) |
| `pt` | Portuguese (PortuguÃªs) | `it` | Italian (Italiano) |
| `nl` | Dutch (Nederlands) | `pl` | Polish (Polski) |
| `tr` | Turkish (TÃ¼rkÃ§e) | `ar` | Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©) |
| `hi` | Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€) | `th` | Thai (à¹„à¸—à¸¢) |
| `vi` | Vietnamese (Tiáº¿ng Viá»‡t) | `id` | Indonesian (Bahasa Indonesia) |

Use `video-translate --list-languages` to view the complete list.

## ğŸ“ Project Structure

```
video-translate/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ video_translate/
â”‚       â”œâ”€â”€ __init__.py      # Package initialization
â”‚       â”œâ”€â”€ __main__.py      # Entry point
â”‚       â”œâ”€â”€ cli.py           # Command-line interface
â”‚       â”œâ”€â”€ config.py        # Configuration management
â”‚       â”œâ”€â”€ models.py        # Data models
â”‚       â”œâ”€â”€ transcriber.py   # Speech recognition module
â”‚       â”œâ”€â”€ translator.py    # Translation module
â”‚       â”œâ”€â”€ subtitle.py      # Subtitle processing module
â”‚       â”œâ”€â”€ video.py         # Video processing module
â”‚       â”œâ”€â”€ pipeline.py      # Processing pipeline
â”‚       â””â”€â”€ utils.py         # Utility functions
â”œâ”€â”€ pyproject.toml           # Project configuration
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ LICENSE                  # MIT License
â”œâ”€â”€ .gitignore               # Git ignore file
â””â”€â”€ README.md
```

## ğŸ“¦ Installation

### Prerequisites

FFmpeg is required for video processing. Please install it first:

**macOS:**
```bash
# Basic installation (sufficient for soft subtitles)
brew install ffmpeg

# For hard subtitles (--hard-sub), you need FFmpeg with libass support:
brew install ffmpeg-full
echo 'export PATH="/opt/homebrew/opt/ffmpeg-full/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc
```

> **Note**: The standard `brew install ffmpeg` does not include libass support, which is required for the `--hard-sub` feature. If you encounter errors like "No option name near force_style", please install `ffmpeg-full` instead.

**Ubuntu/Debian:**
```bash
sudo apt update && sudo apt install ffmpeg
```
> The apt package typically includes libass support. If you encounter "No option name near force_style" errors with `--hard-sub`, install libass: `sudo apt install libass-dev` and reinstall ffmpeg.

**Windows:**
Download and install [FFmpeg](https://ffmpeg.org/download.html) (recommended: [gyan.dev](https://www.gyan.dev/ffmpeg/builds/) full build or [BtbN](https://github.com/BtbN/FFmpeg-Builds/releases) builds, which include libass support)

### Quick Installation (Recommended)

```bash
pip install video-translate
```

Or use [uv](https://github.com/astral-sh/uv) (faster):

```bash
uv pip install video-translate
```

### Development Installation

If you want to contribute to development or modify the code:

```bash
# 1. Clone the project
git clone https://github.com/yourusername/video-translate.git
cd video-translate

# 2. Install uv (if not already installed)
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
# Windows
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

# 3. Install dependencies (including dev tools)
uv sync --dev

# Or install with pip in editable mode
pip install -e ".[dev]"
```

### Set up API Key

Register and get an API Key from [DeepSeek Open Platform](https://platform.deepseek.com/):

```bash
export DEEPSEEK_API_KEY='your-api-key-here'
```

Or use OpenAI:
```bash
export OPENAI_API_KEY='your-api-key-here'
```

## ğŸš€ Usage

### Command Line Usage

```bash
# Basic usage (English â†’ Chinese)
video-translate video.mp4

# Or use python -m
python -m video_translate video.mp4
```

### Multi-language Translation Examples

```bash
# English â†’ Chinese (default)
video-translate video.mp4

# Japanese â†’ Chinese
video-translate video.mp4 --source ja --target zh

# English â†’ Japanese
video-translate video.mp4 --source en --target ja

# Chinese â†’ English
video-translate video.mp4 --source zh --target en

# Korean â†’ Japanese
video-translate video.mp4 --source ko --target ja

# French â†’ German
video-translate video.mp4 --source fr --target de
```

### Command Line Options

| Option | Description |
|--------|-------------|
| `-s, --source` | Source language code (default: en) |
| `-t, --target` | Target language code (default: zh) |
| `--list-languages` | List all supported languages |
| `-o, --output` | Specify output directory |
| `-m, --model` | Whisper model size (tiny/base/small/medium/large) |
| `--translator` | Translation engine (deepseek/openai) |
| `--api-key` | Translation API Key |
| `--target-only` | Output only target language subtitles, without source text |
| `--source-first` | Source language on top, target language below |
| `--no-embed` | Don't embed subtitles into video, only generate subtitle files |
| `--hard-sub` | Use hard subtitles (burned into video) |
| `--font-size` | Hard subtitle font size (default: 24) |

### More Examples

```bash
# Use a larger model for better accuracy
video-translate video.mp4 --model large

# Only generate subtitle files, don't embed into video
video-translate video.mp4 --no-embed

# Generate hard subtitles (burned into video)
video-translate video.mp4 --hard-sub

# Output only target language subtitles
video-translate video.mp4 --target-only

# Use OpenAI translation
video-translate video.mp4 --translator openai

# Specify output directory
video-translate video.mp4 -o ./output
```

### Use as a Library

```python
from video_translate import (
    Config,
    TranscriberConfig,
    TranslatorConfig,
    TranslationPipeline,
    WhisperModel,
    TranslatorType,
    Language,
)

# Create configuration - Japanese to Chinese translation
config = Config(
    transcriber=TranscriberConfig(
        model=WhisperModel.BASE,
        language="ja"  # Source language
    ),
    translator=TranslatorConfig(
        type=TranslatorType.DEEPSEEK,
        api_key="your-api-key",
        source_language=Language.JAPANESE,
        target_language=Language.CHINESE,
    ),
)

# Create processing pipeline
pipeline = TranslationPipeline(config)

# Process video
result = pipeline.process("video.mp4")

print(f"Subtitle file: {result['subtitle_file']}")
print(f"Output video: {result['output_video']}")
```

## ğŸ¤– Whisper Model Selection

| Model | Size | Memory | Speed | Accuracy |
|-------|------|--------|-------|----------|
| tiny | 39M | ~1GB | Fastest | Lower |
| base | 74M | ~1GB | Fast | Medium |
| small | 244M | ~2GB | Medium | Good |
| medium | 769M | ~5GB | Slow | High |
| large | 1550M | ~10GB | Slowest | Highest |

Recommendations:
- Quick preview: Use `tiny` or `base`
- Production use: Use `small` or `medium`
- Highest quality: Use `large`

## ğŸ”Œ Extending Translation Engines

The project uses a modular design, making it easy to add new translation engines:

```python
from video_translate.translator import BaseTranslator

class MyTranslator(BaseTranslator):
    @property
    def name(self) -> str:
        return "MyTranslator"

    def translate_text(self, text: str, context: str = "") -> str:
        # Implement translation logic
        pass

    def translate_batch(self, texts: list[str]) -> list[str]:
        # Implement batch translation logic
        pass
```

## ğŸ“ Output Files

- `videoname_{language_code}.srt` - Subtitle file (e.g., `video_zh.srt`, `video_ja.srt`)
- `videoname_{language_code}.mp4` - Video with embedded subtitles (if embedding is selected)

## âš ï¸ Notes

1. **First run** will automatically download the Whisper model, please ensure a stable internet connection
2. **Hard subtitles** will re-encode the video, which takes longer
3. **Soft subtitles** only copy streams, faster but may not be supported by some players
4. Ensure FFmpeg is installed on your system
5. Apple Silicon Macs will automatically use MPS acceleration

## ğŸ› ï¸ Development

```bash
# Install development dependencies
uv sync --dev

# Run tests
uv run pytest

# Code formatting
uv run black src/

# Code linting
uv run ruff check src/

# Type checking
uv run mypy src/
```

## ğŸ“„ License

This project is open-sourced under the [MIT License](LICENSE).

Copyright (c) 2026 innovationmech
