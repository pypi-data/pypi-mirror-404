#!/usr/bin/env python3
"""
Simplified A2A Integration for WorldArchitect.AI Orchestrator

Lightweight file-based Agent-to-Agent protocol wrapper that enables
direct agent communication while preserving existing tmux orchestration.
"""

from __future__ import annotations

import fcntl
import json
import logging
import os
import tempfile
import time
import uuid
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any

# Use standard logging - orchestration package doesn't have logging_util dependency
# Per coding guidelines: module-level imports only, no try/except imports
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# A2A Communication Directory - configurable for production
A2A_BASE_DIR = os.environ.get("A2A_BASE_DIR", "/tmp/orchestration/a2a")


@dataclass
class A2AMessage:
    """Simple A2A message format for file-based communication"""

    id: str
    from_agent: str
    to_agent: str  # or "broadcast" for all agents
    message_type: str  # discover, claim, delegate, status, result
    payload: dict[str, Any]
    timestamp: float
    reply_to: str | None = None

    def to_json(self) -> str:
        """Serialize to JSON string"""
        return json.dumps(asdict(self), indent=2)

    @classmethod
    def from_json(cls, json_str: str) -> "A2AMessage":
        """Deserialize from JSON string"""
        data = json.loads(json_str)
        return cls(**data)


@dataclass
class AgentInfo:
    """Agent capabilities and status information"""

    agent_id: str
    agent_type: str  # frontend, backend, testing, opus-master
    capabilities: list[str]
    status: str  # idle, busy, offline
    current_task: str | None
    created_at: float
    last_heartbeat: float
    workspace: str

    def to_json(self) -> str:
        """Serialize to JSON string"""
        return json.dumps(asdict(self), indent=2)

    @classmethod
    def from_json(cls, json_str: str) -> "AgentInfo":
        """Deserialize from JSON string"""
        data = json.loads(json_str)
        return cls(**data)


class FileBasedMessaging:
    """Handles file-based inbox/outbox messaging between agents"""

    def __init__(self, agent_id: str):
        self.agent_id = agent_id
        self.agent_dir = Path(A2A_BASE_DIR) / "agents" / agent_id
        self.inbox_dir = self.agent_dir / "inbox"
        self.outbox_dir = self.agent_dir / "outbox"

        # Ensure directories exist
        self.inbox_dir.mkdir(parents=True, exist_ok=True)
        self.outbox_dir.mkdir(parents=True, exist_ok=True)

    def send_message(self, message: A2AMessage) -> bool:
        """Send message to another agent's inbox"""
        try:
            if message.to_agent == "broadcast":
                return self._broadcast_message(message)
            return self._send_direct_message(message)
        except Exception as e:
            logger.error(f"Failed to send message: {e}")
            return False

    def _send_direct_message(self, message: A2AMessage) -> bool:
        """Send direct message to specific agent"""
        target_inbox = Path(A2A_BASE_DIR) / "agents" / message.to_agent / "inbox"
        target_inbox.mkdir(parents=True, exist_ok=True)

        filename = f"{message.timestamp}_{message.from_agent}_{message.id}.json"
        filepath = target_inbox / filename

        with open(filepath, "w") as f:
            f.write(message.to_json())

        logger.info(f"Sent message {message.id} to {message.to_agent}")
        return True

    def _broadcast_message(self, message: A2AMessage) -> bool:
        """Broadcast message to all registered agents"""
        agents_dir = Path(A2A_BASE_DIR) / "agents"
        if not agents_dir.exists():
            return False

        success_count = 0
        for agent_dir in agents_dir.iterdir():
            if agent_dir.is_dir() and agent_dir.name != self.agent_id:
                target_message = A2AMessage(
                    id=message.id,
                    from_agent=message.from_agent,
                    to_agent=agent_dir.name,
                    message_type=message.message_type,
                    payload=message.payload,
                    timestamp=message.timestamp,
                    reply_to=message.reply_to,
                )
                if self._send_direct_message(target_message):
                    success_count += 1

        logger.info(f"Broadcast message {message.id} to {success_count} agents")
        return success_count > 0

    def receive_messages(self) -> list[A2AMessage]:
        """Retrieve all messages from inbox"""
        messages = []

        if not self.inbox_dir.exists():
            return messages

        for message_file in self.inbox_dir.glob("*.json"):
            try:
                with open(message_file) as f:
                    message = A2AMessage.from_json(f.read())
                    messages.append(message)

                # Move processed message to prevent re-processing
                processed_dir = self.inbox_dir / "processed"
                processed_dir.mkdir(exist_ok=True)
                message_file.rename(processed_dir / message_file.name)

            except Exception as e:
                logger.error(f"Failed to process message {message_file}: {e}")

        return messages


class AgentRegistry:
    """Manages agent discovery and registration"""

    def __init__(self):
        self.registry_file = Path(A2A_BASE_DIR) / "registry.json"
        self.registry_file.parent.mkdir(parents=True, exist_ok=True)

    def register_agent(self, agent_info: AgentInfo) -> bool:
        """Register an agent in the registry"""
        try:
            registry = self._load_registry()
            registry[agent_info.agent_id] = asdict(agent_info)
            self._save_registry(registry)

            # Also save agent info to its directory
            agent_dir = Path(A2A_BASE_DIR) / "agents" / agent_info.agent_id
            agent_dir.mkdir(parents=True, exist_ok=True)

            with open(agent_dir / "info.json", "w") as f:
                f.write(agent_info.to_json())

            logger.info(f"Registered agent {agent_info.agent_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to register agent: {e}")
            return False

    def unregister_agent(self, agent_id: str) -> bool:
        """Remove agent from registry"""
        try:
            registry = self._load_registry()
            if agent_id in registry:
                del registry[agent_id]
                self._save_registry(registry)
                logger.info(f"Unregistered agent {agent_id}")
            return True
        except Exception as e:
            logger.error(f"Failed to unregister agent: {e}")
            return False

    def discover_agents(self, capability_filter: list[str] | None = None) -> list[AgentInfo]:
        """Discover available agents, optionally filtered by capabilities"""
        try:
            registry = self._load_registry()
            agents = []

            for agent_data in registry.values():
                agent_info = AgentInfo(**agent_data)

                # Filter by capabilities if specified
                if capability_filter and not any(cap in agent_info.capabilities for cap in capability_filter):
                    continue

                # Check if agent is still alive (heartbeat within last 60 seconds)
                if time.time() - agent_info.last_heartbeat < 60:
                    agents.append(agent_info)

            return agents

        except Exception as e:
            logger.error(f"Failed to discover agents: {e}")
            return []

    def update_heartbeat(self, agent_id: str) -> bool:
        """Update agent heartbeat timestamp"""
        try:
            registry = self._load_registry()
            if agent_id in registry:
                registry[agent_id]["last_heartbeat"] = time.time()
                self._save_registry(registry)

                # Also update heartbeat file
                agent_dir = Path(A2A_BASE_DIR) / "agents" / agent_id
                heartbeat_file = agent_dir / "heartbeat.json"
                with open(heartbeat_file, "w") as f:
                    json.dump({"last_heartbeat": time.time()}, f)

            return True
        except Exception as e:
            logger.error(f"Failed to update heartbeat: {e}")
            return False

    def _load_registry(self) -> dict[str, Any]:
        """Load registry from file"""
        if self.registry_file.exists():
            with open(self.registry_file) as f:
                return json.load(f)
        return {}

    def _save_registry(self, registry: dict[str, Any]) -> None:
        """Save registry to file"""
        with open(self.registry_file, "w") as f:
            json.dump(registry, f, indent=2)


class TaskPool:
    """Manages task distribution and claiming"""

    def __init__(self):
        self.tasks_dir = Path(A2A_BASE_DIR) / "tasks"
        self.available_dir = self.tasks_dir / "available"
        self.claimed_dir = self.tasks_dir / "claimed"
        self.completed_dir = self.tasks_dir / "completed"

        # Ensure directories exist
        for dir_path in [self.available_dir, self.claimed_dir, self.completed_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

    def publish_task(
        self,
        task_id: str,
        task_description: str,
        requirements: list[str] | None = None,
        constraints: dict[str, Any] | None = None,
    ) -> bool:
        """Publish a task to the available pool with optional constraints

        Args:
            task_id: Unique identifier for the task
            task_description: Description of the task to be performed
            requirements: List of capability requirements for agents
            constraints: Optional constraint information for task execution
                        Can include: resource limits, timing constraints,
                        validation rules, execution preferences, etc.
        """
        try:
            task_data = {
                "task_id": task_id,
                "description": task_description,
                "requirements": requirements or [],
                "constraints": constraints or {},
                "constraint_enforcement": {
                    "enabled": bool(constraints),
                    "validation_required": bool(constraints and constraints.get("validation_rules")),
                    "created_at": time.time(),
                },
                "created_at": time.time(),
                "status": "available",
            }

            task_file = self.available_dir / f"{task_id}.json"
            with open(task_file, "w") as f:
                json.dump(task_data, f, indent=2)

            logger.info(f"Published task {task_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to publish task: {e}")
            return False

    def claim_task(self, task_id: str, agent_id: str, timeout: float = 10.0) -> dict[str, Any]:
        """Claim a task from the available pool and return task data with constraints

        Uses atomic file locking to prevent race conditions when multiple agents
        attempt to claim the same task simultaneously.

        Args:
            task_id: ID of the task to claim
            agent_id: ID of the agent claiming the task
            timeout: Timeout in seconds for lock acquisition (default: 10.0)

        Returns:
            Dict containing task data including constraints, or empty dict if claim failed
        """
        lock_file = None
        lock_fd = None

        try:
            available_file = self.available_dir / f"{task_id}.json"
            if not available_file.exists():
                return {}

            # Create lock file for atomic task claiming
            lock_file = self.available_dir / f"{task_id}.lock"
            lock_fd = os.open(lock_file, os.O_CREAT | os.O_WRONLY | os.O_TRUNC)

            # Attempt to acquire exclusive lock with timeout
            start_time = time.time()
            while True:
                try:
                    fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                    break  # Lock acquired successfully
                except BlockingIOError:
                    if time.time() - start_time >= timeout:
                        logger.warning(f"Lock acquisition timeout for task {task_id} by agent {agent_id}")
                        return {}
                    time.sleep(0.01)  # Short sleep before retry

            # Double-check file still exists after acquiring lock
            if not available_file.exists():
                logger.info(f"Task {task_id} no longer available (claimed by another agent)")
                return {}

            # Load and validate task data
            with open(available_file) as f:
                task_data = json.load(f)

            # Add claiming timestamp for conflict detection
            claim_timestamp = time.time()

            # Check if task was recently claimed (additional safety check)
            if task_data.get("status") == "claimed":
                logger.warning(f"Task {task_id} already claimed by {task_data.get('claimed_by')}")
                return {}

            # Update task status and claimer with atomic timestamp
            task_data["status"] = "claimed"
            task_data["claimed_by"] = agent_id
            task_data["claimed_at"] = claim_timestamp
            task_data["claim_lock_acquired_at"] = claim_timestamp

            # Update constraint enforcement metadata
            if "constraint_enforcement" in task_data:
                task_data["constraint_enforcement"]["claimed_at"] = claim_timestamp
                task_data["constraint_enforcement"]["claimed_by"] = agent_id

            # Atomic move operation: write to temp file first, then move
            claimed_file = self.claimed_dir / f"{task_id}_{agent_id}.json"

            # Use atomic write with temp file
            with tempfile.NamedTemporaryFile(mode="w", dir=self.claimed_dir, suffix=".tmp", delete=False) as temp_file:
                json.dump(task_data, temp_file, indent=2)
                temp_file.flush()
                os.fsync(temp_file.fileno())  # Force write to disk
                temp_path = temp_file.name

            # Atomic move to final location
            os.rename(temp_path, claimed_file)

            # Remove from available directory (atomic operation)
            available_file.unlink()

            logger.info(f"Task {task_id} claimed by {agent_id} with atomic locking")
            if task_data.get("constraints"):
                logger.info(f"Task {task_id} includes constraints: {list(task_data['constraints'].keys())}")

            return task_data

        except OSError as e:
            logger.error(f"File operation failed during task claim for {task_id}: {e}")
            return {}
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in task file {task_id}: {e}")
            return {}
        except Exception as e:
            logger.error(f"Failed to claim task {task_id}: {e}")
            return {}
        finally:
            # Always release lock and cleanup
            if lock_fd is not None:
                try:
                    fcntl.flock(lock_fd, fcntl.LOCK_UN)
                    os.close(lock_fd)
                except OSError:
                    pass  # Ignore cleanup errors

            if lock_file and lock_file.exists():
                try:
                    lock_file.unlink()
                except OSError:
                    pass  # Ignore cleanup errors

    def complete_task(self, task_id: str, agent_id: str, result: dict[str, Any]) -> bool:
        """Mark a task as completed"""
        try:
            claimed_file = self.claimed_dir / f"{task_id}_{agent_id}.json"
            if not claimed_file.exists():
                return False

            # Load task data
            with open(claimed_file) as f:
                task_data = json.load(f)

            # Update task status and result
            task_data["status"] = "completed"
            task_data["completed_at"] = time.time()
            task_data["result"] = result

            # Move to completed directory
            completed_file = self.completed_dir / f"{task_id}_complete.json"
            with open(completed_file, "w") as f:
                json.dump(task_data, f, indent=2)

            # Remove from claimed
            claimed_file.unlink()

            logger.info(f"Task {task_id} completed by {agent_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to complete task: {e}")
            return False

    def get_available_tasks(self, capability_filter: list[str] | None = None) -> list[dict[str, Any]]:
        """Get list of available tasks, optionally filtered by requirements"""
        tasks = []

        for task_file in self.available_dir.glob("*.json"):
            try:
                with open(task_file) as f:
                    task_data = json.load(f)

                # Filter by capabilities if specified
                if capability_filter and task_data.get("requirements"):
                    if not any(req in capability_filter for req in task_data["requirements"]):
                        continue

                tasks.append(task_data)

            except Exception as e:
                logger.error(f"Failed to load task {task_file}: {e}")

        return tasks

    def validate_task_constraints(self, task_data: dict[str, Any], agent_capabilities: list[str]) -> bool:
        """Validate if an agent can handle task constraints

        Args:
            task_data: Complete task data including constraints
            agent_capabilities: List of agent capabilities

        Returns:
            True if agent can handle constraints, False otherwise
        """
        constraints = task_data.get("constraints", {})
        if not constraints:
            return True

        # Check resource constraints
        if "resource_limits" in constraints:
            # Could be extended to check actual resource availability
            pass

        # Check capability constraints
        if "required_capabilities" in constraints:
            required = constraints["required_capabilities"]
            if not all(cap in agent_capabilities for cap in required):
                return False

        # Check timing constraints
        if "deadline" in constraints:
            deadline = constraints["deadline"]
            if isinstance(deadline, int | float) and deadline < time.time():
                return False

        # Check validation rules
        if "validation_rules" in constraints:
            # Could be extended with specific validation logic
            # For now, assume agent can handle if it has validation capability
            if "validation" not in agent_capabilities:
                logger.warning("Task requires validation but agent lacks validation capability")

        return True


class A2AClient:
    """Main A2A client for agent integration"""

    def __init__(self, agent_id: str, agent_type: str, capabilities: list[str], workspace: str):
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.capabilities = capabilities
        self.workspace = workspace

        # Initialize components
        self.messaging = FileBasedMessaging(agent_id)
        self.registry = AgentRegistry()
        self.task_pool = TaskPool()

        # Register this agent
        self.agent_info = AgentInfo(
            agent_id=agent_id,
            agent_type=agent_type,
            capabilities=capabilities,
            status="idle",
            current_task=None,
            created_at=time.time(),
            last_heartbeat=time.time(),
            workspace=workspace,
        )
        self.registry.register_agent(self.agent_info)

    def send_message(self, to_agent: str, message_type: str, payload: dict[str, Any]) -> bool:
        """Send message to another agent"""
        message = A2AMessage(
            id=str(uuid.uuid4()),
            from_agent=self.agent_id,
            to_agent=to_agent,
            message_type=message_type,
            payload=payload,
            timestamp=time.time(),
        )
        return self.messaging.send_message(message)

    def receive_messages(self) -> list[A2AMessage]:
        """Receive all pending messages"""
        return self.messaging.receive_messages()

    def discover_agents(self) -> list[AgentInfo]:
        """Discover other available agents"""
        return self.registry.discover_agents()

    def publish_task(
        self,
        task_description: str,
        requirements: list[str] | None = None,
        constraints: dict[str, Any] | None = None,
    ) -> str:
        """Publish a new task with optional constraints

        Args:
            task_description: Description of the task
            requirements: List of capability requirements
            constraints: Optional constraint information for task execution
        """
        task_id = str(uuid.uuid4())
        if self.task_pool.publish_task(task_id, task_description, requirements, constraints):
            return task_id
        return None

    def claim_task(self, task_id: str, timeout: float = 10.0) -> dict[str, Any]:
        """Claim an available task and return task data with constraints

        Args:
            task_id: ID of the task to claim
            timeout: Timeout in seconds for lock acquisition (default: 10.0)

        Returns:
            Dict containing complete task data including constraints,
            or empty dict if claim failed
        """
        return self.task_pool.claim_task(task_id, self.agent_id, timeout)

    def complete_task(self, task_id: str, result: dict[str, Any]) -> bool:
        """Complete a claimed task"""
        return self.task_pool.complete_task(task_id, self.agent_id, result)

    def get_available_tasks(self) -> list[dict[str, Any]]:
        """Get available tasks matching this agent's capabilities"""
        return self.task_pool.get_available_tasks(self.capabilities)

    def get_compatible_tasks(self) -> list[dict[str, Any]]:
        """Get available tasks that are compatible with agent capabilities and constraints

        Returns:
            List of tasks that this agent can handle, including constraint validation
        """
        all_tasks = self.task_pool.get_available_tasks(self.capabilities)
        compatible_tasks = []

        for task in all_tasks:
            if self.task_pool.validate_task_constraints(task, self.capabilities):
                compatible_tasks.append(task)
            else:
                logger.info(f"Task {task.get('task_id')} filtered out due to constraint mismatch")

        return compatible_tasks

    def can_handle_task(self, task_data: dict[str, Any]) -> bool:
        """Check if this agent can handle a specific task including constraints

        Args:
            task_data: Complete task data including constraints

        Returns:
            True if agent can handle the task, False otherwise
        """
        return self.task_pool.validate_task_constraints(task_data, self.capabilities)

    def update_status(self, status: str, current_task: str = None) -> None:
        """Update agent status"""
        self.agent_info.status = status
        self.agent_info.current_task = current_task
        self.agent_info.last_heartbeat = time.time()
        self.registry.register_agent(self.agent_info)

    def heartbeat(self) -> None:
        """Send heartbeat to maintain registration"""
        self.registry.update_heartbeat(self.agent_id)

    def shutdown(self) -> None:
        """Clean shutdown - unregister agent"""
        self.registry.unregister_agent(self.agent_id)


# Utility functions for orchestration integration
def create_a2a_client(agent_id: str, agent_type: str, capabilities: list[str], workspace: str) -> A2AClient:
    """Factory function to create A2A client for agents"""
    return A2AClient(agent_id, agent_type, capabilities, workspace)


def get_a2a_status() -> dict[str, Any]:
    """Get overall A2A system status"""
    registry = AgentRegistry()
    task_pool = TaskPool()

    agents = registry.discover_agents()
    available_tasks = task_pool.get_available_tasks()

    return {
        "agents_online": len(agents),
        "available_tasks": len(available_tasks),
        "a2a_directory": A2A_BASE_DIR,
        "agents": [asdict(agent) for agent in agents],
        "tasks": available_tasks,
    }


if __name__ == "__main__":
    # Test the A2A system
    import shutil
    import tempfile

    # Use temp directory for testing
    test_dir = tempfile.mkdtemp()
    A2A_BASE_DIR = test_dir + "/a2a"

    try:
        # Create secure temporary directories for test agents
        agent1_workspace = tempfile.mkdtemp(prefix="agent1_")
        agent2_workspace = tempfile.mkdtemp(prefix="agent2_")

        # Create test agents with secure temporary workspaces
        agent1 = create_a2a_client(
            "agent-1",
            "frontend",
            ["javascript", "react", "validation"],
            agent1_workspace,
        )
        agent2 = create_a2a_client("agent-2", "backend", ["python", "api"], agent2_workspace)

        # Test task publishing with constraints
        constraints = {
            "resource_limits": {"memory_mb": 512, "timeout_seconds": 300},
            "required_capabilities": ["javascript"],
            "deadline": time.time() + 3600,  # 1 hour from now
            "validation_rules": {"code_review": True, "testing": True},
        }
        task_id = agent1.publish_task("Build login form with constraints", ["javascript"], constraints)
        print(f"Published task with constraints: {task_id}")

        # Test basic task publishing (backward compatibility)
        simple_task_id = agent1.publish_task("Simple task", ["python"])
        print(f"Published simple task: {simple_task_id}")

        # Agent 2 discovers tasks
        tasks = agent2.get_available_tasks()
        print(f"Available tasks: {len(tasks)}")

        # Test constraint compatibility
        compatible_tasks = agent2.get_compatible_tasks()
        print(f"Compatible tasks for agent2: {len(compatible_tasks)}")

        # Test task claiming with constraint information
        if compatible_tasks:
            claimed_task = agent2.claim_task(compatible_tasks[0]["task_id"])
            if claimed_task:
                print(f"Claimed task: {claimed_task.get('task_id')}")
                print(f"Task constraints: {claimed_task.get('constraints', {})}")
                print(f"Constraint enforcement: {claimed_task.get('constraint_enforcement', {})}")

        # Test messaging
        agent1.send_message("agent-2", "status", {"message": "Hello from agent 1"})
        messages = agent2.receive_messages()
        print(f"Agent 2 received {len(messages)} messages")

        # Get system status
        status = get_a2a_status()
        print(f"System status: {status}")
        print(f"Tasks with constraints: {sum(1 for task in status['tasks'] if task.get('constraints'))}")

    finally:
        # Cleanup test directories and agent workspaces
        shutil.rmtree(test_dir, ignore_errors=True)
        # Clean up agent workspaces if they exist
        try:
            shutil.rmtree(agent1_workspace, ignore_errors=True)
            shutil.rmtree(agent2_workspace, ignore_errors=True)
        except NameError:
            # Variables not defined if creation failed
            pass
