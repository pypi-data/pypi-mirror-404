{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mechanistic Interpretability Toolkit Examples\n",
        "\n",
        "This notebook provides examples of how to use the mech_interp_toolkit library for mechanistic interpretability research.\n",
        "\n",
        "It covers:\n",
        "1. Loading models and tokenizers\n",
        "2. Extracting activations from specific model components\n",
        "3. Performing Direct Logit Attribution (DLA)\n",
        "4. Running Gradient-based Attribution (Integrated Gradients)\n",
        "5. Patching activations to test causal interventions\n",
        "6. Training Linear Probes on extracted activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from mech_interp_toolkit.utils import load_model_tokenizer_config\n",
        "from mech_interp_toolkit.activation_dict import ActivationDict\n",
        "from mech_interp_toolkit.activations import get_activations, patch_activations\n",
        "from mech_interp_toolkit.direct_logit_attribution import run_componentwise_dla\n",
        "from mech_interp_toolkit.gradient_based_attribution import simple_integrated_gradients\n",
        "from mech_interp_toolkit.linear_probes import LinearProbe\n",
        "from mech_interp_toolkit.tokenizer import ChatTemplateTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading model...\")\n",
        "# Replace with your model name, e.g., \"Qwen/Qwen2-0.5B\"\n",
        "# Note: This requires the 'nnsight' library as per the toolkit's implementation.\n",
        "model_name = \"Qwen/Qwen2-0.5B\" \n",
        "\n",
        "try:\n",
        "    model, tokenizer, config = load_model_tokenizer_config(model_name)\n",
        "    print(f\"Successfully loaded {model_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load model {model_name} (this is expected if not running in a configured env): {e}\")\n",
        "    # Mocking config for the rest of the script if model load fails, \n",
        "    # so the example code structure is visible.\n",
        "    from transformers import AutoConfig\n",
        "    config = AutoConfig.from_pretrained(model_name)\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Tokenization with Chat Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Tokenization ---\")\n",
        "chat_tokenizer = ChatTemplateTokenizer(tokenizer)\n",
        "prompt = \"Explain the theory of relativity in one sentence.\"\n",
        "# Returns a dict with 'input_ids' and 'attention_mask'\n",
        "inputs = chat_tokenizer(prompt)\n",
        "print(f\"Input shape: {inputs['input_ids'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extracting Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Extracting Activations ---\")\n",
        "# Define components to extract: (layer_index, component_name)\n",
        "# Common names: \"attn\", \"mlp\", \"z\" (attention head output), \"layer_in\", \"layer_out\"\n",
        "components_to_extract = [(0, \"mlp\"), (0, \"attn\")]\n",
        "\n",
        "# get_activations returns (activations, grads, logits)\n",
        "activations, grads, logits = get_activations(model, inputs, components_to_extract)\n",
        "\n",
        "for key, val in activations.items():\n",
        "    print(f\"Extracted {key}: {val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Direct Logit Attribution (DLA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Direct Logit Attribution ---\")\n",
        "# Calculate the contribution of each component to a specific direction in the residual stream.\n",
        "# Typically, this direction is (embedding[correct_token] - embedding[incorrect_token]).\n",
        "# Here we use a random direction for demonstration.\n",
        "logit_diff_direction = torch.randn(config.hidden_size).to(model.device)\n",
        "\n",
        "dla_results = run_componentwise_dla(model, inputs, logit_diff_direction)\n",
        "\n",
        "# dla_results is an ActivationDict containing attribution scores\n",
        "if dla_results:\n",
        "    print(f\"DLA computed for {len(dla_results)} components.\")\n",
        "    print(f\"Attribution for Layer 0 MLP: {dla_results.get((0, 'mlp'), 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Activation Patching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Activation Patching ---\")\n",
        "# We can modify activations and see the effect on the output.\n",
        "# Let's zero-ablate the MLP at layer 0.\n",
        "\n",
        "# Create a new ActivationDict for patching\n",
        "patch_dict = ActivationDict(config, positions=slice(None))\n",
        "# Set the value to patch with (zeros in this case)\n",
        "patch_dict[(0, \"mlp\")] = torch.zeros_like(activations[(0, \"mlp\")])\n",
        "\n",
        "# patch_activations returns (activations, grads, logits)\n",
        "_, _, patched_logits = patch_activations(model, inputs, patch_dict, position=0)\n",
        "\n",
        "print(f\"Original logits norm: {logits.norm().item():.4f}\")\n",
        "print(f\"Patched logits norm: {patched_logits.norm().item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Gradient-Based Attribution (Integrated Gradients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Integrated Gradients ---\")\n",
        "# Attribution of input features (or internal activations) to the output.\n",
        "# We need a baseline activation (usually zeros).\n",
        "\n",
        "baseline_embeddings = ActivationDict(config, positions=slice(None))\n",
        "seq_len = inputs['input_ids'].shape[1]\n",
        "# Assuming we want to attribute to 'layer_in' at layer 0\n",
        "baseline_embeddings[(0, \"layer_in\")] = torch.zeros(1, seq_len, config.hidden_size).to(model.device)\n",
        "\n",
        "ig_attributions = simple_integrated_gradients(\n",
        "    model, inputs, baseline_embeddings, steps=5\n",
        ")\n",
        "print(\"Integrated Gradients computed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Linear Probes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n--- Linear Probes ---\")\n",
        "# Train a linear classifier on activations.\n",
        "\n",
        "# Generate dummy data for demonstration\n",
        "# In reality, you would collect activations over a dataset\n",
        "X = ActivationDict(config, positions=slice(None))\n",
        "# LinearProbe expects exactly one component in the ActivationDict\n",
        "X[(0, \"mlp\")] = torch.randn(100, 1, config.hidden_size) # 100 samples\n",
        "y = np.random.randint(0, 2, 100) # Binary classification targets\n",
        "\n",
        "probe = LinearProbe(target_type=\"classification\")\n",
        "probe.fit(X, y)\n",
        "print(\"Linear probe trained.\")\n",
        "\n",
        "# Predict on new data\n",
        "X_test = ActivationDict(config, positions=slice(None))\n",
        "X_test[(0, \"mlp\")] = torch.randn(10, 1, config.hidden_size)\n",
        "preds = probe.predict(X_test)\n",
        "print(f\"Predictions shape: {preds.shape}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}