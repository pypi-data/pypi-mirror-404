# This file was auto-generated by Fern from our API Definition.

import typing

import pydantic
import typing_extensions
from ...core.pydantic_utilities import IS_PYDANTIC_V2, UniversalBaseModel
from ...core.serialization import FieldMetadata
from .harmful_content_analysis import HarmfulContentAnalysis


class SafetyCheckReport(UniversalBaseModel):
    attack_detected: typing_extensions.Annotated[bool, FieldMetadata(alias="attackDetected")] = pydantic.Field()
    """
    Whether the check detected a malicious attack.
    """

    harmful_content_detected: typing_extensions.Annotated[bool, FieldMetadata(alias="harmfulContentDetected")] = (
        pydantic.Field()
    )
    """
    Whether the check detected harmful content such as hate speech, references to self-harm, violence or sexual references.
    """

    harmful_content_analysis: typing_extensions.Annotated[
        typing.List[HarmfulContentAnalysis], FieldMetadata(alias="harmfulContentAnalysis")
    ] = pydantic.Field()
    """
    Includes details on each category of harmful content.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
