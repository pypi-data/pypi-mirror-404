"""
–ü—Ä–∏–º–µ—Ä—ã —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ç–µ—Ö–Ω–∏–∫ —Ä–∞–±–æ—Ç—ã —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏.

–≠—Ç–æ—Ç —Ñ–∞–π–ª –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
- –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è Redis –∏ API
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
- –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤

–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã SemanticChunk.
"""

from typing import List, Dict, Any, Optional, Tuple
from chunk_metadata_adapter.chunk_query import ChunkQuery
from chunk_metadata_adapter.data_types import ChunkType, ChunkStatus, LanguageEnum


def example_query_serialization():
    """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ API."""
    print("=== –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ ===")
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    original_data = {
        "type": ChunkType.CODE_BLOCK.value,
        "language": LanguageEnum.PYTHON.value,
        "quality_score": ">=0.8",
        "year": ">=2020",
        "status": ChunkStatus.RELIABLE.value,  # –û–¥–∏–Ω–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ enum
        "is_public": True,
        "category": "tutorial"
    }
    original_query, errors = ChunkQuery.from_dict_with_validation(original_data)
    assert errors is None
    
    # 1. –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ –ø–ª–æ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å (–¥–ª—è Redis/–ë–î)
    flat_dict = original_query.to_flat_dict(for_redis=True)
    print(f"‚úÖ –ü–ª–æ—Å–∫–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è: {len(flat_dict)} –ø–æ–ª–µ–π")
    print(f"   type={flat_dict.get('type')}, quality_score={flat_dict.get('quality_score')}")
    
    # 2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –ø–ª–æ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
    restored_from_flat = ChunkQuery.from_flat_dict(flat_dict)
    print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ –ø–ª–æ—Å–∫–æ–≥–æ: type={restored_from_flat.type}")
    
    # 3. –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ JSON (–¥–ª—è API)
    json_dict = original_query.to_json_dict()
    print(f"‚úÖ JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è: {len(json_dict)} –ø–æ–ª–µ–π")
    print(f"   type={json_dict.get('type')}, is_public={json_dict.get('is_public')}")
    
    # 4. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ JSON
    restored_from_json = ChunkQuery.from_json_dict(json_dict)
    print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∏–∑ JSON: language={restored_from_json.language}")
    
    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    assert original_query.type == restored_from_flat.type == restored_from_json.type
    print(f"‚úÖ –í—Å–µ –º–µ—Ç–æ–¥—ã —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –¥–∞–Ω–Ω—ã–µ")
    
    return {
        "original": original_query,
        "flat_dict": flat_dict,
        "json_dict": json_dict
    }


def example_dynamic_query_building():
    """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤."""
    print("\n=== –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ ===")
    
    def build_content_filter(
        min_quality: Optional[float] = None,
        languages: Optional[List[str]] = None,
        chunk_types: Optional[List[str]] = None,
        statuses: Optional[List[str]] = None,
        public_only: bool = False,
        recent_only: bool = False,
        category: Optional[str] = None
    ) -> Tuple[Optional[ChunkQuery], Optional[dict]]:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤."""
        query_data = {}
        
        if min_quality is not None:
            query_data["quality_score"] = f">={min_quality}"
        
        # –î–ª—è enum –ø–æ–ª–µ–π –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞
        if languages and len(languages) > 0:
            query_data["language"] = languages[0]  # –¢–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        if chunk_types and len(chunk_types) > 0:
            query_data["type"] = chunk_types[0]  # –¢–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
            
        if statuses and len(statuses) > 0:
            query_data["status"] = statuses[0]  # –¢–æ–ª—å–∫–æ –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        if public_only:
            query_data["is_public"] = True
        
        if recent_only:
            query_data["year"] = ">=2023"
            
        if category:
            query_data["category"] = category
        
        return ChunkQuery.from_dict_with_validation(query_data)
    
        # 1. –ë–∞–∑–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    basic_filter, errors = build_content_filter(min_quality=0.8, public_only=True)
    assert basic_filter is not None
    print(f"‚úÖ –ë–∞–∑–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä: –∫–∞—á–µ—Å—Ç–≤–æ>={basic_filter.quality_score}")

    # 2. –§–∏–ª—å—Ç—Ä –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    prog_filter, errors = build_content_filter(
        min_quality=0.7,
        languages=["Python"],  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —è–∑—ã–∫ –∑–∞ —Ä–∞–∑ –¥–ª—è enum
        chunk_types=[ChunkType.CODE_BLOCK.value],  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ç–∏–ø –∑–∞ —Ä–∞–∑
        recent_only=True
    )
    assert prog_filter is not None
    print(f"‚úÖ –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: —è–∑—ã–∫–∏={prog_filter.language}")
    
    # 3. –§–∏–ª—å—Ç—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    doc_filter, errors = build_content_filter(
        min_quality=0.85,
        chunk_types=[ChunkType.DOC_BLOCK.value],
        statuses=[ChunkStatus.RELIABLE.value],  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–∞—Ç—É—Å –∑–∞ —Ä–∞–∑
        public_only=True,
        category="documentation"
    )
    assert doc_filter is not None
    print(f"‚úÖ –§–∏–ª—å—Ç—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: —Ç–∏–ø={doc_filter.type}, –∫–∞—Ç–µ–≥–æ—Ä–∏—è={doc_filter.category}")
    
    return [basic_filter, prog_filter, doc_filter]


def example_optimization_patterns():
    """–ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤."""
    print("\n=== –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ===")
    
    # 1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ–π (—Å–∞–º—ã–µ —Å–µ–ª–µ–∫—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    indexed_data = {
        "project": "SpecificProject",  # –í—ã—Å–æ–∫–∞—è —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        "type": ChunkType.DOC_BLOCK.value,  # –û–±—ã—á–Ω–æ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç—Å—è
        "status": ChunkStatus.RELIABLE.value,  # –û–±—ã—á–Ω–æ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç—Å—è
        "is_public": True  # –ë—É–ª–µ–≤ –∏–Ω–¥–µ–∫—Å
    }
    indexed_query, errors = ChunkQuery.from_dict_with_validation(indexed_data)
    assert errors is None
    print(f"‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤: project -> type -> status -> is_public")
    
    # 2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ (–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤–º–µ—Å—Ç–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π)
    range_data = {
        "quality_score": "[0.8,1.0]",  # –î–∏–∞–ø–∞–∑–æ–Ω –≤–º–µ—Å—Ç–æ >=0.8
        "year": "[2020,2024]",  # –î–∏–∞–ø–∞–∑–æ–Ω –≤–º–µ—Å—Ç–æ IN
        "start": "[100,1000]",  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
        "feedback_accepted": "[5,50]"  # –†–∞–∑—É–º–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
    }
    range_query, errors = ChunkQuery.from_dict_with_validation(range_data)
    assert errors is None
    print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    
    # 3. –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã)
    minimal_data = {
        "type": ChunkType.CODE_BLOCK.value,
        "language": LanguageEnum.PYTHON.value,
        "quality_score": ">=0.8"
    }
    minimal_query, errors = ChunkQuery.from_dict_with_validation(minimal_data)
    assert errors is None
    print(f"‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä: —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")
    
    # 4. –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–¥–ª—è –º–∞—Å—Å–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π)
    batch_data = {
        "status": ChunkStatus.RAW.value,  # –û–¥–∏–Ω–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ enum
        "quality_score": "<0.6",  # –ß–µ—Ç–∫–∞—è —Ü–µ–ª—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
        "year": ">=2020"  # –†–∞–∑—É–º–Ω–æ–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ
    }
    batch_query, errors = ChunkQuery.from_dict_with_validation(batch_data)
    assert errors is None
    print(f"‚úÖ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –º–∞—Å—Å–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏")
    
    return [indexed_query, range_query, minimal_query, batch_query]


def example_error_handling_patterns():
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫."""
    print("\n=== –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ ===")
    
    def safe_query_builder(query_data: dict) -> Tuple[Optional[ChunkQuery], List[str]]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
        query, errors = ChunkQuery.from_dict_with_validation(query_data)
        
        if errors:
            error_messages = []
            for field, field_errors in errors.get('fields', {}).items():
                for error in field_errors:
                    error_messages.append(f"–ü–æ–ª–µ '{field}': {error}")
            return None, error_messages
        
        return query, []
    
    def validate_and_sanitize_query(query_data: dict) -> Tuple[Optional[ChunkQuery], List[str], List[str]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å –ø–æ–ø—ã—Ç–∫–æ–π —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö."""
        warnings = []
        sanitized_data = query_data.copy()
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
        if 'type' in sanitized_data and isinstance(sanitized_data['type'], str):
            # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä
            for chunk_type in ChunkType:
                if sanitized_data['type'].lower() == chunk_type.value.lower():
                    sanitized_data['type'] = chunk_type.value
                    warnings.append(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω —Ä–µ–≥–∏—Å—Ç—Ä –¥–ª—è type: {query_data['type']} -> {chunk_type.value}")
                    break
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
        if 'quality_score' in sanitized_data:
            qs = sanitized_data['quality_score']
            if isinstance(qs, (int, float)):
                if qs > 1.0:
                    sanitized_data['quality_score'] = ">=0.8"
                    warnings.append(f"–ö–∞—á–µ—Å—Ç–≤–æ {qs} > 1.0, –∑–∞–º–µ–Ω–µ–Ω–æ –Ω–∞ '>=0.8'")
                elif qs < 0.0:
                    sanitized_data['quality_score'] = ">=0.0"
                    warnings.append(f"–ö–∞—á–µ—Å—Ç–≤–æ {qs} < 0.0, –∑–∞–º–µ–Ω–µ–Ω–æ –Ω–∞ '>=0.0'")
        
        query, errors = safe_query_builder(sanitized_data)
        return query, errors, warnings
    
    # 1. –£—Å–ø–µ—à–Ω—ã–π —Å–ª—É—á–∞–π
    valid_data = {"type": ChunkType.DOC_BLOCK.value, "quality_score": ">=0.8"}
    query, error_msgs = safe_query_builder(valid_data)
    assert query is not None
    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {query.type}")
    
    # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–µ–π
    fixable_data = {"type": "docblock", "quality_score": 1.5}  # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä –∏ –∑–Ω–∞—á–µ–Ω–∏–µ
    query, errors, warnings = validate_and_sanitize_query(fixable_data)
    if warnings:
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {'; '.join(warnings)}")
    if query:
        print(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: type={query.type}, quality={query.quality_score}")
    
    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
    critical_errors_data = {
        "uuid": "bad-uuid",
        "type": "CompletelyWrongType",
        "start": {"invalid": "object"}
    }
    query, error_msgs = safe_query_builder(critical_errors_data)
    assert query is None
    print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ ({len(error_msgs)}):")
    for msg in error_msgs[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
        print(f"   - {msg}")
    
    return error_msgs


def example_query_composition():
    """–ö–æ–º–ø–æ–∑–∏—Ü–∏—è –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤."""
    print("\n=== –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ ===")
    
    class QueryBuilder:
        """–ë–∏–ª–¥–µ—Ä –¥–ª—è –ø–æ—à–∞–≥–æ–≤–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤."""
        
        def __init__(self):
            self.data = {}
        
        def with_type(self, chunk_type: ChunkType):
            self.data["type"] = chunk_type.value
            return self
        
        def with_language(self, language: LanguageEnum):
            self.data["language"] = language.value
            return self
        
        def with_min_quality(self, min_quality: float):
            self.data["quality_score"] = f">={min_quality}"
            return self
        
        def with_status(self, status: ChunkStatus):
            """–î–æ–±–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π —Å—Ç–∞—Ç—É—Å (enum –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ)."""
            self.data["status"] = status.value
            return self
        
        def public_only(self):
            self.data["is_public"] = True
            return self
        
        def recent_only(self, year: int = 2023):
            self.data["year"] = f">={year}"
            return self
        
        def with_category(self, category: str):
            self.data["category"] = category
            return self
        
        def build(self) -> Tuple[Optional[ChunkQuery], Optional[dict]]:
            return ChunkQuery.from_dict_with_validation(self.data)
    
    # 1. –ü–æ—à–∞–≥–æ–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    quality_docs_query, errors = (QueryBuilder()
                                  .with_type(ChunkType.DOC_BLOCK)
                                  .with_language(LanguageEnum.PYTHON)
                                  .with_min_quality(0.8)
                                  .with_status(ChunkStatus.RELIABLE)
                                  .public_only()
                                  .with_category("documentation")
                                  .build())
    
    assert errors is None
    print(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: {quality_docs_query.type}, {quality_docs_query.language}")
    
    # 2. –ó–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
    code_analysis_query, errors = (QueryBuilder()
                                   .with_type(ChunkType.CODE_BLOCK)
                                   .with_language(LanguageEnum.PYTHON)
                                   .with_min_quality(0.6)
                                   .with_status(ChunkStatus.VERIFIED)  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–∞—Ç—É—Å
                                   .recent_only(2022)
                                   .build())
    
    assert errors is None
    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞: —Å—Ç–∞—Ç—É—Å—ã={code_analysis_query.status}, –≥–æ–¥={code_analysis_query.year}")
    
    # 3. –ó–∞–ø—Ä–æ—Å –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞, —Ç—Ä–µ–±—É—é—â–µ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è
    attention_needed_query, errors = (QueryBuilder()
                                      .with_min_quality(0.4)  # –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                                      .with_status(ChunkStatus.RAW)  # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–∞—Ç—É—Å
                                      .build())
    
    assert errors is None
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –≤—Ä—É—á–Ω—É—é
    attention_needed_query.feedback_rejected = ">0"  # –ï—Å—Ç—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
    attention_needed_query.used_in_generation = False  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    
    print(f"‚úÖ –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è: –∫–∞—á–µ—Å—Ç–≤–æ={attention_needed_query.quality_score}")
    
    return [quality_docs_query, code_analysis_query, attention_needed_query]


if __name__ == "__main__":
    print("üöÄ –ü–†–û–î–í–ò–ù–£–¢–´–ï –¢–ï–•–ù–ò–ö–ò –†–ê–ë–û–¢–´ –° –ó–ê–ü–†–û–°–ê–ú–ò")
    print("=" * 55)
    
    example_query_serialization()
    example_dynamic_query_building()
    example_optimization_patterns()
    example_error_handling_patterns()
    example_query_composition()
    
    print("\n" + "=" * 55)
    print("‚úÖ –í—Å–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    print("üìö –°–º. —Ç–∞–∫–∂–µ query_examples.py –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤") 