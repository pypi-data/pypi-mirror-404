{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Learning MongoDB queries and index choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from origami import DataConfig, ModelConfig, OrigamiConfig, OrigamiPipeline, TrainingConfig\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Data\n",
    "\n",
    "The car dataset contains nested JSON objects with car attributes and acceptability ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4000 train records\n",
      "Loaded 2000 test records\n",
      "\n",
      "Sample record:\n",
      "{\n",
      "  \"filter\": {\n",
      "    \"SCHEDULED_ARRIVAL\": {\n",
      "      \"$lte\": \"2118\"\n",
      "    },\n",
      "    \"ORIGIN_AIRPORT\": {\n",
      "      \"$gte\": \"TVC\"\n",
      "    },\n",
      "    \"SCHEDULED_DEPARTURE\": {\n",
      "      \"$lte\": \"0534\"\n",
      "    }\n",
      "  },\n",
      "  \"sort\": {\n",
      "    \"SCHEDULED_DEPARTURE\": 1\n",
      "  },\n",
      "  \"limit\": 819,\n",
      "  \"projection\": {\n",
      "    \"SCHEDULED_ARRIVAL\": 1,\n",
      "    \"CANCELLED\": 1,\n",
      "    \"_id\": 0\n",
      "  },\n",
      "  \"index_id\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load data from JSONL file\n",
    "train_path = Path(\"../datasets/mongodb_workload_train.jsonl\")\n",
    "with open(train_path) as f:\n",
    "    train_data = [json.loads(line) for line in f][:4000]\n",
    "\n",
    "test_path = Path(\"../datasets/mongodb_workload_test.jsonl\")\n",
    "with open(test_path) as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"Loaded {len(train_data)} train records\")\n",
    "print(f\"Loaded {len(test_data)} test records\")\n",
    "\n",
    "print(f\"\\nSample record:\")\n",
    "print(json.dumps(train_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Training with Custom Configuration\n",
    "\n",
    "`OrigamiConfig` with nested `ModelConfig`, `TrainingConfig`, and `DataConfig` lets you customize model architecture, training parameters, and preprocessing options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom configuration:\n",
      "  d_model: 128\n",
      "  n_layers: 4\n",
      "  batch_size: 100\n",
      "  shuffle_keys: True\n"
     ]
    }
   ],
   "source": [
    "from origami.training import accuracy\n",
    "\n",
    "# Create a custom configuration with nested structure\n",
    "custom_config = OrigamiConfig(\n",
    "    model=ModelConfig(\n",
    "        d_model=128,  # Embedding dimension\n",
    "        n_heads=4,  # Attention heads (must divide d_model)\n",
    "        n_layers=4,  # Transformer layers\n",
    "        d_ff=512,  # Feed-forward dimension\n",
    "        dropout=0.0,  # Dropout rate\n",
    "        use_continuous_head=True,\n",
    "        continuous_loss_weight=-1.0,\n",
    "    ),\n",
    "    training=TrainingConfig(\n",
    "        batch_size=100,\n",
    "        learning_rate=1e-3,\n",
    "        num_epochs=50,\n",
    "        warmup_steps=1000,\n",
    "        shuffle_keys=True,  # Data augmentation via key order shuffling\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        eval_metrics={\"acc\": accuracy},\n",
    "        target_key=\"index_id\",\n",
    "        eval_sample_size=100,\n",
    "        eval_on_train=True,  # Evaluate on training data as well\n",
    "    ),\n",
    "    data=DataConfig(\n",
    "        numeric_mode=\"scale\",  # Car dataset has no high-cardinality numerics\n",
    "        max_vocab_size=2000,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Custom configuration:\")\n",
    "print(f\"  d_model: {custom_config.model.d_model}\")\n",
    "print(f\"  n_layers: {custom_config.model.n_layers}\")\n",
    "print(f\"  batch_size: {custom_config.training.batch_size}\")\n",
    "print(f\"  shuffle_keys: {custom_config.training.shuffle_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| step: 10 | epoch: 0 | lr: 1.00e-05 | batch_dt:   86ms | loss: 4.9749 |\n",
      "| step: 20 | epoch: 0 | lr: 2.00e-05 | batch_dt:   90ms | loss: 4.8637 |\n",
      "| step: 30 | epoch: 0 | lr: 3.00e-05 | batch_dt:   86ms | loss: 4.7389 |\n",
      "| step: 40 | epoch: 0 | lr: 4.00e-05 | batch_dt:   84ms | loss: 4.5851 |\n",
      "| step: 50 | epoch: 1 | lr: 5.00e-05 | batch_dt:   87ms | loss: 4.3660 |\n",
      "| step: 60 | epoch: 1 | lr: 6.00e-05 | batch_dt:   78ms | loss: 4.1497 |\n",
      "| step: 70 | epoch: 1 | lr: 7.00e-05 | batch_dt:   86ms | loss: 3.9410 |\n",
      "| step: 80 | epoch: 1 | lr: 8.00e-05 | batch_dt:   90ms | loss: 3.7794 |\n",
      "| step: 90 | epoch: 2 | lr: 9.00e-05 | batch_dt:   84ms | loss: 3.5506 |\n",
      "| step: 100 | epoch: 2 | lr: 1.00e-04 | batch_dt:   87ms | loss: 3.3752 | train_acc: 0.1600 | train_loss: 3.3737 | val_acc: 0.1200 | val_loss: 3.3927 |\n",
      "| step: 110 | epoch: 2 | lr: 1.10e-04 | batch_dt:   82ms | loss: 3.1924 |\n",
      "| step: 120 | epoch: 2 | lr: 1.20e-04 | batch_dt:   87ms | loss: 3.0812 |\n",
      "| step: 130 | epoch: 3 | lr: 1.30e-04 | batch_dt:   78ms | loss: 2.8535 |\n",
      "| step: 140 | epoch: 3 | lr: 1.40e-04 | batch_dt:   84ms | loss: 2.7722 |\n",
      "| step: 150 | epoch: 3 | lr: 1.50e-04 | batch_dt:   94ms | loss: 2.5660 |\n",
      "| step: 160 | epoch: 3 | lr: 1.60e-04 | batch_dt:  100ms | loss: 2.4411 |\n",
      "| step: 170 | epoch: 4 | lr: 1.70e-04 | batch_dt:   84ms | loss: 2.2738 |\n",
      "| step: 180 | epoch: 4 | lr: 1.80e-04 | batch_dt:   84ms | loss: 2.3382 |\n",
      "| step: 190 | epoch: 4 | lr: 1.90e-04 | batch_dt:   95ms | loss: 2.1938 |\n",
      "| step: 200 | epoch: 4 | lr: 2.00e-04 | batch_dt:   88ms | loss: 2.1078 | train_acc: 0.1600 | train_loss: 1.9674 | val_acc: 0.1500 | val_loss: 1.9574 |\n",
      "| step: 210 | epoch: 5 | lr: 2.10e-04 | batch_dt:   99ms | loss: 2.0267 |\n",
      "| step: 220 | epoch: 5 | lr: 2.20e-04 | batch_dt:   82ms | loss: 1.9711 |\n",
      "| step: 230 | epoch: 5 | lr: 2.30e-04 | batch_dt:  127ms | loss: 1.8617 |\n",
      "| step: 240 | epoch: 5 | lr: 2.40e-04 | batch_dt:   80ms | loss: 1.8079 |\n",
      "| step: 250 | epoch: 6 | lr: 2.50e-04 | batch_dt:  116ms | loss: 1.7161 |\n",
      "| step: 260 | epoch: 6 | lr: 2.60e-04 | batch_dt:   89ms | loss: 1.8461 |\n",
      "| step: 270 | epoch: 6 | lr: 2.70e-04 | batch_dt:   89ms | loss: 1.7582 |\n",
      "| step: 280 | epoch: 6 | lr: 2.80e-04 | batch_dt:   93ms | loss: 1.7567 |\n",
      "| step: 290 | epoch: 7 | lr: 2.90e-04 | batch_dt:   94ms | loss: 1.7112 |\n",
      "| step: 300 | epoch: 7 | lr: 3.00e-04 | batch_dt:   89ms | loss: 1.7386 | train_acc: 0.5200 | train_loss: 1.5816 | val_acc: 0.4900 | val_loss: 1.7396 |\n",
      "| step: 310 | epoch: 7 | lr: 3.10e-04 | batch_dt:  104ms | loss: 1.6883 |\n",
      "| step: 320 | epoch: 7 | lr: 3.20e-04 | batch_dt:  107ms | loss: 1.6811 |\n",
      "| step: 330 | epoch: 8 | lr: 3.30e-04 | batch_dt:   86ms | loss: 1.7013 |\n",
      "| step: 340 | epoch: 8 | lr: 3.40e-04 | batch_dt:   86ms | loss: 1.6092 |\n",
      "| step: 350 | epoch: 8 | lr: 3.50e-04 | batch_dt:   99ms | loss: 1.7200 |\n",
      "| step: 360 | epoch: 8 | lr: 3.60e-04 | batch_dt:   99ms | loss: 1.5777 |\n",
      "| step: 370 | epoch: 9 | lr: 3.70e-04 | batch_dt:   89ms | loss: 1.5866 |\n",
      "| step: 380 | epoch: 9 | lr: 3.80e-04 | batch_dt:   78ms | loss: 1.5525 |\n",
      "| step: 390 | epoch: 9 | lr: 3.90e-04 | batch_dt:   75ms | loss: 1.5832 |\n",
      "| step: 400 | epoch: 9 | lr: 4.00e-04 | batch_dt:   97ms | loss: 1.5734 | train_acc: 0.7800 | train_loss: 1.5654 | val_acc: 0.7100 | val_loss: 1.5236 |\n",
      "| step: 410 | epoch: 10 | lr: 4.10e-04 | batch_dt:   87ms | loss: 1.6256 |\n",
      "| step: 420 | epoch: 10 | lr: 4.20e-04 | batch_dt:   95ms | loss: 1.6699 |\n",
      "| step: 430 | epoch: 10 | lr: 4.30e-04 | batch_dt:   78ms | loss: 1.4487 |\n",
      "| step: 440 | epoch: 10 | lr: 4.40e-04 | batch_dt:  103ms | loss: 1.5630 |\n",
      "| step: 450 | epoch: 11 | lr: 4.50e-04 | batch_dt:   82ms | loss: 1.5248 |\n",
      "| step: 460 | epoch: 11 | lr: 4.60e-04 | batch_dt:   95ms | loss: 1.5033 |\n",
      "| step: 470 | epoch: 11 | lr: 4.70e-04 | batch_dt:  146ms | loss: 1.5843 |\n",
      "| step: 480 | epoch: 11 | lr: 4.80e-04 | batch_dt:   77ms | loss: 1.4129 |\n",
      "| step: 490 | epoch: 12 | lr: 4.90e-04 | batch_dt:  100ms | loss: 1.4934 |\n",
      "| step: 500 | epoch: 12 | lr: 5.00e-04 | batch_dt:   81ms | loss: 1.5163 | train_acc: 0.7700 | train_loss: 1.4504 | val_acc: 0.7700 | val_loss: 1.5514 |\n",
      "| step: 510 | epoch: 12 | lr: 5.10e-04 | batch_dt:  116ms | loss: 1.4289 |\n",
      "| step: 520 | epoch: 12 | lr: 5.20e-04 | batch_dt:  117ms | loss: 1.4757 |\n",
      "| step: 530 | epoch: 13 | lr: 5.30e-04 | batch_dt:  103ms | loss: 1.5157 |\n",
      "| step: 540 | epoch: 13 | lr: 5.40e-04 | batch_dt:   88ms | loss: 1.4636 |\n",
      "| step: 550 | epoch: 13 | lr: 5.50e-04 | batch_dt:   86ms | loss: 1.4638 |\n",
      "| step: 560 | epoch: 13 | lr: 5.60e-04 | batch_dt:   88ms | loss: 1.4633 |\n",
      "| step: 570 | epoch: 14 | lr: 5.70e-04 | batch_dt:   90ms | loss: 1.3806 |\n",
      "| step: 580 | epoch: 14 | lr: 5.80e-04 | batch_dt:   85ms | loss: 1.5375 |\n",
      "| step: 590 | epoch: 14 | lr: 5.90e-04 | batch_dt:   99ms | loss: 1.4108 |\n",
      "| step: 600 | epoch: 14 | lr: 6.00e-04 | batch_dt:  102ms | loss: 1.5144 | train_acc: 0.7300 | train_loss: 1.5090 | val_acc: 0.7800 | val_loss: 1.5125 |\n",
      "| step: 610 | epoch: 15 | lr: 6.10e-04 | batch_dt:  137ms | loss: 1.4796 |\n",
      "| step: 620 | epoch: 15 | lr: 6.20e-04 | batch_dt:   85ms | loss: 1.4974 |\n",
      "| step: 630 | epoch: 15 | lr: 6.30e-04 | batch_dt:   88ms | loss: 1.3863 |\n",
      "| step: 640 | epoch: 15 | lr: 6.40e-04 | batch_dt:  100ms | loss: 1.4007 |\n",
      "| step: 650 | epoch: 16 | lr: 6.50e-04 | batch_dt:   84ms | loss: 1.3791 |\n",
      "| step: 660 | epoch: 16 | lr: 6.60e-04 | batch_dt:   86ms | loss: 1.5068 |\n",
      "| step: 670 | epoch: 16 | lr: 6.70e-04 | batch_dt:   87ms | loss: 1.4331 |\n",
      "| step: 680 | epoch: 16 | lr: 6.80e-04 | batch_dt:   86ms | loss: 1.4733 |\n",
      "| step: 690 | epoch: 17 | lr: 6.90e-04 | batch_dt:  102ms | loss: 1.3378 |\n",
      "| step: 700 | epoch: 17 | lr: 7.00e-04 | batch_dt:   98ms | loss: 1.3727 | train_acc: 0.7900 | train_loss: 1.4228 | val_acc: 0.8100 | val_loss: 1.5248 |\n",
      "| step: 710 | epoch: 17 | lr: 7.10e-04 | batch_dt:   75ms | loss: 1.4254 |\n",
      "| step: 720 | epoch: 17 | lr: 7.20e-04 | batch_dt:   96ms | loss: 1.4796 |\n",
      "| step: 730 | epoch: 18 | lr: 7.30e-04 | batch_dt:   93ms | loss: 1.4331 |\n",
      "| step: 740 | epoch: 18 | lr: 7.40e-04 | batch_dt:   88ms | loss: 1.3791 |\n",
      "| step: 750 | epoch: 18 | lr: 7.50e-04 | batch_dt:   95ms | loss: 1.4184 |\n",
      "| step: 760 | epoch: 18 | lr: 7.60e-04 | batch_dt:   97ms | loss: 1.4362 |\n",
      "| step: 770 | epoch: 19 | lr: 7.70e-04 | batch_dt:   88ms | loss: 1.4060 |\n",
      "| step: 780 | epoch: 19 | lr: 7.80e-04 | batch_dt:  107ms | loss: 1.4411 |\n",
      "| step: 790 | epoch: 19 | lr: 7.90e-04 | batch_dt:   90ms | loss: 1.3595 |\n",
      "| step: 800 | epoch: 19 | lr: 8.00e-04 | batch_dt:  101ms | loss: 1.4082 | train_acc: 0.7800 | train_loss: 1.3961 | val_acc: 0.8700 | val_loss: 1.5399 |\n",
      "| step: 810 | epoch: 20 | lr: 8.10e-04 | batch_dt:  100ms | loss: 1.3625 |\n",
      "| step: 820 | epoch: 20 | lr: 8.20e-04 | batch_dt:  107ms | loss: 1.4005 |\n",
      "| step: 830 | epoch: 20 | lr: 8.30e-04 | batch_dt:   84ms | loss: 1.4013 |\n",
      "| step: 840 | epoch: 20 | lr: 8.40e-04 | batch_dt:   74ms | loss: 1.3609 |\n",
      "| step: 850 | epoch: 21 | lr: 8.50e-04 | batch_dt:   75ms | loss: 1.2997 |\n",
      "| step: 860 | epoch: 21 | lr: 8.60e-04 | batch_dt:  134ms | loss: 1.3429 |\n",
      "| step: 870 | epoch: 21 | lr: 8.70e-04 | batch_dt:   89ms | loss: 1.3421 |\n",
      "| step: 880 | epoch: 21 | lr: 8.80e-04 | batch_dt:   93ms | loss: 1.4128 |\n",
      "| step: 890 | epoch: 22 | lr: 8.90e-04 | batch_dt:  105ms | loss: 1.3583 |\n",
      "| step: 900 | epoch: 22 | lr: 9.00e-04 | batch_dt:   91ms | loss: 1.3286 | train_acc: 0.8100 | train_loss: 1.3173 | val_acc: 0.8600 | val_loss: 1.5038 |\n",
      "| step: 910 | epoch: 22 | lr: 9.10e-04 | batch_dt:   79ms | loss: 1.3342 |\n",
      "| step: 920 | epoch: 22 | lr: 9.20e-04 | batch_dt:   98ms | loss: 1.4206 |\n",
      "| step: 930 | epoch: 23 | lr: 9.30e-04 | batch_dt:   93ms | loss: 1.3403 |\n",
      "| step: 940 | epoch: 23 | lr: 9.40e-04 | batch_dt:  111ms | loss: 1.3335 |\n",
      "| step: 950 | epoch: 23 | lr: 9.50e-04 | batch_dt:  103ms | loss: 1.3434 |\n",
      "| step: 960 | epoch: 23 | lr: 9.60e-04 | batch_dt:   85ms | loss: 1.3037 |\n",
      "| step: 970 | epoch: 24 | lr: 9.70e-04 | batch_dt:   87ms | loss: 1.2915 |\n",
      "| step: 980 | epoch: 24 | lr: 9.80e-04 | batch_dt:   96ms | loss: 1.3804 |\n",
      "| step: 990 | epoch: 24 | lr: 9.90e-04 | batch_dt:   94ms | loss: 1.3579 |\n",
      "| step: 1000 | epoch: 24 | lr: 5.00e-04 | batch_dt:  133ms | loss: 1.3539 | train_acc: 0.8300 | train_loss: 1.2983 | val_acc: 0.7900 | val_loss: 1.4911 |\n",
      "| step: 1010 | epoch: 25 | lr: 4.95e-04 | batch_dt:   89ms | loss: 1.2532 |\n",
      "| step: 1020 | epoch: 25 | lr: 4.90e-04 | batch_dt:   92ms | loss: 1.3072 |\n",
      "| step: 1030 | epoch: 25 | lr: 4.85e-04 | batch_dt:   84ms | loss: 1.3082 |\n",
      "| step: 1040 | epoch: 25 | lr: 4.80e-04 | batch_dt:   79ms | loss: 1.3163 |\n",
      "| step: 1050 | epoch: 26 | lr: 4.75e-04 | batch_dt:   89ms | loss: 1.2577 |\n",
      "| step: 1060 | epoch: 26 | lr: 4.70e-04 | batch_dt:   80ms | loss: 1.3192 |\n",
      "| step: 1070 | epoch: 26 | lr: 4.65e-04 | batch_dt:  110ms | loss: 1.3074 |\n",
      "| step: 1080 | epoch: 26 | lr: 4.60e-04 | batch_dt:  103ms | loss: 1.3457 |\n",
      "| step: 1090 | epoch: 27 | lr: 4.55e-04 | batch_dt:   94ms | loss: 1.2327 |\n",
      "| step: 1100 | epoch: 27 | lr: 4.50e-04 | batch_dt:  104ms | loss: 1.2811 | train_acc: 0.8800 | train_loss: 1.2749 | val_acc: 0.9000 | val_loss: 1.5738 |\n",
      "| step: 1110 | epoch: 27 | lr: 4.45e-04 | batch_dt:  129ms | loss: 1.2454 |\n",
      "| step: 1120 | epoch: 27 | lr: 4.40e-04 | batch_dt:   84ms | loss: 1.3205 |\n",
      "| step: 1130 | epoch: 28 | lr: 4.35e-04 | batch_dt:  124ms | loss: 1.2645 |\n",
      "| step: 1140 | epoch: 28 | lr: 4.30e-04 | batch_dt:   87ms | loss: 1.2722 |\n",
      "| step: 1150 | epoch: 28 | lr: 4.25e-04 | batch_dt:   91ms | loss: 1.2518 |\n",
      "| step: 1160 | epoch: 28 | lr: 4.20e-04 | batch_dt:   90ms | loss: 1.2482 |\n",
      "| step: 1170 | epoch: 29 | lr: 4.15e-04 | batch_dt:   86ms | loss: 1.2198 |\n",
      "| step: 1180 | epoch: 29 | lr: 4.10e-04 | batch_dt:   90ms | loss: 1.1855 |\n",
      "| step: 1190 | epoch: 29 | lr: 4.05e-04 | batch_dt:   96ms | loss: 1.2487 |\n",
      "| step: 1200 | epoch: 29 | lr: 4.00e-04 | batch_dt:   85ms | loss: 1.2588 | train_acc: 0.8100 | train_loss: 1.2234 | val_acc: 0.8900 | val_loss: 1.4630 |\n",
      "| step: 1210 | epoch: 30 | lr: 3.95e-04 | batch_dt:  103ms | loss: 1.2377 |\n",
      "| step: 1220 | epoch: 30 | lr: 3.90e-04 | batch_dt:   84ms | loss: 1.2318 |\n",
      "| step: 1230 | epoch: 30 | lr: 3.85e-04 | batch_dt:   90ms | loss: 1.1788 |\n",
      "| step: 1240 | epoch: 30 | lr: 3.80e-04 | batch_dt:   97ms | loss: 1.2744 |\n",
      "| step: 1250 | epoch: 31 | lr: 3.75e-04 | batch_dt:   94ms | loss: 1.2439 |\n",
      "| step: 1260 | epoch: 31 | lr: 3.70e-04 | batch_dt:   74ms | loss: 1.2479 |\n",
      "| step: 1270 | epoch: 31 | lr: 3.65e-04 | batch_dt:   76ms | loss: 1.2524 |\n",
      "| step: 1280 | epoch: 31 | lr: 3.60e-04 | batch_dt:   82ms | loss: 1.2200 |\n",
      "| step: 1290 | epoch: 32 | lr: 3.55e-04 | batch_dt:   98ms | loss: 1.2069 |\n",
      "| step: 1300 | epoch: 32 | lr: 3.50e-04 | batch_dt:   86ms | loss: 1.2379 | train_acc: 0.8700 | train_loss: 1.1737 | val_acc: 0.8600 | val_loss: 1.5796 |\n",
      "| step: 1310 | epoch: 32 | lr: 3.45e-04 | batch_dt:  102ms | loss: 1.1997 |\n",
      "| step: 1320 | epoch: 32 | lr: 3.40e-04 | batch_dt:   78ms | loss: 1.2028 |\n",
      "| step: 1330 | epoch: 33 | lr: 3.35e-04 | batch_dt:   84ms | loss: 1.1961 |\n",
      "| step: 1340 | epoch: 33 | lr: 3.30e-04 | batch_dt:   79ms | loss: 1.2343 |\n",
      "| step: 1350 | epoch: 33 | lr: 3.25e-04 | batch_dt:  102ms | loss: 1.2538 |\n",
      "| step: 1360 | epoch: 33 | lr: 3.20e-04 | batch_dt:   80ms | loss: 1.1956 |\n",
      "| step: 1370 | epoch: 34 | lr: 3.15e-04 | batch_dt:   86ms | loss: 1.2116 |\n",
      "| step: 1380 | epoch: 34 | lr: 3.10e-04 | batch_dt:   96ms | loss: 1.2312 |\n",
      "| step: 1390 | epoch: 34 | lr: 3.05e-04 | batch_dt:   91ms | loss: 1.1839 |\n",
      "| step: 1400 | epoch: 34 | lr: 3.00e-04 | batch_dt:   92ms | loss: 1.1846 | train_acc: 0.8700 | train_loss: 1.1762 | val_acc: 0.8800 | val_loss: 1.5644 |\n",
      "| step: 1410 | epoch: 35 | lr: 2.95e-04 | batch_dt:   84ms | loss: 1.1650 |\n",
      "| step: 1420 | epoch: 35 | lr: 2.90e-04 | batch_dt:   90ms | loss: 1.2132 |\n",
      "| step: 1430 | epoch: 35 | lr: 2.85e-04 | batch_dt:   98ms | loss: 1.2080 |\n",
      "| step: 1440 | epoch: 35 | lr: 2.80e-04 | batch_dt:   89ms | loss: 1.1619 |\n",
      "| step: 1450 | epoch: 36 | lr: 2.75e-04 | batch_dt:  100ms | loss: 1.1755 |\n",
      "| step: 1460 | epoch: 36 | lr: 2.70e-04 | batch_dt:   86ms | loss: 1.1897 |\n",
      "| step: 1470 | epoch: 36 | lr: 2.65e-04 | batch_dt:   95ms | loss: 1.2404 |\n",
      "| step: 1480 | epoch: 36 | lr: 2.60e-04 | batch_dt:   91ms | loss: 1.1847 |\n",
      "| step: 1490 | epoch: 37 | lr: 2.55e-04 | batch_dt:   98ms | loss: 1.1844 |\n",
      "| step: 1500 | epoch: 37 | lr: 2.50e-04 | batch_dt:   78ms | loss: 1.1846 | train_acc: 0.8600 | train_loss: 1.1724 | val_acc: 0.8200 | val_loss: 1.6529 |\n",
      "| step: 1510 | epoch: 37 | lr: 2.45e-04 | batch_dt:   91ms | loss: 1.1482 |\n",
      "| step: 1520 | epoch: 37 | lr: 2.40e-04 | batch_dt:  110ms | loss: 1.1918 |\n",
      "| step: 1530 | epoch: 38 | lr: 2.35e-04 | batch_dt:  101ms | loss: 1.1478 |\n",
      "| step: 1540 | epoch: 38 | lr: 2.30e-04 | batch_dt:   78ms | loss: 1.1499 |\n",
      "| step: 1550 | epoch: 38 | lr: 2.25e-04 | batch_dt:   75ms | loss: 1.1845 |\n",
      "| step: 1560 | epoch: 38 | lr: 2.20e-04 | batch_dt:   97ms | loss: 1.1844 |\n",
      "| step: 1570 | epoch: 39 | lr: 2.15e-04 | batch_dt:   97ms | loss: 1.1571 |\n",
      "| step: 1580 | epoch: 39 | lr: 2.10e-04 | batch_dt:   83ms | loss: 1.1929 |\n",
      "| step: 1590 | epoch: 39 | lr: 2.05e-04 | batch_dt:   90ms | loss: 1.2221 |\n",
      "| step: 1600 | epoch: 39 | lr: 2.00e-04 | batch_dt:   89ms | loss: 1.1619 | train_acc: 0.8400 | train_loss: 1.1794 | val_acc: 0.8800 | val_loss: 1.5553 |\n",
      "| step: 1610 | epoch: 40 | lr: 1.95e-04 | batch_dt:   91ms | loss: 1.1606 |\n",
      "| step: 1620 | epoch: 40 | lr: 1.90e-04 | batch_dt:   92ms | loss: 1.1576 |\n",
      "| step: 1630 | epoch: 40 | lr: 1.85e-04 | batch_dt:   87ms | loss: 1.1792 |\n",
      "| step: 1640 | epoch: 40 | lr: 1.80e-04 | batch_dt:   84ms | loss: 1.2258 |\n",
      "| step: 1650 | epoch: 41 | lr: 1.75e-04 | batch_dt:   86ms | loss: 1.1425 |\n",
      "| step: 1660 | epoch: 41 | lr: 1.70e-04 | batch_dt:   85ms | loss: 1.1486 |\n",
      "| step: 1670 | epoch: 41 | lr: 1.65e-04 | batch_dt:   95ms | loss: 1.1696 |\n",
      "| step: 1680 | epoch: 41 | lr: 1.60e-04 | batch_dt:   84ms | loss: 1.1117 |\n",
      "| step: 1690 | epoch: 42 | lr: 1.55e-04 | batch_dt:  100ms | loss: 1.1523 |\n",
      "| step: 1700 | epoch: 42 | lr: 1.50e-04 | batch_dt:   90ms | loss: 1.1215 | train_acc: 0.8500 | train_loss: 1.1661 | val_acc: 0.9100 | val_loss: 1.4352 |\n",
      "| step: 1710 | epoch: 42 | lr: 1.45e-04 | batch_dt:   97ms | loss: 1.1566 |\n",
      "| step: 1720 | epoch: 42 | lr: 1.40e-04 | batch_dt:   77ms | loss: 1.1720 |\n",
      "| step: 1730 | epoch: 43 | lr: 1.35e-04 | batch_dt:   97ms | loss: 1.1419 |\n",
      "| step: 1740 | epoch: 43 | lr: 1.30e-04 | batch_dt:   82ms | loss: 1.1297 |\n",
      "| step: 1750 | epoch: 43 | lr: 1.25e-04 | batch_dt:   77ms | loss: 1.1006 |\n",
      "| step: 1760 | epoch: 43 | lr: 1.20e-04 | batch_dt:   94ms | loss: 1.1455 |\n",
      "| step: 1770 | epoch: 44 | lr: 1.15e-04 | batch_dt:   91ms | loss: 1.1339 |\n",
      "| step: 1780 | epoch: 44 | lr: 1.10e-04 | batch_dt:   98ms | loss: 1.1494 |\n",
      "| step: 1790 | epoch: 44 | lr: 1.05e-04 | batch_dt:   86ms | loss: 1.1228 |\n",
      "| step: 1800 | epoch: 44 | lr: 1.00e-04 | batch_dt:   88ms | loss: 1.2045 | train_acc: 0.8600 | train_loss: 1.1209 | val_acc: 0.9000 | val_loss: 1.6332 |\n",
      "| step: 1810 | epoch: 45 | lr: 9.50e-05 | batch_dt:   91ms | loss: 1.1309 |\n",
      "| step: 1820 | epoch: 45 | lr: 9.00e-05 | batch_dt:   75ms | loss: 1.1455 |\n",
      "| step: 1830 | epoch: 45 | lr: 8.50e-05 | batch_dt:  116ms | loss: 1.1436 |\n",
      "| step: 1840 | epoch: 45 | lr: 8.00e-05 | batch_dt:  100ms | loss: 1.1520 |\n",
      "| step: 1850 | epoch: 46 | lr: 7.50e-05 | batch_dt:   90ms | loss: 1.1202 |\n",
      "| step: 1860 | epoch: 46 | lr: 7.00e-05 | batch_dt:   86ms | loss: 1.1541 |\n",
      "| step: 1870 | epoch: 46 | lr: 6.50e-05 | batch_dt:   97ms | loss: 1.1675 |\n",
      "| step: 1880 | epoch: 46 | lr: 6.00e-05 | batch_dt:   92ms | loss: 1.1473 |\n",
      "| step: 1890 | epoch: 47 | lr: 5.50e-05 | batch_dt:   80ms | loss: 1.0981 |\n",
      "| step: 1900 | epoch: 47 | lr: 5.00e-05 | batch_dt:   84ms | loss: 1.1054 | train_acc: 0.8700 | train_loss: 1.1205 | val_acc: 0.8800 | val_loss: 1.5140 |\n",
      "| step: 1910 | epoch: 47 | lr: 4.50e-05 | batch_dt:  118ms | loss: 1.1006 |\n",
      "| step: 1920 | epoch: 47 | lr: 4.00e-05 | batch_dt:  127ms | loss: 1.1334 |\n",
      "| step: 1930 | epoch: 48 | lr: 3.50e-05 | batch_dt:   88ms | loss: 1.1192 |\n",
      "| step: 1940 | epoch: 48 | lr: 3.00e-05 | batch_dt:  104ms | loss: 1.1136 |\n",
      "| step: 1950 | epoch: 48 | lr: 2.50e-05 | batch_dt:   93ms | loss: 1.1007 |\n",
      "| step: 1960 | epoch: 48 | lr: 2.00e-05 | batch_dt:   84ms | loss: 1.1500 |\n",
      "| step: 1970 | epoch: 49 | lr: 1.50e-05 | batch_dt:   78ms | loss: 1.1359 |\n",
      "| step: 1980 | epoch: 49 | lr: 1.00e-05 | batch_dt:   89ms | loss: 1.1555 |\n",
      "| step: 1990 | epoch: 49 | lr: 5.00e-06 | batch_dt:  135ms | loss: 1.1319 |\n",
      "| step: 2000 | epoch: 49 | lr: 0.00e+00 | batch_dt:   87ms | loss: 1.1076 | train_acc: 0.8900 | train_loss: 1.1494 | val_acc: 0.8500 | val_loss: 1.6435 |\n",
      "\n",
      "Training complete!\n",
      "Model parameters: 1,342,175\n"
     ]
    }
   ],
   "source": [
    "from origami.training import TableLogCallback\n",
    "\n",
    "# Create and train pipeline with custom config\n",
    "pipeline = OrigamiPipeline(custom_config)\n",
    "pipeline.fit(train_data, eval_data=test_data, callbacks=[TableLogCallback(print_every=10)])\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Model parameters: {pipeline._model.get_num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0366091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 1.5894116503851754, 'acc': 0.868}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.evaluate(test_data, metrics={\"acc\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pipeline.embed_batch(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "origami",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
