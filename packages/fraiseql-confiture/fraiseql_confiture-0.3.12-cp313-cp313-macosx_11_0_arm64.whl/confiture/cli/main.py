"""Main CLI entry point for Confiture.

This module defines the main Typer application and all CLI commands.
"""

from pathlib import Path
from typing import Any

import typer
from rich.console import Console
from rich.table import Table

from confiture.cli.branch import branch_app
from confiture.cli.coordinate import coordinate_app
from confiture.cli.generate import generate_app
from confiture.cli.lint_formatter import format_lint_report, save_report
from confiture.cli.seed import seed_app
from confiture.core.builder import SchemaBuilder
from confiture.core.differ import SchemaDiffer
from confiture.core.linting import SchemaLinter
from confiture.core.linting.schema_linter import (
    LintConfig as LinterConfig,
)
from confiture.core.linting.schema_linter import (
    LintReport as LinterReport,
)
from confiture.core.linting.schema_linter import (
    RuleSeverity,
)
from confiture.core.migration_generator import MigrationGenerator
from confiture.models.lint import LintReport, LintSeverity, Violation

# Valid output formats for linting
LINT_FORMATS = ("table", "json", "csv")


def _convert_linter_report(linter_report: LinterReport, schema_name: str = "schema") -> LintReport:
    """Convert a schema_linter.LintReport to models.lint.LintReport.

    Args:
        linter_report: Report from SchemaLinter
        schema_name: Name of schema being linted

    Returns:
        LintReport compatible with format_lint_report
    """
    violations = []

    # Map RuleSeverity to LintSeverity
    severity_map = {
        RuleSeverity.ERROR: LintSeverity.ERROR,
        RuleSeverity.WARNING: LintSeverity.WARNING,
        RuleSeverity.INFO: LintSeverity.INFO,
    }

    # Convert all violations
    for violation in linter_report.errors:
        violations.append(
            Violation(
                rule_name=violation.rule_name,
                severity=severity_map[violation.severity],
                message=violation.message,
                location=violation.object_name,
            )
        )

    for violation in linter_report.warnings:
        violations.append(
            Violation(
                rule_name=violation.rule_name,
                severity=severity_map[violation.severity],
                message=violation.message,
                location=violation.object_name,
            )
        )

    for violation in linter_report.info:
        violations.append(
            Violation(
                rule_name=violation.rule_name,
                severity=severity_map[violation.severity],
                message=violation.message,
                location=violation.object_name,
            )
        )

    return LintReport(
        violations=violations,
        schema_name=schema_name,
        tables_checked=0,  # Not tracked in linter
        columns_checked=0,  # Not tracked in linter
        errors_count=len(linter_report.errors),
        warnings_count=len(linter_report.warnings),
        info_count=len(linter_report.info),
        execution_time_ms=0,  # Not tracked in linter
    )


# Create Typer app
app = typer.Typer(
    name="confiture",
    help="PostgreSQL migrations, sweetly done ðŸ“",
    add_completion=False,
)

# Create Rich console for pretty output
console = Console()

# Version
__version__ = "0.3.12"


def version_callback(value: bool) -> None:
    """Print version and exit."""
    if value:
        console.print(f"confiture version {__version__}")
        raise typer.Exit()


@app.callback()
def main(
    version: bool = typer.Option(
        False,
        "--version",
        callback=version_callback,
        is_eager=True,
        help="Show version and exit",
    ),
) -> None:
    """Confiture - PostgreSQL migrations, sweetly done ðŸ“."""
    pass


@app.command()
def init(
    path: Path = typer.Argument(
        Path("."),
        help="Project directory to initialize",
    ),
) -> None:
    """Initialize a new Confiture project.

    Creates necessary directory structure and configuration files.
    """
    try:
        # Create directory structure
        db_dir = path / "db"
        schema_dir = db_dir / "schema"
        seeds_dir = db_dir / "seeds"
        migrations_dir = db_dir / "migrations"
        environments_dir = db_dir / "environments"

        # Check if already initialized
        if db_dir.exists():
            console.print(
                "[yellow]âš ï¸  Project already exists. Some files may be overwritten.[/yellow]"
            )
            if not typer.confirm("Continue?"):
                raise typer.Exit()

        # Create directories
        schema_dir.mkdir(parents=True, exist_ok=True)
        (seeds_dir / "common").mkdir(parents=True, exist_ok=True)
        (seeds_dir / "development").mkdir(parents=True, exist_ok=True)
        (seeds_dir / "test").mkdir(parents=True, exist_ok=True)
        migrations_dir.mkdir(parents=True, exist_ok=True)
        environments_dir.mkdir(parents=True, exist_ok=True)

        # Create example schema directory structure
        (schema_dir / "00_common").mkdir(exist_ok=True)
        (schema_dir / "10_tables").mkdir(exist_ok=True)

        # Create example schema file
        example_schema = schema_dir / "00_common" / "extensions.sql"
        example_schema.write_text(
            """-- PostgreSQL extensions
-- Add commonly used extensions here

-- Example:
-- CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
-- CREATE EXTENSION IF NOT EXISTS "pg_trgm";
"""
        )

        # Create example table
        example_table = schema_dir / "10_tables" / "example.sql"
        example_table.write_text(
            """-- Example table
-- Replace with your actual schema

CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,
    username TEXT NOT NULL UNIQUE,
    email TEXT NOT NULL UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);
"""
        )

        # Create example seed file
        example_seed = seeds_dir / "common" / "00_example.sql"
        example_seed.write_text(
            """-- Common seed data
-- These records are included in all non-production environments

-- Example: Test users
-- INSERT INTO users (username, email) VALUES
--     ('admin', 'admin@example.com'),
--     ('editor', 'editor@example.com'),
--     ('reader', 'reader@example.com');
"""
        )

        # Create local environment config
        local_config = environments_dir / "local.yaml"
        local_config.write_text(
            """# Local development environment configuration

name: local
include_dirs:
  - db/schema/00_common
  - db/schema/10_tables
exclude_dirs: []

database:
  host: localhost
  port: 5432
  database: myapp_local
  user: postgres
  password: postgres
"""
        )

        # Create README
        readme = db_dir / "README.md"
        readme.write_text(
            """# Database Schema

This directory contains your database schema and migrations.

## Directory Structure

- `schema/` - DDL files organized by category
  - `00_common/` - Extensions, types, functions
  - `10_tables/` - Table definitions
- `migrations/` - Python migration files
- `environments/` - Environment-specific configurations

## Quick Start

1. Edit schema files in `schema/`
2. Generate migrations: `confiture migrate diff old.sql new.sql --generate`
3. Apply migrations: `confiture migrate up`

## Learn More

Documentation: https://github.com/evoludigit/confiture
"""
        )

        console.print("[green]âœ… Confiture project initialized successfully![/green]")
        console.print(f"\nðŸ“ Created structure in: {path.absolute()}")
        console.print("\nðŸ“ Next steps:")
        console.print("  1. Edit your schema files in db/schema/")
        console.print("  2. Configure environments in db/environments/")
        console.print("  3. Run 'confiture migrate diff' to detect changes")

    except Exception as e:
        console.print(f"[red]âŒ Error initializing project: {e}[/red]")
        raise typer.Exit(1) from e


@app.command()
def build(
    env: str = typer.Option(
        "local",
        "--env",
        "-e",
        help="Environment to build (references db/environments/{env}.yaml)",
    ),
    output: Path = typer.Option(
        None,
        "--output",
        "-o",
        help="Output file path (default: db/generated/schema_{env}.sql)",
    ),
    project_dir: Path = typer.Option(
        Path("."),
        "--project-dir",
        help="Project directory (default: current directory)",
    ),
    show_hash: bool = typer.Option(
        False,
        "--show-hash",
        help="Display schema hash after build",
    ),
    schema_only: bool = typer.Option(
        False,
        "--schema-only",
        help="Build schema only, exclude seed data",
    ),
) -> None:
    """Build complete schema from DDL files.

    This command builds a complete schema by concatenating all SQL files
    from the db/schema/ directory in deterministic order. This is the
    fastest way to create or recreate a database from scratch.

    The build process:
    1. Reads environment configuration (db/environments/{env}.yaml)
    2. Discovers all .sql files in configured include_dirs
    3. Concatenates files in alphabetical order
    4. Adds metadata headers (environment, file count, timestamp)
    5. Writes to output file (default: db/generated/schema_{env}.sql)

    Examples:
        # Build local environment schema
        confiture build

        # Build for specific environment
        confiture build --env production

        # Custom output location
        confiture build --output /tmp/schema.sql

        # Show hash for change detection
        confiture build --show-hash
    """
    try:
        # Create schema builder
        builder = SchemaBuilder(env=env, project_dir=project_dir)

        # Override to exclude seeds if --schema-only is specified
        if schema_only:
            builder.include_dirs = [d for d in builder.include_dirs if "seed" not in str(d).lower()]
            # Recalculate base_dir after filtering
            if builder.include_dirs:
                builder.base_dir = builder._find_common_parent(builder.include_dirs)

        # Set default output path if not specified
        if output is None:
            output_dir = project_dir / "db" / "generated"
            output_dir.mkdir(parents=True, exist_ok=True)
            output = output_dir / f"schema_{env}.sql"

        # Build schema
        console.print(f"[cyan]ðŸ”¨ Building schema for environment: {env}[/cyan]")

        sql_files = builder.find_sql_files()
        console.print(f"[cyan]ðŸ“„ Found {len(sql_files)} SQL files[/cyan]")

        schema = builder.build(output_path=output)

        # Success message
        console.print("[green]âœ… Schema built successfully![/green]")
        console.print(f"\nðŸ“ Output: {output.absolute()}")
        console.print(f"ðŸ“ Size: {len(schema):,} bytes")
        console.print(f"ðŸ“Š Files: {len(sql_files)}")

        # Show hash if requested
        if show_hash:
            schema_hash = builder.compute_hash()
            console.print(f"ðŸ” Hash: {schema_hash}")

        console.print("\nðŸ’¡ Next steps:")
        console.print(f"  â€¢ Apply schema: psql -f {output}")
        console.print("  â€¢ Or use: confiture migrate up")

    except FileNotFoundError as e:
        console.print(f"[red]âŒ File not found: {e}[/red]")
        console.print("\nðŸ’¡ Tip: Run 'confiture init' to create project structure")
        raise typer.Exit(1) from e
    except Exception as e:
        console.print(f"[red]âŒ Error building schema: {e}[/red]")
        raise typer.Exit(1) from e


@app.command()
def lint(
    env: str = typer.Option(
        "local",
        "--env",
        "-e",
        help="Environment to lint (references db/environments/{env}.yaml)",
    ),
    project_dir: Path = typer.Option(
        Path("."),
        "--project-dir",
        help="Project directory (default: current directory)",
    ),
    format_type: str = typer.Option(
        "table",
        "--format",
        "-f",
        help="Output format (table, json, csv)",
    ),
    output: Path = typer.Option(
        None,
        "--output",
        "-o",
        help="Output file path (only with json/csv format)",
    ),
    fail_on_error: bool = typer.Option(
        True,
        "--fail-on-error",
        help="Exit with code 1 if errors found",
    ),
    fail_on_warning: bool = typer.Option(
        False,
        "--fail-on-warning",
        help="Exit with code 1 if warnings found (stricter)",
    ),
) -> None:
    """Lint schema against best practices.

    Validates the schema against 6 built-in linting rules:
    - Naming conventions (snake_case)
    - Primary keys on all tables
    - Documentation (COMMENT on tables)
    - Multi-tenant identifier columns
    - Indexes on foreign keys
    - Security best practices (passwords, tokens, secrets)

    Examples:
        # Lint local environment, display as table
        confiture lint

        # Lint production environment, output as JSON
        confiture lint --env production --format json

        # Save results to file
        confiture lint --format json --output lint-report.json

        # Strict mode: fail on warnings
        confiture lint --fail-on-warning
    """
    try:
        # Validate format option
        if format_type not in LINT_FORMATS:
            console.print(f"[red]âŒ Invalid format: {format_type}[/red]")
            console.print(f"Valid formats: {', '.join(LINT_FORMATS)}")
            raise typer.Exit(1)

        # Create linter configuration (use LinterConfig for the linter)
        config = LinterConfig(
            enabled=True,
            fail_on_error=fail_on_error,
            fail_on_warning=fail_on_warning,
        )

        # Create linter and run linting
        console.print(f"[cyan]ðŸ” Linting schema for environment: {env}[/cyan]")
        linter = SchemaLinter(env=env, config=config)
        linter_report = linter.lint()

        # Convert to model LintReport for formatting
        report = _convert_linter_report(linter_report, schema_name=env)

        # Display results based on format
        if format_type == "table":
            format_lint_report(report, format_type="table", console=console)
        else:
            # JSON/CSV format: format and optionally save
            # Cast format_type for type checker
            fmt = "json" if format_type == "json" else "csv"
            formatted = format_lint_report(
                report,
                format_type=fmt,
                console=console,
            )

            if output:
                save_report(report, output, format_type=fmt)
                console.print(f"[green]âœ… Report saved to: {output.absolute()}[/green]")
            else:
                console.print(formatted)

        # Determine exit code based on violations and fail mode
        should_fail = (report.has_errors and fail_on_error) or (
            report.has_warnings and fail_on_warning
        )
        if should_fail:
            raise typer.Exit(1)

    except FileNotFoundError as e:
        console.print(f"[red]âŒ File not found: {e}[/red]")
        console.print("\nðŸ’¡ Tip: Make sure schema files exist in db/schema/")
        raise typer.Exit(1) from e
    except Exception as e:
        console.print(f"[red]âŒ Error linting schema: {e}[/red]")
        raise typer.Exit(1) from e


# Create migrate subcommand group
migrate_app = typer.Typer(help="Migration commands")
app.add_typer(migrate_app, name="migrate")

# Add branch subcommand group (pgGit integration)
app.add_typer(branch_app, name="branch")

# Add generate subcommand group (pgGit migration generation)
app.add_typer(generate_app, name="generate")

# Add coordinate subcommand group (multi-agent coordination)
app.add_typer(coordinate_app, name="coordinate")

# Add seed subcommand group (seed validation)
app.add_typer(seed_app, name="seed")


@migrate_app.command("status")
def migrate_status(
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    config: Path = typer.Option(
        None,
        "--config",
        "-c",
        help="Configuration file (optional, to show applied status)",
    ),
    output_format: str = typer.Option(
        "table",
        "--format",
        "-f",
        help="Output format: table (default) or json",
    ),
    output_file: Path = typer.Option(
        None,
        "--output",
        "-o",
        help="Save output to file (useful with --format json)",
    ),
) -> None:
    """Show migration status.

    If config is provided, shows which migrations are applied vs pending.

    Examples:
        confiture migrate status
        confiture migrate status --format json
        confiture migrate status -f json -o status.json
    """
    try:
        # Validate output format
        if output_format not in ("table", "json"):
            console.print(f"[red]âŒ Invalid format: {output_format}. Use 'table' or 'json'[/red]")
            raise typer.Exit(1)

        if not migrations_dir.exists():
            if output_format == "json":
                result = {"error": f"Migrations directory not found: {migrations_dir.absolute()}"}
                _output_json(result, output_file, console)
            else:
                console.print("[yellow]No migrations directory found.[/yellow]")
                console.print(f"Expected: {migrations_dir.absolute()}")
            return

        # Find migration files (both Python and SQL)
        py_files = list(migrations_dir.glob("*.py"))
        sql_files = list(migrations_dir.glob("*.up.sql"))
        migration_files = sorted(py_files + sql_files, key=lambda f: f.name.split("_")[0])

        # Check for orphaned SQL files that don't match the naming pattern
        orphaned_sql_files = _find_orphaned_sql_files(migrations_dir)

        if not migration_files:
            if output_format == "json":
                result = {
                    "applied": [],
                    "pending": [],
                    "current": None,
                    "total": 0,
                    "migrations": [],
                }
                if orphaned_sql_files:
                    result["orphaned_migrations"] = [f.name for f in orphaned_sql_files]
                _output_json(result, output_file, console)
            else:
                console.print("[yellow]No migrations found.[/yellow]")
                if orphaned_sql_files:
                    _print_orphaned_files_warning(orphaned_sql_files, console)
            return

        # Get applied migrations from database if config provided
        applied_versions: set[str] = set()
        db_error: str | None = None
        if config and config.exists():
            try:
                from confiture.core.connection import create_connection, load_config
                from confiture.core.migrator import Migrator

                config_data = load_config(config)
                conn = create_connection(config_data)
                migrator = Migrator(connection=conn)
                migrator.initialize()
                applied_versions = set(migrator.get_applied_versions())
                conn.close()
            except Exception as e:
                db_error = str(e)
                if output_format != "json":
                    console.print(f"[yellow]âš ï¸  Could not connect to database: {e}[/yellow]")
                    console.print("[yellow]Showing file list only (status unknown)[/yellow]\n")

        # Build migrations data
        migrations_data: list[dict[str, str]] = []
        applied_list: list[str] = []
        pending_list: list[str] = []

        for migration_file in migration_files:
            # Extract version and name from filename
            # Python: "001_add_users.py" -> version="001", name="add_users"
            # SQL: "001_add_users.up.sql" -> version="001", name="add_users"
            base_name = migration_file.stem
            if base_name.endswith(".up"):
                base_name = base_name[:-3]  # Remove ".up" suffix
            parts = base_name.split("_", 1)
            version = parts[0] if len(parts) > 0 else "???"
            name = parts[1] if len(parts) > 1 else base_name

            # Determine status
            if applied_versions:
                if version in applied_versions:
                    status = "applied"
                    applied_list.append(version)
                else:
                    status = "pending"
                    pending_list.append(version)
            else:
                status = "unknown"

            migrations_data.append(
                {
                    "version": version,
                    "name": name,
                    "status": status,
                }
            )

        # Determine current version (highest applied)
        current_version = applied_list[-1] if applied_list else None

        if output_format == "json":
            result: dict[str, Any] = {
                "applied": applied_list,
                "pending": pending_list,
                "current": current_version,
                "total": len(migration_files),
                "migrations": migrations_data,
            }
            if db_error:
                result["warning"] = f"Could not connect to database: {db_error}"
            if orphaned_sql_files:
                result["orphaned_migrations"] = [f.name for f in orphaned_sql_files]
            _output_json(result, output_file, console)
        else:
            # Display migrations in a table
            table = Table(title="Migrations")
            table.add_column("Version", style="cyan")
            table.add_column("Name", style="green")
            table.add_column("Status", style="yellow")

            for migration in migrations_data:
                if migration["status"] == "applied":
                    status_display = "[green]âœ… applied[/green]"
                elif migration["status"] == "pending":
                    status_display = "[yellow]â³ pending[/yellow]"
                else:
                    status_display = "unknown"

                table.add_row(migration["version"], migration["name"], status_display)

            console.print(table)
            console.print(f"\nðŸ“Š Total: {len(migration_files)} migrations", end="")
            if applied_versions:
                console.print(f" ({len(applied_list)} applied, {len(pending_list)} pending)")
            else:
                console.print()

            # Warn about orphaned files
            if orphaned_sql_files:
                _print_orphaned_files_warning(orphaned_sql_files, console)

    except Exception as e:
        if output_format == "json":
            result = {"error": str(e)}
            _output_json(result, output_file, console)
        else:
            console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


def _output_json(data: dict[str, Any], output_file: Path | None, console: Console) -> None:
    """Output JSON data to file or console.

    Args:
        data: Data to output as JSON
        output_file: Optional file to write to
        console: Console for output
    """
    import json

    json_str = json.dumps(data, indent=2)
    if output_file:
        output_file.write_text(json_str)
        console.print(f"[green]âœ… Output written to {output_file}[/green]")
    else:
        # Use print() instead of console.print() to avoid Rich wrapping long lines
        print(json_str)


def _find_orphaned_sql_files(migrations_dir: Path) -> list[Path]:
    """Find .sql files that don't match the expected naming pattern.

    Args:
        migrations_dir: Directory to search for migrations

    Returns:
        List of orphaned .sql file paths
    """
    if not migrations_dir.exists():
        return []

    # Find all .sql files
    all_sql_files = set(migrations_dir.glob("*.sql"))

    # Find all properly named migration files
    expected_files = set(migrations_dir.glob("*.up.sql")) | set(migrations_dir.glob("*.down.sql"))

    # Orphaned files are SQL files that don't match the expected pattern
    orphaned = all_sql_files - expected_files
    return sorted(orphaned, key=lambda f: f.name)


def _print_orphaned_files_warning(orphaned_files: list[Path], console: Console) -> None:
    """Print a warning about orphaned migration files.

    Args:
        orphaned_files: List of orphaned migration file paths
        console: Console for output
    """
    console.print("\n[yellow]âš ï¸  WARNING: Orphaned migration files detected[/yellow]")
    console.print("[yellow]These SQL files exist but won't be applied by Confiture:[/yellow]")

    for orphaned_file in orphaned_files:
        # Suggest the rename
        suggested_name = f"{orphaned_file.stem}.up.sql"
        console.print(f"  â€¢ {orphaned_file.name} â†’ rename to: {suggested_name}")

    console.print(
        "\n[yellow]Confiture only recognizes migration files with these patterns:[/yellow]"
    )
    console.print("[yellow]  â€¢ {NNN}_{name}.up.sql   (forward migrations)[/yellow]")
    console.print("[yellow]  â€¢ {NNN}_{name}.down.sql (rollback migrations)[/yellow]")
    console.print("[yellow]  â€¢ {NNN}_{name}.py       (Python class migrations)[/yellow]")
    console.print("[yellow]Learn more: https://github.com/evoludigit/confiture/issues/13[/yellow]")


@migrate_app.command("up")
def migrate_up(
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    config: Path = typer.Option(
        Path("db/environments/local.yaml"),
        "--config",
        "-c",
        help="Configuration file",
    ),
    target: str = typer.Option(
        None,
        "--target",
        "-t",
        help="Target migration version (applies all if not specified)",
    ),
    strict: bool = typer.Option(
        False,
        "--strict",
        help="Enable strict mode (fail on warnings)",
    ),
    force: bool = typer.Option(
        False,
        "--force",
        help="Force migration application, skipping state checks",
    ),
    lock_timeout: int = typer.Option(
        30000,
        "--lock-timeout",
        help="Lock acquisition timeout in milliseconds (default: 30000ms = 30s)",
    ),
    no_lock: bool = typer.Option(
        False,
        "--no-lock",
        help="Disable migration locking (DANGEROUS in multi-pod environments)",
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Analyze migrations without executing (metadata queries only)",
    ),
    dry_run_execute: bool = typer.Option(
        False,
        "--dry-run-execute",
        help="Execute migrations in SAVEPOINT for realistic testing (guaranteed rollback)",
    ),
    verify_checksums: bool = typer.Option(
        True,
        "--verify-checksums/--no-verify-checksums",
        help="Verify migration file checksums before running (default: enabled)",
    ),
    on_checksum_mismatch: str = typer.Option(
        "fail",
        "--on-checksum-mismatch",
        help="Behavior on checksum mismatch: fail, warn, ignore",
    ),
    verbose: bool = typer.Option(
        False,
        "--verbose",
        "-v",
        help="Show detailed analysis in dry-run report",
    ),
    format_output: str = typer.Option(
        "text",
        "--format",
        "-f",
        help="Report format (text or json)",
    ),
    output_file: Path | None = typer.Option(
        None,
        "--output",
        "-o",
        help="Save report to file",
    ),
) -> None:
    """Apply pending migrations.

    Applies all pending migrations up to the target version (or all if no target).

    Uses distributed locking to ensure only one migration process runs at a time.
    This is critical for Kubernetes/multi-pod deployments.

    Verifies migration file checksums to detect unauthorized modifications.
    Use --no-verify-checksums to skip verification.

    Use --dry-run for analysis without execution, or --dry-run-execute to test in SAVEPOINT.
    """
    from confiture.cli.dry_run import (
        ask_dry_run_execute_confirmation,
        display_dry_run_header,
        print_json_report,
        save_json_report,
        save_text_report,
    )
    from confiture.core.checksum import (
        ChecksumConfig,
        ChecksumMismatchBehavior,
        ChecksumVerificationError,
        MigrationChecksumVerifier,
    )
    from confiture.core.connection import (
        create_connection,
        load_config,
        load_migration_class,
    )
    from confiture.core.locking import LockAcquisitionError, LockConfig, MigrationLock
    from confiture.core.migrator import Migrator

    try:
        # Validate dry-run options
        if dry_run and dry_run_execute:
            console.print("[red]âŒ Error: Cannot use both --dry-run and --dry-run-execute[/red]")
            raise typer.Exit(1)

        if (dry_run or dry_run_execute) and force:
            console.print("[red]âŒ Error: Cannot use --dry-run with --force[/red]")
            raise typer.Exit(1)

        # Validate format option
        if format_output not in ("text", "json"):
            console.print(
                f"[red]âŒ Error: Invalid format '{format_output}'. Use 'text' or 'json'[/red]"
            )
            raise typer.Exit(1)

        # Validate checksum mismatch option
        valid_mismatch_behaviors = ("fail", "warn", "ignore")
        if on_checksum_mismatch not in valid_mismatch_behaviors:
            console.print(
                f"[red]âŒ Error: Invalid --on-checksum-mismatch '{on_checksum_mismatch}'. "
                f"Use one of: {', '.join(valid_mismatch_behaviors)}[/red]"
            )
            raise typer.Exit(1)

        # Load configuration
        config_data = load_config(config)

        # Try to load environment config for migration settings
        effective_strict_mode = strict
        if (
            not strict
            and config.parent.name == "environments"
            and config.parent.parent.name == "db"
        ):
            # Check if config is in standard environments directory
            try:
                from confiture.config.environment import Environment

                env_name = config.stem  # e.g., "local" from "local.yaml"
                project_dir = config.parent.parent.parent
                env_config = Environment.load(env_name, project_dir=project_dir)
                effective_strict_mode = env_config.migration.strict_mode
            except Exception:
                # If environment config loading fails, use default (False)
                pass

        # Show warnings for force mode before attempting database operations
        if force:
            console.print(
                "[yellow]âš ï¸  Force mode enabled - skipping migration state checks[/yellow]"
            )
            console.print(
                "[yellow]This may cause issues if applied incorrectly. Use with caution![/yellow]\n"
            )

        # Show warning for no-lock mode
        if no_lock:
            console.print(
                "[yellow]âš ï¸  Locking disabled - DANGEROUS in multi-pod environments![/yellow]"
            )
            console.print(
                "[yellow]Concurrent migrations may cause race conditions or data corruption.[/yellow]\n"
            )

        # Create database connection
        conn = create_connection(config_data)

        # Create migrator
        migrator = Migrator(connection=conn)
        migrator.initialize()

        # Verify checksums before running migrations (unless force mode)
        if verify_checksums and not force:
            mismatch_behavior = ChecksumMismatchBehavior(on_checksum_mismatch)
            checksum_config = ChecksumConfig(
                enabled=True,
                on_mismatch=mismatch_behavior,
            )
            verifier = MigrationChecksumVerifier(conn, checksum_config)

            try:
                mismatches = verifier.verify_all(migrations_dir)
                if not mismatches:
                    console.print("[cyan]ðŸ” Checksum verification passed[/cyan]\n")
            except ChecksumVerificationError as e:
                console.print("[red]âŒ Checksum verification failed![/red]\n")
                for m in e.mismatches:
                    console.print(f"  [yellow]{m.version}_{m.name}[/yellow]")
                    console.print(f"    Expected: {m.expected[:16]}...")
                    console.print(f"    Actual:   {m.actual[:16]}...")
                console.print(
                    "\n[yellow]ðŸ’¡ Tip: Use 'confiture verify --fix' to update checksums, "
                    "or --no-verify-checksums to skip[/yellow]"
                )
                conn.close()
                raise typer.Exit(1) from e

        # Find migrations to apply
        if force:
            # In force mode, apply all migrations regardless of state
            migrations_to_apply = migrator.find_migration_files(migrations_dir=migrations_dir)
            if not migrations_to_apply:
                console.print("[yellow]âš ï¸  No migration files found.[/yellow]")
                conn.close()
                return
            console.print(
                f"[cyan]ðŸ“¦ Force mode: Found {len(migrations_to_apply)} migration(s) to apply[/cyan]\n"
            )
        else:
            # Normal mode: only apply pending migrations
            migrations_to_apply = migrator.find_pending(migrations_dir=migrations_dir)
            if not migrations_to_apply:
                console.print("[green]âœ… No pending migrations. Database is up to date.[/green]")
                conn.close()
                return
            console.print(
                f"[cyan]ðŸ“¦ Found {len(migrations_to_apply)} pending migration(s)[/cyan]\n"
            )

        # Check for orphaned migration files
        orphaned_files = _find_orphaned_sql_files(migrations_dir)
        if orphaned_files:
            _print_orphaned_files_warning(orphaned_files, console)
            if effective_strict_mode:
                console.print("\n[red]âŒ Strict mode enabled: Aborting due to orphaned files[/red]")
                conn.close()
                raise typer.Exit(1)

        # Handle dry-run modes
        if dry_run or dry_run_execute:
            display_dry_run_header("testing" if dry_run_execute else "analysis")

            # Build migration summary
            migration_summary: dict[str, Any] = {
                "migration_id": f"dry_run_{config.stem}",
                "mode": "execute_and_analyze" if dry_run_execute else "analysis",
                "statements_analyzed": len(migrations_to_apply),
                "migrations": [],
                "summary": {
                    "unsafe_count": 0,
                    "total_estimated_time_ms": 0,
                    "total_estimated_disk_mb": 0.0,
                    "has_unsafe_statements": False,
                },
                "warnings": [],
                "analyses": [],
            }

            try:
                # Collect migration information
                for migration_file in migrations_to_apply:
                    migration_class = load_migration_class(migration_file)
                    migration = migration_class(connection=conn)

                    migration_info = {
                        "version": migration.version,
                        "name": migration.name,
                        "classification": "warning",  # Most migrations are complex changes
                        "estimated_duration_ms": 500,  # Conservative estimate
                        "estimated_disk_usage_mb": 1.0,
                        "estimated_cpu_percent": 30.0,
                    }
                    migration_summary["migrations"].append(migration_info)
                    migration_summary["analyses"].append(migration_info)

                # Display format
                if format_output == "json":
                    if output_file:
                        save_json_report(migration_summary, output_file)
                        console.print(
                            f"\n[green]âœ… Report saved to: {output_file.absolute()}[/green]"
                        )
                    else:
                        print_json_report(migration_summary)
                else:
                    # Text format (default)
                    console.print("\n[cyan]Migration Analysis Summary[/cyan]")
                    console.print("=" * 80)
                    console.print(f"Migrations to apply: {len(migrations_to_apply)}")
                    console.print()
                    for mig in migration_summary["migrations"]:
                        console.print(f"  {mig['version']}: {mig['name']}")
                        console.print(
                            f"    Estimated time: {mig['estimated_duration_ms']}ms | "
                            f"Disk: {mig['estimated_disk_usage_mb']:.1f}MB | "
                            f"CPU: {mig['estimated_cpu_percent']:.0f}%"
                        )
                    console.print()
                    console.print("[green]âœ“ All migrations appear safe to execute[/green]")
                    console.print("=" * 80)

                    if output_file:
                        # Create a simple text report for file output
                        text_report = "DRY-RUN MIGRATION ANALYSIS REPORT\n"
                        text_report += "=" * 80 + "\n\n"
                        for mig in migration_summary["migrations"]:
                            text_report += f"{mig['version']}: {mig['name']}\n"
                        save_text_report(text_report, output_file)
                        console.print(
                            f"[green]âœ… Report saved to: {output_file.absolute()}[/green]"
                        )

                # Stop here if dry-run only (not execute)
                if dry_run and not dry_run_execute:
                    conn.close()
                    return

                # For dry_run_execute: ask for confirmation
                if dry_run_execute and not ask_dry_run_execute_confirmation():
                    console.print("[yellow]Cancelled - no changes applied[/yellow]")
                    conn.close()
                    return

                # Continue to actual execution below

            except Exception as e:
                console.print(f"\n[red]âŒ Dry-run analysis failed: {e}[/red]")
                conn.close()
                raise typer.Exit(1) from e

        # Configure locking
        lock_config = LockConfig(
            enabled=not no_lock,
            timeout_ms=lock_timeout,
        )

        # Create lock manager
        lock = MigrationLock(conn, lock_config)

        # Apply migrations with distributed lock
        applied_count = 0
        failed_migration = None
        failed_exception = None

        try:
            with lock.acquire():
                if not no_lock:
                    console.print("[cyan]ðŸ”’ Acquired migration lock[/cyan]\n")

                for migration_file in migrations_to_apply:
                    # Load migration module
                    migration_class = load_migration_class(migration_file)

                    # Create migration instance
                    migration = migration_class(connection=conn)
                    # Override strict_mode from CLI/config if not already set on class
                    if effective_strict_mode and not getattr(migration_class, "strict_mode", False):
                        migration.strict_mode = effective_strict_mode

                    # Check target
                    if target and migration.version > target:
                        console.print(
                            f"[yellow]â­ï¸  Skipping {migration.version} (after target)[/yellow]"
                        )
                        break

                    # Apply migration
                    console.print(
                        f"[cyan]âš¡ Applying {migration.version}_{migration.name}...[/cyan]", end=" "
                    )

                    try:
                        migrator.apply(migration, force=force, migration_file=migration_file)
                        console.print("[green]âœ…[/green]")
                        applied_count += 1
                    except Exception as e:
                        console.print("[red]âŒ[/red]")
                        failed_migration = migration
                        failed_exception = e
                        break

        except LockAcquisitionError as e:
            console.print(f"\n[red]âŒ Failed to acquire migration lock: {e}[/red]")
            if e.timeout:
                console.print(
                    f"[yellow]ðŸ’¡ Tip: Increase timeout with --lock-timeout {lock_timeout * 2}[/yellow]"
                )
            else:
                console.print(
                    "[yellow]ðŸ’¡ Tip: Check if another migration is running, or use --no-lock (dangerous)[/yellow]"
                )
            conn.close()
            raise typer.Exit(1) from e

        # Handle results
        if failed_migration:
            console.print("\n[red]âŒ Migration failed![/red]")
            if applied_count > 0:
                console.print(
                    f"[yellow]âš ï¸  {applied_count} migration(s) were applied successfully before the failure.[/yellow]"
                )

            # Show detailed error information
            _show_migration_error_details(failed_migration, failed_exception, applied_count)
            conn.close()
            raise typer.Exit(1)
        else:
            if force:
                console.print(
                    f"\n[green]âœ… Force mode: Successfully applied {applied_count} migration(s)![/green]"
                )
                console.print(
                    "[yellow]âš ï¸  Remember to verify your database state after force application[/yellow]"
                )
            else:
                console.print(
                    f"\n[green]âœ… Successfully applied {applied_count} migration(s)![/green]"
                )
            conn.close()

    except LockAcquisitionError:
        # Already handled above
        raise
    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


def _show_migration_error_details(failed_migration, exception, applied_count: int) -> None:
    """Show detailed error information for a failed migration with actionable guidance.

    Args:
        failed_migration: The Migration instance that failed
        exception: The exception that was raised
        applied_count: Number of migrations that succeeded before this one
    """
    from confiture.exceptions import MigrationError

    console.print("\n[red]Failed Migration Details:[/red]")
    console.print(f"  Version: {failed_migration.version}")
    console.print(f"  Name: {failed_migration.name}")
    console.print(f"  File: db/migrations/{failed_migration.version}_{failed_migration.name}.py")

    # Analyze error type and provide specific guidance
    error_message = str(exception)

    # Check if this is a SQL error wrapped in a MigrationError
    if "SQL execution failed" in error_message:
        console.print("  Error Type: SQL Execution Error")

        # Extract SQL and error details from the message
        # Message format: "...SQL execution failed | SQL: ... | Error: ..."
        parts = error_message.split(" | ")
        sql_part = next((part for part in parts if part.startswith("SQL: ")), None)
        error_part = next((part for part in parts if part.startswith("Error: ")), None)

        if sql_part:
            sql_content = sql_part[5:].strip()  # Remove "SQL: " prefix
            console.print(
                f"  SQL Statement: {sql_content[:100]}{'...' if len(sql_content) > 100 else ''}"
            )

        if error_part:
            db_error = error_part[7:].strip()  # Remove "Error: " prefix
            console.print(f"  Database Error: {db_error.split(chr(10))[0]}")

            # Specific SQL error guidance
            error_msg = db_error.lower()
            if "syntax error" in error_msg:
                console.print("\n[yellow]ðŸ” SQL Syntax Error Detected:[/yellow]")
                console.print("  â€¢ Check for typos in SQL keywords, table names, or column names")
                console.print(
                    "  â€¢ Verify quotes, parentheses, and semicolons are properly balanced"
                )
                if sql_part:
                    sql_content = sql_part[5:].strip()
                    console.print(f'  â€¢ Test the SQL manually: psql -c "{sql_content}"')
            elif "does not exist" in error_msg:
                if "schema" in error_msg:
                    console.print("\n[yellow]ðŸ” Missing Schema Error:[/yellow]")
                    console.print(
                        "  â€¢ Create the schema first: CREATE SCHEMA IF NOT EXISTS schema_name;"
                    )
                    console.print("  â€¢ Or use the public schema by default")
                elif "table" in error_msg or "relation" in error_msg:
                    console.print("\n[yellow]ðŸ” Missing Table Error:[/yellow]")
                    console.print("  â€¢ Ensure dependent migrations ran first")
                    console.print("  â€¢ Check table name spelling and schema qualification")
                elif "function" in error_msg:
                    console.print("\n[yellow]ðŸ” Missing Function Error:[/yellow]")
                    console.print("  â€¢ Define the function before using it")
                    console.print("  â€¢ Check function name and parameter types")
            elif "already exists" in error_msg:
                console.print("\n[yellow]ðŸ” Object Already Exists:[/yellow]")
                console.print("  â€¢ Use IF NOT EXISTS clauses for safe creation")
                console.print("  â€¢ Check if migration was partially applied")
            elif "permission denied" in error_msg:
                console.print("\n[yellow]ðŸ” Permission Error:[/yellow]")
                console.print("  â€¢ Verify database user has required privileges")
                console.print("  â€¢ Check GRANT statements in earlier migrations")

    elif isinstance(exception, MigrationError):
        console.print("  Error Type: Migration Framework Error")
        console.print(f"  Message: {exception}")

        # Migration-specific guidance
        error_msg = str(exception).lower()
        if "already been applied" in error_msg:
            console.print("\n[yellow]ðŸ” Migration Already Applied:[/yellow]")
            console.print("  â€¢ Check migration status: confiture migrate status")
            console.print("  â€¢ This migration may have run successfully before")
        elif "connection" in error_msg:
            console.print("\n[yellow]ðŸ” Database Connection Error:[/yellow]")
            console.print("  â€¢ Verify database is running and accessible")
            console.print("  â€¢ Check connection string in config file")
            console.print("  â€¢ Test connection: psql 'your-connection-string'")

    else:
        console.print(f"  Error Type: {type(exception).__name__}")
        console.print(f"  Message: {exception}")

    # General troubleshooting
    console.print("\n[yellow]ðŸ› ï¸  General Troubleshooting:[/yellow]")
    console.print(
        f"  â€¢ View migration file: cat db/migrations/{failed_migration.version}_{failed_migration.name}.py"
    )
    console.print("  â€¢ Check database logs for more details")
    console.print("  â€¢ Test SQL manually in psql")

    if applied_count > 0:
        console.print(f"  â€¢ {applied_count} migration(s) succeeded - database is partially updated")
        console.print("  â€¢ Fix the error and re-run: confiture migrate up")
        console.print(f"  â€¢ Or rollback and retry: confiture migrate down --steps {applied_count}")
    else:
        console.print("  â€¢ No migrations applied yet - database state is clean")
        console.print("  â€¢ Fix the error and re-run: confiture migrate up")


@migrate_app.command("generate")
def migrate_generate(
    name: str = typer.Argument(..., help="Migration name (snake_case)"),
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
) -> None:
    """Generate a new migration file.

    Creates an empty migration template with the given name.
    """
    try:
        # Ensure migrations directory exists
        migrations_dir.mkdir(parents=True, exist_ok=True)

        # Generate migration file template
        generator = MigrationGenerator(migrations_dir=migrations_dir)

        # For empty migration, create a template manually
        version = generator._get_next_version()
        class_name = generator._to_class_name(name)
        filename = f"{version}_{name}.py"
        filepath = migrations_dir / filename

        # Create template
        template = f'''"""Migration: {name}

Version: {version}
"""

from confiture.models.migration import Migration


class {class_name}(Migration):
    """Migration: {name}."""

    version = "{version}"
    name = "{name}"

    def up(self) -> None:
        """Apply migration."""
        # TODO: Add your SQL statements here
        # Example:
        # self.execute("CREATE TABLE users (id SERIAL PRIMARY KEY)")
        pass

    def down(self) -> None:
        """Rollback migration."""
        # TODO: Add your rollback SQL statements here
        # Example:
        # self.execute("DROP TABLE users")
        pass
'''

        filepath.write_text(template)

        console.print("[green]âœ… Migration generated successfully![/green]")
        # Use plain print to avoid Rich wrapping long paths
        print(f"\nðŸ“„ File: {filepath.absolute()}")
        console.print("\nâœï¸  Edit the migration file to add your SQL statements.")

    except Exception as e:
        console.print(f"[red]âŒ Error generating migration: {e}[/red]")
        raise typer.Exit(1) from e


@migrate_app.command("baseline")
def migrate_baseline(
    through: str = typer.Option(
        ...,
        "--through",
        "-t",
        help="Mark all migrations through this version as applied",
    ),
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    config: Path = typer.Option(
        Path("db/environments/local.yaml"),
        "--config",
        "-c",
        help="Configuration file with database connection",
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Show what would be marked without making changes",
    ),
) -> None:
    """Mark migrations as applied without executing them.

    Use this to establish a baseline when:
    - Adopting confiture on an existing database
    - Setting up a new environment from a backup
    - Recovering from a failed migration state

    Examples:
        confiture migrate baseline --through 002
        confiture migrate baseline -t 005 --dry-run
        confiture migrate baseline -t 003 -c db/environments/production.yaml
    """
    from confiture.core.connection import create_connection, load_config
    from confiture.core.migrator import Migrator

    try:
        if not config.exists():
            console.print(f"[red]âŒ Config file not found: {config}[/red]")
            console.print(
                "[yellow]ðŸ’¡ Tip: Specify config with --config path/to/config.yaml[/yellow]"
            )
            raise typer.Exit(1)

        if not migrations_dir.exists():
            console.print(f"[red]âŒ Migrations directory not found: {migrations_dir}[/red]")
            raise typer.Exit(1)

        # Load config and create connection
        config_data = load_config(config)
        conn = create_connection(config_data)

        # Initialize migrator
        migrator = Migrator(connection=conn)
        migrator.initialize()

        # Find all migration files
        all_migrations = migrator.find_migration_files(migrations_dir)

        if not all_migrations:
            console.print("[yellow]No migrations found.[/yellow]")
            conn.close()
            return

        # Filter migrations up to and including the target version
        migrations_to_mark: list[Path] = []
        for migration_file in all_migrations:
            version = migrator._version_from_filename(migration_file.name)
            migrations_to_mark.append(migration_file)
            if version == through:
                break
        else:
            # Target version not found
            console.print(f"[red]âŒ Migration version '{through}' not found[/red]")
            console.print("[yellow]Available versions:[/yellow]")
            for mf in all_migrations[:10]:
                v = migrator._version_from_filename(mf.name)
                console.print(f"  â€¢ {v}")
            if len(all_migrations) > 10:
                console.print(f"  ... and {len(all_migrations) - 10} more")
            conn.close()
            raise typer.Exit(1)

        # Get already applied versions
        applied_versions = set(migrator.get_applied_versions())

        # Show what will be done
        console.print(f"\n[cyan]ðŸ“‹ Baseline: marking migrations through {through}[/cyan]\n")

        if dry_run:
            console.print("[yellow]ðŸ” DRY RUN - no changes will be made[/yellow]\n")

        marked_count = 0
        skipped_count = 0

        for migration_file in migrations_to_mark:
            version = migrator._version_from_filename(migration_file.name)
            # Extract name
            base_name = migration_file.stem
            if base_name.endswith(".up"):
                base_name = base_name[:-3]
            parts = base_name.split("_", 1)
            name = parts[1] if len(parts) > 1 else base_name

            if version in applied_versions:
                console.print(f"  [dim]â­ï¸  {version} {name} (already applied)[/dim]")
                skipped_count += 1
            else:
                if dry_run:
                    console.print(f"  [cyan]ðŸ“ {version} {name} (would mark as applied)[/cyan]")
                else:
                    migrator.mark_applied(migration_file, reason="baseline")
                    console.print(f"  [green]âœ… {version} {name} (marked as applied)[/green]")
                marked_count += 1

        # Summary
        console.print()
        if dry_run:
            console.print(
                f"[cyan]ðŸ“Š Would mark {marked_count} migration(s), "
                f"skip {skipped_count} already applied[/cyan]"
            )
            console.print("\n[yellow]Run without --dry-run to apply changes[/yellow]")
        else:
            console.print(
                f"[green]âœ… Marked {marked_count} migration(s) as applied, "
                f"skipped {skipped_count} already applied[/green]"
            )

        conn.close()

    except typer.Exit:
        raise
    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


@migrate_app.command("diff")
def migrate_diff(
    old_schema: Path = typer.Argument(..., help="Old schema file"),
    new_schema: Path = typer.Argument(..., help="New schema file"),
    generate: bool = typer.Option(
        False,
        "--generate",
        help="Generate migration from diff",
    ),
    name: str = typer.Option(
        None,
        "--name",
        help="Migration name (required with --generate)",
    ),
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
) -> None:
    """Compare two schema files and show differences.

    Optionally generate a migration file from the diff.
    """
    try:
        # Validate files exist
        if not old_schema.exists():
            console.print(f"[red]âŒ Old schema file not found: {old_schema}[/red]")
            raise typer.Exit(1)

        if not new_schema.exists():
            console.print(f"[red]âŒ New schema file not found: {new_schema}[/red]")
            raise typer.Exit(1)

        # Read schemas
        old_sql = old_schema.read_text()
        new_sql = new_schema.read_text()

        # Compare schemas
        differ = SchemaDiffer()
        diff = differ.compare(old_sql, new_sql)

        # Display diff
        if not diff.has_changes():
            console.print("[green]âœ… No changes detected. Schemas are identical.[/green]")
            return

        console.print("[cyan]ðŸ“Š Schema differences detected:[/cyan]\n")

        # Display changes in a table
        table = Table()
        table.add_column("Type", style="yellow")
        table.add_column("Details", style="white")

        for change in diff.changes:
            table.add_row(change.type, str(change))

        console.print(table)
        console.print(f"\nðŸ“ˆ Total changes: {len(diff.changes)}")

        # Generate migration if requested
        if generate:
            if not name:
                console.print("[red]âŒ Migration name is required when using --generate[/red]")
                console.print(
                    "Usage: confiture migrate diff old.sql new.sql --generate --name migration_name"
                )
                raise typer.Exit(1)

            # Ensure migrations directory exists
            migrations_dir.mkdir(parents=True, exist_ok=True)

            # Generate migration
            generator = MigrationGenerator(migrations_dir=migrations_dir)
            migration_file = generator.generate(diff, name=name)

            console.print(f"\n[green]âœ… Migration generated: {migration_file.name}[/green]")

    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


@migrate_app.command("down")
def migrate_down(
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    config: Path = typer.Option(
        Path("db/environments/local.yaml"),
        "--config",
        "-c",
        help="Configuration file",
    ),
    steps: int = typer.Option(
        1,
        "--steps",
        "-n",
        help="Number of migrations to rollback",
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Analyze rollback without executing",
    ),
    verbose: bool = typer.Option(
        False,
        "--verbose",
        "-v",
        help="Show detailed analysis in dry-run report",
    ),
    format_output: str = typer.Option(
        "text",
        "--format",
        "-f",
        help="Report format (text or json)",
    ),
    output_file: Path | None = typer.Option(
        None,
        "--output",
        "-o",
        help="Save report to file",
    ),
) -> None:
    """Rollback applied migrations.

    Rolls back the last N applied migrations (default: 1).

    Use --dry-run to analyze rollback without executing.
    """
    from confiture.core.connection import (
        create_connection,
        load_config,
        load_migration_class,
    )
    from confiture.core.migrator import Migrator

    try:
        # Validate format option
        if format_output not in ("text", "json"):
            console.print(
                f"[red]âŒ Error: Invalid format '{format_output}'. Use 'text' or 'json'[/red]"
            )
            raise typer.Exit(1)

        # Load configuration
        config_data = load_config(config)

        # Create database connection
        conn = create_connection(config_data)

        # Create migrator
        migrator = Migrator(connection=conn)
        migrator.initialize()

        # Get applied migrations
        applied_versions = migrator.get_applied_versions()

        if not applied_versions:
            console.print("[yellow]âš ï¸  No applied migrations to rollback.[/yellow]")
            conn.close()
            return

        # Get migrations to rollback (last N)
        versions_to_rollback = applied_versions[-steps:]

        # Handle dry-run mode
        if dry_run:
            from confiture.cli.dry_run import (
                display_dry_run_header,
                save_json_report,
                save_text_report,
            )

            display_dry_run_header("analysis")

            # Build rollback summary
            rollback_summary: dict[str, Any] = {
                "migration_id": f"dry_run_rollback_{config.stem}",
                "mode": "analysis",
                "statements_analyzed": len(versions_to_rollback),
                "migrations": [],
                "summary": {
                    "unsafe_count": 0,
                    "total_estimated_time_ms": 0,
                    "total_estimated_disk_mb": 0.0,
                    "has_unsafe_statements": False,
                },
                "warnings": [],
                "analyses": [],
            }

            # Collect rollback migration information
            for version in reversed(versions_to_rollback):
                # Find migration file
                migration_files = migrator.find_migration_files(migrations_dir=migrations_dir)
                migration_file = None
                for mf in migration_files:
                    if migrator._version_from_filename(mf.name) == version:
                        migration_file = mf
                        break

                if not migration_file:
                    continue

                # Load migration class
                migration_class = load_migration_class(migration_file)

                migration = migration_class(connection=conn)

                migration_info = {
                    "version": migration.version,
                    "name": migration.name,
                    "classification": "warning",
                    "estimated_duration_ms": 500,
                    "estimated_disk_usage_mb": 1.0,
                    "estimated_cpu_percent": 30.0,
                }
                rollback_summary["migrations"].append(migration_info)
                rollback_summary["analyses"].append(migration_info)

            # Display format
            if format_output == "json":
                if output_file:
                    save_json_report(rollback_summary, output_file)
                    console.print(f"\n[green]âœ… Report saved to: {output_file.absolute()}[/green]")
                else:
                    from confiture.cli.dry_run import print_json_report

                    print_json_report(rollback_summary)
            else:
                # Text format (default)
                console.print("[cyan]Rollback Analysis Summary[/cyan]")
                console.print("=" * 80)
                console.print(f"Migrations to rollback: {len(versions_to_rollback)}")
                console.print()
                for mig in rollback_summary["migrations"]:
                    console.print(f"  {mig['version']}: {mig['name']}")
                    console.print(
                        f"    Estimated time: {mig['estimated_duration_ms']}ms | "
                        f"Disk: {mig['estimated_disk_usage_mb']:.1f}MB | "
                        f"CPU: {mig['estimated_cpu_percent']:.0f}%"
                    )
                console.print()
                console.print("[yellow]âš ï¸  Rollback will undo these migrations[/yellow]")
                console.print("=" * 80)

                if output_file:
                    text_report = "DRY-RUN ROLLBACK ANALYSIS REPORT\n"
                    text_report += "=" * 80 + "\n\n"
                    for mig in rollback_summary["migrations"]:
                        text_report += f"{mig['version']}: {mig['name']}\n"
                    save_text_report(text_report, output_file)
                    console.print(f"[green]âœ… Report saved to: {output_file.absolute()}[/green]")

            conn.close()
            return

        console.print(f"[cyan]ðŸ“¦ Rolling back {len(versions_to_rollback)} migration(s)[/cyan]\n")

        # Rollback migrations in reverse order
        rolled_back_count = 0
        for version in reversed(versions_to_rollback):
            # Find migration file
            migration_files = migrator.find_migration_files(migrations_dir=migrations_dir)
            migration_file = None
            for mf in migration_files:
                if migrator._version_from_filename(mf.name) == version:
                    migration_file = mf
                    break

            if not migration_file:
                console.print(f"[red]âŒ Migration file for version {version} not found[/red]")
                continue

            # Load migration module
            migration_class = load_migration_class(migration_file)

            # Create migration instance
            migration = migration_class(connection=conn)

            # Rollback migration
            console.print(
                f"[cyan]âš¡ Rolling back {migration.version}_{migration.name}...[/cyan]", end=" "
            )
            migrator.rollback(migration)
            console.print("[green]âœ…[/green]")
            rolled_back_count += 1

        console.print(
            f"\n[green]âœ… Successfully rolled back {rolled_back_count} migration(s)![/green]"
        )
        conn.close()

    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


@migrate_app.command("validate")
def migrate_validate(
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    fix_naming: bool = typer.Option(
        False,
        "--fix-naming",
        help="Automatically rename orphaned migration files to match naming convention",
    ),
    idempotent: bool = typer.Option(
        False,
        "--idempotent",
        help="Validate that migrations are idempotent (can be safely re-run)",
    ),
    check_drift: bool = typer.Option(
        False,
        "--check-drift",
        help="Validate schema against git refs for drift detection",
    ),
    require_migration: bool = typer.Option(
        False,
        "--require-migration",
        help="Ensure DDL changes have corresponding migration files",
    ),
    base_ref: str = typer.Option(
        "origin/main",
        "--base-ref",
        help="Base git reference for comparison (default: origin/main)",
    ),
    since: str | None = typer.Option(
        None,
        "--since",
        help="Shortcut for --base-ref",
    ),
    staged: bool = typer.Option(
        False,
        "--staged",
        help="Only validate staged files (pre-commit hook mode)",
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Preview changes without actually renaming files",
    ),
    format_output: str = typer.Option(
        "text",
        "--format",
        "-f",
        help="Output format: text (default) or json",
    ),
    output_file: Path | None = typer.Option(
        None,
        "--output",
        "-o",
        help="Save output to file",
    ),
) -> None:
    """Validate migration file naming conventions, idempotency, and git integrity.

    Checks for .sql files that don't match the expected naming pattern.
    With --idempotent, also validates that SQL statements are idempotent.
    With --check-drift, validates schema against git refs for drift detection.
    With --require-migration, ensures DDL changes have migration files.

    Confiture only recognizes:
    - {NNN}_{name}.up.sql (forward migrations)
    - {NNN}_{name}.down.sql (rollback migrations)
    - {NNN}_{name}.py (Python class migrations)

    Idempotent SQL patterns include:
    - CREATE TABLE IF NOT EXISTS
    - CREATE INDEX IF NOT EXISTS
    - CREATE OR REPLACE FUNCTION/VIEW
    - DROP TABLE IF EXISTS

    Examples:
        # Check for orphaned files
        confiture migrate validate

        # Validate idempotency of all migrations
        confiture migrate validate --idempotent

        # Check schema drift against main branch
        confiture migrate validate --check-drift --base-ref origin/main

        # Require migration files for DDL changes
        confiture migrate validate --require-migration --base-ref origin/main

        # Pre-commit hook: validate staged changes
        confiture migrate validate --check-drift --require-migration --staged

        # Auto-fix orphaned file names
        confiture migrate validate --fix-naming

        # Output as JSON
        confiture migrate validate --format json
    """
    try:
        # Validate output format
        if format_output not in ("text", "json"):
            console.print(f"[red]âŒ Invalid format: {format_output}. Use 'text' or 'json'[/red]")
            raise typer.Exit(1)

        # Handle git validation flags
        if check_drift or require_migration or staged:
            from confiture.cli.git_validation import (
                validate_git_drift,
                validate_git_flags_in_repo,
                validate_migration_accompaniment,
            )

            # Override base_ref with since if provided
            effective_base_ref = since or base_ref

            # Validate we're in a git repo
            try:
                validate_git_flags_in_repo()
            except Exception as e:
                if format_output == "json":
                    result = {"error": str(e)}
                    _output_json(result, output_file, console)
                else:
                    console.print(f"[red]âŒ {e}[/red]")
                raise typer.Exit(2) from e

            # Run git drift check
            drift_passed = True
            if check_drift:
                try:
                    drift_result = validate_git_drift(
                        env="local",
                        base_ref=effective_base_ref,
                        target_ref="HEAD" if not staged else "HEAD",
                        console=console,
                        format_output=format_output,
                    )
                    if not drift_result.get("passed"):
                        drift_passed = False
                        if format_output == "json":
                            result = {
                                "status": "failed",
                                "check": "drift",
                                **drift_result,
                            }
                            _output_json(result, output_file, console)
                            raise typer.Exit(1)
                except Exception as e:
                    if format_output == "json":
                        result = {"error": f"Drift check failed: {e}"}
                        _output_json(result, output_file, console)
                    else:
                        console.print(f"[red]âŒ Drift check failed: {e}[/red]")
                    raise typer.Exit(1) from e

            # Run migration accompaniment check
            accompaniment_passed = True
            if require_migration:
                try:
                    acc_result = validate_migration_accompaniment(
                        env="local",
                        base_ref=effective_base_ref,
                        target_ref="HEAD" if not staged else "HEAD",
                        console=console,
                        format_output=format_output,
                    )
                    if not acc_result.get("is_valid"):
                        accompaniment_passed = False
                        if format_output == "json":
                            result = {
                                "status": "failed",
                                "check": "accompaniment",
                                **acc_result,
                            }
                            _output_json(result, output_file, console)
                            raise typer.Exit(1)
                except Exception as e:
                    if format_output == "json":
                        result = {"error": f"Accompaniment check failed: {e}"}
                        _output_json(result, output_file, console)
                    else:
                        console.print(f"[red]âŒ Accompaniment check failed: {e}[/red]")
                    raise typer.Exit(1) from e

            # Check if all checks passed (for text output)
            if drift_passed and accompaniment_passed:
                if format_output == "json":
                    result = {
                        "status": "passed",
                        "checks": ["drift", "accompaniment"]
                        if (check_drift and require_migration)
                        else (["drift"] if check_drift else ["accompaniment"]),
                    }
                    _output_json(result, output_file, console)
                else:
                    console.print("[green]âœ… All git validation checks passed[/green]")
                return
            else:
                # At least one check failed in text mode
                raise typer.Exit(1)

        if not migrations_dir.exists():
            if format_output == "json":
                result = {"error": f"Migrations directory not found: {migrations_dir.absolute()}"}
                _output_json(result, output_file, console)
            else:
                console.print(f"[red]âŒ Migrations directory not found: {migrations_dir}[/red]")
            raise typer.Exit(1)

        # Handle idempotency validation
        if idempotent:
            _validate_idempotency(migrations_dir, format_output, output_file)
            return

        # Use Migrator to find and optionally fix orphaned files
        from unittest.mock import Mock

        from confiture.core.migrator import Migrator

        mock_conn = Mock()
        migrator = Migrator(connection=mock_conn)

        # Find orphaned files
        orphaned_files = migrator.find_orphaned_sql_files(migrations_dir)

        if not orphaned_files:
            if format_output == "json":
                result = {
                    "status": "ok",
                    "message": "No orphaned migration files found",
                    "fixed": [],
                    "errors": [],
                }
                _output_json(result, output_file, console)
            else:
                console.print("[green]âœ… No orphaned migration files found[/green]")
            return

        # If fix_naming is requested, fix the files
        if fix_naming:
            # --dry-run takes precedence
            is_dry_run = dry_run
            result = migrator.fix_orphaned_sql_files(migrations_dir, dry_run=is_dry_run)

            if format_output == "json":
                output_dict: dict[str, Any] = {
                    "status": "fixed" if not is_dry_run else "preview",
                    "fixed": result.get("renamed", []),
                    "errors": result.get("errors", []),
                }
                _output_json(output_dict, output_file, console)
            else:
                # Text output
                if is_dry_run:
                    console.print(
                        "[cyan]ðŸ“‹ DRY-RUN: Would fix the following orphaned files:[/cyan]"
                    )
                else:
                    console.print("[green]âœ… Fixed orphaned migration files:[/green]")

                for old_name, new_name in result.get("renamed", []):
                    console.print(f"  â€¢ {old_name} â†’ {new_name}")

                if result.get("errors"):
                    console.print("[red]Errors:[/red]")
                    for filename, error_msg in result.get("errors", []):
                        console.print(f"  âŒ {filename}: {error_msg}")

        else:
            # Just report the orphaned files (don't fix)
            if format_output == "json":
                output_dict = {
                    "status": "issues_found",
                    "orphaned_files": [f.name for f in orphaned_files],
                }
                _output_json(output_dict, output_file, console)
            else:
                console.print("[yellow]âš ï¸  WARNING: Orphaned migration files detected[/yellow]")
                console.print(
                    "[yellow]These SQL files exist but won't be applied by Confiture:[/yellow]"
                )

                for orphaned_file in orphaned_files:
                    suggested_name = f"{orphaned_file.stem}.up.sql"
                    console.print(f"  â€¢ {orphaned_file.name} â†’ rename to: {suggested_name}")

                console.print()
                console.print("[cyan]To automatically fix these files, run:[/cyan]")
                console.print("[cyan]  confiture migrate validate --fix-naming[/cyan]")
                console.print()
                console.print("[cyan]Or preview the changes first with:[/cyan]")
                console.print("[cyan]  confiture migrate validate --fix-naming --dry-run[/cyan]")

    except typer.Exit:
        raise
    except Exception as e:
        if format_output == "json":
            result = {"error": str(e)}
            _output_json(result, output_file, console)
        else:
            console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


def _validate_idempotency(
    migrations_dir: Path,
    format_output: str,
    output_file: Path | None,
) -> None:
    """Validate idempotency of SQL migration files.

    Args:
        migrations_dir: Directory containing migration files
        format_output: Output format (text or json)
        output_file: Optional file to save output to
    """
    from confiture.core.idempotency import IdempotencyValidator

    validator = IdempotencyValidator()

    # Find all SQL migration files
    sql_files = list(migrations_dir.glob("*.up.sql"))
    sql_files.sort()

    if not sql_files:
        if format_output == "json":
            result: dict[str, Any] = {
                "status": "ok",
                "message": "No migration files found",
                "violations": [],
            }
            _output_json(result, output_file, console)
        else:
            console.print("[green]âœ… No migration files found to validate[/green]")
        return

    # Validate all files
    combined_report = validator.validate_directory(migrations_dir, pattern="*.up.sql")

    if format_output == "json":
        result = combined_report.to_dict()
        result["status"] = "issues_found" if combined_report.has_violations else "ok"
        _output_json(result, output_file, console)
        if combined_report.has_violations:
            raise typer.Exit(1)
    else:
        if not combined_report.has_violations:
            console.print("[green]âœ… All migrations are idempotent[/green]")
            console.print(f"   Scanned {combined_report.files_scanned} file(s)")
            return

        # Display violations
        console.print(
            f"[red]âŒ Found {combined_report.violation_count} idempotency violation(s)[/red]\n"
        )

        # Group violations by file
        violations_by_file: dict[str, list[Any]] = {}
        for violation in combined_report.violations:
            file_path = violation.file_path
            if file_path not in violations_by_file:
                violations_by_file[file_path] = []
            violations_by_file[file_path].append(violation)

        for file_path, violations in violations_by_file.items():
            file_name = Path(file_path).name
            console.print(f"[yellow]{file_name}[/yellow]")
            for v in violations:
                console.print(f"  Line {v.line_number}: {v.pattern.value}")
                console.print(
                    f"    [dim]{v.sql_snippet[:60]}...[/dim]"
                    if len(v.sql_snippet) > 60
                    else f"    [dim]{v.sql_snippet}[/dim]"
                )
                console.print(f"    ðŸ’¡ {v.suggestion}")
            console.print()

        console.print("[cyan]To auto-fix these issues, run:[/cyan]")
        console.print(
            f"[cyan]  confiture migrate fix --idempotent --migrations-dir {migrations_dir}[/cyan]"
        )

        raise typer.Exit(1)


@migrate_app.command("fix")
def migrate_fix(
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    idempotent: bool = typer.Option(
        False,
        "--idempotent",
        help="Fix non-idempotent SQL statements",
    ),
    dry_run: bool = typer.Option(
        False,
        "--dry-run",
        help="Preview changes without modifying files",
    ),
    format_output: str = typer.Option(
        "text",
        "--format",
        "-f",
        help="Output format: text (default) or json",
    ),
    output_file: Path | None = typer.Option(
        None,
        "--output",
        "-o",
        help="Save output to file",
    ),
) -> None:
    """Auto-fix migration files.

    Transforms non-idempotent SQL statements into their idempotent equivalents.

    Transformations applied:
    - CREATE TABLE â†’ CREATE TABLE IF NOT EXISTS
    - CREATE INDEX â†’ CREATE INDEX IF NOT EXISTS
    - CREATE FUNCTION â†’ CREATE OR REPLACE FUNCTION
    - DROP TABLE â†’ DROP TABLE IF EXISTS
    - And more...

    Examples:
        # Preview fixes without modifying files
        confiture migrate fix --idempotent --dry-run

        # Apply fixes to all migration files
        confiture migrate fix --idempotent

        # Output as JSON
        confiture migrate fix --idempotent --dry-run --format json
    """
    try:
        # Validate output format
        if format_output not in ("text", "json"):
            console.print(f"[red]âŒ Invalid format: {format_output}. Use 'text' or 'json'[/red]")
            raise typer.Exit(1)

        if not migrations_dir.exists():
            if format_output == "json":
                result: dict[str, Any] = {
                    "error": f"Migrations directory not found: {migrations_dir.absolute()}"
                }
                _output_json(result, output_file, console)
            else:
                console.print(f"[red]âŒ Migrations directory not found: {migrations_dir}[/red]")
            raise typer.Exit(1)

        if not idempotent:
            console.print(
                "[yellow]âš ï¸  No fix type specified. Use --idempotent to fix idempotency issues.[/yellow]"
            )
            return

        _fix_idempotency(migrations_dir, dry_run, format_output, output_file)

    except typer.Exit:
        raise
    except Exception as e:
        if format_output == "json":
            result = {"error": str(e)}
            _output_json(result, output_file, console)
        else:
            console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


def _fix_idempotency(
    migrations_dir: Path,
    dry_run: bool,
    format_output: str,
    output_file: Path | None,
) -> None:
    """Fix idempotency issues in SQL migration files.

    Args:
        migrations_dir: Directory containing migration files
        dry_run: If True, preview changes without modifying files
        format_output: Output format (text or json)
        output_file: Optional file to save output to
    """
    from confiture.core.idempotency import IdempotencyFixer

    fixer = IdempotencyFixer()

    # Find all SQL migration files
    sql_files = list(migrations_dir.glob("*.up.sql"))
    sql_files.sort()

    if not sql_files:
        if format_output == "json":
            result: dict[str, Any] = {
                "status": "ok",
                "message": "No migration files found",
                "files": [],
            }
            _output_json(result, output_file, console)
        else:
            console.print("[green]âœ… No migration files found to fix[/green]")
        return

    # Process each file
    files_changed: list[dict[str, Any]] = []

    for sql_file in sql_files:
        original_content = sql_file.read_text()
        fixed_content = fixer.fix(original_content)

        if fixed_content != original_content:
            # Get list of changes for reporting
            changes = fixer.dry_run(original_content)

            file_info: dict[str, Any] = {
                "file": sql_file.name,
                "changes": [
                    {
                        "pattern": c.pattern.value,
                        "original": c.original[:50] + "..." if len(c.original) > 50 else c.original,
                        "suggested_fix": c.suggested_fix[:50] + "..."
                        if len(c.suggested_fix) > 50
                        else c.suggested_fix,
                        "line": c.line_number,
                    }
                    for c in changes
                ],
            }
            files_changed.append(file_info)

            if not dry_run:
                sql_file.write_text(fixed_content)

    # Output results
    if format_output == "json":
        result = {
            "status": "fixed" if not dry_run and files_changed else "preview" if dry_run else "ok",
            "files": files_changed,
            "total_files_changed": len(files_changed),
        }
        _output_json(result, output_file, console)
    else:
        if not files_changed:
            console.print("[green]âœ… All migrations are already idempotent[/green]")
            return

        if dry_run:
            console.print("[cyan]ðŸ“‹ DRY-RUN: Would apply the following fixes:[/cyan]\n")
        else:
            console.print("[green]âœ… Applied idempotency fixes:[/green]\n")

        for file_info in files_changed:
            console.print(f"[yellow]{file_info['file']}[/yellow]")
            for change in file_info["changes"]:
                console.print(f"  Line {change['line']}: {change['pattern']}")
                console.print(f"    - {change['original']}")
                console.print(f"    + {change['suggested_fix']}")
            console.print()

        if dry_run:
            console.print(f"[cyan]Would fix {len(files_changed)} file(s)[/cyan]")
            console.print("[cyan]Run without --dry-run to apply changes[/cyan]")
        else:
            console.print(f"[green]Fixed {len(files_changed)} file(s)[/green]")


@app.command()
def validate_profile(
    path: Path = typer.Argument(
        ...,
        help="Path to anonymization profile YAML file",
    ),
) -> None:
    """Validate anonymization profile YAML structure and schema.

    Performs security validation:
    - Uses safe_load() to prevent YAML injection
    - Validates against Pydantic schema
    - Checks strategy types are whitelisted
    - Verifies all required fields present

    Example:
        confiture validate-profile db/profiles/production.yaml
    """
    try:
        from confiture.core.anonymization.profile import AnonymizationProfile

        console.print(f"[cyan]ðŸ“‹ Validating profile: {path}[/cyan]")
        profile = AnonymizationProfile.load(path)

        # Print profile summary
        console.print("[green]âœ… Valid profile![/green]")
        console.print(f"   Name: {profile.name}")
        console.print(f"   Version: {profile.version}")
        if profile.global_seed:
            console.print(f"   Global Seed: {profile.global_seed}")

        # List strategies
        console.print(f"\n[cyan]Strategies ({len(profile.strategies)})[/cyan]:")
        for strategy_name, strategy_def in profile.strategies.items():
            console.print(
                f"   â€¢ {strategy_name}: {strategy_def.type}",
                end="",
            )
            if strategy_def.seed_env_var:
                console.print(f" [env: {strategy_def.seed_env_var}]")
            else:
                console.print()

        # List tables
        console.print(f"\n[cyan]Tables ({len(profile.tables)})[/cyan]:")
        for table_name, table_def in profile.tables.items():
            console.print(f"   â€¢ {table_name}: {len(table_def.rules)} rules")
            for rule in table_def.rules:
                console.print(f"      - {rule.column} â†’ {rule.strategy}", end="")
                if rule.seed:
                    console.print(f" [seed: {rule.seed}]")
                else:
                    console.print()

        console.print("[green]\nâœ… Profile validation passed![/green]")

    except FileNotFoundError as e:
        console.print(f"[red]âŒ File not found: {e}[/red]")
        raise typer.Exit(1) from e
    except ValueError as e:
        console.print(f"[red]âŒ Invalid profile: {e}[/red]")
        raise typer.Exit(1) from e
    except Exception as e:
        console.print(f"[red]âŒ Error validating profile: {e}[/red]")
        raise typer.Exit(1) from e


@app.command()
def verify(
    migrations_dir: Path = typer.Option(
        Path("db/migrations"),
        "--migrations-dir",
        help="Migrations directory",
    ),
    config: Path = typer.Option(
        Path("db/environments/local.yaml"),
        "--config",
        "-c",
        help="Configuration file",
    ),
    fix: bool = typer.Option(
        False,
        "--fix",
        help="Update stored checksums to match current files (dangerous)",
    ),
) -> None:
    """Verify migration file integrity against stored checksums.

    Compares SHA-256 checksums of migration files against the checksums
    stored when migrations were applied. Detects if files have been
    modified after application.

    This helps prevent:
    - Silent schema drift between environments
    - Production/staging mismatches
    - Debugging nightmares from modified migrations

    Examples:
        # Verify all migrations
        confiture verify

        # Verify with specific config
        confiture verify --config db/environments/production.yaml

        # Fix checksums (update stored to match current files)
        confiture verify --fix
    """
    from confiture.core.checksum import (
        ChecksumConfig,
        ChecksumMismatchBehavior,
        MigrationChecksumVerifier,
    )
    from confiture.core.connection import create_connection, load_config

    try:
        # Load config and connect
        config_data = load_config(config)
        conn = create_connection(config_data)

        # Run verification (warn mode - we'll handle display)
        verifier = MigrationChecksumVerifier(
            conn,
            ChecksumConfig(
                enabled=True,
                on_mismatch=ChecksumMismatchBehavior.WARN,
            ),
        )
        mismatches = verifier.verify_all(migrations_dir)

        if not mismatches:
            console.print("[green]âœ… All migration checksums verified![/green]")
            conn.close()
            return

        # Display mismatches
        console.print(f"[red]âŒ Found {len(mismatches)} checksum mismatch(es):[/red]\n")

        for m in mismatches:
            console.print(f"  [yellow]{m.version}_{m.name}[/yellow]")
            console.print(f"    File: {m.file_path}")
            console.print(f"    Expected: {m.expected[:16]}...")
            console.print(f"    Actual:   {m.actual[:16]}...")
            console.print()

        if fix:
            # Update checksums in database
            console.print("[yellow]âš ï¸  Updating stored checksums...[/yellow]")
            updated = verifier.update_all_checksums(migrations_dir)
            console.print(f"[green]âœ… Updated {updated} checksum(s)[/green]")
        else:
            console.print(
                "[yellow]ðŸ’¡ Tip: Use --fix to update stored checksums (dangerous)[/yellow]"
            )
            conn.close()
            raise typer.Exit(1)

        conn.close()

    except typer.Exit:
        raise
    except Exception as e:
        console.print(f"[red]âŒ Error: {e}[/red]")
        raise typer.Exit(1) from e


if __name__ == "__main__":
    app()
