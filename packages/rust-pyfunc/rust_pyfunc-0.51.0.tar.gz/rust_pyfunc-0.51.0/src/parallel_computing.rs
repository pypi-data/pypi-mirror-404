use chrono::Local;
use crossbeam::channel::{unbounded, Receiver, Sender};
use memmap2::MmapMut;
use pyo3::prelude::*;
use pyo3::types::PyList;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::collections::HashSet;
use std::env;
use std::fs::OpenOptions;
use std::io::{self, Read, Write};
use std::path::Path;
use std::process::{Command, Stdio};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::sync::Mutex;
use std::thread;
use std::time::{Duration, Instant};

#[cfg(target_family = "unix")]
use nix::errno::Errno;
#[cfg(target_family = "unix")]
use nix::sys::signal::{kill, Signal};
#[cfg(target_family = "unix")]
use nix::sys::wait::{waitpid, WaitPidFlag, WaitStatus};
#[cfg(target_family = "unix")]
use nix::unistd::Pid;

// å¯¼å…¥å¤‡ä»½ç›¸å…³æ¨¡å—
use crate::backup_reader::{
    read_backup_results, read_backup_results_with_filter, read_existing_backup,
    read_existing_backup_with_filter, TaskResult,
};

#[cfg(target_family = "unix")]
fn reap_process(pid: u32) {
    let target = Pid::from_raw(pid as i32);
    for _ in 0..10 {
        match waitpid(target, Some(WaitPidFlag::WNOHANG)) {
            Ok(WaitStatus::StillAlive) => {
                thread::sleep(Duration::from_millis(50));
            }
            Ok(_) => break,
            Err(Errno::ECHILD) => break,
            Err(_) => break,
        }
    }
}

#[cfg(target_family = "unix")]
fn terminate_process(pid: u32, graceful_timeout: Duration) {
    let target = Pid::from_raw(pid as i32);
    if kill(target, Signal::SIGTERM).is_ok() {
        let mut waited = Duration::ZERO;
        while waited < graceful_timeout {
            match waitpid(target, Some(WaitPidFlag::WNOHANG)) {
                Ok(WaitStatus::StillAlive) => {
                    thread::sleep(Duration::from_millis(50));
                    waited += Duration::from_millis(50);
                }
                Ok(_) => return,
                Err(Errno::ECHILD) => return,
                Err(_) => break,
            }
        }
    }

    let _ = kill(target, Signal::SIGKILL);
    reap_process(pid);
}

#[cfg(target_family = "unix")]
fn ensure_fd_limit(desired: u64) {
    use libc::{getrlimit, rlim_t, setrlimit, RLIMIT_NOFILE, RLIM_INFINITY};

    unsafe {
        let mut current = libc::rlimit {
            rlim_cur: 0 as rlim_t,
            rlim_max: 0 as rlim_t,
        };

        if getrlimit(RLIMIT_NOFILE, &mut current) != 0 {
            eprintln!(
                "âš ï¸ æ— æ³•è·å–RLIMIT_NOFILE: {}",
                std::io::Error::last_os_error()
            );
            return;
        }

        let max_available = if current.rlim_max == RLIM_INFINITY {
            desired as rlim_t
        } else {
            std::cmp::min(current.rlim_max, desired as rlim_t)
        };

        if max_available <= current.rlim_cur {
            return;
        }

        let new_limit = libc::rlimit {
            rlim_cur: max_available,
            rlim_max: current.rlim_max,
        };

        if setrlimit(RLIMIT_NOFILE, &new_limit) != 0 {
            eprintln!(
                "âš ï¸ æå‡RLIMIT_NOFILEå¤±è´¥: {}",
                std::io::Error::last_os_error()
            );
        } else {
            println!(
                "ğŸ”§ å°†RLIMIT_NOFILEä»{}æå‡åˆ°{}",
                current.rlim_cur, max_available
            );
        }
    }
}

#[cfg(not(target_family = "unix"))]
fn ensure_fd_limit(_desired: u64) {}

// é€šç”¨ç»“æœç»“æ„ä½“ï¼Œç”¨äºååºåˆ—åŒ–å•ä¸ªä»»åŠ¡ç»“æœ
#[derive(Debug, Serialize, Deserialize)]
#[allow(dead_code)]
struct SingleResult {
    result: TaskResult,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskParam {
    pub date: i64,
    pub code: String,
}

// æ—§çš„æ‰¹å¤„ç†ç»“æ„ä½“å·²åˆ é™¤ï¼Œåªä¿ç•™å•ä»»åŠ¡ç»“æ„ä½“
#[derive(Debug, Serialize, Deserialize)]
struct SingleTask {
    python_code: String,
    task: TaskParam,
    expected_result_length: usize,
}

// æ–°å¢ï¼šWorkerç›‘æ§ä¿¡æ¯
#[derive(Debug, Clone)]
#[allow(dead_code)]
struct WorkerMonitor {
    worker_id: usize,
    last_heartbeat: Instant,
    current_task: Option<TaskParam>,
    task_start_time: Option<Instant>,
    is_alive: bool,
    consecutive_failures: u32,
    process_id: Option<u32>, // å­è¿›ç¨‹IDï¼Œç”¨äºè¿›ç¨‹å­˜æ´»æ£€æµ‹
}

impl WorkerMonitor {
    fn new(worker_id: usize) -> Self {
        Self {
            worker_id,
            last_heartbeat: Instant::now(),
            current_task: None,
            task_start_time: None,
            is_alive: true,
            consecutive_failures: 0,
            process_id: None,
        }
    }

    fn start_task(&mut self, task: TaskParam) {
        self.current_task = Some(task);
        self.task_start_time = Some(Instant::now());
    }

    fn finish_task(&mut self) {
        self.current_task = None;
        self.task_start_time = None;
        self.consecutive_failures = 0; // é‡ç½®å¤±è´¥è®¡æ•°
    }

    fn update_heartbeat(&mut self) {
        self.last_heartbeat = Instant::now();
        self.is_alive = true;
    }

    fn set_process_id(&mut self, pid: u32) {
        self.process_id = Some(pid);
    }

    fn is_process_alive(&self) -> bool {
        if let Some(pid) = self.process_id {
            // åœ¨Linuxä¸Šï¼Œæ£€æŸ¥/proc/PIDç›®å½•æ˜¯å¦å­˜åœ¨
            #[cfg(target_os = "linux")]
            {
                std::path::Path::new(&format!("/proc/{}", pid)).exists()
            }

            // åœ¨å…¶ä»–ç³»ç»Ÿä¸Šï¼Œç®€åŒ–ä¸ºLinuxçš„æ–¹æ³•ï¼Œå› ä¸ºå¤§å¤šæ•°ç³»ç»Ÿéƒ½æœ‰/proc
            #[cfg(not(target_os = "linux"))]
            {
                // ç®€åŒ–å¤„ç†ï¼šåœ¨éLinuxç³»ç»Ÿä¹Ÿå°è¯•/procæ–¹æ³•ï¼Œå¦‚æœå¤±è´¥å°±å‡è®¾è¿›ç¨‹å­˜æ´»
                std::path::Path::new(&format!("/proc/{}", pid)).exists()
            }
        } else {
            true // å¦‚æœæ²¡æœ‰è¿›ç¨‹IDï¼Œå‡è®¾è¿›ç¨‹å­˜æ´»
        }
    }

    fn is_stuck(
        &self,
        task_timeout: Duration,
        heartbeat_timeout: Duration,
    ) -> Option<&'static str> {
        // é¦–å…ˆæ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜æ´»ç€
        if !self.is_process_alive() {
            return Some("process_death");
        }

        // æ£€æŸ¥å¿ƒè·³è¶…æ—¶
        if self.last_heartbeat.elapsed() > heartbeat_timeout {
            return Some("heartbeat_timeout");
        }

        // æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œè¶…æ—¶
        if let Some(start_time) = self.task_start_time {
            if start_time.elapsed() > task_timeout {
                return Some("task_timeout");
            }
        }

        None
    }
}

// æ–°å¢ï¼šè¯Šæ–­ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
struct DiagnosticStats {
    total_stuck_detections: u32,
    total_force_kills: u32,
    total_restarts: u32,
    stuck_by_timeout: u32,
    stuck_by_heartbeat: u32,
    stuck_by_process_death: u32,
}

impl DiagnosticStats {
    fn new() -> Self {
        Self {
            total_stuck_detections: 0,
            total_force_kills: 0,
            total_restarts: 0,
            stuck_by_timeout: 0,
            stuck_by_heartbeat: 0,
            stuck_by_process_death: 0,
        }
    }
}

// å¡æ­»ä»»åŠ¡ä¿¡æ¯ç»“æ„ä½“
#[derive(Debug, Clone)]
struct StuckTaskInfo {
    date: i64,
    code: String,
    worker_id: usize,
    runtime: Duration,
    reason: String,
}

// æ–°å¢ï¼šWorkerç›‘æ§ç®¡ç†å™¨
#[derive(Debug)]
struct WorkerMonitorManager {
    monitors: Arc<Mutex<HashMap<usize, WorkerMonitor>>>,
    task_timeout: Duration,
    health_check_interval: Duration,
    debug_monitor: bool,
    stats: Arc<Mutex<DiagnosticStats>>,
    should_stop: Arc<AtomicBool>,
    stuck_tasks: Arc<Mutex<Vec<StuckTaskInfo>>>,
}

impl WorkerMonitorManager {
    fn new(task_timeout: Duration, health_check_interval: Duration, debug_monitor: bool) -> Self {
        Self {
            monitors: Arc::new(Mutex::new(HashMap::new())),
            task_timeout,
            health_check_interval,
            debug_monitor,
            stats: Arc::new(Mutex::new(DiagnosticStats::new())),
            should_stop: Arc::new(AtomicBool::new(false)),
            stuck_tasks: Arc::new(Mutex::new(Vec::new())),
        }
    }

    fn add_worker(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            monitors.insert(worker_id, WorkerMonitor::new(worker_id));
            if self.debug_monitor {
                println!("ğŸ” ç›‘æ§å™¨: æ·»åŠ worker {}", worker_id);
            }
        }
    }

    fn set_worker_process_id(&self, worker_id: usize, pid: u32) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                monitor.set_process_id(pid);
                if self.debug_monitor {
                    println!("ğŸ” ç›‘æ§å™¨: Worker {} è®¾ç½®è¿›ç¨‹ID: {}", worker_id, pid);
                }
            }
        }
    }

    fn start_task(&self, worker_id: usize, task: TaskParam) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                monitor.start_task(task.clone());
                if self.debug_monitor {
                    println!(
                        "ğŸ” ç›‘æ§å™¨: Worker {} å¼€å§‹ä»»åŠ¡ date={}, code={}",
                        worker_id, task.date, task.code
                    );
                }
            }
        }
    }

    fn finish_task(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                if self.debug_monitor && monitor.current_task.is_some() {
                    let task = monitor.current_task.as_ref().unwrap();
                    println!(
                        "ğŸ” ç›‘æ§å™¨: Worker {} å®Œæˆä»»åŠ¡ date={}, code={}",
                        worker_id, task.date, task.code
                    );
                }
                monitor.finish_task();
            }
        }
    }

    fn update_heartbeat(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                monitor.update_heartbeat();
            }
        }
    }

    fn check_stuck_workers(&self) -> Vec<(usize, &'static str)> {
        let heartbeat_timeout = self.health_check_interval * 3; // 3ä¸ªæ£€æŸ¥å‘¨æœŸæ— å“åº”è§†ä¸ºå¡æ­»
        let mut stuck_workers = Vec::new();

        if let Ok(monitors) = self.monitors.lock() {
            for (worker_id, monitor) in monitors.iter() {
                // è·³è¿‡å·²ç»æ ‡è®°ä¸ºä¸å­˜æ´»æˆ–æ²¡æœ‰è¿›ç¨‹IDçš„worker
                if !monitor.is_alive || monitor.process_id.is_none() {
                    continue;
                }

                if let Some(stuck_reason) = monitor.is_stuck(self.task_timeout, heartbeat_timeout) {
                    stuck_workers.push((*worker_id, stuck_reason));

                    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    if let Ok(mut stats) = self.stats.lock() {
                        stats.total_stuck_detections += 1;
                        match stuck_reason {
                            "task_timeout" => stats.stuck_by_timeout += 1,
                            "heartbeat_timeout" => stats.stuck_by_heartbeat += 1,
                            "process_death" => stats.stuck_by_process_death += 1,
                            _ => {}
                        }
                    }

                    if self.debug_monitor {
                        println!(
                            "âš ï¸ ç›‘æ§å™¨: æ£€æµ‹åˆ°Worker {} å¡æ­» (åŸå› : {})",
                            worker_id, stuck_reason
                        );
                        if let Some(task) = &monitor.current_task {
                            println!("   æ­£åœ¨å¤„ç†ä»»åŠ¡: date={}, code={}", task.date, task.code);
                        }
                        println!("   æœ€åå¿ƒè·³: {:?}å‰", monitor.last_heartbeat.elapsed());
                        if let Some(start_time) = monitor.task_start_time {
                            println!("   ä»»åŠ¡è¿è¡Œæ—¶é—´: {:?}", start_time.elapsed());
                        }
                    }
                }
            }
        }

        stuck_workers
    }

    fn log_stuck_worker(&self, worker_id: usize, reason: &str) {
        if let Ok(monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get(&worker_id) {
                // åªåœ¨debugæ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                if self.debug_monitor {
                    println!("ğŸš¨ Worker {} è¢«æ ‡è®°ä¸ºå¡æ­»å¹¶å°†é‡å¯", worker_id);
                    if let Some(task) = &monitor.current_task {
                        println!(
                            "   è·³è¿‡ä»»åŠ¡: date={}, code={} (å·²è¿è¡Œ {:?})",
                            task.date,
                            task.code,
                            monitor
                                .task_start_time
                                .map(|t| t.elapsed())
                                .unwrap_or(Duration::ZERO)
                        );
                    }
                    println!("   æœ€åå¿ƒè·³æ—¶é—´: {:?}å‰", monitor.last_heartbeat.elapsed());
                    if let Some(pid) = monitor.process_id {
                        println!("   è¿›ç¨‹ID: {}", pid);
                    }
                }

                // è®°å½•å¡æ­»ä»»åŠ¡ä¿¡æ¯
                if let Some(task) = &monitor.current_task {
                    let stuck_task = StuckTaskInfo {
                        date: task.date,
                        code: task.code.clone(),
                        worker_id,
                        runtime: monitor
                            .task_start_time
                            .map(|t| t.elapsed())
                            .unwrap_or(Duration::ZERO),
                        reason: reason.to_string(),
                    };

                    if let Ok(mut stuck_tasks) = self.stuck_tasks.lock() {
                        stuck_tasks.push(stuck_task);
                    }
                }
            }
        }
    }

    fn terminate_all_workers(&self, graceful_timeout: Duration) {
        #[cfg(target_family = "unix")]
        {
            let targets: Vec<(usize, u32)> = match self.monitors.lock() {
                Ok(monitors) => monitors
                    .iter()
                    .filter_map(|(id, monitor)| monitor.process_id.map(|pid| (*id, pid)))
                    .collect(),
                Err(_) => Vec::new(),
            };

            for (worker_id, pid) in targets {
                terminate_process(pid, graceful_timeout);

                if let Ok(mut monitors) = self.monitors.lock() {
                    if let Some(monitor) = monitors.get_mut(&worker_id) {
                        monitor.process_id = None;
                        monitor.is_alive = false;
                    }
                }
            }
        }

        #[cfg(not(target_family = "unix"))]
        {
            let _ = graceful_timeout;
        }
    }

    fn force_kill_worker(&self, worker_id: usize) -> bool {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                if let Some(pid) = monitor.process_id {
                    // é¦–å…ˆæ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»ç„¶å­˜åœ¨
                    if !monitor.is_process_alive() {
                        if self.debug_monitor {
                            println!(
                                "ğŸ” Worker {} è¿›ç¨‹ {} å·²ä¸å­˜åœ¨ï¼Œæ¸…ç†ç›‘æ§è®°å½•",
                                worker_id, pid
                            );
                        }
                        // ç›´æ¥ç§»é™¤æ•´ä¸ªç›‘æ§è®°å½•
                        drop(monitors); // é‡Šæ”¾é”
                        self.remove_worker(worker_id);
                        return true;
                    }

                    if self.debug_monitor {
                        println!("ğŸ”¥ å¼ºåˆ¶ç»ˆæ­¢Worker {} è¿›ç¨‹ (PID: {})", worker_id, pid);
                    }

                    #[cfg(target_family = "unix")]
                    {
                        match kill(Pid::from_raw(pid as i32), Signal::SIGKILL) {
                            Ok(()) => {
                                reap_process(pid);
                                monitor.process_id = None; // æ¸…é™¤è¿›ç¨‹ID

                                if let Ok(mut stats) = self.stats.lock() {
                                    stats.total_force_kills += 1;
                                }

                                return true;
                            }
                            Err(err) => {
                                if err == Errno::ESRCH {
                                    if self.debug_monitor {
                                        println!("ğŸ” è¿›ç¨‹ {} å·²ä¸å­˜åœ¨ï¼Œæ¸…ç†ç›‘æ§è®°å½•", pid);
                                    }
                                    drop(monitors);
                                    self.remove_worker(worker_id);
                                    return true;
                                } else {
                                    eprintln!("âŒ ç»ˆæ­¢è¿›ç¨‹å¤±è´¥: {}", err);
                                }
                            }
                        }
                    }

                    #[cfg(not(target_family = "unix"))]
                    {
                        println!("âš ï¸ éUnixç³»ç»Ÿï¼Œæ— æ³•å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {}", pid);
                        monitor.process_id = None; // æ¸…é™¤è¿›ç¨‹IDï¼Œå‡è®¾è¿›ç¨‹å·²æ­»
                        return true;
                    }
                }
            }
        }
        false
    }

    fn remove_worker(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            monitors.remove(&worker_id);
            if self.debug_monitor {
                println!("ğŸ” ç›‘æ§å™¨: ç§»é™¤worker {}", worker_id);
            }
        }
    }

    fn stop_monitoring(&self) {
        self.should_stop.store(true, Ordering::SeqCst);
        if self.debug_monitor {
            println!("ğŸ” ç›‘æ§å™¨: æ¥æ”¶åˆ°åœæ­¢ä¿¡å·");
        }
    }

    fn should_stop_monitoring(&self) -> bool {
        self.should_stop.load(Ordering::SeqCst)
    }

    fn print_diagnostic_stats(&self) {
        // ä½¿ç”¨try_locké¿å…æ— é™ç­‰å¾…
        match self.stats.try_lock() {
            Ok(stats) => {
                if stats.total_stuck_detections > 0 {
                    println!("\nğŸ“Š ç›‘æ§å™¨è¯Šæ–­ç»Ÿè®¡:");
                    println!("   æ€»å¡æ­»æ£€æµ‹æ¬¡æ•°: {}", stats.total_stuck_detections);
                    println!("   ä»»åŠ¡è¶…æ—¶å¯¼è‡´: {}", stats.stuck_by_timeout);
                    println!("   å¿ƒè·³è¶…æ—¶å¯¼è‡´: {}", stats.stuck_by_heartbeat);
                    println!("   è¿›ç¨‹æ­»äº¡å¯¼è‡´: {}", stats.stuck_by_process_death);
                    println!("   å¼ºåˆ¶ç»ˆæ­¢æ¬¡æ•°: {}", stats.total_force_kills);
                    println!("   é‡å¯æ¬¡æ•°: {}", stats.total_restarts);
                } else {
                    println!(
                        "[{}] ğŸ“Š ç›‘æ§å™¨ç»Ÿè®¡: æœªæ£€æµ‹åˆ°ä»»ä½•workerå¡æ­»",
                        Local::now().format("%Y-%m-%d %H:%M:%S")
                    );
                }
            }
            Err(_) => {
                println!("âš ï¸ æ— æ³•è·å–è¯Šæ–­ç»Ÿè®¡é”ï¼Œè·³è¿‡ç»Ÿè®¡è¾“å‡º");
            }
        }
    }

    fn print_stuck_tasks_table(&self) {
        // ä½¿ç”¨try_locké¿å…æ— é™ç­‰å¾…ï¼Œå¹¶æ·»åŠ é”™è¯¯å¤„ç†
        match self.stuck_tasks.try_lock() {
            Ok(stuck_tasks) => {
                if stuck_tasks.is_empty() {
                    println!("\nâœ… æ²¡æœ‰ä»»åŠ¡å› è¶…æ—¶è¢«è·³è¿‡");
                } else {
                    println!("\nğŸ“‹ å¡æ­»ä»»åŠ¡ç»Ÿè®¡è¡¨");
                    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
                    println!("â”‚   Date   â”‚   Code   â”‚ Worker  â”‚   Runtime    â”‚    Reason    â”‚");
                    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");

                    for task in stuck_tasks.iter() {
                        let runtime_str = if task.runtime.as_secs() > 0 {
                            format!("{:.1}s", task.runtime.as_secs_f64())
                        } else {
                            format!("{}ms", task.runtime.as_millis())
                        };

                        println!(
                            "â”‚ {:8} â”‚ {:8} â”‚ {:7} â”‚ {:12} â”‚ {:12} â”‚",
                            task.date,
                            task.code,
                            task.worker_id,
                            runtime_str,
                            match task.reason.as_str() {
                                "task_timeout" => "ä»»åŠ¡è¶…æ—¶",
                                "heartbeat_timeout" => "å¿ƒè·³è¶…æ—¶",
                                "process_death" => "è¿›ç¨‹æ­»äº¡",
                                _ => &task.reason,
                            }
                        );
                    }

                    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
                    println!("å…± {} ä¸ªä»»åŠ¡å› è¶…æ—¶è¢«è·³è¿‡", stuck_tasks.len());
                }
            }
            Err(_) => {
                println!("âš ï¸ æ— æ³•è·å–å¡æ­»ä»»åŠ¡ç»Ÿè®¡é”ï¼Œè·³è¿‡ç»Ÿè®¡è¡¨æ‰“å°");
            }
        }
    }

    /// æ¸…ç†ç›‘æ§ç®¡ç†å™¨çš„æ‰€æœ‰èµ„æºï¼Œç¡®ä¿æ²¡æœ‰é—ç•™å¼•ç”¨
    fn cleanup(&self) {
        if self.debug_monitor {
            println!("ğŸ§¹ ç›‘æ§å™¨: å¼€å§‹æ¸…ç†èµ„æº...");
        }

        // æ¸…ç†æ‰€æœ‰monitorè®°å½•
        if let Ok(mut monitors) = self.monitors.try_lock() {
            monitors.clear();
            if self.debug_monitor {
                println!("ğŸ§¹ ç›‘æ§å™¨: å·²æ¸…ç†æ‰€æœ‰workerç›‘æ§è®°å½•");
            }
        } else if self.debug_monitor {
            println!("âš ï¸ ç›‘æ§å™¨: æ— æ³•è·å–monitorsé”è¿›è¡Œæ¸…ç†");
        }

        // æ¸…ç†å¡æ­»ä»»åŠ¡è®°å½•
        if let Ok(mut stuck_tasks) = self.stuck_tasks.try_lock() {
            stuck_tasks.clear();
            if self.debug_monitor {
                println!("ğŸ§¹ ç›‘æ§å™¨: å·²æ¸…ç†æ‰€æœ‰å¡æ­»ä»»åŠ¡è®°å½•");
            }
        } else if self.debug_monitor {
            println!("âš ï¸ ç›‘æ§å™¨: æ— æ³•è·å–stuck_tasksé”è¿›è¡Œæ¸…ç†");
        }

        // é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        if let Ok(mut stats) = self.stats.try_lock() {
            *stats = DiagnosticStats::new();
            if self.debug_monitor {
                println!("ğŸ§¹ ç›‘æ§å™¨: å·²é‡ç½®è¯Šæ–­ç»Ÿè®¡ä¿¡æ¯");
            }
        } else if self.debug_monitor {
            println!("âš ï¸ ç›‘æ§å™¨: æ— æ³•è·å–statsé”è¿›è¡Œæ¸…ç†");
        }

        if self.debug_monitor {
            println!("âœ… ç›‘æ§å™¨: èµ„æºæ¸…ç†å®Œæˆ");
        }
    }
}

fn detect_python_interpreter() -> String {
    // 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    if let Ok(python_path) = env::var("PYTHON_INTERPRETER") {
        if Path::new(&python_path).exists() {
            return python_path;
        }
    }

    // 2. æ£€æŸ¥æ˜¯å¦åœ¨ conda ç¯å¢ƒä¸­
    if let Ok(conda_prefix) = env::var("CONDA_PREFIX") {
        let conda_python = format!("{}/bin/python", conda_prefix);
        if Path::new(&conda_python).exists() {
            return conda_python;
        }
    }

    // 3. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if let Ok(virtual_env) = env::var("VIRTUAL_ENV") {
        let venv_python = format!("{}/bin/python", virtual_env);
        if Path::new(&venv_python).exists() {
            return venv_python;
        }
    }

    // 4. å°è¯•å¸¸è§çš„ Python è§£é‡Šå™¨
    let candidates = ["python3", "python"];
    for candidate in &candidates {
        if Command::new("which")
            .arg(candidate)
            .output()
            .map(|output| output.status.success())
            .unwrap_or(false)
        {
            return candidate.to_string();
        }
    }

    // 5. é»˜è®¤å€¼
    "python".to_string()
}

// ä¿ç•™å¤‡ä»½ä¿å­˜åŠŸèƒ½ï¼Œä½†ä½¿ç”¨æ¥è‡ªbackup_readerçš„ç»“æ„ä½“å®šä¹‰
fn save_results_to_backup(
    results: &[TaskResult],
    backup_file: &str,
    expected_result_length: usize,
) -> Result<(), Box<dyn std::error::Error>> {
    use crate::backup_reader::{calculate_record_size, DynamicRecord, FileHeader};

    if results.is_empty() {
        return Ok(());
    }

    let factor_count = expected_result_length;
    let record_size = calculate_record_size(factor_count);
    let header_size = 64; // HEADER_SIZE from backup_reader

    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    let file_path = Path::new(backup_file);
    let file_exists = file_path.exists();
    let file_valid = if file_exists {
        file_path
            .metadata()
            .map(|m| m.len() >= header_size as u64)
            .unwrap_or(false)
    } else {
        false
    };

    if !file_valid {
        // åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå†™å…¥æ–‡ä»¶å¤´
        let mut file = OpenOptions::new()
            .create(true)
            .write(true)
            .truncate(true)
            .open(backup_file)?;

        let header = FileHeader {
            magic: *b"RPBACKUP",
            version: 2, // ç‰ˆæœ¬2è¡¨ç¤ºæ”¯æŒåŠ¨æ€å› å­æ•°é‡
            record_count: 0,
            record_size: record_size as u32,
            factor_count: factor_count as u32,
            reserved: [0; 36],
        };

        // å†™å…¥æ–‡ä»¶å¤´
        let header_bytes = unsafe {
            std::slice::from_raw_parts(
                &header as *const FileHeader as *const u8,
                std::mem::size_of::<FileHeader>(),
            )
        };

        file.write_all(header_bytes)?;
        file.flush()?;
    }

    // è¯»å–å½“å‰è®°å½•æ•°
    let mut file = OpenOptions::new()
        .create(true)
        .read(true)
        .write(true)
        .open(backup_file)?;

    let file_len = file.metadata()?.len() as usize;
    if file_len < header_size {
        return Err(format!(
            "File is too small to contain valid header: {} < {}",
            file_len, header_size
        )
        .into());
    }

    let mut header_bytes = [0u8; 64];
    use std::io::Read;
    file.read_exact(&mut header_bytes)?;

    let header = unsafe { &mut *(header_bytes.as_mut_ptr() as *mut FileHeader) };

    // éªŒè¯å› å­æ•°é‡åŒ¹é…
    let file_factor_count = header.factor_count;
    if file_factor_count != factor_count as u32 {
        return Err(format!(
            "Factor count mismatch: file has {}, expected {}",
            file_factor_count, factor_count
        )
        .into());
    }

    let current_count = header.record_count;
    let new_count = current_count + results.len() as u64;

    // æ‰©å±•æ–‡ä»¶å¤§å°
    let new_file_size = header_size as u64 + new_count * record_size as u64;
    file.set_len(new_file_size)?;

    // ä½¿ç”¨å†…å­˜æ˜ å°„è¿›è¡Œé«˜é€Ÿå†™å…¥
    drop(file);
    let file = OpenOptions::new()
        .create(true)
        .read(true)
        .write(true)
        .open(backup_file)?;

    let mut mmap = unsafe { MmapMut::map_mut(&file)? };

    // æ›´æ–°æ–‡ä»¶å¤´ä¸­çš„è®°å½•æ•°é‡
    let header = unsafe { &mut *(mmap.as_mut_ptr() as *mut FileHeader) };
    header.record_count = new_count;

    // å†™å…¥æ–°è®°å½•
    let start_offset = header_size + current_count as usize * record_size;

    for (i, result) in results.iter().enumerate() {
        let record = DynamicRecord::from_task_result(result);
        let record_bytes = record.to_bytes();
        let record_offset = start_offset + i * record_size;

        // ç¡®ä¿è®°å½•å¤§å°æ­£ç¡®
        if record_bytes.len() != record_size {
            return Err(format!(
                "Record size mismatch: got {}, expected {}",
                record_bytes.len(),
                record_size
            )
            .into());
        }

        mmap[record_offset..record_offset + record_size].copy_from_slice(&record_bytes);
    }

    mmap.flush()?;

    Ok(())
}

fn create_persistent_worker_script() -> String {
    format!(
        r#"#!/usr/bin/env python3
import sys
import msgpack
import time
import struct
import math
import signal
import os
import traceback

class WorkerHealthManager:
    """Workerå¥åº·çŠ¶æ€ç®¡ç†å™¨"""
    def __init__(self):
        self.task_count = 0
        self.error_count = 0
        self.consecutive_errors = 0
        self.start_time = time.time()
        self.last_heartbeat = time.time()
        self.max_consecutive_errors = 5
        self.max_errors = 100
        self.health_check_interval = 60  # 60ç§’
        self.max_memory_mb = 1024  # 1GBå†…å­˜é™åˆ¶

    def record_task_success(self):
        """è®°å½•ä»»åŠ¡æˆåŠŸ"""
        self.task_count += 1
        self.consecutive_errors = 0
        self.last_heartbeat = time.time()

    def record_task_error(self):
        """è®°å½•ä»»åŠ¡é”™è¯¯"""
        self.error_count += 1
        self.consecutive_errors += 1
        self.last_heartbeat = time.time()

    def should_restart(self):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡å¯worker"""
        # è¿ç»­é”™è¯¯è¿‡å¤š
        if self.consecutive_errors >= self.max_consecutive_errors:
            print(f"Worker restart: è¿ç»­é”™è¯¯è¾¾åˆ° {{self.consecutive_errors}} æ¬¡", file=sys.stderr)
            return True

        # æ€»é”™è¯¯æ•°è¿‡å¤š
        if self.error_count >= self.max_errors:
            print(f"Worker restart: æ€»é”™è¯¯æ•°è¾¾åˆ° {{self.error_count}} æ¬¡", file=sys.stderr)
            return True

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        try:
            import psutil
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            if memory_mb > self.max_memory_mb:
                print(f"Worker restart: å†…å­˜ä½¿ç”¨è¿‡é«˜ ({{memory_mb:.1f}}MB > {{self.max_memory_mb}}MB)", file=sys.stderr)
                return True
        except ImportError:
            pass  # å¦‚æœæ²¡æœ‰psutilï¼Œè·³è¿‡å†…å­˜æ£€æŸ¥

        return False

    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        uptime = time.time() - self.start_time
        return {{
            'uptime': uptime,
            'task_count': self.task_count,
            'error_count': self.error_count,
            'consecutive_errors': self.consecutive_errors
        }}

# å…¨å±€å¥åº·ç®¡ç†å™¨
health_manager = WorkerHealthManager()

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    print(f"Worker received signal {{signum}}, shutting down gracefully...", file=sys.stderr)
    stats = health_manager.get_stats()
    print(f"Worker stats: uptime={{stats['uptime']:.1f}}s, tasks={{stats['task_count']}}, errors={{stats['error_count']}}", file=sys.stderr)
    sys.exit(0)

# æ³¨å†Œä¿¡å·å¤„ç†å™¨
signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

def normalize_value(x):
    '''å°†å€¼æ ‡å‡†åŒ–ï¼Œå°† Noneã€infã€-infã€nan éƒ½è½¬æ¢ä¸º nan'''
    if x is None:
        return float('nan')
    try:
        val = float(x)
        if math.isinf(val) or math.isnan(val):
            return float('nan')
        return val
    except (ValueError, TypeError):
        return float('nan')

def execute_task_with_timeout(func_code, date, code, expected_length, timeout=120):
    '''å¸¦è¶…æ—¶çš„ä»»åŠ¡æ‰§è¡Œ'''
    import threading
    import queue

    result_queue = queue.Queue()

    def worker():
        try:
            namespace = {{'__builtins__': __builtins__}}
            exec(func_code, namespace)

            # æ‰¾åˆ°ç”¨æˆ·å®šä¹‰çš„å‡½æ•°
            user_functions = [name for name, obj in namespace.items()
                             if callable(obj) and not name.startswith('_') and name != 'execute_task']

            if not user_functions:
                result_queue.put([float('nan')] * expected_length)
                return

            func = namespace[user_functions[0]]
            result = func(date, code)

            if isinstance(result, list):
                normalized_result = [normalize_value(x) for x in result]
                result_queue.put(normalized_result)
            else:
                result_queue.put([float('nan')] * expected_length)

        except Exception as e:
            print(f"Task execution error for {{date}}, {{code}}: {{e}}", file=sys.stderr)
            result_queue.put([float('nan')] * expected_length)

    # å¯åŠ¨å·¥ä½œçº¿ç¨‹
    thread = threading.Thread(target=worker)
    thread.daemon = True
    thread.start()

    try:
        result = result_queue.get(timeout=timeout)
        thread.join(timeout=1)
        return result
    except queue.Empty:
        print(f"Task timeout for {{date}}, {{code}} after {{timeout}}s", file=sys.stderr)
        return [float('nan')] * expected_length
    except Exception as e:
        print(f"Task error for {{date}}, {{code}}: {{e}}", file=sys.stderr)
        return [float('nan')] * expected_length

def read_message_with_timeout(timeout=30):
    '''å¸¦è¶…æ—¶çš„æ¶ˆæ¯è¯»å–'''
    import select

    # æ£€æŸ¥stdinæ˜¯å¦å¯è¯»
    if not select.select([sys.stdin.buffer], [], [], timeout)[0]:
        return None

    # è¯»å–4å­—èŠ‚é•¿åº¦å‰ç¼€
    length_bytes = sys.stdin.buffer.read(4)
    if len(length_bytes) != 4:
        return None

    length = struct.unpack('<I', length_bytes)[0]
    if length == 0:
        return None

    # éªŒè¯é•¿åº¦åˆç†æ€§
    if length > 100 * 1024 * 1024:  # 100MBé™åˆ¶
        print(f"Message too large: {{length}} bytes", file=sys.stderr)
        return None

    # è¯»å–å®é™…æ•°æ®
    data = sys.stdin.buffer.read(length)
    if len(data) != length:
        return None

    return data

def write_message(data):
    '''å‘stdoutå†™å…¥ä¸€æ¡æ¶ˆæ¯ï¼Œå¸¦é•¿åº¦å‰ç¼€'''
    try:
        length = len(data)
        length_bytes = struct.pack('<I', length)
        sys.stdout.buffer.write(length_bytes)
        sys.stdout.buffer.write(data)
        sys.stdout.buffer.flush()
    except IOError as e:
        print(f"Failed to write message: {{e}}", file=sys.stderr)
        raise

def main():
    print("ğŸš€ Enhanced worker started (PID: {{}})".format(os.getpid()), file=sys.stderr)

    # æŒç»­å¤„ç†ä»»åŠ¡ï¼Œç›´åˆ°æ”¶åˆ°ç©ºæ¶ˆæ¯æˆ–éœ€è¦é‡å¯
    while True:
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
            if health_manager.should_restart():
                print("ğŸ”„ Worker initiating restart due to health check", file=sys.stderr)
                sys.exit(1)

            # å¸¦è¶…æ—¶è¯»å–ä»»åŠ¡æ¶ˆæ¯
            message_data = read_message_with_timeout(timeout=30)
            if message_data is None:
                break

            try:
                task_data = msgpack.unpackb(message_data, raw=False)
            except Exception as e:
                print(f"Failed to unpack message: {{e}}", file=sys.stderr)
                continue

            if not isinstance(task_data, dict):
                print(f"Error: Expected dict, got {{type(task_data)}}: {{task_data}}", file=sys.stderr)
                continue

            func_code = task_data['python_code']
            task = task_data['task']
            expected_length = task_data['expected_result_length']

            # æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
            timestamp = int(time.time() * 1000)
            date = task['date']
            code = task['code']

            try:
                facs = execute_task_with_timeout(func_code, date, code, expected_length, timeout=120)
                health_manager.record_task_success()
            except Exception as e:
                print(f"Task execution failed for {{date}}, {{code}}: {{e}}", file=sys.stderr)
                facs = [float('nan')] * expected_length
                health_manager.record_task_error()

            result = {{
                'date': date,
                'code': code,
                'timestamp': timestamp,
                'facs': facs
            }}

            # ä½¿ç”¨MessagePackåºåˆ—åŒ–å¹¶å‘é€ç»“æœ
            output = {{'result': result}}
            packed_output = msgpack.packb(output, use_bin_type=True)
            write_message(packed_output)

        except KeyboardInterrupt:
            print("ğŸ Worker interrupted by user", file=sys.stderr)
            break
        except IOError as e:
            print(f"ğŸ Worker I/O error: {{e}}", file=sys.stderr)
            break
        except Exception as e:
            print(f"Worker error: {{e}}", file=sys.stderr)
            traceback.print_exc(file=sys.stderr)
            health_manager.record_task_error()

            # å‘é€é”™è¯¯ç»“æœ
            error_result = {{
                'result': {{
                    'date': 0,
                    'code': '',
                    'timestamp': int(time.time() * 1000),
                    'facs': [float('nan')] * expected_length
                }}
            }}
            try:
                packed_error = msgpack.packb(error_result, use_bin_type=True)
                write_message(packed_error)
            except Exception as write_error:
                print(f"Failed to send error result: {{write_error}}", file=sys.stderr)
                break

    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    stats = health_manager.get_stats()
    print("ğŸ Enhanced worker finished", file=sys.stderr)
    print(f"Final stats: uptime={{stats['uptime']:.1f}}s, tasks={{stats['task_count']}}, errors={{stats['error_count']}}", file=sys.stderr)

if __name__ == '__main__':
    main()
"#
    )
}

fn extract_python_function_code(py_func: &PyObject) -> PyResult<String> {
    Python::with_gil(|py| {
        // å°è¯•è·å–å‡½æ•°çš„æºä»£ç 
        let inspect = py.import("inspect")?;

        match inspect.call_method1("getsource", (py_func,)) {
            Ok(source) => {
                let source_str: String = source.extract()?;
                Ok(source_str)
            }
            Err(_) => {
                // å¦‚æœæ— æ³•è·å–æºä»£ç ï¼Œå°è¯•ä½¿ç”¨pickle
                let pickle = py.import("pickle")?;
                match pickle.call_method1("dumps", (py_func,)) {
                    Ok(pickled) => {
                        let bytes: Vec<u8> = pickled.extract()?;
                        let base64 = py.import("base64")?;
                        let encoded = base64.call_method1("b64encode", (bytes,))?;
                        let encoded_str: String = encoded.call_method0("decode")?.extract()?;
                        
                        Ok(format!(r#"
import pickle
import base64
_func_data = base64.b64decode('{}')
user_function = pickle.loads(_func_data)
"#, encoded_str))
                    }
                    Err(_) => {
                        Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
                            "Cannot serialize the Python function. Please ensure the function can be pickled or provide source code."
                        ))
                    }
                }
            }
        }
    })
}

fn run_persistent_task_worker(
    worker_id: usize,
    task_queue: Receiver<TaskParam>,
    python_code: String,
    expected_result_length: usize,
    python_path: String,
    result_sender: Sender<TaskResult>,
    restart_flag: Arc<AtomicBool>,
    monitor_manager: Arc<WorkerMonitorManager>,
) {
    // å‘ç›‘æ§ç®¡ç†å™¨æ³¨å†Œworker
    monitor_manager.add_worker(worker_id);

    loop {
        // å¾ªç¯ä»¥æ”¯æŒworkeré‡å¯
        if restart_flag
            .compare_exchange(true, false, Ordering::SeqCst, Ordering::Relaxed)
            .is_ok()
        {
            // println!("ğŸ”„ Worker {} æ£€æµ‹åˆ°é‡å¯ä¿¡å·ï¼Œæ­£åœ¨é‡å¯...", worker_id);
        }

        // println!("ğŸš€ Persistent Worker {} å¯åŠ¨ï¼Œåˆ›å»ºæŒä¹…Pythonè¿›ç¨‹", worker_id);

        let script_content = create_persistent_worker_script();
        let script_path = format!("/tmp/persistent_worker_{}.py", worker_id);

        // åˆ›å»ºworkerè„šæœ¬
        if let Err(e) = std::fs::write(&script_path, script_content) {
            eprintln!("âŒ Worker {} åˆ›å»ºè„šæœ¬å¤±è´¥: {}", worker_id, e);
            continue; // ç»§ç»­å¤–å±‚å¾ªç¯ï¼Œå°è¯•é‡æ–°åˆ›å»ºè„šæœ¬
        }

        // å¯åŠ¨æŒä¹…çš„Pythonå­è¿›ç¨‹
        let mut child = match Command::new(&python_path)
            .arg(&script_path)
            .stdin(Stdio::piped())
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .spawn()
        {
            Ok(child) => child,
            Err(e) => {
                eprintln!("âŒ Worker {} å¯åŠ¨Pythonè¿›ç¨‹å¤±è´¥: {}", worker_id, e);
                continue; // ç»§ç»­å¤–å±‚å¾ªç¯ï¼Œå°è¯•é‡æ–°å¯åŠ¨è¿›ç¨‹
            }
        };

        // è®¾ç½®å­è¿›ç¨‹IDåˆ°ç›‘æ§ç®¡ç†å™¨
        let pid = child.id();
        monitor_manager.set_worker_process_id(worker_id, pid);
        monitor_manager.update_heartbeat(worker_id);

        let mut stdin = child.stdin.take().expect("Failed to get stdin");
        let mut stdout = child.stdout.take().expect("Failed to get stdout");

        let mut task_count = 0;
        let mut needs_restart = false;

        // æŒç»­ä»é˜Ÿåˆ—ä¸­å–ä»»åŠ¡å¹¶å‘é€ç»™Pythonè¿›ç¨‹
        while let Ok(task) = task_queue.recv() {
            // åœ¨å¤„ç†ä»»åŠ¡å‰æ£€æŸ¥é‡å¯æ ‡å¿—
            if restart_flag.load(Ordering::Relaxed) {
                needs_restart = true;
                break;
            }

            task_count += 1;

            // é€šçŸ¥ç›‘æ§ç®¡ç†å™¨å¼€å§‹å¤„ç†ä»»åŠ¡
            monitor_manager.start_task(worker_id, task.clone());
            monitor_manager.update_heartbeat(worker_id);

            // åˆ›å»ºå•ä»»åŠ¡æ•°æ®
            let single_task = SingleTask {
                python_code: python_code.clone(),
                task: task.clone(),
                expected_result_length,
            };

            // åºåˆ—åŒ–ä»»åŠ¡æ•°æ®
            let packed_data = match rmp_serde::to_vec_named(&single_task) {
                Ok(data) => data,
                Err(_e) => {
                    // eprintln!("âŒ Worker {} ä»»åŠ¡ #{} åºåˆ—åŒ–å¤±è´¥: {}", worker_id, task_count, e);
                    continue;
                }
            };

            // å‘é€ä»»åŠ¡åˆ°Pythonè¿›ç¨‹ï¼ˆå¸¦é•¿åº¦å‰ç¼€ï¼‰
            let length = packed_data.len() as u32;
            let length_bytes = length.to_le_bytes();

            if let Err(_e) = stdin.write_all(&length_bytes) {
                // eprintln!("âŒ Worker {} å‘é€é•¿åº¦å‰ç¼€å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }

            if let Err(_e) = stdin.write_all(&packed_data) {
                // eprintln!("âŒ Worker {} å‘é€ä»»åŠ¡æ•°æ®å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }

            if let Err(_e) = stdin.flush() {
                // eprintln!("âŒ Worker {} flushå¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }

            // è¯»å–ç»“æœï¼ˆå¸¦é•¿åº¦å‰ç¼€ï¼‰
            let mut length_bytes = [0u8; 4];
            if let Err(_e) = stdout.read_exact(&mut length_bytes) {
                // eprintln!("âŒ Worker {} è¯»å–ç»“æœé•¿åº¦å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }

            let length = u32::from_le_bytes(length_bytes) as usize;
            let mut result_data = vec![0u8; length];

            if let Err(_e) = stdout.read_exact(&mut result_data) {
                // eprintln!("âŒ Worker {} è¯»å–ç»“æœæ•°æ®å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }

            // è§£æç»“æœ
            #[derive(Debug, Serialize, Deserialize)]
            struct SingleResult {
                result: TaskResult,
            }

            match rmp_serde::from_slice::<SingleResult>(&result_data) {
                Ok(single_result) => {
                    // å‘é€ç»“æœ
                    if let Err(e) = result_sender.send(single_result.result) {
                        eprintln!(
                            "âŒ Worker {} ä»»åŠ¡ #{} ç»“æœå‘é€å¤±è´¥: {}",
                            worker_id, task_count, e
                        );
                        // ç»“æœå‘é€å¤±è´¥å¯èƒ½æ˜¯æ”¶é›†å™¨å·²é€€å‡ºï¼Œä½†ä¸å½±å“å…¶ä»–workerï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
                        // ä¸è®¾ç½®needs_restartï¼Œé¿å…ä¸å¿…è¦çš„å­è¿›ç¨‹é‡å¯
                    }
                    // é€šçŸ¥ç›‘æ§ç®¡ç†å™¨ä»»åŠ¡å·²å®Œæˆ
                    monitor_manager.finish_task(worker_id);
                    monitor_manager.update_heartbeat(worker_id);
                }
                Err(e) => {
                    eprintln!(
                        "âŒ Worker {} ä»»åŠ¡ #{} ç»“æœè§£æå¤±è´¥: {}",
                        worker_id, task_count, e
                    );

                    // å‘é€NaNç»“æœ
                    let error_result = TaskResult {
                        date: task.date,
                        code: task.code,
                        timestamp: chrono::Utc::now().timestamp_millis(),
                        facs: vec![f64::NAN; expected_result_length],
                    };

                    if let Err(e) = result_sender.send(error_result) {
                        eprintln!("âŒ Worker {} é”™è¯¯ç»“æœå‘é€å¤±è´¥: {}", worker_id, e);
                        // é”™è¯¯ç»“æœå‘é€å¤±è´¥ä¹Ÿä¸å½±å“å…¶ä»–workerï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
                        // ä¸è®¾ç½®needs_restartï¼Œé¿å…ä¸å¿…è¦çš„å­è¿›ç¨‹é‡å¯
                    }
                    // é€šçŸ¥ç›‘æ§ç®¡ç†å™¨ä»»åŠ¡å·²å®Œæˆï¼ˆå³ä½¿å¤±è´¥ï¼‰
                    monitor_manager.finish_task(worker_id);
                    monitor_manager.update_heartbeat(worker_id);
                }
            }
        }

        // å‘é€ç»“æŸä¿¡å·ï¼ˆé•¿åº¦ä¸º0ï¼‰
        let _ = stdin.write_all(&[0u8; 4]);
        let _ = stdin.flush();

        // ç­‰å¾…å­è¿›ç¨‹ç»“æŸ
        let _ = child.wait();

        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        let _ = std::fs::remove_file(&script_path);
        // println!("ğŸ Persistent Worker {} ç»“æŸï¼Œå…±å¤„ç† {} ä¸ªä»»åŠ¡", worker_id, task_count);

        if !needs_restart {
            // å¦‚æœä¸æ˜¯å› ä¸ºé‡å¯ä¿¡å·è€Œé€€å‡ºï¼Œè¯´æ˜æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
            break;
        }
    }

    // Workerå®Œå…¨ç»“æŸæ—¶ï¼Œä»ç›‘æ§å™¨ä¸­ç§»é™¤è®°å½•
    monitor_manager.remove_worker(worker_id);
}

#[pyfunction]
#[pyo3(signature = (python_function, args, n_jobs, backup_file, expected_result_length, restart_interval=None, update_mode=None, return_results=None, task_timeout=None, health_check_interval=None, debug_monitor=None, backup_batch_size=None))]
pub fn run_pools_queue(
    python_function: PyObject,
    args: &PyList,
    n_jobs: usize,
    backup_file: String,
    expected_result_length: usize,
    restart_interval: Option<usize>,
    update_mode: Option<bool>,
    return_results: Option<bool>,
    task_timeout: Option<u64>,
    health_check_interval: Option<u64>,
    debug_monitor: Option<bool>,
    backup_batch_size: Option<usize>,
) -> PyResult<PyObject> {
    // å¤„ç† restart_interval å‚æ•°
    let restart_interval_value = restart_interval.unwrap_or(200);
    if restart_interval_value == 0 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "restart_interval must be greater than 0",
        ));
    }

    // å¤„ç† update_mode å‚æ•°
    let update_mode_enabled = update_mode.unwrap_or(false);

    // å¤„ç† return_results å‚æ•°
    let return_results_enabled = return_results.unwrap_or(true);

    // å¤„ç†æ–°çš„ç›‘æ§å‚æ•°
    let task_timeout_secs = task_timeout.unwrap_or(120);
    let health_check_interval_secs = health_check_interval.unwrap_or(300); // ä¼˜åŒ–: ä»120ç§’å¢åŠ åˆ°300ç§’
    let debug_monitor_enabled = debug_monitor.unwrap_or(false);

    // å¤„ç†æ‰¹å¤„ç†å¤§å°å‚æ•°
    let backup_batch_size_value = backup_batch_size.unwrap_or(5000); // ä¼˜åŒ–: ä»1000å¢åŠ åˆ°5000

    let task_timeout_duration = Duration::from_secs(task_timeout_secs);
    let health_check_duration = Duration::from_secs(health_check_interval_secs);

    let desired_fd_limit = std::cmp::max(65_536_u64, (n_jobs as u64).saturating_mul(16));
    ensure_fd_limit(desired_fd_limit);

    if debug_monitor_enabled {
        println!(
            "ğŸ” ç›‘æ§é…ç½®: ä»»åŠ¡è¶…æ—¶={}s, å¥åº·æ£€æŸ¥é—´éš”={}s",
            task_timeout_secs, health_check_interval_secs
        );
    }

    // è§£æå‚æ•°
    let mut all_tasks = Vec::new();
    for item in args.iter() {
        let task_args: &PyList = item.extract()?;
        if task_args.len() != 2 {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
                "Each task should have exactly 2 parameters: date and code",
            ));
        }

        let date: i64 = task_args.get_item(0)?.extract()?;
        let code: String = task_args.get_item(1)?.extract()?;

        all_tasks.push(TaskParam { date, code });
    }

    // ä¿å­˜æ‰€æœ‰ä»»åŠ¡çš„å‰¯æœ¬ä»¥ä¾¿åç»­ä½¿ç”¨
    let all_tasks_clone = all_tasks.clone();

    // è¯»å–ç°æœ‰å¤‡ä»½ï¼Œè¿‡æ»¤å·²å®Œæˆçš„ä»»åŠ¡
    let existing_tasks = if update_mode_enabled {
        // update_modeå¼€å¯æ—¶ï¼Œåªè¯»å–ä¼ å…¥å‚æ•°ä¸­æ¶‰åŠçš„æ—¥æœŸ
        let task_dates: HashSet<i64> = all_tasks.iter().map(|t| t.date).collect();
        read_existing_backup_with_filter(&backup_file, Some(&task_dates)).map_err(|e| {
            PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to read backup: {}", e))
        })?
    } else {
        // æ­£å¸¸æ¨¡å¼ï¼Œè¯»å–æ‰€æœ‰å¤‡ä»½æ•°æ®
        read_existing_backup(&backup_file).map_err(|e| {
            PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to read backup: {}", e))
        })?
    };

    let pending_tasks: Vec<TaskParam> = all_tasks
        .into_iter()
        .filter(|task| !existing_tasks.contains(&(task.date, task.code.clone())))
        .collect();

    if pending_tasks.is_empty() {
        // æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œç›´æ¥è¿”å›ç»“æœ
        println!(
            "[{}] âœ… æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œä»å¤‡ä»½æ–‡ä»¶è¯»å–ç»“æœ",
            Local::now().format("%Y-%m-%d %H:%M:%S")
        );

        return if return_results_enabled {
            // ç›´æ¥è¯»å–å¤‡ä»½æ–‡ä»¶ï¼Œé¿å…ä½¿ç”¨çº¿ç¨‹æ± å¯èƒ½å¯¼è‡´çš„æ­»é”é—®é¢˜
            let read_start_time = Instant::now();
            println!(
                "[{}] ğŸ” å¼€å§‹è¯»å–å¤‡ä»½æ–‡ä»¶: {}",
                Local::now().format("%Y-%m-%d %H:%M:%S"),
                backup_file
            );

            let result = if update_mode_enabled {
                // update_modeä¸‹ï¼Œåªè¿”å›ä¼ å…¥å‚æ•°ä¸­æ¶‰åŠçš„æ—¥æœŸå’Œä»£ç 
                let task_dates: HashSet<i64> = all_tasks_clone.iter().map(|t| t.date).collect();
                let task_codes: HashSet<String> =
                    all_tasks_clone.iter().map(|t| t.code.clone()).collect();
                println!(
                    "[{}] ğŸ” ä½¿ç”¨è¿‡æ»¤æ¨¡å¼è¯»å– {} ä¸ªæ—¥æœŸå’Œ {} ä¸ªä»£ç ",
                    Local::now().format("%Y-%m-%d %H:%M:%S"),
                    task_dates.len(),
                    task_codes.len()
                );
                read_backup_results_with_filter(&backup_file, Some(&task_dates), Some(&task_codes))
            } else {
                println!(
                    "[{}] ğŸ” è¯»å–å®Œæ•´å¤‡ä»½æ–‡ä»¶",
                    Local::now().format("%Y-%m-%d %H:%M:%S")
                );
                read_backup_results(&backup_file)
            };

            println!(
                "[{}] âœ… å¤‡ä»½æ–‡ä»¶è¯»å–å®Œæˆï¼Œè€—æ—¶: {:?}",
                Local::now().format("%Y-%m-%d %H:%M:%S"),
                read_start_time.elapsed()
            );

            result.map_err(|e| {
                PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("è¯»å–å¤‡ä»½æ–‡ä»¶å¤±è´¥: {}", e))
            })
        } else {
            println!("âœ… æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œä¸è¿”å›ç»“æœ");
            Python::with_gil(|py| Ok(py.None()))
        };
    }

    let start_time = Instant::now();
    if update_mode_enabled {
        // update_modeä¸‹ï¼Œåªæ˜¾ç¤ºä¼ å…¥ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
        println!(
            "[{}] ğŸ“‹ ä¼ å…¥ä»»åŠ¡æ•°: {}, å¾…å¤„ç†: {}, å·²å®Œæˆ: {}",
            Local::now().format("%Y-%m-%d %H:%M:%S"),
            all_tasks_clone.len(),
            pending_tasks.len(),
            existing_tasks.len()
        );
    } else {
        // æ­£å¸¸æ¨¡å¼ï¼Œæ˜¾ç¤ºæ€»çš„ç»Ÿè®¡ä¿¡æ¯
        println!(
            "[{}] ğŸ“‹ æ€»ä»»åŠ¡æ•°: {}, å¾…å¤„ç†: {}, å·²å®Œæˆ: {}",
            Local::now().format("%Y-%m-%d %H:%M:%S"),
            pending_tasks.len() + existing_tasks.len(),
            pending_tasks.len(),
            existing_tasks.len()
        );
    }

    // æå–Pythonå‡½æ•°ä»£ç 
    let python_code = extract_python_function_code(&python_function)?;

    // è·å–Pythonè§£é‡Šå™¨è·¯å¾„
    let python_path = detect_python_interpreter();

    // åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœæ”¶é›†é€šé“
    let (task_sender, task_receiver) = unbounded::<TaskParam>();
    let (result_sender, result_receiver) = unbounded::<TaskResult>();

    // å°†æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
    for task in pending_tasks.clone() {
        if let Err(e) = task_sender.send(task) {
            return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!(
                "Failed to send task to queue: {}",
                e
            )));
        }
    }
    drop(task_sender); // å…³é—­ä»»åŠ¡é˜Ÿåˆ—ï¼Œworkerä¼šåœ¨é˜Ÿåˆ—ç©ºæ—¶é€€å‡º

    let restart_flag = Arc::new(AtomicBool::new(false));

    // åˆ›å»ºç›‘æ§ç®¡ç†å™¨
    let monitor_manager = Arc::new(WorkerMonitorManager::new(
        task_timeout_duration,
        health_check_duration,
        debug_monitor_enabled,
    ));

    println!(
        "[{}] ğŸš€ å¯åŠ¨ {} ä¸ªworkerå¤„ç† {} ä¸ªä»»åŠ¡",
        Local::now().format("%Y-%m-%d %H:%M:%S"),
        n_jobs,
        pending_tasks.len()
    );

    // å¯åŠ¨workerçº¿ç¨‹
    let mut worker_handles = Vec::new();
    for i in 0..n_jobs {
        let worker_task_receiver = task_receiver.clone();
        let worker_python_code = python_code.clone();
        let worker_python_path = python_path.clone();
        let worker_result_sender = result_sender.clone();
        let worker_restart_flag = restart_flag.clone();
        let worker_monitor_manager = monitor_manager.clone();

        let handle = thread::spawn(move || {
            run_persistent_task_worker(
                i,
                worker_task_receiver,
                worker_python_code,
                expected_result_length,
                worker_python_path,
                worker_result_sender,
                worker_restart_flag,
                worker_monitor_manager,
            );
        });

        worker_handles.push(handle);
    }

    // å…³é—­ä¸»çº¿ç¨‹çš„result_sender
    drop(result_sender);

    // å¯åŠ¨ç›‘æ§çº¿ç¨‹
    let monitor_manager_clone = monitor_manager.clone();
    let monitor_restart_flag = restart_flag.clone();
    let _worker_count = n_jobs;
    let monitor_handle = thread::spawn(move || {
        let mut _workers_completed = 0;
        loop {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡ºç›‘æ§å¾ªç¯
            if monitor_manager_clone.should_stop_monitoring() {
                println!(
                    "[{}] ğŸ” ç›‘æ§å™¨: æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡ºç›‘æ§å¾ªç¯",
                    Local::now().format("%Y-%m-%d %H:%M:%S")
                );
                break;
            }

            // æ£€æŸ¥æ˜¯å¦æ‰€æœ‰workeréƒ½å·²å®Œæˆï¼ˆç›‘æ§å™¨ä¸­æ²¡æœ‰æ´»è·ƒworkerï¼‰
            if let Ok(monitors) = monitor_manager_clone.monitors.lock() {
                // å¦‚æœç›‘æ§å™¨ä¸­æ²¡æœ‰æ´»è·ƒçš„workerï¼Œè¯´æ˜æ‰€æœ‰workeréƒ½å·²ç»å®Œæˆå¹¶è¢«ç§»é™¤
                if monitors.is_empty() {
                    println!(
                        "[{}] ğŸ” ç›‘æ§å™¨: æ‰€æœ‰workerå·²å®Œæˆï¼Œæ­£åœ¨é€€å‡º",
                        Local::now().format("%Y-%m-%d %H:%M:%S")
                    );
                    break;
                } else {
                    // è°ƒè¯•ä¿¡æ¯ï¼šæŸ¥çœ‹è¿˜æœ‰å“ªäº›workeråœ¨ç›‘æ§å™¨ä¸­
                    if monitor_manager_clone.debug_monitor {
                        let active_workers: Vec<usize> = monitors.keys().cloned().collect();
                        println!(
                            "[{}] ğŸ” ç›‘æ§å™¨: ä»æœ‰æ´»è·ƒworker {:?}",
                            Local::now().format("%Y-%m-%d %H:%M:%S"),
                            active_workers
                        );
                    }
                }
            }

            // æ£€æŸ¥å¡æ­»çš„worker
            let stuck_workers = monitor_manager_clone.check_stuck_workers();
            if !stuck_workers.is_empty() {
                for (worker_id, reason) in stuck_workers {
                    monitor_manager_clone.log_stuck_worker(worker_id, reason);

                    // å°è¯•å¼ºåˆ¶ç»ˆæ­¢å¡æ­»çš„workerè¿›ç¨‹
                    if monitor_manager_clone.force_kill_worker(worker_id) {
                        // ç®€åŒ–è¾“å‡ºï¼Œé¿å…é¢‘ç¹æ‰“æ–­è¿è¡Œæµç¨‹
                        if monitor_manager_clone.debug_monitor {
                            println!(
                                "ğŸ”„ å·²å¼ºåˆ¶ç»ˆæ­¢Worker {} (åŸå› : {}), workerå°†è‡ªåŠ¨é‡å¯",
                                worker_id, reason
                            );
                        }
                    }
                }

                // è§¦å‘é‡å¯ï¼ˆé€šè¿‡è®¾ç½®é‡å¯æ ‡å¿—ï¼Œworkerä¼šæ£€æµ‹åˆ°å¹¶é‡å¯ï¼‰
                monitor_restart_flag.store(true, Ordering::SeqCst);

                // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©workeræ£€æµ‹åˆ°é‡å¯ä¿¡å·
                thread::sleep(Duration::from_millis(100));

                // é‡ç½®é‡å¯æ ‡å¿—ï¼Œä¸ºä¸‹æ¬¡ç›‘æ§åšå‡†å¤‡
                monitor_restart_flag.store(false, Ordering::SeqCst);
            }

            // ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥ï¼Œä½†åœ¨æ”¶åˆ°åœæ­¢ä¿¡å·æ—¶ç«‹å³é€€å‡º
            for _ in 0..10 {
                // æ£€æŸ¥10æ¬¡ï¼Œæ¯æ¬¡é—´éš”1/10çš„health_check_interval
                if monitor_manager_clone.should_stop_monitoring() {
                    break;
                }
                thread::sleep(monitor_manager_clone.health_check_interval / 10);
            }
        }
    });

    // å¯åŠ¨ç»“æœæ”¶é›†å™¨
    let backup_file_clone = backup_file.clone();
    let expected_result_length_clone = expected_result_length;
    let pending_tasks_len = pending_tasks.len();
    let collector_restart_flag = restart_flag.clone();
    let restart_interval_clone = restart_interval_value;
    let backup_batch_size_clone = backup_batch_size_value;
    let collector_handle = thread::spawn(move || {
        let mut batch_results = Vec::new();
        let mut total_collected = 0;
        let mut batch_count = 0;
        let mut batch_count_this_chunk = 0;
        let total_batches =
            (pending_tasks_len + backup_batch_size_clone - 1) / backup_batch_size_clone;

        println!(
            "[{}] ğŸ”„ ç»“æœæ”¶é›†å™¨å¯åŠ¨ï¼Œç­‰å¾…workerç»“æœ...",
            Local::now().format("%Y-%m-%d %H:%M:%S")
        );

        while let Ok(result) = result_receiver.recv() {
            total_collected += 1;
            batch_results.push(result);

            // æ ¹æ®backup_batch_sizeåŠ¨æ€å¤‡ä»½
            if batch_results.len() >= backup_batch_size_clone {
                batch_count += 1;
                batch_count_this_chunk += 1;

                let elapsed = start_time.elapsed();
                let elapsed_secs = elapsed.as_secs();
                let elapsed_h = elapsed_secs / 3600;
                let elapsed_m = (elapsed_secs % 3600) / 60;
                let elapsed_s = elapsed_secs % 60;

                let progress = if total_batches > 0 {
                    batch_count as f64 / total_batches as f64
                } else {
                    1.0
                };
                let estimated_total_secs = if progress > 0.0 && progress <= 1.0 {
                    elapsed.as_secs_f64() / progress
                } else {
                    elapsed.as_secs_f64()
                };
                let remaining_secs = if estimated_total_secs > elapsed.as_secs_f64() {
                    (estimated_total_secs - elapsed.as_secs_f64()) as u64
                } else {
                    0
                };

                let remaining_h = remaining_secs / 3600;
                let remaining_m = (remaining_secs % 3600) / 60;
                let remaining_s = remaining_secs % 60;

                let current_time = Local::now().format("%Y-%m-%d %H:%M:%S");
                print!(
                    "\r[{}] ğŸ’¾ ç¬¬ {}/{} æ¬¡å¤‡ä»½ã€‚å·²ç”¨{}å°æ—¶{}åˆ†é’Ÿ{}ç§’ï¼Œé¢„ä½™{}å°æ—¶{}åˆ†é’Ÿ{}ç§’",
                    current_time,
                    batch_count,
                    total_batches,
                    elapsed_h,
                    elapsed_m,
                    elapsed_s,
                    remaining_h,
                    remaining_m,
                    remaining_s
                );
                io::stdout().flush().unwrap(); // å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº

                match save_results_to_backup(
                    &batch_results,
                    &backup_file_clone,
                    expected_result_length_clone,
                ) {
                    Ok(()) => {
                        // println!("âœ… ç¬¬{}æ¬¡å¤‡ä»½æˆåŠŸï¼", batch_count);
                    }
                    Err(e) => {
                        eprintln!("âŒ ç¬¬{}æ¬¡å¤‡ä»½å¤±è´¥: {}", batch_count, e);
                    }
                }
                batch_results.clear();

                if batch_count_this_chunk >= restart_interval_clone {
                    // println!("\nğŸ”„ è¾¾åˆ°{}æ¬¡å¤‡ä»½ï¼Œè§¦å‘ workers é‡å¯...", restart_interval_clone);
                    collector_restart_flag.store(true, Ordering::SeqCst);
                    batch_count_this_chunk = 0;
                }
            }
        }

        // ä¿å­˜å‰©ä½™ç»“æœ
        if !batch_results.is_empty() {
            batch_count += 1;
            println!(
                "[{}] ğŸ’¾ ä¿å­˜æœ€ç»ˆå‰©ä½™ç»“æœ: {} ä¸ª",
                Local::now().format("%Y-%m-%d %H:%M:%S"),
                batch_results.len()
            );

            match save_results_to_backup(
                &batch_results,
                &backup_file_clone,
                expected_result_length_clone,
            ) {
                Ok(()) => {
                    println!(
                        "[{}] âœ… æœ€ç»ˆå¤‡ä»½æˆåŠŸï¼",
                        Local::now().format("%Y-%m-%d %H:%M:%S")
                    );
                }
                Err(e) => {
                    eprintln!("âŒ æœ€ç»ˆå¤‡ä»½å¤±è´¥: {}", e);
                }
            }
        }

        println!(
            "[{}] ğŸ“Š æ”¶é›†å™¨ç»Ÿè®¡: æ€»æ”¶é›†{}ä¸ªç»“æœï¼Œè¿›è¡Œäº†{}æ¬¡å¤‡ä»½",
            Local::now().format("%Y-%m-%d %H:%M:%S"),
            total_collected,
            batch_count
        );
    });

    // ç­‰å¾…æ‰€æœ‰workerå®Œæˆ
    println!(
        "[{}] â³ ç­‰å¾…æ‰€æœ‰workerå®Œæˆ...",
        Local::now().format("%Y-%m-%d %H:%M:%S")
    );
    for (i, handle) in worker_handles.into_iter().enumerate() {
        match handle.join() {
            Ok(()) => {}
            Err(e) => eprintln!("âŒ Worker {} å¼‚å¸¸: {:?}", i, e),
        }
    }

    // ç«‹å³åœæ­¢ç›‘æ§çº¿ç¨‹ï¼Œé¿å…æ£€æŸ¥å·²æ­»è¿›ç¨‹
    if debug_monitor_enabled {
        println!("ğŸ” ç›‘æ§å™¨: æ‰€æœ‰workerå·²å®Œæˆï¼Œç«‹å³åœæ­¢ç›‘æ§");
    }
    monitor_manager.stop_monitoring();

    // ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
    println!(
        "[{}] â³ ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ...",
        Local::now().format("%Y-%m-%d %H:%M:%S")
    );
    match monitor_handle.join() {
        Ok(()) => {
            if debug_monitor_enabled {
                println!("âœ… ç›‘æ§çº¿ç¨‹å·²å®‰å…¨é€€å‡º");
            }
        }
        Err(e) => eprintln!("âŒ ç›‘æ§çº¿ç¨‹å¼‚å¸¸: {:?}", e),
    }

    // ç­‰å¾…æ”¶é›†å™¨å®Œæˆ
    println!(
        "[{}] â³ ç­‰å¾…ç»“æœæ”¶é›†å™¨å®Œæˆ...",
        Local::now().format("%Y-%m-%d %H:%M:%S")
    );
    match collector_handle.join() {
        Ok(()) => {
            println!(
                "[{}] âœ… ç»“æœæ”¶é›†å™¨å·²å®Œæˆ",
                Local::now().format("%Y-%m-%d %H:%M:%S")
            );
            // ç¡®ä¿å¤‡ä»½æ–‡ä»¶çš„æ‰€æœ‰å†™å…¥æ“ä½œå·²åŒæ­¥åˆ°ç£ç›˜
            println!(
                "[{}] ğŸ”„ åŒæ­¥å¤‡ä»½æ–‡ä»¶åˆ°ç£ç›˜...",
                Local::now().format("%Y-%m-%d %H:%M:%S")
            );
            if let Ok(file) = std::fs::File::open(&backup_file) {
                let _ = file.sync_all();
            }
        }
        Err(e) => eprintln!("âŒ ç»“æœæ”¶é›†å™¨å¼‚å¸¸: {:?}", e),
    }

    // æ‰“å°ç›‘æ§è¯Šæ–­ç»Ÿè®¡
    monitor_manager.print_diagnostic_stats();

    // æ‰“å°å¡æ­»ä»»åŠ¡ç»Ÿè®¡è¡¨
    monitor_manager.print_stuck_tasks_table();

    // ç¡®ä¿æ‰€æœ‰æŒä¹…åŒ–workerè¿›ç¨‹å·²é€€å‡ºï¼Œé¿å…åç»­ä½œä¸šå—é™
    monitor_manager.terminate_all_workers(Duration::from_secs(2));

    // æ˜¾å¼æ¸…ç†ç›‘æ§ç®¡ç†å™¨èµ„æºï¼Œé¿å…ä¸åç»­æ“ä½œå†²çª
    println!(
        "[{}] ğŸ§¹ æ¸…ç†ç›‘æ§å™¨èµ„æº...",
        Local::now().format("%Y-%m-%d %H:%M:%S")
    );
    monitor_manager.cleanup();

    // æ˜¾å¼é‡Šæ”¾monitor_managerï¼Œç¡®ä¿æ‰€æœ‰Arcå¼•ç”¨è¢«æ¸…ç†
    drop(monitor_manager);

    // ç­‰å¾…çŸ­æš‚æ—¶é—´ï¼Œç¡®ä¿æ‰€æœ‰èµ„æºå®Œå…¨é‡Šæ”¾ï¼Œé¿å…æ–‡ä»¶è®¿é—®å†²çª
    println!(
        "[{}] â³ ç­‰å¾…èµ„æºå®Œå…¨é‡Šæ”¾...",
        Local::now().format("%Y-%m-%d %H:%M:%S")
    );
    thread::sleep(Duration::from_millis(100));

    // æ¸…ç†å…±äº«è„šæœ¬æ–‡ä»¶
    let shared_script_path = "/tmp/persistent_worker_shared.py";
    if Path::new(shared_script_path).exists() {
        let _ = std::fs::remove_file(shared_script_path);
        println!(
            "[{}] ğŸ§¹ å·²æ¸…ç†å…±äº«è„šæœ¬æ–‡ä»¶",
            Local::now().format("%Y-%m-%d %H:%M:%S")
        );
    }

    // è¯»å–å¹¶è¿”å›æœ€ç»ˆç»“æœ
    if return_results_enabled {
        println!(
            "[{}] ğŸ“– è¯»å–æœ€ç»ˆå¤‡ä»½ç»“æœ...",
            Local::now().format("%Y-%m-%d %H:%M:%S")
        );

        // ç›´æ¥è¯»å–å¤‡ä»½æ–‡ä»¶ï¼Œé¿å…çº¿ç¨‹æ± å†²çª
        println!(
            "[{}] ğŸ” å¼€å§‹è¯»å–å¤‡ä»½æ–‡ä»¶: {}",
            Local::now().format("%Y-%m-%d %H:%M:%S"),
            backup_file
        );
        let start_read_time = Instant::now();

        let result = if update_mode_enabled {
            // update_modeä¸‹ï¼Œåªè¿”å›ä¼ å…¥å‚æ•°ä¸­æ¶‰åŠçš„æ—¥æœŸå’Œä»£ç 
            let task_dates: HashSet<i64> = all_tasks_clone.iter().map(|t| t.date).collect();
            let task_codes: HashSet<String> =
                all_tasks_clone.iter().map(|t| t.code.clone()).collect();
            println!(
                "[{}] ğŸ” ä½¿ç”¨è¿‡æ»¤æ¨¡å¼è¯»å– {} ä¸ªæ—¥æœŸå’Œ {} ä¸ªä»£ç ",
                Local::now().format("%Y-%m-%d %H:%M:%S"),
                task_dates.len(),
                task_codes.len()
            );
            read_backup_results_with_filter(&backup_file, Some(&task_dates), Some(&task_codes))
        } else {
            println!(
                "[{}] ğŸ” è¯»å–å®Œæ•´å¤‡ä»½æ–‡ä»¶",
                Local::now().format("%Y-%m-%d %H:%M:%S")
            );
            read_backup_results(&backup_file)
        };

        println!(
            "[{}] âœ… å¤‡ä»½æ–‡ä»¶è¯»å–å®Œæˆï¼Œè€—æ—¶: {:?}",
            Local::now().format("%Y-%m-%d %H:%M:%S"),
            start_read_time.elapsed()
        );
        result
    } else {
        println!("âœ… ä»»åŠ¡å®Œæˆï¼Œä¸è¿”å›ç»“æœ");
        Python::with_gil(|py| Ok(py.None()))
    }
}
