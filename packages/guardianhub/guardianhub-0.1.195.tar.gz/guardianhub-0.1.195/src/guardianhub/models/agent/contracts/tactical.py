# guardianhub_sdk/models/contracts/tactical.py
from .base import SovereignBaseContract, SovereignBaseResponse
from guardianhub.models.template.agent_plan import MacroPlan
from .history import HistoryResponse
from .discovery import DiscoveryResponse
from pydantic import ConfigDict

from pydantic import Field
from typing import List, Dict, Any, Literal, Optional

# guardianhub_sdk/models/contracts/tactical.py

class TacticalBundle(SovereignBaseContract):
    """The 'Brain' Request: Plan + Reality + Safety Mode."""
    proposed_plan: MacroPlan = Field(..., description="The steps generated by the Specialist")
    recon_intelligence: DiscoveryResponse = Field(..., description="The current state of the world")
    history_intelligence: HistoryResponse = Field(..., description="The past lessons learned")
    risk_threshold: float = Field(0.8, description="Max acceptable risk score")
    # ðŸŽ¯ NEW: Brain awareness of the safety sheath
    is_dry_run: bool = Field(False, description="If True, audit for education/simulation")

class TacticalAuditReport(SovereignBaseResponse):
    """The 'Brain' Response: Proceed or Halt."""
    decision: str = Field(..., description="PROCEED or HALT")
    risk_score: float = Field(..., ge=0.0, le=1.0)
    justification: str = Field(..., description="Reasoning for the decision")
    suggested_modifications: List[str] = Field(default_factory=list)

# 1. Standardized Prompting (No more digging through dicts)
TACTICAL_RISK_PROMPT = """
        Role: You are the Sovereign Tactical Safety Officer (TSO).
        Objective: Perform a high-fidelity risk assessment of a proposed action plan based on real-time reconnaissance data.

        INPUT DATA:
        1. PROPOSED STEPS: {steps}
        2. RECONNAISSANCE FACTS: {facts}

        YOUR TASK:
        Analyze the delta between the 'Plan' and the 'Reality'. 
        Specifically look for:
        - RESOURCE COLLISION: Does the plan attempt to modify a CI that is currently 'unstable' or 'unverified'?
        - BLAST RADIUS: Will the steps impact downstream dependencies not mentioned in the plan?
        - POLICY VIOLATION: Are any steps violating 'safe-window' or 'least-privilege' protocols?

        OUTPUT FORMAT:
        Return a structured JSON with: risk_score (0.0-1.0), reasoning (punchy justification), and recommendation (PROCEED/HALT).
        """

# Add this to your models file (e.g., guardianhub_sdk/models/agent_models.py)

