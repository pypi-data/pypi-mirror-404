{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c9cec63ae4a2a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T17:53:03.568243Z",
     "start_time": "2025-12-29T17:53:03.546669Z"
    }
   },
   "source": [
    "Profound API\n",
    "\n",
    "This notebook demonstrates how to replicate Profound's frontend functionality using the `profound` Python library.\n",
    "\n",
    "**API Documentation**: [https://docs.tryprofound.com/rest-api](https://docs.tryprofound.com/rest-api)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Configuration](#configuration)\n",
    "- [Common Filters](#common-filters)\n",
    "- [Helper Functions](#helper-functions)\n",
    "- [Visibility Reports](#visibility-reports)\n",
    "- [Citations Reports](#citations-reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba646f1a27d72640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T14:26:45.557890Z",
     "start_time": "2026-01-05T14:26:45.539698Z"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies using `uv`:\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d301c7b7f018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import pytz\n",
    "import pandas as pd\n",
    "\n",
    "import profound\n",
    "\n",
    "profound_api_key = os.getenv(\n",
    "    \"PROFOUND_API_KEY\", \"change-me!\"\n",
    ")  # Provide using the environmental variable PROFOUND_API_KEY, or change the fallback value\n",
    "profound_api_host = os.getenv(\"PROFOUND_API_HOST\", \"https://api.tryprofound.com\")\n",
    "client = profound.Client(api_key=profound_api_key, base_url=profound_api_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c896ba5c46138",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your API credentials and query parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54444219a6d9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TIMEZONE = pytz.timezone(\"America/New_York\")\n",
    "category_id = \"00000000-0000-0000-0000-000000000000\"\n",
    "domain_url = \"example.com\"\n",
    "\n",
    "today = datetime.datetime.now(DEFAULT_TIMEZONE).date()\n",
    "start_date = today - datetime.timedelta(days=7)\n",
    "end_date = today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8349c9cc3d2c7",
   "metadata": {},
   "source": [
    "## Common Filters\n",
    "\n",
    "Define reusable filter configurations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95650177be75d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_filters = {\n",
    "    \"prompts_visibility\": {\"field\": \"prompt_type\", \"operator\": \"is\", \"value\": \"visibility\"},\n",
    "    \"region_us\": {\"field\": \"region_id\", \"operator\": \"in\", \"value\": [\"3c37529b-e592-43a9-839a-14bee2673a6b\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1722e6bcf357d18",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "### Core API Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63019b91f7bbb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_payload(payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove None values from payload dictionary without mutating the original.\n",
    "\n",
    "    Args:\n",
    "        payload: Dictionary containing API request parameters\n",
    "\n",
    "    Returns:\n",
    "        New dictionary with None values removed\n",
    "\n",
    "    Example:\n",
    "        >>> payload = {\"filters\": None, \"pagination\": None, \"category_id\": \"123\"}\n",
    "        >>> clean_payload(payload)\n",
    "        {'category_id': '123'}\n",
    "    \"\"\"\n",
    "    return {k: v for k, v in payload.items() if v is not None}\n",
    "\n",
    "\n",
    "def format_response_data(response) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract and format response data from API response.\n",
    "\n",
    "    Args:\n",
    "        response: Response object from Profound API (has .info and .data attributes)\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries containing dimension and metric values\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If response structure is unexpected\n",
    "\n",
    "    Example:\n",
    "        >>> response = client.reports.citations(...)\n",
    "        >>> data = format_response_data(response)\n",
    "        >>> df = pd.DataFrame(data)\n",
    "    \"\"\"\n",
    "    query_info = response.info.query\n",
    "    dim_names = query_info[\"dimensions\"]\n",
    "    metric_names = query_info[\"metrics\"]\n",
    "    results = []\n",
    "    for row in response.data:\n",
    "        result = {}\n",
    "        for i, name in enumerate(dim_names):\n",
    "            result[name] = row.dimensions[i]\n",
    "        for i, name in enumerate(metric_names):\n",
    "            result[name] = row.metrics[i]\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def build_payload(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    metrics: List[str],\n",
    "    dimensions: Optional[List[str]] = None,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build API payload dictionary for report queries.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        metrics: List of metric names to retrieve\n",
    "        dimensions: Optional list of dimension names to group by\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        Dictionary ready to be sent as JSON payload\n",
    "\n",
    "    Example:\n",
    "        >>> payload = build_payload(\n",
    "        ...     category_id=\"123\",\n",
    "        ...     start_date=\"2025-01-01\",\n",
    "        ...     end_date=\"2025-01-07\",\n",
    "        ...     metrics=[\"count\"],\n",
    "        ...     dimensions=[\"root_domain\"],\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"category_id\": category_id,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "    if dimensions is not None:\n",
    "        payload[\"dimensions\"] = dimensions\n",
    "    if filters is not None:\n",
    "        payload[\"filters\"] = filters\n",
    "    if pagination is not None:\n",
    "        payload[\"pagination\"] = pagination\n",
    "    return payload\n",
    "\n",
    "\n",
    "def query_report(report_type: str, payload: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Query a report endpoint and return results as a pandas DataFrame.\n",
    "\n",
    "    This function handles cleaning the payload, making the API request,\n",
    "    and formatting the response into a DataFrame with proper column names.\n",
    "\n",
    "    Args:\n",
    "        report_type: Type of report - either \"citations\" or \"visibility\"\n",
    "        payload: Dictionary containing request parameters. None values for\n",
    "                 'filters' and 'pagination' will be automatically removed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns corresponding to dimensions and metrics\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If response structure is unexpected\n",
    "\n",
    "    Example:\n",
    "        >>> df = query_report(\n",
    "        ...     \"citations\",\n",
    "        ...     {\n",
    "        ...         \"category_id\": \"123\",\n",
    "        ...         \"start_date\": \"2025-01-01\",\n",
    "        ...         \"end_date\": \"2025-01-07\",\n",
    "        ...         \"metrics\": [\"count\"],\n",
    "        ...         \"filters\": None,\n",
    "        ...         \"pagination\": None,\n",
    "        ...     },\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    clean_payload_dict = clean_payload(payload)\n",
    "\n",
    "    if report_type == \"citations\":\n",
    "        response = client.reports.citations(**clean_payload_dict)\n",
    "    elif report_type == \"visibility\":\n",
    "        response = client.reports.visibility(**clean_payload_dict)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown report type: {report_type}. Must be 'citations' or 'visibility'\")\n",
    "\n",
    "    results = format_response_data(response)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10b9aa2a2d0844",
   "metadata": {},
   "source": [
    "### Visibility Report Functions\n",
    "\n",
    "Functions for querying visibility reports. See [API Documentation](https://docs.tryprofound.com/api-reference/reports/query-visibility) for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab174d0412069bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visibility_share_by_date(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get visibility scores by date and asset name.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries. Each filter should have\n",
    "                 'field', 'operator', and 'value' keys.\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['date', 'asset_name', 'visibility_score'],\n",
    "        sorted by date (ascending) and visibility_score (descending)\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_visibility_share_by_date(\n",
    "        ...     category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\", filters=[common_filters[\"region_us\"]]\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"visibility_score\"],\n",
    "        dimensions=[\"date\", \"asset_name\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    visibility_df = query_report(\"visibility\", payload)\n",
    "    return visibility_df.sort_values([\"date\", \"visibility_score\"], ascending=[True, False])\n",
    "\n",
    "\n",
    "def get_visibility_score_rank(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get visibility score rankings by asset name.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['asset_name', 'visibility_score']\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_visibility_score_rank(category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\")\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"visibility_score\"],\n",
    "        dimensions=[\"asset_name\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    return query_report(\"visibility\", payload)\n",
    "\n",
    "\n",
    "def get_visibility_share_of_voice_rank(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get share of voice rankings by asset name.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['asset_name', 'share_of_voice']\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_visibility_share_of_voice_rank(category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\")\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"share_of_voice\"],\n",
    "        dimensions=[\"asset_name\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    return query_report(\"visibility\", payload)\n",
    "\n",
    "\n",
    "def get_visibility_rankings_by_topic(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get visibility score rankings broken down by topic and asset.\n",
    "\n",
    "    Retrieves visibility scores for each asset within each topic, allowing\n",
    "    analysis of competitive positioning across different topic areas.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries. Each filter should have\n",
    "                 'field', 'operator', and 'value' keys.\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['topic', 'asset_name', 'visibility_score'],\n",
    "        sorted by topic (ascending), visibility_score (descending), and\n",
    "        asset_name (ascending)\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_visibility_rankings_by_topic(\n",
    "        ...     category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\", filters=[common_filters[\"region_us\"]]\n",
    "        ... )\n",
    "        >>> # View top assets per topic\n",
    "        >>> df.groupby(\"topic\").head(10)\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"visibility_score\"],\n",
    "        dimensions=[\"asset_name\", \"topic\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    visibility_df = query_report(\"visibility\", payload)\n",
    "    visibility_df = visibility_df[[\"topic\", \"asset_name\", \"visibility_score\"]]\n",
    "\n",
    "    return (\n",
    "        visibility_df.assign(\n",
    "            _topic=visibility_df[\"topic\"].str.lower(),\n",
    "            _asset=visibility_df[\"asset_name\"].str.lower(),\n",
    "        )\n",
    "        .sort_values([\"_topic\", \"visibility_score\", \"_asset\"], ascending=[True, False, True])\n",
    "        .drop(columns=[\"_topic\", \"_asset\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec76b4e688604c",
   "metadata": {},
   "source": [
    "### Citations Report Functions\n",
    "\n",
    "Functions for querying citations reports. See [API Documentation](https://docs.tryprofound.com/api-reference/reports/query-citations) for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c8a588ac31326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations_count(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get total citation count.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with a single row containing the 'count' column\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_citations_count(\n",
    "        ...     category_id=\"123\",\n",
    "        ...     start_date=\"2025-01-01\",\n",
    "        ...     end_date=\"2025-01-07\",\n",
    "        ...     filters=[common_filters[\"prompts_visibility\"]],\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"count\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    return query_report(\"citations\", payload)\n",
    "\n",
    "\n",
    "def get_citation_share(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get citation share of voice by root domain.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['root_domain', 'share_of_voice']\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_citation_share(category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\")\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"share_of_voice\"],\n",
    "        dimensions=[\"root_domain\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    return query_report(\"citations\", payload)\n",
    "\n",
    "\n",
    "def get_citation_share_by_date(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get citation share of voice by date and root domain.\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['date', 'root_domain', 'share_of_voice'],\n",
    "        sorted by date (ascending) and share_of_voice (descending)\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_citation_share_by_date(category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\")\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"share_of_voice\"],\n",
    "        dimensions=[\"date\", \"root_domain\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    citations_df = query_report(\"citations\", payload)\n",
    "    return citations_df.sort_values([\"date\", \"share_of_voice\"], ascending=[True, False])\n",
    "\n",
    "\n",
    "def get_citation_categories(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get citation categories with share of voice calculations.\n",
    "\n",
    "    Calculates share of voice for each citation category by:\n",
    "    1. Computing share of voice per model\n",
    "    2. Averaging across all models\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['citation_category', 'share_of_voice', 'count'],\n",
    "        sorted by share_of_voice (descending)\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_citation_categories(category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\")\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"count\"],\n",
    "        dimensions=[\"citation_category\", \"model\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    citations_df = query_report(\"citations\", payload)\n",
    "\n",
    "    total_unique_models = citations_df[\"model\"].nunique()\n",
    "    model_total_citations = citations_df.groupby(\"model\")[\"count\"].sum()\n",
    "\n",
    "    citations_df[\"share_of_voice\"] = citations_df[\"count\"] / citations_df[\"model\"].map(model_total_citations)\n",
    "\n",
    "    domain_category_scores = citations_df.groupby([\"citation_category\"], as_index=False)[\n",
    "        [\"share_of_voice\", \"count\"]\n",
    "    ].sum()\n",
    "\n",
    "    domain_category_scores[\"share_of_voice\"] = domain_category_scores[\"share_of_voice\"] / total_unique_models\n",
    "\n",
    "    return domain_category_scores.sort_values(\"share_of_voice\", ascending=False)\n",
    "\n",
    "\n",
    "def get_top_citation_domains(\n",
    "    category_id: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    filters: Optional[List[Dict[str, Any]]] = None,\n",
    "    pagination: Optional[Dict[str, int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate top citation domains based on citation share across models.\n",
    "\n",
    "    Calculates share of voice for each root domain by:\n",
    "    1. Computing share of voice per model\n",
    "    2. Averaging across all models\n",
    "\n",
    "    Args:\n",
    "        category_id: Category identifier for the query\n",
    "        start_date: Start date in ISO format (YYYY-MM-DD)\n",
    "        end_date: End date in ISO format (YYYY-MM-DD)\n",
    "        filters: Optional list of filter dictionaries\n",
    "        pagination: Optional pagination dict with 'limit' and 'offset' keys\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['root_domain', 'share_of_voice', 'count'],\n",
    "        sorted by share_of_voice (descending)\n",
    "\n",
    "    Example:\n",
    "        >>> df = get_top_citation_domains(category_id=\"123\", start_date=\"2025-01-01\", end_date=\"2025-01-07\")\n",
    "    \"\"\"\n",
    "    payload = build_payload(\n",
    "        category_id=category_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        metrics=[\"count\"],\n",
    "        dimensions=[\"root_domain\", \"model\"],\n",
    "        filters=filters,\n",
    "        pagination=pagination,\n",
    "    )\n",
    "    citations_df = query_report(\"citations\", payload)\n",
    "\n",
    "    total_unique_models = citations_df[\"model\"].nunique()\n",
    "    model_total_citations = citations_df.groupby(\"model\")[\"count\"].sum()\n",
    "\n",
    "    citations_df[\"share_of_voice\"] = citations_df[\"count\"] / citations_df[\"model\"].map(model_total_citations)\n",
    "\n",
    "    domain_category_scores = citations_df.groupby([\"root_domain\"], as_index=False)[[\"share_of_voice\", \"count\"]].sum()\n",
    "\n",
    "    domain_category_scores[\"share_of_voice\"] = domain_category_scores[\"share_of_voice\"] / total_unique_models\n",
    "\n",
    "    return domain_category_scores.sort_values(\"share_of_voice\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f192e32e3c833fe",
   "metadata": {},
   "source": "## Visibility Reports\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a376e0d00a5fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_share_by_date = get_visibility_share_by_date(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[common_filters[\"region_us\"]],\n",
    ")\n",
    "visibility_share_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98e9fe347b74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_score_rank = get_visibility_score_rank(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[common_filters[\"region_us\"]],\n",
    ")\n",
    "visibility_score_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f43dd93c38c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_share_of_voice_rank = get_visibility_share_of_voice_rank(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[common_filters[\"region_us\"]],\n",
    ")\n",
    "visibility_share_of_voice_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ab98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_rankings_by_topic = get_visibility_rankings_by_topic(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[common_filters[\"region_us\"]],\n",
    ")\n",
    "visibility_rankings_by_topic.groupby(\"topic\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13185b90dd586",
   "metadata": {},
   "source": "## Citations Reports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1043c2e28f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_count = get_citations_count(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[\n",
    "        common_filters[\"prompts_visibility\"],\n",
    "        common_filters[\"region_us\"],\n",
    "    ],\n",
    ")\n",
    "citations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8827873dc95935",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_share = get_citation_share(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[\n",
    "        {\n",
    "            \"field\": \"root_domain\",\n",
    "            \"operator\": \"is\",\n",
    "            \"value\": domain_url,\n",
    "        },\n",
    "        common_filters[\"prompts_visibility\"],\n",
    "        common_filters[\"region_us\"],\n",
    "    ],\n",
    ")\n",
    "citation_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd532f569cd20262",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_share_by_date = get_citation_share_by_date(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[\n",
    "        common_filters[\"prompts_visibility\"],\n",
    "        common_filters[\"region_us\"],\n",
    "    ],\n",
    ")\n",
    "citation_share_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9bb6effbe5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_categories = get_citation_categories(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[\n",
    "        common_filters[\"prompts_visibility\"],\n",
    "        common_filters[\"region_us\"],\n",
    "    ],\n",
    ")\n",
    "citation_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fba9d0509fb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_citation_domains = get_top_citation_domains(\n",
    "    category_id=category_id,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    filters=[\n",
    "        common_filters[\"prompts_visibility\"],\n",
    "        common_filters[\"region_us\"],\n",
    "    ],\n",
    ")\n",
    "top_citation_domains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
