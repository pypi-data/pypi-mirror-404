"""xAI Grok LLM provider for Local Deep Research."""

from loguru import logger

from ...llm_registry import register_llm
from ..openai_base import OpenAICompatibleProvider


class XAIProvider(OpenAICompatibleProvider):
    """xAI Grok provider using OpenAI-compatible endpoint.

    This uses xAI's OpenAI-compatible API endpoint to access Grok models.
    """

    provider_name = "xAI Grok"
    api_key_setting = "llm.xai.api_key"
    default_base_url = "https://api.x.ai/v1"
    default_model = "grok-beta"

    # Metadata for auto-discovery
    provider_key = "XAI"
    company_name = "xAI"
    region = "US"
    country = "United States"
    data_location = "United States"
    is_cloud = True

    @classmethod
    def requires_auth_for_models(cls):
        """xAI requires authentication for listing models."""
        return True


# Keep the standalone functions for backward compatibility and registration
def create_xai_llm(model_name=None, temperature=0.7, **kwargs):
    """Factory function for xAI Grok LLMs using OpenAI-compatible endpoint.

    Args:
        model_name: Name of the model to use (e.g., "grok-beta", "grok-2", "grok-2-mini")
        temperature: Model temperature (0.0-1.0)
        **kwargs: Additional arguments including settings_snapshot

    Returns:
        A configured ChatOpenAI instance pointing to xAI's API

    Raises:
        ValueError: If xAI API key is not configured
    """
    return XAIProvider.create_llm(model_name, temperature, **kwargs)


def is_xai_available(settings_snapshot=None):
    """Check if xAI Grok is available.

    Args:
        settings_snapshot: Optional settings snapshot to use

    Returns:
        True if xAI API key is configured, False otherwise
    """
    return XAIProvider.is_available(settings_snapshot)


def register_xai_provider():
    """Register the xAI Grok provider with the LLM registry."""
    register_llm("xai", create_xai_llm)
    logger.info("Registered xAI Grok LLM provider")
