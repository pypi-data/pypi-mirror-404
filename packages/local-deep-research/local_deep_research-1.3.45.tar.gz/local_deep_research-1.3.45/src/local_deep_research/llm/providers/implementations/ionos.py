"""IONOS AI Model Hub LLM provider for Local Deep Research."""

from loguru import logger

from ...llm_registry import register_llm
from ..openai_base import OpenAICompatibleProvider


class IONOSProvider(OpenAICompatibleProvider):
    """IONOS AI Model Hub provider using OpenAI-compatible endpoint.

    IONOS provides GDPR-compliant AI services with data processing
    in Germany. The service offers OpenAI-compatible API endpoints
    and is currently free until September 30, 2025.
    """

    provider_name = "IONOS AI Model Hub"
    api_key_setting = "llm.ionos.api_key"
    default_base_url = "https://openai.inference.de-txl.ionos.com/v1"
    default_model = "meta-llama/llama-3.2-3b-instruct"  # Default open model

    # Metadata for auto-discovery
    provider_key = "IONOS"
    company_name = "IONOS"
    region = "EU"  # EU, US, etc.
    country = "Germany"
    gdpr_compliant = True
    data_location = "Germany"  # Where data is processed
    is_cloud = True

    @classmethod
    def requires_auth_for_models(cls):
        """IONOS requires authentication for listing models."""
        return True


# Keep the standalone functions for backward compatibility and registration
def create_ionos_llm(model_name=None, temperature=0.7, **kwargs):
    """Factory function for IONOS AI Model Hub LLMs using OpenAI-compatible endpoint.

    Args:
        model_name: Name of the model to use (e.g., "meta-llama/llama-3.2-3b-instruct", etc.)
        temperature: Model temperature (0.0-1.0)
        **kwargs: Additional arguments including settings_snapshot

    Returns:
        A configured ChatOpenAI instance pointing to IONOS's API

    Raises:
        ValueError: If IONOS API key is not configured
    """
    return IONOSProvider.create_llm(model_name, temperature, **kwargs)


def is_ionos_available(settings_snapshot=None):
    """Check if IONOS is available.

    Args:
        settings_snapshot: Optional settings snapshot to use

    Returns:
        True if IONOS API key is configured, False otherwise
    """
    return IONOSProvider.is_available(settings_snapshot)


def register_ionos_provider():
    """Register the IONOS provider with the LLM registry."""
    register_llm("ionos", create_ionos_llm)
    logger.info("Registered IONOS AI Model Hub LLM provider")
