"""Tests for Anthropic LLM provider."""

import pytest
from unittest.mock import Mock, patch

from local_deep_research.llm.providers.implementations.anthropic import (
    AnthropicProvider,
    create_anthropic_llm,
    is_anthropic_available,
    register_anthropic_provider,
)


class TestAnthropicProviderMetadata:
    """Tests for AnthropicProvider class metadata."""

    def test_provider_name(self):
        """Provider name is correct."""
        assert AnthropicProvider.provider_name == "Anthropic"

    def test_provider_key(self):
        """Provider key is correct."""
        assert AnthropicProvider.provider_key == "ANTHROPIC"

    def test_is_cloud(self):
        """Anthropic is a cloud provider."""
        assert AnthropicProvider.is_cloud is True

    def test_region(self):
        """Region is US."""
        assert AnthropicProvider.region == "US"

    def test_country(self):
        """Country is United States."""
        assert AnthropicProvider.country == "United States"

    def test_data_location(self):
        """Data location is United States."""
        assert AnthropicProvider.data_location == "United States"

    def test_company_name(self):
        """Company name is Anthropic."""
        assert AnthropicProvider.company_name == "Anthropic"

    def test_api_key_setting(self):
        """API key setting is correct."""
        assert AnthropicProvider.api_key_setting == "llm.anthropic.api_key"

    def test_default_model(self):
        """Default model is set."""
        assert AnthropicProvider.default_model is not None
        assert "claude" in AnthropicProvider.default_model.lower()

    def test_default_base_url(self):
        """Default base URL is correct."""
        assert "anthropic.com" in AnthropicProvider.default_base_url


class TestAnthropicCreateLLM:
    """Tests for create_llm method."""

    def test_create_llm_raises_without_api_key(self):
        """Raises ValueError when API key not configured."""
        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.return_value = None

            with pytest.raises(ValueError) as exc_info:
                AnthropicProvider.create_llm()

            assert "api key" in str(exc_info.value).lower()

    def test_create_llm_with_valid_api_key(self):
        """Successfully creates ChatAnthropic instance with valid API key."""

        def mock_get_setting_side_effect(key, default=None, *args, **kwargs):
            settings_map = {
                "llm.anthropic.api_key": "test-anthropic-key",
                "llm.max_tokens": None,
            }
            return settings_map.get(key, default)

        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = mock_get_setting_side_effect

            with patch(
                "local_deep_research.llm.providers.implementations.anthropic.ChatAnthropic"
            ) as mock_chat:
                mock_llm = Mock()
                mock_chat.return_value = mock_llm

                result = AnthropicProvider.create_llm()

                assert result is mock_llm
                mock_chat.assert_called_once()

    def test_create_llm_uses_default_model_when_none(self):
        """Uses default model when none specified."""

        def mock_get_setting_side_effect(key, default=None, *args, **kwargs):
            settings_map = {
                "llm.anthropic.api_key": "test-key",
                "llm.max_tokens": None,
            }
            return settings_map.get(key, default)

        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = mock_get_setting_side_effect

            with patch(
                "local_deep_research.llm.providers.implementations.anthropic.ChatAnthropic"
            ) as mock_chat:
                AnthropicProvider.create_llm()

                call_kwargs = mock_chat.call_args[1]
                assert call_kwargs["model"] == AnthropicProvider.default_model

    def test_create_llm_with_custom_model(self):
        """Uses custom model when specified."""

        def mock_get_setting_side_effect(key, default=None, *args, **kwargs):
            settings_map = {
                "llm.anthropic.api_key": "test-key",
                "llm.max_tokens": None,
            }
            return settings_map.get(key, default)

        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = mock_get_setting_side_effect

            with patch(
                "local_deep_research.llm.providers.implementations.anthropic.ChatAnthropic"
            ) as mock_chat:
                AnthropicProvider.create_llm(
                    model_name="claude-3-opus-20240229"
                )

                call_kwargs = mock_chat.call_args[1]
                assert call_kwargs["model"] == "claude-3-opus-20240229"

    def test_create_llm_passes_temperature(self):
        """Passes temperature parameter."""

        def mock_get_setting_side_effect(key, default=None, *args, **kwargs):
            settings_map = {
                "llm.anthropic.api_key": "test-key",
                "llm.max_tokens": None,
            }
            return settings_map.get(key, default)

        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = mock_get_setting_side_effect

            with patch(
                "local_deep_research.llm.providers.implementations.anthropic.ChatAnthropic"
            ) as mock_chat:
                AnthropicProvider.create_llm(temperature=0.5)

                call_kwargs = mock_chat.call_args[1]
                assert call_kwargs["temperature"] == 0.5

    def test_create_llm_passes_max_tokens_when_set(self):
        """Passes max_tokens when configured in settings."""

        def mock_get_setting_side_effect(key, default=None, *args, **kwargs):
            settings_map = {
                "llm.anthropic.api_key": "test-key",
                "llm.max_tokens": 4096,
            }
            return settings_map.get(key, default)

        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = mock_get_setting_side_effect

            with patch(
                "local_deep_research.llm.providers.implementations.anthropic.ChatAnthropic"
            ) as mock_chat:
                AnthropicProvider.create_llm()

                call_kwargs = mock_chat.call_args[1]
                assert call_kwargs["max_tokens"] == 4096

    def test_create_llm_uses_anthropic_api_key_param(self):
        """Uses anthropic_api_key parameter name."""

        def mock_get_setting_side_effect(key, default=None, *args, **kwargs):
            settings_map = {
                "llm.anthropic.api_key": "my-anthropic-key",
                "llm.max_tokens": None,
            }
            return settings_map.get(key, default)

        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = mock_get_setting_side_effect

            with patch(
                "local_deep_research.llm.providers.implementations.anthropic.ChatAnthropic"
            ) as mock_chat:
                AnthropicProvider.create_llm()

                call_kwargs = mock_chat.call_args[1]
                assert call_kwargs["anthropic_api_key"] == "my-anthropic-key"


class TestAnthropicIsAvailable:
    """Tests for is_available method."""

    def test_is_available_true_when_key_exists(self):
        """Returns True when API key is configured."""
        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.return_value = "test-key"

            result = AnthropicProvider.is_available()
            assert result is True

    def test_is_available_false_when_no_key(self):
        """Returns False when API key is not configured."""
        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.return_value = None

            result = AnthropicProvider.is_available()
            assert result is False

    def test_is_available_false_when_empty_key(self):
        """Returns False when API key is empty string."""
        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.return_value = ""

            result = AnthropicProvider.is_available()
            assert result is False

    def test_is_available_false_on_exception(self):
        """Returns False when exception occurs."""
        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.get_setting_from_snapshot"
        ) as mock_get_setting:
            mock_get_setting.side_effect = Exception("Settings error")

            result = AnthropicProvider.is_available()
            assert result is False


class TestAnthropicBackwardCompatibility:
    """Tests for backward compatibility functions."""

    def test_create_anthropic_llm_function(self):
        """create_anthropic_llm() delegates to AnthropicProvider."""
        with patch.object(AnthropicProvider, "create_llm") as mock_create:
            mock_llm = Mock()
            mock_create.return_value = mock_llm

            result = create_anthropic_llm(
                model_name="test-model", temperature=0.5
            )

            mock_create.assert_called_once_with("test-model", 0.5)
            assert result is mock_llm

    def test_is_anthropic_available_function(self):
        """is_anthropic_available() delegates to AnthropicProvider."""
        with patch.object(AnthropicProvider, "is_available") as mock_available:
            mock_available.return_value = True

            result = is_anthropic_available()

            mock_available.assert_called_once()
            assert result is True

    def test_register_anthropic_provider_function(self):
        """register_anthropic_provider() registers with registry."""
        with patch(
            "local_deep_research.llm.providers.implementations.anthropic.register_llm"
        ) as mock_register:
            register_anthropic_provider()

            mock_register.assert_called_once_with(
                "anthropic", create_anthropic_llm
            )
