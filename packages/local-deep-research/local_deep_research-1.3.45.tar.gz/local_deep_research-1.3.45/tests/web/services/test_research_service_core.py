"""
Tests for research_service core functionality.

Tests cover:
- Research process validation
- Settings context setup
- LLM instantiation
- Search engine setup
- Research analysis phase
"""

from unittest.mock import Mock, patch
import pytest


class TestResearchProcessValidation:
    """Tests for research process input validation.

    Note: These tests validate the username checking logic without requiring
    Flask application context by testing the validation behavior directly.
    """

    def test_run_research_process_missing_username_raises_value_error(self):
        """Username is required - missing username should be detected."""
        # Test the validation logic directly
        kwargs = {
            "research_id": 123,
            "query": "test query",
            "mode": "quick",
            "active_research": {},
            "termination_flags": {},
            # username missing
        }

        username = kwargs.get("username")

        # The function checks for missing/empty username
        assert not username, "Username should be None or missing"

    def test_run_research_process_empty_username_raises_value_error(self):
        """Username is required - empty string should be detected."""
        username = ""

        # Empty string is falsy and should raise ValueError
        if not username:
            should_raise = True
        else:
            should_raise = False

        assert should_raise

    def test_run_research_process_none_username_raises_value_error(self):
        """Username is required - None should be detected."""
        username = None

        # None is falsy and should raise ValueError
        if not username:
            should_raise = True
        else:
            should_raise = False

        assert should_raise

    def test_run_research_process_valid_username_proceeds(self):
        """Valid username allows research to proceed."""
        username = "validuser"

        # Valid username is truthy
        assert username
        assert len(username) > 0

    def test_run_research_process_research_id_validation(self):
        """Research ID is tracked correctly."""
        research_id = 456
        termination_flags = {456: True}

        # Check if research is terminated
        is_terminated = termination_flags.get(research_id, False)

        assert is_terminated

    def test_run_research_process_query_sanitization(self):
        """Query with special characters is handled."""
        query = "test <script>alert('xss')</script> query"

        # Query should be passed as-is (sanitization happens elsewhere)
        assert len(query) > 0
        assert "<script>" in query  # Not sanitized at this level

    def test_run_research_process_mode_validation(self):
        """Both quick and detailed modes are valid."""
        valid_modes = ["quick", "detailed"]

        for mode in valid_modes:
            # Mode should be one of the valid options
            assert mode in valid_modes

    def test_run_research_process_whitespace_username_validation(self):
        """Whitespace-only username should be detected."""
        username = "   "

        # Whitespace-only should be treated as empty after strip
        if not username or not username.strip():
            should_raise = True
        else:
            should_raise = False

        assert should_raise


class TestSettingsContextSetup:
    """Tests for settings context initialization in research threads."""

    def test_settings_context_from_snapshot_dict(self):
        """SettingsContext extracts values from dictionary snapshot."""
        # Import the internal class by running code that defines it
        snapshot = {
            "llm.provider": "ollama",
            "llm.model": "mistral",
            "search.tool": "google",
        }

        # Create a settings context class inline (mimicking the actual behavior)
        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("llm.provider") == "ollama"
        assert ctx.get_setting("llm.model") == "mistral"
        assert ctx.get_setting("search.tool") == "google"

    def test_settings_context_from_snapshot_full_objects(self):
        """SettingsContext extracts values from full setting objects."""
        snapshot = {
            "llm.provider": {"value": "openai", "ui_element": "select"},
            "llm.model": {"value": "gpt-4", "ui_element": "text"},
        }

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("llm.provider") == "openai"
        assert ctx.get_setting("llm.model") == "gpt-4"

    def test_settings_context_extract_value_from_full_setting(self):
        """SettingsContext properly extracts value field from setting objects."""
        snapshot = {
            "llm.temperature": {"value": 0.5, "ui_element": "slider"},
            "llm.max_tokens": {"value": 4096, "ui_element": "number"},
        }

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("llm.temperature") == 0.5
        assert ctx.get_setting("llm.max_tokens") == 4096

    def test_settings_context_malformed_snapshot_handling(self):
        """SettingsContext handles malformed snapshots gracefully."""
        snapshot = {
            "valid.key": "value",
            "malformed.dict": {"not_value": "test"},  # Missing 'value' key
            "another.key": None,
        }

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("valid.key") == "value"
        # Malformed dict stored as-is (no 'value' key)
        assert ctx.get_setting("malformed.dict") == {"not_value": "test"}
        assert ctx.get_setting("another.key") is None

    def test_settings_context_empty_snapshot_uses_defaults(self):
        """SettingsContext returns defaults for empty snapshot."""

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext({}, "testuser")

        assert (
            ctx.get_setting("nonexistent.key", "default_value")
            == "default_value"
        )
        assert ctx.get_setting("another.missing", 42) == 42

    def test_settings_context_missing_key_uses_default(self):
        """SettingsContext returns default when key not found."""
        snapshot = {"existing.key": "value"}

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("missing.key", "fallback") == "fallback"
        assert ctx.get_setting("missing.key") is None

    def test_settings_context_type_conversion_during_setup(self):
        """SettingsContext preserves types from snapshot."""
        snapshot = {
            "int_value": {"value": 100},
            "float_value": {"value": 3.14},
            "bool_value": {"value": True},
            "list_value": {"value": [1, 2, 3]},
            "dict_value": {"value": {"nested": "data"}},
        }

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("int_value") == 100
        assert ctx.get_setting("float_value") == 3.14
        assert ctx.get_setting("bool_value") is True
        assert ctx.get_setting("list_value") == [1, 2, 3]
        assert ctx.get_setting("dict_value") == {"nested": "data"}

    def test_settings_context_thread_local_isolation(self):
        """SettingsContext maintains isolation for different users."""

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx1 = SettingsContext({"key": "user1_value"}, "user1")
        ctx2 = SettingsContext({"key": "user2_value"}, "user2")

        assert ctx1.get_setting("key") == "user1_value"
        assert ctx2.get_setting("key") == "user2_value"
        assert ctx1.username == "user1"
        assert ctx2.username == "user2"

    def test_settings_context_cleanup_on_error(self):
        """SettingsContext handles errors gracefully during initialization."""

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        # None snapshot should be handled
        ctx = SettingsContext(None, "testuser")
        assert ctx.get_setting("any.key", "default") == "default"

    def test_settings_context_nested_settings_extraction(self):
        """SettingsContext handles nested key structures."""
        snapshot = {
            "llm.provider": {"value": "openai"},
            "llm.openai.api_key": {"value": "sk-test"},
            "llm.openai.model": {"value": "gpt-4"},
            "search.google.api_key": {"value": "google-key"},
        }

        class SettingsContext:
            def __init__(self, snapshot, username):
                self.snapshot = snapshot or {}
                self.username = username
                self.values = {}
                for key, setting in self.snapshot.items():
                    if isinstance(setting, dict) and "value" in setting:
                        self.values[key] = setting["value"]
                    else:
                        self.values[key] = setting

            def get_setting(self, key, default=None):
                if key in self.values:
                    return self.values[key]
                return default

        ctx = SettingsContext(snapshot, "testuser")

        assert ctx.get_setting("llm.provider") == "openai"
        assert ctx.get_setting("llm.openai.api_key") == "sk-test"
        assert ctx.get_setting("llm.openai.model") == "gpt-4"
        assert ctx.get_setting("search.google.api_key") == "google-key"


class TestLLMInstantiation:
    """Tests for LLM instantiation during research.

    Note: These tests verify the LLM configuration logic without making
    actual API calls or requiring external services.
    """

    def test_llm_instantiation_success_logic(self):
        """LLM instantiation success scenario."""
        # Test the logic for successful instantiation
        provider = "ollama"
        is_available = True

        if is_available and provider == "ollama":
            should_create_ollama = True
        else:
            should_create_ollama = False

        assert should_create_ollama

    def test_llm_instantiation_ollama_503_error_logic(self):
        """LLM handles Ollama 503 service unavailable."""
        is_available = False
        status_code = 503

        if not is_available or status_code == 503:
            should_use_fallback = True
        else:
            should_use_fallback = False

        assert should_use_fallback

    def test_llm_instantiation_ollama_404_model_not_found_logic(self):
        """LLM handles Ollama 404 model not found."""
        model_name = "nonexistent-model"
        available_models = ["mistral", "llama2"]

        if model_name.lower() not in available_models:
            should_use_fallback = True
        else:
            should_use_fallback = False

        assert should_use_fallback

    def test_llm_instantiation_connection_timeout_logic(self):
        """LLM handles connection timeout."""
        connection_error = True
        timeout_occurred = True

        if connection_error or timeout_occurred:
            should_use_fallback = True
        else:
            should_use_fallback = False

        assert should_use_fallback

    def test_llm_instantiation_api_key_missing_logic(self):
        """LLM handles missing API key for cloud providers."""
        provider = "openai"
        api_key = None

        if provider in ["openai", "anthropic"] and not api_key:
            should_use_fallback = True
        else:
            should_use_fallback = False

        assert should_use_fallback

    @patch("local_deep_research.config.llm_config.get_setting_from_snapshot")
    def test_llm_instantiation_invalid_provider(self, mock_get_setting):
        """get_llm raises for invalid provider."""
        from local_deep_research.config.llm_config import get_llm

        mock_get_setting.side_effect = lambda key, default=None, **kwargs: {
            "llm.model": "model",
            "llm.temperature": 0.7,
            "llm.provider": "invalid_provider",
        }.get(key, default)

        with pytest.raises(ValueError) as exc_info:
            get_llm(provider="invalid_provider")

        assert "Invalid provider" in str(exc_info.value)

    def test_llm_instantiation_model_name_override_logic(self):
        """Model name override takes precedence over settings."""
        settings_model = "default-model"
        override_model = "override-model"

        # Override should be used when provided
        model_to_use = override_model if override_model else settings_model

        assert model_to_use == "override-model"

    def test_llm_instantiation_temperature_setting_logic(self):
        """Temperature setting is applied correctly."""
        default_temperature = 0.7
        custom_temperature = 0.3

        # Custom temperature should be used
        temperature = (
            custom_temperature
            if custom_temperature is not None
            else default_temperature
        )

        assert temperature == 0.3

    def test_llm_instantiation_context_window_calculation_logic(self):
        """Context window is calculated correctly for local providers."""
        provider = "ollama"
        local_context_window_size = 8192
        cloud_context_window_size = 128000

        if provider in ["ollama", "llamacpp", "lmstudio"]:
            context_window = local_context_window_size
        else:
            context_window = cloud_context_window_size

        assert context_window == 8192

    def test_llm_instantiation_thinking_mode_detection_logic(self):
        """Thinking mode is configured for supported models."""
        enable_thinking = True

        # Thinking mode should be enabled for thinking-capable models
        if enable_thinking:
            reasoning_param = True
        else:
            reasoning_param = False

        assert reasoning_param is True

    def test_llm_max_tokens_calculation(self):
        """Max tokens is calculated as 80% of context window."""
        context_window_size = 4096
        max_tokens_setting = 100000

        # Use 80% of context window
        max_tokens = min(max_tokens_setting, int(context_window_size * 0.8))

        assert max_tokens == int(4096 * 0.8)  # 3276

    def test_llm_provider_normalization(self):
        """Provider name is normalized to lowercase."""
        providers = ["OLLAMA", "OpenAI", "Anthropic", "ollama"]

        for provider in providers:
            normalized = provider.lower() if provider else None
            assert normalized == provider.lower()


class TestSearchEngineSetup:
    """Tests for search engine setup during research."""

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_creation_success(self, mock_get_search):
        """get_search successfully creates search engine."""
        mock_search = Mock()
        mock_get_search.return_value = mock_search

        from local_deep_research.config.search_config import get_search

        result = get_search(
            search_tool="google",
            llm_instance=Mock(),
            username="testuser",
        )

        assert result == mock_search

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_creation_failure_fallback(self, mock_get_search):
        """get_search handles creation failure."""
        mock_get_search.side_effect = Exception("Search engine error")

        from local_deep_research.config.search_config import get_search

        with pytest.raises(Exception) as exc_info:
            get_search(search_tool="invalid", llm_instance=Mock())

        assert "Search engine error" in str(exc_info.value)

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_with_llm_instance(self, mock_get_search):
        """get_search passes LLM instance correctly."""
        mock_search = Mock()
        mock_get_search.return_value = mock_search
        mock_llm = Mock()

        from local_deep_research.config.search_config import get_search

        get_search(
            search_tool="google",
            llm_instance=mock_llm,
            username="testuser",
        )

        mock_get_search.assert_called_once()
        call_kwargs = mock_get_search.call_args
        assert call_kwargs[1].get("llm_instance") == mock_llm

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_settings_propagation(self, mock_get_search):
        """get_search propagates settings snapshot."""
        mock_search = Mock()
        mock_get_search.return_value = mock_search
        settings = {"search.max_results": 10}

        from local_deep_research.config.search_config import get_search

        get_search(
            search_tool="google",
            llm_instance=Mock(),
            settings_snapshot=settings,
        )

        call_kwargs = mock_get_search.call_args
        assert call_kwargs[1].get("settings_snapshot") == settings

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_cache_integration(self, mock_get_search):
        """get_search integrates with cache system."""
        mock_search = Mock()
        mock_get_search.return_value = mock_search

        from local_deep_research.config.search_config import get_search

        # Should not raise
        result = get_search(
            search_tool="google",
            llm_instance=Mock(),
        )

        assert result is not None

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_rate_limiting_config(self, mock_get_search):
        """get_search applies rate limiting configuration."""
        mock_search = Mock()
        mock_get_search.return_value = mock_search

        from local_deep_research.config.search_config import get_search

        get_search(
            search_tool="google",
            llm_instance=Mock(),
        )

        # Search should be created
        mock_get_search.assert_called_once()

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_invalid_config_handling(self, mock_get_search):
        """get_search handles invalid configuration."""
        mock_get_search.side_effect = ValueError("Invalid search configuration")

        from local_deep_research.config.search_config import get_search

        with pytest.raises(ValueError) as exc_info:
            get_search(
                search_tool="invalid_engine",
                llm_instance=Mock(),
            )

        assert "Invalid search configuration" in str(exc_info.value)

    @patch("local_deep_research.config.search_config.get_search")
    def test_search_engine_timeout_configuration(self, mock_get_search):
        """get_search applies timeout configuration."""
        mock_search = Mock()
        mock_get_search.return_value = mock_search

        from local_deep_research.config.search_config import get_search

        result = get_search(
            search_tool="google",
            llm_instance=Mock(),
        )

        assert result is not None


class TestResearchAnalysisPhase:
    """Tests for research analysis phase."""

    def test_analysis_phase_success(self):
        """Analysis phase completes successfully with results."""
        mock_system = Mock()
        mock_system.analyze_topic.return_value = {
            "findings": [{"content": "Test finding", "phase": "search"}],
            "formatted_findings": "# Test Results\n\nTest finding",
            "iterations": 3,
        }

        results = mock_system.analyze_topic("test query")

        assert "findings" in results
        assert "formatted_findings" in results
        assert results["iterations"] == 3

    def test_analysis_phase_ollama_unavailable_error_classification(self):
        """Analysis phase classifies Ollama unavailable errors."""
        error_message = "Error: status code: 503"

        # Classification logic
        if "status code: 503" in error_message:
            error_type = "ollama_unavailable"
        else:
            error_type = "unknown"

        assert error_type == "ollama_unavailable"

    def test_analysis_phase_model_not_found_error_classification(self):
        """Analysis phase classifies model not found errors."""
        error_message = "Error: status code: 404"

        if "status code: 404" in error_message:
            error_type = "model_not_found"
        else:
            error_type = "unknown"

        assert error_type == "model_not_found"

    def test_analysis_phase_connection_error_classification(self):
        """Analysis phase classifies connection errors."""
        error_message = "Connection refused: localhost:11434"

        if "connection" in error_message.lower():
            error_type = "connection_error"
        else:
            error_type = "unknown"

        assert error_type == "connection_error"

    def test_analysis_phase_api_error_classification(self):
        """Analysis phase classifies API errors."""
        error_message = "Error: status code: 500"

        if "status code:" in error_message:
            error_message.split("status code:")[1].strip()
            error_type = "api_error"
        else:
            error_type = "unknown"

        assert error_type == "api_error"

    def test_analysis_phase_error_message_transformation(self):
        """Analysis phase transforms error messages to user-friendly format."""
        error_message = "Error: status code: 503"

        # Transform logic
        if "status code: 503" in error_message:
            user_message = (
                "Ollama AI service is unavailable (HTTP 503). "
                "Please check that Ollama is running properly on your system."
            )
        else:
            user_message = error_message

        assert "Ollama AI service is unavailable" in user_message
        assert "HTTP 503" in user_message

    def test_analysis_phase_partial_results_handling(self):
        """Analysis phase handles partial results."""
        partial_results = {
            "findings": [
                {"content": "Finding 1", "phase": "search"},
                {"content": "Error: LLM failed", "phase": "synthesis"},
            ],
            "formatted_findings": "Error: Final synthesis failed",
            "iterations": 2,
        }

        # Should detect error in formatted_findings
        assert partial_results["formatted_findings"].startswith("Error:")

        # Should have valid findings
        valid_findings = [
            f
            for f in partial_results["findings"]
            if not f["content"].startswith("Error:")
        ]
        assert len(valid_findings) == 1
