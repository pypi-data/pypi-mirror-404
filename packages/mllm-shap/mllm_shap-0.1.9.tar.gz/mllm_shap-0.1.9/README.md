# Welcome to MLLM-SHAP

**MLLM-SHAP** is a Python package designed to **interpret the predictions of large language models (LLMs)** using **SHAP (SHapley Additive exPlanations)** values.
It helps you understand the contribution of input features to model outputs, enabling **transparent and explainable AI workflows**.
This work also has companion GUI visualization tools for easier interpretation of results, which is available at the official [shap-mllm-explainer](https://github.com/mvishiu11/shap-mllm-explainer) repository.

---

## âœ¨ Key Features

- Integration with **audio and text models**, supporting multi-modal inputs and outputs.
- Flexible aggregation strategies: *mean*, *sum*, *max*, *min*, etc.
- Multiple similarity metrics (*cosine*, *euclidean*, etc.) for embedding analysis.
- Customizable SHAP calculation algorithms: *exact*, *Monte Carlo approximations*, and more.
- Examples showcasing common explainability pipelines in [`examples/`](https://github.com/Pawlo77/MLLM-Shap/tree/main/examples) on the official GitHub repository.

---

## ðŸ“Š Visualization & Examples

If youâ€™re interested in GUI visualization of SHAP values, check out the section  **Extension - GUI Visualization** in the docs.

For more advanced CLI usages, refer to:

- The [official GitHub repository examples](https://github.com/Pawlo77/MLLM-Shap/tree/main/examples)
- Or explore more advanced pipelines from exemplary [research projects](https://github.com/Pawlo77/MLLM-Shap/tree/main/experiments)

---

## ðŸ¤– Supported LLM Integrations

- [Liquid-Audio](https://github.com/Liquid4All/liquid-audio/)
