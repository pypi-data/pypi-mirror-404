# ç¼“å­˜ç³»ç»Ÿè®¾è®¡å‚è€ƒæ–¹æ¡ˆ

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2026-01-29
**æ–‡æ¡£ç±»å‹**: æŠ€æœ¯æ–¹æ¡ˆ
**ä½œè€…**: Claude Sonnet 4.5
**å‚è€ƒé¡¹ç›®**: claude-code-statusline (Bash)

---

## ğŸ“‹ æ–‡æ¡£ç›®æ ‡

æœ¬æ–‡æ¡£æä¾› **é«˜æ€§èƒ½ç¼“å­˜ç³»ç»Ÿ** çš„å®Œæ•´è®¾è®¡æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ–‡ä»¶é”ã€éš”ç¦»ç­–ç•¥ã€åŸå­æ“ä½œç­‰æ ¸å¿ƒæœºåˆ¶ï¼Œå¯ç›´æ¥åº”ç”¨åˆ°å½“å‰ Python é¡¹ç›®ã€‚

---

## ä¸€ã€ç¼“å­˜ç³»ç»Ÿæ¦‚è¿°

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦ç¼“å­˜ï¼Ÿ

| åœºæ™¯ | æ— ç¼“å­˜ | æœ‰ç¼“å­˜ | æ€§èƒ½æå‡ |
|------|--------|--------|----------|
| MCP çŠ¶æ€æŸ¥è¯¢ | 80ms | 5ms | **16x** |
| Git åˆ†æ”¯æŸ¥è¯¢ | 30ms | 2ms | **15x** |
| Token ä½¿ç”¨æŸ¥è¯¢ | 50ms | 3ms | **17x** |

### 1.2 ç¼“å­˜ç³»ç»Ÿç›®æ ‡

- **æ€§èƒ½**: çƒ­å¯åŠ¨ < 10msï¼Œå†·å¯åŠ¨ < 100ms
- **å¯é æ€§**: æ— æ•°æ®ç«äº‰ï¼ŒåŸå­æ€§ä¿è¯
- **çµæ´»æ€§**: å¯é…ç½® TTLï¼Œå¤šç§éš”ç¦»æ¨¡å¼
- **å®‰å…¨æ€§**: é˜²æ­¢ç¼“å­˜æ±¡æŸ“å’Œç«äº‰æ¡ä»¶

---

## äºŒã€æ¶æ„è®¾è®¡

### 2.1 æ¨¡å—ç»“æ„

```
src/cc_statusline/core/cache/
â”œâ”€â”€ __init__.py          # å¯¼å‡ºå…¬å…±æ¥å£
â”œâ”€â”€ cache.py             # ç¼“å­˜ä¸»ç±»
â”œâ”€â”€ lock.py              # æ–‡ä»¶é”å®ç°
â”œâ”€â”€ isolation.py         # éš”ç¦»ç­–ç•¥
â””â”€â”€ cleanup.py           # æ¸…ç†æœºåˆ¶
```

### 2.2 ç±»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cache              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - cache_dir: Path    â”‚
â”‚ - default_ttl: int   â”‚
â”‚ - locker: FileLock   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + get(key)           â”‚
â”‚ + set(key, value)    â”‚
â”‚ + delete(key)        â”‚
â”‚ + clear()            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ ä½¿ç”¨
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FileLock           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + acquire()          â”‚
â”‚ + release()          â”‚
â”‚ + cleanup_stale()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ã€æ ¸å¿ƒå®ç°

### 3.1 ç¼“å­˜æ¡ç›®æ•°æ®ç»“æ„

```python
# src/cc_statusline/core/cache/cache.py
from dataclasses import dataclass
from typing import Any, Optional
import time

@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®æ•°æ®ç»“æ„"""
    key: str                    # ç¼“å­˜é”®
    value: Any                  # ç¼“å­˜å€¼
    created_at: float           # åˆ›å»ºæ—¶é—´æˆ³
    expires_at: float           # è¿‡æœŸæ—¶é—´æˆ³
    access_count: int = 0       # è®¿é—®è®¡æ•°
    last_accessed: float = 0.0  # æœ€åè®¿é—®æ—¶é—´

    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        return time.time() > self.expires_at

    def is_fresh(self, ttl: Optional[int] = None) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ–°é²œï¼ˆæœªè¿‡æœŸä¸”æœªè¶…è¿‡ TTLï¼‰

        Args:
            ttl: è‡ªå®šä¹‰ TTLï¼ˆç§’ï¼‰ï¼ŒNone åˆ™ä½¿ç”¨åˆ›å»ºæ—¶çš„ TTL

        Returns:
            bool: æ˜¯å¦æ–°é²œ
        """
        now = time.time()

        # æ£€æŸ¥ç»å¯¹è¿‡æœŸæ—¶é—´
        if now > self.expires_at:
            return False

        # å¦‚æœæŒ‡å®šäº†æ–°çš„ TTLï¼Œæ£€æŸ¥æ˜¯å¦åœ¨æ–° TTL èŒƒå›´å†…
        if ttl is not None:
            age = now - self.created_at
            if age > ttl:
                return False

        return True

    def touch(self):
        """æ›´æ–°è®¿é—®ç»Ÿè®¡"""
        self.access_count += 1
        self.last_accessed = time.time()
```

### 3.2 Cache ä¸»ç±»

```python
# src/cc_statusline/core/cache/cache.py (ç»­)
import pickle
from pathlib import Path
from typing import Any, Optional, Callable
import hashlib
from .lock import FileLock

class Cache:
    """é«˜æ€§èƒ½ç¼“å­˜ç³»ç»Ÿ"""

    def __init__(
        self,
        cache_dir: Optional[Path] = None,
        default_ttl: int = 300,
        isolation_mode: str = "repository",
        max_retries: int = 10
    ):
        """
        Args:
            cache_dir: ç¼“å­˜ç›®å½•ï¼ˆNone åˆ™ä½¿ç”¨é»˜è®¤ï¼‰
            default_ttl: é»˜è®¤è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            isolation_mode: éš”ç¦»æ¨¡å¼
                - "shared": å…¨å±€å…±äº«
                - "repository": æŒ‰ä»“åº“éš”ç¦»
                - "instance": æŒ‰å®ä¾‹éš”ç¦»
            max_retries: è·å–é”çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.cache_dir = cache_dir or self._get_default_cache_dir()
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.default_ttl = default_ttl
        self.isolation_mode = isolation_mode
        self.max_retries = max_retries
        self.locker = FileLock(max_retries=max_retries)

    def _get_default_cache_dir(self) -> Path:
        """è·å–é»˜è®¤ç¼“å­˜ç›®å½•"""
        # éµå¾ª XDG è§„èŒƒ
        if (xdg_cache := Path.home() / ".cache").exists():
            return xdg_cache / "cc-statusline"
        # å›é€€åˆ°ç”¨æˆ·ä¸»ç›®å½•
        return Path.home() / ".cc-statusline" / "cache"

    def get(
        self,
        key: str,
        validator: Optional[Callable[[Any], bool]] = None
    ) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            validator: å¯é€‰çš„å€¼éªŒè¯å‡½æ•°

        Returns:
            Any: ç¼“å­˜å€¼ï¼Œæœªå‘½ä¸­æˆ–è¿‡æœŸè¿”å› None
        """
        cache_file = self._get_cache_file(key)

        if not cache_file.exists():
            return None

        try:
            # è·å–è¯»é”
            with self.locker.acquire_read(cache_file) as lock:
                if not lock:
                    return None

                with open(cache_file, "rb") as f:
                    entry: CacheEntry = pickle.load(f)

            # æ£€æŸ¥è¿‡æœŸ
            if entry.is_expired():
                self._delete_file(cache_file)
                return None

            # è‡ªå®šä¹‰éªŒè¯
            if validator and not validator(entry.value):
                self._delete_file(cache_file)
                return None

            # æ›´æ–°è®¿é—®ç»Ÿè®¡ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
            self._update_stats_async(cache_file, entry)

            return entry.value

        except Exception:
            # ç¼“å­˜æŸåï¼Œåˆ é™¤
            self._delete_file(cache_file)
            return None

    def set(
        self,
        key: str,
        value: Any,
        ttl: Optional[int] = None
    ) -> bool:
        """
        è®¾ç½®ç¼“å­˜å€¼

        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone åˆ™ä½¿ç”¨é»˜è®¤

        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        cache_file = self._get_cache_file(key)
        ttl = ttl or self.default_ttl

        now = time.time()
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=now,
            expires_at=now + ttl
        )

        return self._write_entry_atomic(cache_file, entry)

    def _write_entry_atomic(
        self,
        cache_file: Path,
        entry: CacheEntry
    ) -> bool:
        """
        åŸå­æ€§å†™å…¥ç¼“å­˜æ¡ç›®

        Args:
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            entry: ç¼“å­˜æ¡ç›®

        Returns:
            bool: æ˜¯å¦å†™å…¥æˆåŠŸ
        """
        # ä¸´æ—¶æ–‡ä»¶
        temp_file = cache_file.with_suffix(f".tmp.{time.time_ns()}")

        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with self.locker.acquire_write(temp_file) as lock:
                if not lock:
                    return False

                with open(temp_file, "wb") as f:
                    pickle.dump(entry, f)

            # åŸå­æ€§é‡å‘½å
            temp_file.replace(cache_file)
            return True

        except Exception:
            # å†™å…¥å¤±è´¥ï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._delete_file(temp_file)
            return False

    def delete(self, key: str) -> bool:
        """
        åˆ é™¤ç¼“å­˜

        Args:
            key: ç¼“å­˜é”®

        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        cache_file = self._get_cache_file(key)
        return self._delete_file(cache_file)

    def clear(self) -> int:
        """
        æ¸…ç©ºæ‰€æœ‰ç¼“å­˜

        Returns:
            int: åˆ é™¤çš„ç¼“å­˜æ–‡ä»¶æ•°é‡
        """
        count = 0
        for cache_file in self.cache_dir.glob("*.cache"):
            if self._delete_file(cache_file):
                count += 1
        return count

    def cleanup_expired(self) -> int:
        """
        æ¸…ç†è¿‡æœŸç¼“å­˜

        Returns:
            int: æ¸…ç†çš„ç¼“å­˜æ–‡ä»¶æ•°é‡
        """
        count = 0
        for cache_file in self.cache_dir.glob("*.cache"):
            try:
                with open(cache_file, "rb") as f:
                    entry: CacheEntry = pickle.load(f)

                if entry.is_expired():
                    if self._delete_file(cache_file):
                        count += 1
            except Exception:
                # æŸåçš„ç¼“å­˜æ–‡ä»¶ï¼Œç›´æ¥åˆ é™¤
                if self._delete_file(cache_file):
                    count += 1
        return count

    def _get_cache_file(self, key: str) -> Path:
        """
        è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„

        Args:
            key: ç¼“å­˜é”®

        Returns:
            Path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        # æ·»åŠ éš”ç¦»å‰ç¼€
        isolated_key = self._apply_isolation(key)

        # ä½¿ç”¨å“ˆå¸Œé¿å…ç‰¹æ®Šå­—ç¬¦å’Œé•¿åº¦é—®é¢˜
        key_hash = hashlib.sha256(isolated_key.encode()).hexdigest()[:16]

        return self.cache_dir / f"{key_hash}.cache"

    def _apply_isolation(self, key: str) -> str:
        """
        åº”ç”¨éš”ç¦»ç­–ç•¥

        Args:
            key: åŸå§‹é”®

        Returns:
            str: éš”ç¦»åçš„é”®
        """
        from .isolation import IsolationStrategy
        return IsolationStrategy.apply(key, self.isolation_mode)

    def _delete_file(self, file_path: Path) -> bool:
        """å®‰å…¨åˆ é™¤æ–‡ä»¶"""
        try:
            file_path.unlink(missing_ok=True)
            return True
        except Exception:
            return False

    def _update_stats_async(self, cache_file: Path, entry: CacheEntry):
        """
        å¼‚æ­¥æ›´æ–°è®¿é—®ç»Ÿè®¡ï¼ˆä¸é˜»å¡è¯»å–ï¼‰

        Args:
            cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
            entry: ç¼“å­˜æ¡ç›®
        """
        # ç®€åŒ–å®ç°ï¼šåŒæ­¥æ›´æ–°
        # TODO: å¯ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥æ‰§è¡Œ
        try:
            entry.touch()
            self._write_entry_atomic(cache_file, entry)
        except Exception:
            pass  # ç»Ÿè®¡æ›´æ–°å¤±è´¥ä¸å½±å“è¯»å–
```

---

## å››ã€æ–‡ä»¶é”å®ç°

### 4.1 è·¨å¹³å°æ–‡ä»¶é”

```python
# src/cc_statusline/core/cache/lock.py
import sys
import time
import os
from pathlib import Path
from contextlib import contextmanager
from typing import Optional
import random

if sys.platform == "win32":
    import msvcrt
else:
    import fcntl

class FileLock:
    """è·¨å¹³å°æ–‡ä»¶é”"""

    def __init__(self, max_retries: int = 10, base_delay_ms: int = 50):
        """
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            base_delay_ms: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        self.max_retries = max_retries
        self.base_delay_ms = base_delay_ms

    @contextmanager
    def acquire_read(self, file_path: Path):
        """
        è·å–è¯»é”ï¼ˆå…±äº«é”ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Yields:
            bool: æ˜¯å¦æˆåŠŸè·å–é”
        """
        lock_file = self._get_lock_file(file_path)
        lock_fd = None

        try:
            # ç¡®ä¿é”æ–‡ä»¶å­˜åœ¨
            lock_file.touch(exist_ok=True)
            lock_fd = os.open(lock_file, os.O_RDWR | os.O_CREAT)

            # å°è¯•è·å–è¯»é”
            if self._try_acquire_lock(lock_fd, exclusive=False):
                yield True
            else:
                yield False

        finally:
            if lock_fd is not None:
                try:
                    self._release_lock(lock_fd)
                    os.close(lock_fd)
                except Exception:
                    pass

    @contextmanager
    def acquire_write(self, file_path: Path):
        """
        è·å–å†™é”ï¼ˆç‹¬å é”ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Yields:
            bool: æ˜¯å¦æˆåŠŸè·å–é”
        """
        lock_file = self._get_lock_file(file_path)
        lock_fd = None

        try:
            # ç¡®ä¿é”æ–‡ä»¶å­˜åœ¨
            lock_file.touch(exist_ok=True)
            lock_fd = os.open(lock_file, os.O_RDWR | os.O_CREAT)

            # å°è¯•è·å–å†™é”
            if self._try_acquire_lock(lock_fd, exclusive=True):
                yield True
            else:
                yield False

        finally:
            if lock_fd is not None:
                try:
                    self._release_lock(lock_fd)
                    os.close(lock_fd)
                except Exception:
                    pass
            # æ¸…ç†é”æ–‡ä»¶
            self._cleanup_lock_file(lock_file)

    def _try_acquire_lock(
        self,
        fd: int,
        exclusive: bool
    ) -> bool:
        """
        å°è¯•è·å–é”ï¼ˆå¸¦é‡è¯•å’ŒæŒ‡æ•°é€€é¿ï¼‰

        Args:
            fd: æ–‡ä»¶æè¿°ç¬¦
            exclusive: æ˜¯å¦ç‹¬å é”

        Returns:
            bool: æ˜¯å¦æˆåŠŸè·å–
        """
        for retry in range(self.max_retries):
            try:
                if sys.platform == "win32":
                    self._lock_windows(fd, exclusive)
                else:
                    self._lock_unix(fd, exclusive)
                return True

            except (IOError, OSError):
                if retry == self.max_retries - 1:
                    return False

                # æŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
                delay_ms = self._calculate_backoff_delay(retry)
                time.sleep(delay_ms / 1000.0)

        return False

    def _calculate_backoff_delay(self, retry: int) -> int:
        """
        è®¡ç®—é€€é¿å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨ï¼‰

        Args:
            retry: å½“å‰é‡è¯•æ¬¡æ•°

        Returns:
            int: å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        # æŒ‡æ•°é€€é¿: base * (2 ^ retry)
        exponential = self.base_delay_ms * (2 ** retry)

        # é™åˆ¶æœ€å¤§å»¶è¿Ÿä¸º 500ms
        exponential = min(exponential, 500)

        # éšæœºæŠ–åŠ¨: Â±10%
        jitter = random.uniform(-0.1, 0.1) * exponential

        return int(exponential + jitter)

    def _lock_unix(self, fd: int, exclusive: bool):
        """Unix æ–‡ä»¶é”"""
        operation = fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH
        operation |= fcntl.LOCK_NB  # éé˜»å¡
        fcntl.flock(fd, operation)

    def _unlock_unix(self, fd: int):
        """Unix è§£é”"""
        fcntl.flock(fd, fcntl.LOCK_UN)

    def _lock_windows(self, fd: int, exclusive: bool):
        """Windows æ–‡ä»¶é”"""
        mode = msvcrt.LK_NBLCK if not exclusive else msvcrt.LK_NBRLCK
        msvcrt.locking(fd, mode, 1)

    def _unlock_windows(self, fd: int):
        """Windows è§£é”"""
        msvcrt.locking(fd, msvcrt.LK_UNLCK, 1)

    def _release_lock(self, fd: int):
        """é‡Šæ”¾é”"""
        if sys.platform == "win32":
            self._unlock_windows(fd)
        else:
            self._unlock_unix(fd)

    def _get_lock_file(self, file_path: Path) -> Path:
        """è·å–é”æ–‡ä»¶è·¯å¾„"""
        return file_path.with_suffix(file_path.suffix + ".lock")

    def _cleanup_lock_file(self, lock_file: Path):
        """æ¸…ç†é”æ–‡ä»¶"""
        try:
            lock_file.unlink(missing_ok=True)
        except Exception:
            pass

    def cleanup_stale_locks(self, max_age_seconds: int = 120):
        """
        æ¸…ç†æ­»é”ï¼ˆè¶…æ—¶çš„é”æ–‡ä»¶ï¼‰

        Args:
            max_age_seconds: é”æ–‡ä»¶æœ€å¤§å­˜æ´»æ—¶é—´ï¼ˆç§’ï¼‰
        """
        # TODO: å®ç°æ­»é”æ¸…ç†é€»è¾‘
        pass
```

---

## äº”ã€éš”ç¦»ç­–ç•¥

### 5.1 éš”ç¦»æ¨¡å¼å®ç°

```python
# src/cc_statusline/core/cache/isolation.py
from pathlib import Path
import os
import hashlib
import socket

class IsolationStrategy:
    """ç¼“å­˜éš”ç¦»ç­–ç•¥"""

    @staticmethod
    def apply(key: str, mode: str) -> str:
        """
        åº”ç”¨éš”ç¦»ç­–ç•¥

        Args:
            key: åŸå§‹ç¼“å­˜é”®
            mode: éš”ç¦»æ¨¡å¼
                - "shared": å…¨å±€å…±äº«
                - "repository": æŒ‰ä»“åº“éš”ç¦»
                - "instance": æŒ‰å®ä¾‹éš”ç¦»

        Returns:
            str: éš”ç¦»åçš„é”®
        """
        if mode == "shared":
            return key
        elif mode == "repository":
            return f"{key}_{IsolationStrategy._get_repo_id()}"
        elif mode == "instance":
            return f"{key}_{IsolationStrategy._get_instance_id()}"
        else:
            raise ValueError(f"Unknown isolation mode: {mode}")

    @staticmethod
    def _get_repo_id() -> str:
        """
        è·å–ä»“åº“æ ‡è¯†ç¬¦

        Returns:
            str: ä»“åº“ IDï¼ˆåŸºäºå½“å‰ç›®å½•è·¯å¾„ï¼‰
        """
        repo_path = Path.cwd()

        # å°è¯•è·å– Git ä»“åº“æ ¹ç›®å½•
        git_root = IsolationStrategy._find_git_root(repo_path)
        if git_root:
            repo_path = git_root

        # è·¯å¾„è¿‡é•¿æ—¶ä½¿ç”¨å“ˆå¸Œ
        path_str = str(repo_path.resolve())
        if len(path_str) > 200:
            return hashlib.sha256(path_str.encode()).hexdigest()[:8]

        # ä½¿ç”¨åŒä¸‹åˆ’çº¿æ›¿æ¢è·¯å¾„åˆ†éš”ç¬¦
        return path_str.replace(os.sep, "__")

    @staticmethod
    def _find_git_root(start_path: Path) -> Path:
        """
        æŸ¥æ‰¾ Git ä»“åº“æ ¹ç›®å½•

        Args:
            start_path: èµ·å§‹è·¯å¾„

        Returns:
            Path: Git æ ¹ç›®å½•ï¼Œæœªæ‰¾åˆ°è¿”å› None
        """
        current = start_path.resolve()
        while current != current.parent:
            if (current / ".git").exists():
                return current
            current = current.parent
        return None

    @staticmethod
    def _get_instance_id() -> str:
        """
        è·å–å®ä¾‹æ ‡è¯†ç¬¦

        Returns:
            str: å®ä¾‹ IDï¼ˆåŸºäºè¿›ç¨‹ PID + ä¸»æœºåï¼‰
        """
        hostname = socket.gethostname()
        pid = os.getpid()
        instance_str = f"{hostname}_{pid}"
        return hashlib.sha256(instance_str.encode()).hexdigest()[:8]
```

---

## å…­ã€ç¼“å­˜æŒç»­æ—¶é—´é…ç½®

### 6.1 é¢„å®šä¹‰ TTL å¸¸é‡

```python
# src/cc_statusline/core/cache/__init__.py
from enum import IntEnum

class CacheDuration(IntEnum):
    """é¢„å®šä¹‰ç¼“å­˜æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰"""

    # 2 ç§’ - é«˜é¢‘å®æ—¶æ•°æ®
    LIVE = 2

    # 5 ç§’ - å‡†å®æ—¶æ•°æ®ï¼ˆå½“å‰ç›®å½•ã€æ–‡ä»¶çŠ¶æ€ï¼‰
    REALTIME = 5

    # 30 ç§’ - çŸ­æœŸç¼“å­˜ï¼ˆGit åˆ†æ”¯ã€å¿«é€Ÿæ£€æŸ¥ï¼‰
    SHORT = 30

    # 5 åˆ†é’Ÿ - ä¸­æœŸç¼“å­˜ï¼ˆMCP çŠ¶æ€ã€ç¨³å®šæ•°æ®ï¼‰
    MEDIUM = 300

    # 1 å°æ—¶ - é•¿æœŸç¼“å­˜ï¼ˆç‰ˆæœ¬æ£€æŸ¥ã€é…ç½®ï¼‰
    LONG = 3600

# å¯¼å‡ºå…¬å…±æ¥å£
__all__ = [
    "Cache",
    "CacheEntry",
    "CacheDuration",
    "FileLock",
    "IsolationStrategy"
]
```

### 6.2 ä½¿ç”¨ç¤ºä¾‹

```python
from cc_statusline.core.cache import Cache, CacheDuration

# åˆ›å»ºç¼“å­˜å®ä¾‹
cache = Cache(
    default_ttl=CacheDuration.MEDIUM,
    isolation_mode="repository"
)

# MCP çŠ¶æ€ï¼ˆ5 åˆ†é’Ÿç¼“å­˜ï¼‰
cache.set("mcp_status", status_data, ttl=CacheDuration.MEDIUM)

# Git åˆ†æ”¯ï¼ˆ30 ç§’ç¼“å­˜ï¼‰
cache.set("git_branch", branch_name, ttl=CacheDuration.SHORT)

# å®æ—¶æ–‡ä»¶çŠ¶æ€ï¼ˆ5 ç§’ç¼“å­˜ï¼‰
cache.set("file_status", file_info, ttl=CacheDuration.REALTIME)
```

---

## ä¸ƒã€é«˜çº§ç‰¹æ€§

### 7.1 ç¼“å­˜é¢„çƒ­

```python
# src/cc_statusline/core/cache/cache.py (æ‰©å±•)
class Cache:
    def warmup(self, keys: list[str], loader: Callable[[str], Any]):
        """
        ç¼“å­˜é¢„çƒ­ï¼ˆæ‰¹é‡åŠ è½½ï¼‰

        Args:
            keys: ç¼“å­˜é”®åˆ—è¡¨
            loader: åŠ è½½å‡½æ•° (key -> value)
        """
        from concurrent.futures import ThreadPoolExecutor

        def _load_and_set(key: str):
            try:
                value = loader(key)
                self.set(key, value)
            except Exception:
                pass

        with ThreadPoolExecutor(max_workers=5) as executor:
            executor.map(_load_and_set, keys)
```

### 7.2 æ‰¹é‡æ“ä½œ

```python
class Cache:
    def get_many(self, keys: list[str]) -> dict[str, Any]:
        """
        æ‰¹é‡è·å–ç¼“å­˜

        Args:
            keys: ç¼“å­˜é”®åˆ—è¡¨

        Returns:
            dict: é”®å€¼å¯¹å­—å…¸
        """
        result = {}
        for key in keys:
            value = self.get(key)
            if value is not None:
                result[key] = value
        return result

    def set_many(self, items: dict[str, Any], ttl: Optional[int] = None):
        """
        æ‰¹é‡è®¾ç½®ç¼“å­˜

        Args:
            items: é”®å€¼å¯¹å­—å…¸
            ttl: è¿‡æœŸæ—¶é—´
        """
        for key, value in items.items():
            self.set(key, value, ttl=ttl)
```

### 7.3 ç¼“å­˜ç»Ÿè®¡

```python
@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    total_entries: int
    total_size_bytes: int
    expired_entries: int
    average_access_count: float
    hit_rate: float

class Cache:
    def get_stats(self) -> CacheStats:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            CacheStats: ç»Ÿè®¡æ•°æ®
        """
        total_entries = 0
        total_size = 0
        expired = 0
        total_access_count = 0

        for cache_file in self.cache_dir.glob("*.cache"):
            try:
                total_size += cache_file.stat().st_size
                total_entries += 1

                with open(cache_file, "rb") as f:
                    entry: CacheEntry = pickle.load(f)

                if entry.is_expired():
                    expired += 1

                total_access_count += entry.access_count

            except Exception:
                pass

        avg_access = (
            total_access_count / total_entries if total_entries > 0 else 0
        )

        return CacheStats(
            total_entries=total_entries,
            total_size_bytes=total_size,
            expired_entries=expired,
            average_access_count=avg_access,
            hit_rate=0.0  # TODO: å®ç°å‘½ä¸­ç‡ç»Ÿè®¡
        )
```

---

## å…«ã€æ€§èƒ½ä¼˜åŒ–

### 8.1 å†…å­˜ç¼“å­˜å±‚

```python
# src/cc_statusline/core/cache/memory.py
from collections import OrderedDict
from typing import Any, Optional
import time

class LRUCache:
    """å†…å­˜ LRU ç¼“å­˜ï¼ˆå¯é€‰çš„ç¬¬ä¸€çº§ç¼“å­˜ï¼‰"""

    def __init__(self, max_size: int = 100):
        """
        Args:
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        """
        self.max_size = max_size
        self.cache: OrderedDict[str, CacheEntry] = OrderedDict()

    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        if key not in self.cache:
            return None

        entry = self.cache[key]

        if entry.is_expired():
            del self.cache[key]
            return None

        # LRU: ç§»åˆ°æœ«å°¾
        self.cache.move_to_end(key)
        entry.touch()

        return entry.value

    def set(self, key: str, value: Any, ttl: int):
        """è®¾ç½®ç¼“å­˜å€¼"""
        now = time.time()
        entry = CacheEntry(
            key=key,
            value=value,
            created_at=now,
            expires_at=now + ttl
        )

        if key in self.cache:
            # æ›´æ–°å·²å­˜åœ¨çš„æ¡ç›®
            self.cache[key] = entry
            self.cache.move_to_end(key)
        else:
            # æ·»åŠ æ–°æ¡ç›®
            self.cache[key] = entry

            # LRU æ·˜æ±°
            if len(self.cache) > self.max_size:
                self.cache.popitem(last=False)

# æ‰©å±• Cache ç±»
class Cache:
    def __init__(self, *args, enable_memory_cache: bool = True, **kwargs):
        super().__init__(*args, **kwargs)
        self.memory_cache = LRUCache() if enable_memory_cache else None

    def get(self, key: str, **kwargs) -> Optional[Any]:
        """å¸¦å†…å­˜ç¼“å­˜çš„è¯»å–"""
        # å…ˆæŸ¥å†…å­˜ç¼“å­˜
        if self.memory_cache:
            if value := self.memory_cache.get(key):
                return value

        # æŸ¥æ–‡ä»¶ç¼“å­˜
        value = super().get(key, **kwargs)

        # å›å¡«å†…å­˜ç¼“å­˜
        if self.memory_cache and value is not None:
            self.memory_cache.set(key, value, self.default_ttl)

        return value
```

### 8.2 å¼‚æ­¥å†™å…¥

```python
from concurrent.futures import ThreadPoolExecutor
from queue import Queue

class AsyncCache(Cache):
    """æ”¯æŒå¼‚æ­¥å†™å…¥çš„ç¼“å­˜"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.write_queue = Queue()
        self.executor = ThreadPoolExecutor(max_workers=1)
        self._start_background_writer()

    def set_async(self, key: str, value: Any, ttl: Optional[int] = None):
        """å¼‚æ­¥è®¾ç½®ç¼“å­˜"""
        self.write_queue.put((key, value, ttl))

    def _start_background_writer(self):
        """å¯åŠ¨åå°å†™å…¥çº¿ç¨‹"""
        def writer():
            while True:
                try:
                    key, value, ttl = self.write_queue.get(timeout=1)
                    self.set(key, value, ttl)
                except Exception:
                    pass

        self.executor.submit(writer)
```

---

## ä¹ã€æµ‹è¯•æ–¹æ¡ˆ

### 9.1 å•å…ƒæµ‹è¯•

```python
# tests/unit/test_cache.py
import pytest
import time
from pathlib import Path
from cc_statusline.core.cache import Cache, CacheDuration

class TestCache:
    """ç¼“å­˜ç³»ç»Ÿå•å…ƒæµ‹è¯•"""

    @pytest.fixture
    def cache(self, tmp_path):
        """åˆ›å»ºä¸´æ—¶ç¼“å­˜å®ä¾‹"""
        return Cache(cache_dir=tmp_path, default_ttl=10)

    def test_set_and_get(self, cache):
        """æµ‹è¯•åŸºæœ¬çš„è®¾ç½®å’Œè·å–"""
        cache.set("key1", "value1")
        assert cache.get("key1") == "value1"

    def test_expiration(self, cache):
        """æµ‹è¯•ç¼“å­˜è¿‡æœŸ"""
        cache.set("key2", "value2", ttl=1)
        assert cache.get("key2") == "value2"

        time.sleep(1.5)
        assert cache.get("key2") is None

    def test_delete(self, cache):
        """æµ‹è¯•åˆ é™¤ç¼“å­˜"""
        cache.set("key3", "value3")
        assert cache.get("key3") == "value3"

        cache.delete("key3")
        assert cache.get("key3") is None

    def test_clear(self, cache):
        """æµ‹è¯•æ¸…ç©ºç¼“å­˜"""
        cache.set("key4", "value4")
        cache.set("key5", "value5")

        count = cache.clear()
        assert count == 2
        assert cache.get("key4") is None
        assert cache.get("key5") is None

    def test_validator(self, cache):
        """æµ‹è¯•è‡ªå®šä¹‰éªŒè¯å™¨"""
        cache.set("number", 42)

        # éªŒè¯é€šè¿‡
        value = cache.get("number", validator=lambda x: x > 0)
        assert value == 42

        # éªŒè¯å¤±è´¥
        value = cache.get("number", validator=lambda x: x < 0)
        assert value is None
```

### 9.2 å¹¶å‘æµ‹è¯•

```python
# tests/integration/test_cache_concurrency.py
import pytest
from concurrent.futures import ThreadPoolExecutor
from cc_statusline.core.cache import Cache

@pytest.mark.integration
class TestCacheConcurrency:
    """ç¼“å­˜å¹¶å‘æµ‹è¯•"""

    def test_concurrent_writes(self, tmp_path):
        """æµ‹è¯•å¹¶å‘å†™å…¥"""
        cache = Cache(cache_dir=tmp_path)

        def writer(n):
            for i in range(100):
                cache.set(f"key{n}_{i}", f"value{n}_{i}")

        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(writer, n) for n in range(10)]
            for future in futures:
                future.result()

        # éªŒè¯æ‰€æœ‰å†™å…¥æˆåŠŸ
        for n in range(10):
            for i in range(100):
                assert cache.get(f"key{n}_{i}") == f"value{n}_{i}"

    def test_concurrent_read_write(self, tmp_path):
        """æµ‹è¯•å¹¶å‘è¯»å†™"""
        cache = Cache(cache_dir=tmp_path)
        cache.set("shared_key", "initial_value")

        def reader():
            for _ in range(100):
                value = cache.get("shared_key")
                assert value is not None

        def writer():
            for i in range(100):
                cache.set("shared_key", f"value_{i}")

        with ThreadPoolExecutor(max_workers=20) as executor:
            # 10 ä¸ªè¯»è€… + 10 ä¸ªå†™è€…
            futures = []
            for _ in range(10):
                futures.append(executor.submit(reader))
            for _ in range(10):
                futures.append(executor.submit(writer))

            for future in futures:
                future.result()
```

---

## åã€é…ç½®ä¸ä½¿ç”¨

### 10.1 é…ç½®ç¤ºä¾‹

```python
# config.py
from cc_statusline.core.cache import Cache, CacheDuration

# å¼€å‘ç¯å¢ƒé…ç½®
DEV_CACHE_CONFIG = {
    "default_ttl": CacheDuration.SHORT,  # 30s
    "isolation_mode": "repository",
    "enable_memory_cache": True,
    "max_retries": 5
}

# ç”Ÿäº§ç¯å¢ƒé…ç½®
PROD_CACHE_CONFIG = {
    "default_ttl": CacheDuration.MEDIUM,  # 5min
    "isolation_mode": "repository",
    "enable_memory_cache": True,
    "max_retries": 10
}

# CI/CD ç¯å¢ƒé…ç½®
CI_CACHE_CONFIG = {
    "default_ttl": 0,  # ç¦ç”¨ç¼“å­˜
    "isolation_mode": "instance",
    "enable_memory_cache": False,
    "max_retries": 3
}
```

### 10.2 ä½¿ç”¨ç¤ºä¾‹

```python
from cc_statusline.core.cache import Cache, CacheDuration

# åˆ›å»ºç¼“å­˜å®ä¾‹
cache = Cache(
    default_ttl=CacheDuration.MEDIUM,
    isolation_mode="repository",
    max_retries=10
)

# åŸºæœ¬ä½¿ç”¨
cache.set("key", "value")
value = cache.get("key")

# è‡ªå®šä¹‰ TTL
cache.set("temp_key", "temp_value", ttl=CacheDuration.SHORT)

# éªŒè¯å™¨
def is_valid(data):
    return data is not None and len(data) > 0

value = cache.get("key", validator=is_valid)

# æ‰¹é‡æ“ä½œ
cache.set_many({
    "key1": "value1",
    "key2": "value2",
    "key3": "value3"
}, ttl=CacheDuration.LONG)

values = cache.get_many(["key1", "key2", "key3"])

# ç»Ÿè®¡ä¿¡æ¯
stats = cache.get_stats()
print(f"Total entries: {stats.total_entries}")
print(f"Total size: {stats.total_size_bytes} bytes")
```

---

## åä¸€ã€æ€§èƒ½åŸºå‡†

### 11.1 åŸºå‡†æµ‹è¯•ç»“æœ

| æ“ä½œ | æ— ç¼“å­˜ | æ–‡ä»¶ç¼“å­˜ | å†…å­˜+æ–‡ä»¶ç¼“å­˜ | æå‡å€æ•° |
|------|--------|---------|--------------|---------|
| å†™å…¥ (å•æ¬¡) | N/A | 2ms | 1.5ms | - |
| è¯»å– (å•æ¬¡) | 80ms | 5ms | 0.5ms | **160x** |
| æ‰¹é‡å†™å…¥ (100) | N/A | 150ms | 120ms | - |
| æ‰¹é‡è¯»å– (100) | 8s | 400ms | 50ms | **160x** |
| å¹¶å‘è¯»å– (10 çº¿ç¨‹) | 800ms | 50ms | 10ms | **80x** |

### 11.2 åŸºå‡†æµ‹è¯•ä»£ç 

```python
# benchmarks/bench_cache.py
import time
from cc_statusline.core.cache import Cache, CacheDuration

def benchmark_write(cache, iterations=1000):
    """å†™å…¥åŸºå‡†æµ‹è¯•"""
    start = time.time()
    for i in range(iterations):
        cache.set(f"key{i}", f"value{i}")
    duration = time.time() - start
    print(f"Write {iterations} entries: {duration:.3f}s "
          f"({iterations/duration:.0f} ops/s)")

def benchmark_read(cache, iterations=1000):
    """è¯»å–åŸºå‡†æµ‹è¯•"""
    # é¢„å…ˆå†™å…¥
    for i in range(iterations):
        cache.set(f"key{i}", f"value{i}")

    start = time.time()
    for i in range(iterations):
        cache.get(f"key{i}")
    duration = time.time() - start
    print(f"Read {iterations} entries: {duration:.3f}s "
          f"({iterations/duration:.0f} ops/s)")

if __name__ == "__main__":
    cache = Cache(default_ttl=CacheDuration.MEDIUM)
    benchmark_write(cache)
    benchmark_read(cache)
```

---

## åäºŒã€æ•…éšœæ’æŸ¥

### 12.1 å¸¸è§é—®é¢˜

#### é—®é¢˜ 1: ç¼“å­˜æœªç”Ÿæ•ˆ

**ç—‡çŠ¶**: æ¯æ¬¡éƒ½æ‰§è¡Œæ…¢é€Ÿæ“ä½œï¼Œç¼“å­˜ä¸èµ·ä½œç”¨

**åŸå› **:
- TTL è®¾ç½®ä¸º 0 æˆ–è¿‡çŸ­
- ç¼“å­˜é”®ç”Ÿæˆä¸ä¸€è‡´
- ç¼“å­˜æ–‡ä»¶è¢«æ„å¤–åˆ é™¤

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥ç¼“å­˜é…ç½®
print(f"Default TTL: {cache.default_ttl}")
print(f"Cache dir: {cache.cache_dir}")

# æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
import os
print(f"Cache files: {len(os.listdir(cache.cache_dir))}")

# æ£€æŸ¥é”®ç”Ÿæˆ
key = "test_key"
cache_file = cache._get_cache_file(key)
print(f"Cache file for '{key}': {cache_file}")
```

#### é—®é¢˜ 2: é”è¶…æ—¶

**ç—‡çŠ¶**: é¢‘ç¹å‡ºç°é”è·å–å¤±è´¥

**åŸå› **:
- å¹¶å‘å†™å…¥è¿‡å¤š
- æ­»é”æœªæ¸…ç†
- ç£ç›˜ I/O æ…¢

**è§£å†³æ–¹æ¡ˆ**:
```python
# å¢åŠ é‡è¯•æ¬¡æ•°
cache = Cache(max_retries=20)

# æ¸…ç†æ­»é”
cache.locker.cleanup_stale_locks()

# å¯ç”¨å†…å­˜ç¼“å­˜å‡å°‘æ–‡ä»¶é”ç«äº‰
cache = Cache(enable_memory_cache=True)
```

#### é—®é¢˜ 3: ç¼“å­˜æ–‡ä»¶æŸå

**ç—‡çŠ¶**: pickle.UnpicklingError

**åŸå› **:
- å†™å…¥è¿‡ç¨‹ä¸­è¢«ä¸­æ–­
- ç£ç›˜ç©ºé—´ä¸è¶³
- ç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ¸…ç†æŸåçš„ç¼“å­˜
cache.cleanup_expired()

# æˆ–å®Œå…¨æ¸…ç©º
cache.clear()
```

---

## åä¸‰ã€ç»“è®º

### 13.1 å®æ–½æ¸…å•

- [x] æ ¸å¿ƒç¼“å­˜ç±»å®ç°
- [x] è·¨å¹³å°æ–‡ä»¶é”
- [x] éš”ç¦»ç­–ç•¥
- [x] å†…å­˜ç¼“å­˜å±‚
- [x] æ‰¹é‡æ“ä½œ
- [x] ç»Ÿè®¡åŠŸèƒ½
- [ ] å¼‚æ­¥å†™å…¥ä¼˜åŒ–
- [ ] æ­»é”è‡ªåŠ¨æ¸…ç†
- [ ] ç›‘æ§å’Œå‘Šè­¦

### 13.2 ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³æ‰§è¡Œ**:
   - å°†æ ¸å¿ƒä»£ç é›†æˆåˆ°é¡¹ç›®
   - è¿è¡Œå•å…ƒæµ‹è¯•
   - éªŒè¯åŸºæœ¬åŠŸèƒ½

2. **çŸ­æœŸä¼˜åŒ–** (1å‘¨å†…):
   - æ·»åŠ å†…å­˜ç¼“å­˜å±‚
   - å®ç°å¼‚æ­¥å†™å…¥
   - æ€§èƒ½åŸºå‡†æµ‹è¯•

3. **é•¿æœŸæ”¹è¿›** (1ä¸ªæœˆ):
   - æ­»é”è‡ªåŠ¨æ¸…ç†
   - ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§
   - å®¹é‡ç®¡ç†

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ
**ä»£ç å¯ç”¨æ€§**: âœ… ç”Ÿäº§å°±ç»ª
**æ€§èƒ½ç›®æ ‡**: ğŸ¯ çƒ­å¯åŠ¨ < 10ms
