{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb729b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial import cKDTree\n",
    "from matplotlib.path import Path as MplPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6901f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =========================================================\n",
    "# 路径（按你给的）\n",
    "# =========================================================\n",
    "BASE_DIR = r\"Y:\\long\\publication_datasets\\liver\\output-XETG00082_C105\"\n",
    "\n",
    "CLUSTERS_CSV = r\"Y:\\long\\publication_datasets\\liver\\output-XETG00082_C105\\analysis\\clustering\\gene_expression_graphclust\\clusters.csv\"\n",
    "CELLS_PARQUET = r\"Y:\\long\\publication_datasets\\liver\\output-XETG00082_C105\\cells.parquet\"\n",
    "TISSUE_BOUNDARY_CSV = r\"Y:\\long\\publication_datasets\\liver\\output-XETG00082_C105\\tissue_boundary.csv\"\n",
    "\n",
    "OUT_SUBDIR = \"pattern1_isoline0p5_from_graphclust\"\n",
    "\n",
    "# =========================================================\n",
    "# 你的 pattern1 clusters\n",
    "# =========================================================\n",
    "PATTERN1 = [10, 23, 19, 27, 14, 20, 25, 26]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 参数（先用默认，必要时再调）\n",
    "# =========================================================\n",
    "grid_n = 1200\n",
    "knn_k = 30\n",
    "smooth_sigma = 5\n",
    "\n",
    "margin_um = 50.0\n",
    "max_dist_threshold = 200\n",
    "\n",
    "bg_d_min = 20\n",
    "bg_d_max = 250\n",
    "bg_max_points = 60000\n",
    "random_state = 0\n",
    "\n",
    "min_cells_inside = 10  # 防止碎片 contour\n",
    "\n",
    "# synthetic bg：建议开\n",
    "USE_SYN_BG = True\n",
    "BBOX_EXPAND_UM = 100.0\n",
    "SYN_BG_DENSITY = 0.01\n",
    "SYN_BG_MIN = 20000\n",
    "SYN_BG_MAX = 120000\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# utils\n",
    "# =========================================================\n",
    "def make_mesh_from_xy(xy, grid_n=800, pad=0.02, margin_um=50.0):\n",
    "    xy = np.asarray(xy, float)\n",
    "    xmin, ymin = xy.min(axis=0)\n",
    "    xmax, ymax = xy.max(axis=0)\n",
    "    dx, dy = xmax - xmin, ymax - ymin\n",
    "\n",
    "    xmin -= dx * pad; xmax += dx * pad\n",
    "    ymin -= dy * pad; ymax += dy * pad\n",
    "\n",
    "    xmin -= margin_um; xmax += margin_um\n",
    "    ymin -= margin_um; ymax += margin_um\n",
    "\n",
    "    xs = np.linspace(xmin, xmax, grid_n)\n",
    "    ys = np.linspace(ymin, ymax, grid_n)\n",
    "    xx, yy = np.meshgrid(xs, ys)\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    return xx, yy, grid\n",
    "\n",
    "def tissue_mask_from_xy(all_xy, xx, yy, max_dist_threshold=200):\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    tree = cKDTree(np.asarray(all_xy, float))\n",
    "    dist, _ = tree.query(grid, k=1)\n",
    "    return (dist.reshape(xx.shape) <= max_dist_threshold)\n",
    "\n",
    "def extract_contour_paths(xx, yy, z2d, level=0.5):\n",
    "    fig, ax = plt.subplots()\n",
    "    cs = ax.contour(xx, yy, z2d, levels=[level])\n",
    "    plt.close(fig)\n",
    "\n",
    "    verts_list = []\n",
    "    if hasattr(cs, \"allsegs\") and cs.allsegs and len(cs.allsegs) > 0:\n",
    "        for seg in cs.allsegs[0]:\n",
    "            v = np.asarray(seg)\n",
    "            if v.ndim == 2 and v.shape[0] >= 10 and v.shape[1] == 2:\n",
    "                verts_list.append(v)\n",
    "        return verts_list\n",
    "\n",
    "    if hasattr(cs, \"collections\") and cs.collections:\n",
    "        for p in cs.collections[0].get_paths():\n",
    "            v = p.vertices\n",
    "            if len(v) >= 10:\n",
    "                verts_list.append(v)\n",
    "        return verts_list\n",
    "\n",
    "    return []\n",
    "\n",
    "def filter_loops_by_cell_count(verts_list, cells_xy, min_cells_inside=1):\n",
    "    kept = []\n",
    "    for v in verts_list:\n",
    "        path = MplPath(v)\n",
    "        if int(path.contains_points(cells_xy).sum()) >= min_cells_inside:\n",
    "            kept.append(v)\n",
    "    return kept\n",
    "\n",
    "def load_tissue_boundary_csv(boundary_csv):\n",
    "    df = pd.read_csv(boundary_csv)\n",
    "    if {\"x\", \"y\"}.issubset(df.columns):\n",
    "        return df[[\"x\", \"y\"]].to_numpy(float)\n",
    "    if {\"X\", \"Y\"}.issubset(df.columns):\n",
    "        return df[[\"X\", \"Y\"]].to_numpy(float)\n",
    "    raise ValueError(f\"tissue_boundary.csv 必须包含 x,y 或 X,Y 列，当前列={list(df.columns)}\")\n",
    "\n",
    "def generate_synthetic_bg_in_bbox(boundary_xy, expand_um=100.0, density=0.01,\n",
    "                                  min_n=20000, max_n=120000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    xmin, ymin = boundary_xy.min(axis=0)\n",
    "    xmax, ymax = boundary_xy.max(axis=0)\n",
    "    xmin -= expand_um; xmax += expand_um\n",
    "    ymin -= expand_um; ymax += expand_um\n",
    "\n",
    "    area = (xmax - xmin) * (ymax - ymin)\n",
    "    n = int(area * density)\n",
    "    n = max(min_n, min(max_n, n))\n",
    "\n",
    "    xs = rng.uniform(xmin, xmax, size=n)\n",
    "    ys = rng.uniform(ymin, ymax, size=n)\n",
    "    return np.c_[xs, ys].astype(float)\n",
    "\n",
    "def sample_background_from_other_cells_plus_synth(\n",
    "    cells_df,\n",
    "    synthetic_bg_xy,\n",
    "    target_ids,\n",
    "    target_xy,\n",
    "    cell_id_col,\n",
    "    x_col, y_col,\n",
    "    d_min=20, d_max=250,\n",
    "    max_points=60000, seed=0,\n",
    "    margin_um=50.0\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    cid_all = cells_df[cell_id_col].astype(str).to_numpy()\n",
    "    target_ids_arr = np.array(list(target_ids), dtype=str)\n",
    "    is_bg = ~np.isin(cid_all, target_ids_arr)\n",
    "\n",
    "    bg_real_df = cells_df.loc[is_bg, [x_col, y_col]].copy()\n",
    "    bg_real = bg_real_df[[x_col, y_col]].to_numpy(float) if len(bg_real_df) > 0 else np.empty((0, 2), float)\n",
    "\n",
    "    bg_syn = np.asarray(synthetic_bg_xy, float) if synthetic_bg_xy is not None else np.empty((0, 2), float)\n",
    "\n",
    "    bg_xy = bg_real\n",
    "    if len(bg_syn) > 0:\n",
    "        bg_xy = bg_syn if len(bg_xy) == 0 else np.vstack([bg_xy, bg_syn])\n",
    "    if len(bg_xy) == 0:\n",
    "        return np.empty((0, 2), float)\n",
    "\n",
    "    xmin, ymin = target_xy.min(axis=0)\n",
    "    xmax, ymax = target_xy.max(axis=0)\n",
    "    pad = d_max + margin_um\n",
    "    in_box = (\n",
    "        (bg_xy[:, 0] >= xmin - pad) & (bg_xy[:, 0] <= xmax + pad) &\n",
    "        (bg_xy[:, 1] >= ymin - pad) & (bg_xy[:, 1] <= ymax + pad)\n",
    "    )\n",
    "    bg_xy = bg_xy[in_box]\n",
    "    if len(bg_xy) == 0:\n",
    "        return np.empty((0, 2), float)\n",
    "\n",
    "    tree = cKDTree(np.asarray(target_xy, float))\n",
    "    dist, _ = tree.query(bg_xy, k=1)\n",
    "    keep = (dist >= d_min) & (dist <= d_max)\n",
    "    bg_xy = bg_xy[keep]\n",
    "    if len(bg_xy) == 0:\n",
    "        return np.empty((0, 2), float)\n",
    "\n",
    "    if len(bg_xy) > max_points:\n",
    "        idx = rng.choice(len(bg_xy), size=max_points, replace=False)\n",
    "        bg_xy = bg_xy[idx]\n",
    "\n",
    "    return bg_xy\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 关键：对齐 clusters.csv 的 Barcode 和 cells.parquet 的 id\n",
    "# =========================================================\n",
    "def align_clusters_with_cells(clusters_csv, cells_parquet):\n",
    "    cl = pd.read_csv(clusters_csv)\n",
    "    # 兼容列名\n",
    "    if \"Barcode\" not in cl.columns or \"Cluster\" not in cl.columns:\n",
    "        raise ValueError(f\"clusters.csv 需要包含 Barcode/Cluster 列，当前列={list(cl.columns)}\")\n",
    "\n",
    "    cl[\"Barcode\"] = cl[\"Barcode\"].astype(str)\n",
    "    cl[\"Cluster\"] = pd.to_numeric(cl[\"Cluster\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    cells = pd.read_parquet(cells_parquet)\n",
    "\n",
    "    # 找坐标列（尽量自动识别）\n",
    "    cand_x = [c for c in cells.columns if c.lower() in [\"x\", \"x_centroid\", \"x_center\", \"xcoord\", \"x_coord\"]]\n",
    "    cand_y = [c for c in cells.columns if c.lower() in [\"y\", \"y_centroid\", \"y_center\", \"ycoord\", \"y_coord\"]]\n",
    "    if not cand_x or not cand_y:\n",
    "        # Xenium/其他可能是 x_centroid/y_centroid\n",
    "        # 如果你这里失败，把 cells.columns 打印出来即可\n",
    "        raise ValueError(f\"cells.parquet 找不到 x/y 列。列名示例：{list(cells.columns)[:60]}\")\n",
    "\n",
    "    x_col = cand_x[0]\n",
    "    y_col = cand_y[0]\n",
    "\n",
    "    # 找可能的 barcode/id 列\n",
    "    id_candidates = []\n",
    "    for c in cells.columns:\n",
    "        lc = c.lower()\n",
    "        if lc in [\"barcode\", \"barcodes\", \"cell_barcode\", \"cellbarcode\", \"spot_barcode\", \"spot_id\",\n",
    "                  \"cell_id\", \"cellid\", \"id\"]:\n",
    "            id_candidates.append(c)\n",
    "\n",
    "    # 如果没找到典型列名，就退而求其次：所有 object/string 列都试\n",
    "    if not id_candidates:\n",
    "        id_candidates = [c for c in cells.columns if cells[c].dtype == object][:10]\n",
    "\n",
    "    # 逐列尝试 merge（优先原样匹配，再尝试去掉 -1 匹配）\n",
    "    def try_merge(cells_id_col, strip_suffix=False):\n",
    "        tmp = cells.copy()\n",
    "        tmp[\"_join_id\"] = tmp[cells_id_col].astype(str)\n",
    "        cl2 = cl.copy()\n",
    "        cl2[\"_join_id\"] = cl2[\"Barcode\"].astype(str)\n",
    "\n",
    "        if strip_suffix:\n",
    "            tmp[\"_join_id\"] = tmp[\"_join_id\"].str.replace(r\"-1$\", \"\", regex=True)\n",
    "            cl2[\"_join_id\"] = cl2[\"_join_id\"].str.replace(r\"-1$\", \"\", regex=True)\n",
    "\n",
    "        m = tmp.merge(cl2[[\"_join_id\", \"Cluster\"]], on=\"_join_id\", how=\"inner\")\n",
    "        return m\n",
    "\n",
    "    best = None\n",
    "    best_info = None\n",
    "    for c in id_candidates:\n",
    "        m1 = try_merge(c, strip_suffix=False)\n",
    "        if best is None or len(m1) > len(best):\n",
    "            best, best_info = m1, (c, False)\n",
    "        m2 = try_merge(c, strip_suffix=True)\n",
    "        if best is None or len(m2) > len(best):\n",
    "            best, best_info = m2, (c, True)\n",
    "\n",
    "    if best is None or len(best) == 0:\n",
    "        # 打印帮助信息\n",
    "        print(\"[FAIL] 无法将 clusters.csv 的 Barcode 对齐到 cells.parquet\")\n",
    "        print(\"clusters.csv Barcode 示例:\", cl[\"Barcode\"].head().tolist())\n",
    "        print(\"cells.parquet 列名:\", list(cells.columns)[:80])\n",
    "        for c in id_candidates[:6]:\n",
    "            print(f\"cells[{c}] 示例:\", cells[c].astype(str).head().tolist())\n",
    "        raise RuntimeError(\"ID 对齐失败：cells.parquet 里可能没有 barcode，需要一个 barcode↔cell_id 映射文件。\")\n",
    "\n",
    "    id_col_used, stripped = best_info\n",
    "    print(f\"[OK] merge success. cells id col='{id_col_used}', strip_suffix(-1)={stripped}, matched={len(best)}\")\n",
    "\n",
    "    # 返回：带坐标 + cluster 的表\n",
    "    out = best.rename(columns={\"Cluster\": \"cluster\"})\n",
    "    return out, id_col_used, x_col, y_col\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# main：pattern1=1 others=0，取 0.5 isoline\n",
    "# =========================================================\n",
    "def run_pattern1_isoline():\n",
    "    os.makedirs(os.path.join(BASE_DIR, OUT_SUBDIR), exist_ok=True)\n",
    "    out_dir = os.path.join(BASE_DIR, OUT_SUBDIR)\n",
    "\n",
    "    merged, id_col_used, x_col, y_col = align_clusters_with_cells(CLUSTERS_CSV, CELLS_PARQUET)\n",
    "\n",
    "    merged[\"cluster\"] = pd.to_numeric(merged[\"cluster\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    merged = merged.dropna(subset=[\"cluster\"]).copy()\n",
    "    merged[\"cluster\"] = merged[\"cluster\"].astype(int)\n",
    "\n",
    "    p1 = set(int(x) for x in PATTERN1)\n",
    "    merged[\"_is_p1\"] = merged[\"cluster\"].isin(p1)\n",
    "\n",
    "    # 目标细胞（pattern1）\n",
    "    p1_df = merged.loc[merged[\"_is_p1\"], [id_col_used, x_col, y_col]].copy()\n",
    "    if len(p1_df) < 10:\n",
    "        raise RuntimeError(f\"pattern1 cells too few after merge: {len(p1_df)}\")\n",
    "\n",
    "    target_ids = set(p1_df[id_col_used].astype(str))\n",
    "    target_xy = p1_df[[x_col, y_col]].to_numpy(float)\n",
    "\n",
    "    # 组织边界 + synthetic bg\n",
    "    syn_bg_xy = None\n",
    "    if USE_SYN_BG:\n",
    "        boundary_xy = load_tissue_boundary_csv(TISSUE_BOUNDARY_CSV)\n",
    "        syn_bg_xy = generate_synthetic_bg_in_bbox(\n",
    "            boundary_xy,\n",
    "            expand_um=BBOX_EXPAND_UM,\n",
    "            density=SYN_BG_DENSITY,\n",
    "            min_n=SYN_BG_MIN,\n",
    "            max_n=SYN_BG_MAX,\n",
    "            seed=random_state\n",
    "        )\n",
    "        print(f\"[INFO] synthetic bg points: {len(syn_bg_xy)}\")\n",
    "\n",
    "    # 背景点：用 merged 里“非 pattern1 的细胞”作为真实背景来源\n",
    "    # 注意：这里用 merged 作为 cells_df（因为它一定有 id_col_used 和 x/y）\n",
    "    bg0_xy = sample_background_from_other_cells_plus_synth(\n",
    "        cells_df=merged.rename(columns={id_col_used: \"tmp_id\"}),\n",
    "        synthetic_bg_xy=syn_bg_xy,\n",
    "        target_ids=set([str(x) for x in target_ids]),\n",
    "        target_xy=target_xy,\n",
    "        cell_id_col=\"tmp_id\",\n",
    "        x_col=x_col, y_col=y_col,\n",
    "        d_min=bg_d_min, d_max=bg_d_max,\n",
    "        max_points=bg_max_points,\n",
    "        seed=random_state,\n",
    "        margin_um=margin_um\n",
    "    )\n",
    "    if len(bg0_xy) == 0:\n",
    "        raise RuntimeError(\"No bg0 points sampled. Try relaxing bg_d_min/bg_d_max.\")\n",
    "\n",
    "    # 训练：pattern1=1，bg0=0\n",
    "    X_train = np.vstack([bg0_xy, target_xy])\n",
    "    y_train = np.hstack([np.zeros(len(bg0_xy)), np.ones(len(target_xy))])\n",
    "\n",
    "    reg = KNeighborsRegressor(n_neighbors=knn_k, weights=\"distance\")\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    # grid + predict + smooth\n",
    "    xx, yy, grid = make_mesh_from_xy(target_xy, grid_n=grid_n, margin_um=margin_um)\n",
    "    prob = reg.predict(grid).reshape(xx.shape)\n",
    "    prob_smooth = gaussian_filter(prob, sigma=smooth_sigma)\n",
    "\n",
    "    # tissue mask：用 merged 的所有真实细胞坐标（不含虚拟点）\n",
    "    all_xy = merged[[x_col, y_col]].to_numpy(float)\n",
    "    tissue_mask = tissue_mask_from_xy(all_xy, xx, yy, max_dist_threshold=max_dist_threshold)\n",
    "\n",
    "    prob_smooth_masked = prob_smooth.copy()\n",
    "    prob_smooth_masked[~tissue_mask] = np.nan\n",
    "\n",
    "    # ✅ 0.5 isoline\n",
    "    verts_list = extract_contour_paths(xx, yy, prob_smooth_masked, level=0.5)\n",
    "    verts_list = filter_loops_by_cell_count(verts_list, target_xy, min_cells_inside=min_cells_inside)\n",
    "\n",
    "    if len(verts_list) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No 0.5 isoline found.\\n\"\n",
    "            \"建议：min_cells_inside 降低（50->10），smooth_sigma 增大（5->8），knn_k 增大（30->50）。\"\n",
    "        )\n",
    "\n",
    "    # 保存参数\n",
    "    params = dict(\n",
    "        clusters_csv=CLUSTERS_CSV,\n",
    "        cells_parquet=CELLS_PARQUET,\n",
    "        tissue_boundary_csv=TISSUE_BOUNDARY_CSV,\n",
    "        id_col_used=id_col_used,\n",
    "        x_col=x_col, y_col=y_col,\n",
    "        pattern1_clusters=sorted(list(p1)),\n",
    "        grid_n=grid_n, knn_k=knn_k, smooth_sigma=smooth_sigma,\n",
    "        bg_d_min=bg_d_min, bg_d_max=bg_d_max, bg_max_points=bg_max_points,\n",
    "        max_dist_threshold=max_dist_threshold,\n",
    "        isoline_level=0.5,\n",
    "        min_cells_inside=min_cells_inside,\n",
    "        use_synth_bg=USE_SYN_BG,\n",
    "        n_target_cells=int(len(target_xy)),\n",
    "        n_bg0=int(len(bg0_xy)),\n",
    "        n_contours=int(len(verts_list)),\n",
    "    )\n",
    "    with open(os.path.join(out_dir, \"params.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(params, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # 保存 contour\n",
    "    for i, v in enumerate(verts_list):\n",
    "        np.save(os.path.join(out_dir, f\"pattern1_isoline0p5_{i}.npy\"), v)\n",
    "\n",
    "    # 画图检查\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(bg0_xy[:, 0], bg0_xy[:, 1], s=1, alpha=0.05, label=\"bg0 (other cells + synth)\")\n",
    "    plt.scatter(target_xy[:, 0], target_xy[:, 1], s=3, alpha=0.85, label=\"pattern1 cells\")\n",
    "    for v in verts_list:\n",
    "        plt.plot(v[:, 0], v[:, 1], linewidth=2)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.title(f\"Pattern1 segmentation | isoline=0.5 | contours={len(verts_list)}\")\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig_path = os.path.join(out_dir, \"pattern1_isoline0p5.png\")\n",
    "    plt.savefig(fig_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"[OK] saved:\", out_dir)\n",
    "    print(\" -\", fig_path)\n",
    "    print(\" - contours npy:\", len(verts_list))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pattern1_isoline()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
