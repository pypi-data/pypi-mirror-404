# Task 2: Validate Commands

**Phase**: 5 - Testing & Delivery  
**Purpose**: Confirm command language consistent and effective  
**Depends On**: Task 1 (dry run passing)  
**Feeds Into**: Task 3 (Validate Gates Parseable)

---

## Objective

Verify that command symbols are used consistently throughout the workflow and that command language patterns are clear and unambiguous.

---

## Context

ğŸ“Š **CONTEXT**: The command language is the binding contract between workflow author and AI executor. Consistent, proper usage is critical for reliable execution.

âš ï¸ **MUST-READ**: [../../core/command-language-glossary.md](../../core/command-language-glossary.md) for complete command reference, usage patterns, and anti-patterns

ğŸ” **MUST-SEARCH**: "command language symbols binding contract"

---

## Instructions

### Step 1: Review Command Language Reference

From core/command-language-glossary.md, understand all command types:
- Discovery (ğŸ“– DISCOVER-TOOL)
- Navigation (ğŸ¯ NEXT-MANDATORY, â†©ï¸ RETURN-TO)
- Constraints (âš ï¸ CONSTRAINT, ğŸš¨ CRITICAL)
- Knowledge (ğŸ” MUST-SEARCH)
- Context (ğŸ“Š CONTEXT)

### Step 2: Audit Command Usage Across Workflow

For each task file:
- Count command instances by type
- Calculate command presence
- Identify inconsistent usage
- Find missing commands

ğŸ“– **DISCOVER-TOOL**: Search for command symbols in all task files

Generate usage report with:
- Total commands, breakdown by type
- Files with no/low command usage
- Inconsistencies found

### Step 3: Verify Navigation Commands

Check all navigation:
- **ğŸ¯ NEXT-MANDATORY**: Every task except last in phase, correct target, consistent format
- **â†©ï¸ RETURN-TO**: Every task at end, points to phase.md

ğŸ“– **DISCOVER-TOOL**: Search and verify navigation commands

Document missing or broken navigation.

### Step 4: Verify Discovery Commands

Check all ğŸ“– **DISCOVER-TOOL** usage:
- Used instead of hardcoded tool names
- Proper format and clarity
- Appropriate use cases

Common errors:
- Direct tool names ("use grep")
- Hardcoded tools ("run read_file")

### Step 5: Verify Constraints and Critical Markers

Check âš ï¸ **CONSTRAINT** and ğŸš¨ **CRITICAL** usage:
- Appropriate severity
- Clear and actionable
- No overuse or underuse

### Step 6: Verify Knowledge Retrieval Commands

Check ğŸ” **MUST-SEARCH** usage:
- Queries are specific and discoverable
- Used for complex methodology
- Used instead of inline duplication

### Step 7: Check for Anti-Patterns

Identify issues from core/command-language-glossary.md:
- Mixed usage (inconsistent)
- Command redundancy
- Incorrect command selection
- Missing commands where needed

### Step 8: Generate Command Validation Report

Use report format:

```markdown
# Command Language Validation Report

**Total Tasks**: {count}
**Command Usage**: {total_commands} instances

## Usage Breakdown
- ğŸ“– DISCOVER-TOOL: {count}
- ğŸ¯ NEXT-MANDATORY: {count}
- â†©ï¸ RETURN-TO: {count}
- âš ï¸ CONSTRAINT: {count}
- ğŸš¨ CRITICAL: {count}
- ğŸ” MUST-SEARCH: {count}
- ğŸ“Š CONTEXT: {count}

## Issues Found
[List inconsistencies, missing commands, anti-patterns]

## Navigation Integrity: {âœ…/âŒ}
## Command Consistency: {âœ…/âŒ}

## Overall Status: {PASS/FAIL}
```

---

## Expected Output

**Metrics**:
- `total_commands`: Integer
- `command_breakdown`: Object with counts by type
- `tasks_with_low_commands`: Array
- `navigation_issues`: Array

**Report**:
- `command_validation_report`: String

**Evidence**:
- `navigation_intact`: Boolean (true if all navigation works)
- `command_usage_consistent`: Boolean (true if no major issues)

---

## Quality Checks

âœ… Command reference reviewed  
âœ… All tasks audited  
âœ… Navigation verified  
âœ… Discovery commands checked  
âœ… Constraints/Critical validated  
âœ… Knowledge retrieval verified  
âœ… Anti-patterns identified  
âœ… Report generated

---

## Navigation

ğŸ¯ **NEXT-MANDATORY**: task-3-validate-gates-parseable.md

â†©ï¸ **RETURN-TO**: phase.md

