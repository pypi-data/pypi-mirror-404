{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Sentinel Framework","text":"<p>Sentinel is an async-first Python framework for building production-ready AI Agents. It provides the scaffolding, memory, and tooling needed to take an LLM script and turn it into a scalable web application.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-installation","title":"1. Installation","text":"<pre><code>pip install anti-sentinel\n</code></pre>"},{"location":"#2-create-a-project","title":"2. Create a Project","text":"<pre><code>sentinel new my_ai_app\ncd my_ai_app\n</code></pre>"},{"location":"#3-set-api-keys","title":"3. Set API Keys","text":"<p>Open <code>.env</code> and add your keys:</p> <pre><code>GEMINI_API_KEY=AIza...\nOPENAI_API_KEY=sk-...\nMEM0_API_KEY=m0-...\n</code></pre>"},{"location":"#4-run-it","title":"4. Run It","text":"<pre><code>python main.py\n</code></pre> <p>Visit <code>http://127.0.0.1:8000/dashboard</code> to verify it's running.</p>"},{"location":"#setup-configuration","title":"Setup &amp; Configuration","text":""},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>Redis (optional, for async queues)</li> <li>API key for at least one LLM provider</li> </ul>"},{"location":"#configuration-file-sentinelyaml","title":"Configuration File (<code>sentinel.yaml</code>)","text":"<pre><code>app_name: \"My Financial Agent\"\ndebug: true\n\nllm:\n  provider: \"gemini\" # or \"openai\"\n  model: \"gemini-1.5-flash\"\n  temperature: 0.7\n\nmemory:\n  provider: \"mem0\"\n  user_id: \"default_user\"\n</code></pre>"},{"location":"#environment-variables","title":"Environment Variables","text":"<pre><code>OPENAI_API_KEY=sk-...\nGEMINI_API_KEY=AIza...\nMEM0_API_KEY=m0-xxx\n</code></pre>"},{"location":"#agents","title":"Agents","text":"<p>Agents combine an LLM brain with instructions and tools.</p> <pre><code>from anti_sentinel.agents.base import BaseAgent\n\nclass SupportAgent(BaseAgent):\n    def _set_system_prompt(self, context_notes=None):\n        self.system_prompt = (\n            \"You are a helpful customer support assistant. \"\n            \"Be polite and concise.\"\n        )\n\n        if context_notes:\n            self.system_prompt += f\"\\nUser History: {context_notes}\"\n\n        self.history = [{\"role\": \"system\", \"content\": self.system_prompt}]\n</code></pre>"},{"location":"#tools","title":"Tools","text":"<pre><code>def check_order_status(order_id: str):\n    return f\"Order {order_id} is SHIPPED.\"\n\nagent = SupportAgent(name=\"SupportBot\")\nagent.register_tool(check_order_status)\n\nresponse = await agent.think(\"Where is my order #123?\")\n</code></pre>"},{"location":"#memory","title":"Memory","text":"<p>Sentinel integrates with Mem0 for long-term memory.</p> <pre><code>from anti_sentinel.container import ServiceContainer\n\ncontainer = ServiceContainer.get_instance()\nmemory = container.get_memory()\n\nawait memory.save(\"User prefers dark mode\", user_id=\"user_123\")\nfacts = await memory.retrieve(\"What does the user like?\", user_id=\"user_123\")\n</code></pre>"},{"location":"#async-jobs","title":"Async Jobs","text":"<p>For long-running tasks, use the job queue.</p> <pre><code>from fastapi import APIRouter\nfrom anti_sentinel.services.queue import QueueService\n\nrouter = APIRouter()\nqueue = QueueService.get_instance()\n\n@router.post(\"/generate-book\")\nasync def generate_book(topic: str):\n    job_id = await queue.push({\n        \"task_type\": \"write_book\",\n        \"topic\": topic\n    })\n    return {\"status\": \"queued\", \"job_id\": job_id}\n</code></pre> <pre><code>job = await queue.get_status(job_id)\nif job[\"status\"] == \"COMPLETED\":\n    print(job[\"result\"])\n</code></pre>"},{"location":"reference/agents/","title":"Base Agent","text":"<p>The <code>BaseAgent</code> is the brain of your application. All your custom agents (e.g., <code>WriterAgent</code>) should inherit from this.</p>"},{"location":"reference/agents/#anti_sentinel.agents.base.BaseAgent","title":"<code>anti_sentinel.agents.base.BaseAgent</code>","text":"Source code in <code>anti_sentinel\\agents\\base.py</code> <pre><code>class BaseAgent:\n    def __init__(self, name: str = \"Agent\", model: Optional[str] = None, user_id: str = \"default\"):\n        self.name = name\n        self.user_id = user_id\n        self.model = model \n\n        container = ServiceContainer.get_instance()\n        self.llm = container.get_llm()\n        self.memory = container.get_memory()\n\n        self.history: List[Dict[str, Any]] = []\n        self.tools: Dict[str, Tool] = {}  # Registry of available tools\n        self._set_system_prompt()\n\n    def register_tool(self, func: Callable):\n        \"\"\"\n        Give this agent a new ability.\n        \"\"\"\n        tool = Tool(func)\n        self.tools[tool.name] = tool\n        print(f\"\ud83d\udee0\ufe0f Agent '{self.name}' equipped with tool: {tool.name}\")\n\n    def _set_system_prompt(self, context_notes: List[str] = None):\n        base_prompt = f\"You are {self.name}. Use your tools when needed.\"\n        if context_notes:\n            memory_block = \"\\n\".join([f\"- {note}\" for note in context_notes])\n            base_prompt += f\"\\n\\nContext from Memory:\\n{memory_block}\"\n        self.history = [{\"role\": \"system\", \"content\": base_prompt}]\n\n    async def think(self, user_input: str) -&gt; str:\n        # 1. Recall &amp; Setup\n        if self.memory:\n            mems = await self.memory.retrieve(user_input, user_id=self.user_id)\n            if mems: self._set_system_prompt(context_notes=mems)\n\n        self.history.append({\"role\": \"user\", \"content\": user_input})\n\n        # 2. Get Tools List for the LLM\n        tool_schemas = [t.schema for t in self.tools.values()]\n\n        # 3. LLM Interaction Loop\n        response = await self.llm.generate(\n            self.history, \n            model=self.model,\n            tools=tool_schemas\n        )\n\n        # 4. Handle Tool Calls\n        # If response is NOT a string, it means it's a list of tool requests\n        if not isinstance(response, str):\n            tool_calls = response\n\n            # Append the LLM's \"Thought\" (Request to call tool) to history\n            self.history.append({\n                \"role\": \"assistant\",\n                \"content\": None,\n                \"tool_calls\": tool_calls\n            })\n\n            # Execute each requested tool\n            for tool_call in tool_calls:\n                function_name = tool_call.function.name\n                arguments = json.loads(tool_call.function.arguments)\n\n                print(f\"\ud83e\udd16 Agent is using tool: {function_name}({arguments})\")\n\n                if function_name in self.tools:\n                    # Run the python code\n                    result = self.tools[function_name].execute(**arguments)\n\n                    # Feed result back to LLM\n                    self.history.append({\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.id,\n                        \"name\": function_name,\n                        \"content\": str(result)\n                    })\n                else:\n                    print(f\"\u274c Error: Tool {function_name} not found.\")\n\n            # 5. Final Answer (LLM sees tool results and answers user)\n            final_response = await self.llm.generate(self.history, model=self.model)\n            self.history.append({\"role\": \"assistant\", \"content\": final_response})\n            return final_response\n\n        # If no tool called, just return the text\n        self.history.append({\"role\": \"assistant\", \"content\": response})\n        return response\n</code></pre>"},{"location":"reference/agents/#anti_sentinel.agents.base.BaseAgent.register_tool","title":"<code>register_tool(func)</code>","text":"<p>Give this agent a new ability.</p> Source code in <code>anti_sentinel\\agents\\base.py</code> <pre><code>def register_tool(self, func: Callable):\n    \"\"\"\n    Give this agent a new ability.\n    \"\"\"\n    tool = Tool(func)\n    self.tools[tool.name] = tool\n    print(f\"\ud83d\udee0\ufe0f Agent '{self.name}' equipped with tool: {tool.name}\")\n</code></pre>"},{"location":"reference/memory/","title":"Memory System","text":"<p>Sentinel uses adapters to handle long-term memory.</p>"},{"location":"reference/memory/#anti_sentinel.interfaces.BaseMemoryStore","title":"<code>anti_sentinel.interfaces.BaseMemoryStore</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The blueprint for memory (Neo4j, Mem0, Postgres).</p> Source code in <code>anti_sentinel\\interfaces.py</code> <pre><code>class BaseMemoryStore(ABC):\n    \"\"\"\n    The blueprint for memory (Neo4j, Mem0, Postgres).\n    \"\"\"\n\n    @abstractmethod\n    async def save(self, key: str, value: Dict[str, Any]) -&gt; bool:\n        \"\"\"\n        Save data. 'Dict[str, Any]' means a dictionary where keys are strings\n        and values can be anything (text, numbers, lists).\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def retrieve(self, key: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"\n        Get data back. Returns a Dictionary or None if nothing is found.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/memory/#anti_sentinel.interfaces.BaseMemoryStore.retrieve","title":"<code>retrieve(key)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Get data back. Returns a Dictionary or None if nothing is found.</p> Source code in <code>anti_sentinel\\interfaces.py</code> <pre><code>@abstractmethod\nasync def retrieve(self, key: str) -&gt; Optional[Dict[str, Any]]:\n    \"\"\"\n    Get data back. Returns a Dictionary or None if nothing is found.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/memory/#anti_sentinel.interfaces.BaseMemoryStore.save","title":"<code>save(key, value)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Save data. 'Dict[str, Any]' means a dictionary where keys are strings and values can be anything (text, numbers, lists).</p> Source code in <code>anti_sentinel\\interfaces.py</code> <pre><code>@abstractmethod\nasync def save(self, key: str, value: Dict[str, Any]) -&gt; bool:\n    \"\"\"\n    Save data. 'Dict[str, Any]' means a dictionary where keys are strings\n    and values can be anything (text, numbers, lists).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/queues/","title":"Job Queue","text":"<p>The Queue Service handles background processing for long-running tasks.</p>"},{"location":"reference/queues/#anti_sentinel.services.queue.QueueService","title":"<code>anti_sentinel.services.queue.QueueService</code>","text":"Source code in <code>anti_sentinel\\services\\queue.py</code> <pre><code>class QueueService:\n    _instance = None\n    DB_NAME = \"sentinel_metrics.db\" # Reusing the same DB file\n\n    @classmethod\n    def get_instance(cls):\n        if cls._instance is None:\n            cls._instance = QueueService()\n        return cls._instance\n\n    async def init_db(self):\n        \"\"\"Creates the jobs table.\"\"\"\n        async with aiosqlite.connect(self.DB_NAME) as db:\n            await db.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS jobs (\n                    job_id TEXT PRIMARY KEY,\n                    status TEXT, -- PENDING, PROCESSING, COMPLETED, FAILED\n                    input_data TEXT,\n                    result TEXT,\n                    created_at REAL\n                )\n            \"\"\")\n            await db.commit()\n\n    async def push(self, data: Dict[str, Any]) -&gt; str:\n        \"\"\"Adds a job to the queue.\"\"\"\n        job_id = str(uuid.uuid4())\n        async with aiosqlite.connect(self.DB_NAME) as db:\n            await db.execute(\n                \"INSERT INTO jobs (job_id, status, input_data, created_at) VALUES (?, ?, ?, CURRENT_TIMESTAMP)\",\n                (job_id, \"PENDING\", json.dumps(data))\n            )\n            await db.commit()\n        return job_id\n\n    async def fetch_pending(self) -&gt; Optional[Dict]:\n        \"\"\"Gets the next job to process.\"\"\"\n        async with aiosqlite.connect(self.DB_NAME) as db:\n            db.row_factory = aiosqlite.Row\n            cursor = await db.execute(\"SELECT * FROM jobs WHERE status = 'PENDING' LIMIT 1\")\n            row = await cursor.fetchone()\n\n            if row:\n                # Mark as processing immediately so no other worker picks it up\n                await db.execute(\"UPDATE jobs SET status = 'PROCESSING' WHERE job_id = ?\", (row['job_id'],))\n                await db.commit()\n                return dict(row)\n        return None\n\n    async def complete(self, job_id: str, result: str):\n        async with aiosqlite.connect(self.DB_NAME) as db:\n            await db.execute(\"UPDATE jobs SET status = 'COMPLETED', result = ? WHERE job_id = ?\", (result, job_id))\n            await db.commit()\n\n    async def get_status(self, job_id: str):\n        async with aiosqlite.connect(self.DB_NAME) as db:\n            db.row_factory = aiosqlite.Row\n            cursor = await db.execute(\"SELECT * FROM jobs WHERE job_id = ?\", (job_id,))\n            row = await cursor.fetchone()\n            return dict(row) if row else None\n</code></pre>"},{"location":"reference/queues/#anti_sentinel.services.queue.QueueService.fetch_pending","title":"<code>fetch_pending()</code>  <code>async</code>","text":"<p>Gets the next job to process.</p> Source code in <code>anti_sentinel\\services\\queue.py</code> <pre><code>async def fetch_pending(self) -&gt; Optional[Dict]:\n    \"\"\"Gets the next job to process.\"\"\"\n    async with aiosqlite.connect(self.DB_NAME) as db:\n        db.row_factory = aiosqlite.Row\n        cursor = await db.execute(\"SELECT * FROM jobs WHERE status = 'PENDING' LIMIT 1\")\n        row = await cursor.fetchone()\n\n        if row:\n            # Mark as processing immediately so no other worker picks it up\n            await db.execute(\"UPDATE jobs SET status = 'PROCESSING' WHERE job_id = ?\", (row['job_id'],))\n            await db.commit()\n            return dict(row)\n    return None\n</code></pre>"},{"location":"reference/queues/#anti_sentinel.services.queue.QueueService.init_db","title":"<code>init_db()</code>  <code>async</code>","text":"<p>Creates the jobs table.</p> Source code in <code>anti_sentinel\\services\\queue.py</code> <pre><code>async def init_db(self):\n    \"\"\"Creates the jobs table.\"\"\"\n    async with aiosqlite.connect(self.DB_NAME) as db:\n        await db.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS jobs (\n                job_id TEXT PRIMARY KEY,\n                status TEXT, -- PENDING, PROCESSING, COMPLETED, FAILED\n                input_data TEXT,\n                result TEXT,\n                created_at REAL\n            )\n        \"\"\")\n        await db.commit()\n</code></pre>"},{"location":"reference/queues/#anti_sentinel.services.queue.QueueService.push","title":"<code>push(data)</code>  <code>async</code>","text":"<p>Adds a job to the queue.</p> Source code in <code>anti_sentinel\\services\\queue.py</code> <pre><code>async def push(self, data: Dict[str, Any]) -&gt; str:\n    \"\"\"Adds a job to the queue.\"\"\"\n    job_id = str(uuid.uuid4())\n    async with aiosqlite.connect(self.DB_NAME) as db:\n        await db.execute(\n            \"INSERT INTO jobs (job_id, status, input_data, created_at) VALUES (?, ?, ?, CURRENT_TIMESTAMP)\",\n            (job_id, \"PENDING\", json.dumps(data))\n        )\n        await db.commit()\n    return job_id\n</code></pre>"},{"location":"reference/workflows/","title":"Workflow Engine","text":"<p>Use Workflows to chain multiple agents together sequentially.</p>"},{"location":"reference/workflows/#anti_sentinel.workflows.engine.Workflow","title":"<code>anti_sentinel.workflows.engine.Workflow</code>","text":"<p>Chains multiple agents or functions together. Output of Step 1 -&gt; Input of Step 2.</p> Source code in <code>anti_sentinel\\workflows\\engine.py</code> <pre><code>class Workflow:\n    \"\"\"\n    Chains multiple agents or functions together.\n    Output of Step 1 -&gt; Input of Step 2.\n    \"\"\"\n    def __init__(self, name: str):\n        self.name = name\n        self.steps: List[Union[BaseAgent, Callable]] = []\n\n    def add_step(self, step: Union[BaseAgent, Callable]):\n        \"\"\"\n        Add an Agent or a Function to the pipeline.\n        \"\"\"\n        self.steps.append(step)\n        return self # Allow chaining: wf.add_step(a).add_step(b)\n\n    async def run(self, initial_input: str) -&gt; str:\n        \"\"\"\n        Executes the pipeline sequentially.\n        \"\"\"\n        print(f\"\ud83d\udd04 Starting Workflow: {self.name}\")\n        current_data = initial_input\n\n        for i, step in enumerate(self.steps):\n            print(f\"   \u27a1 Step {i+1} starting...\")\n\n            # CASE A: It's an Agent\n            if isinstance(step, BaseAgent):\n                # Agents use the 'think' method\n                current_data = await step.think(current_data)\n\n            # CASE B: It's a standard Function\n            elif callable(step):\n                # Check if it's async or sync\n                if hasattr(step, '__call__') and  step.__code__.co_flags &amp; 0x80: # Check for coroutine\n                     current_data = await step(current_data)\n                else:\n                    current_data = step(current_data)\n\n            print(f\"   \u2705 Step {i+1} complete.\")\n\n        print(f\"\ud83c\udfc1 Workflow {self.name} finished.\")\n        return current_data\n</code></pre>"},{"location":"reference/workflows/#anti_sentinel.workflows.engine.Workflow.add_step","title":"<code>add_step(step)</code>","text":"<p>Add an Agent or a Function to the pipeline.</p> Source code in <code>anti_sentinel\\workflows\\engine.py</code> <pre><code>def add_step(self, step: Union[BaseAgent, Callable]):\n    \"\"\"\n    Add an Agent or a Function to the pipeline.\n    \"\"\"\n    self.steps.append(step)\n    return self # Allow chaining: wf.add_step(a).add_step(b)\n</code></pre>"},{"location":"reference/workflows/#anti_sentinel.workflows.engine.Workflow.run","title":"<code>run(initial_input)</code>  <code>async</code>","text":"<p>Executes the pipeline sequentially.</p> Source code in <code>anti_sentinel\\workflows\\engine.py</code> <pre><code>async def run(self, initial_input: str) -&gt; str:\n    \"\"\"\n    Executes the pipeline sequentially.\n    \"\"\"\n    print(f\"\ud83d\udd04 Starting Workflow: {self.name}\")\n    current_data = initial_input\n\n    for i, step in enumerate(self.steps):\n        print(f\"   \u27a1 Step {i+1} starting...\")\n\n        # CASE A: It's an Agent\n        if isinstance(step, BaseAgent):\n            # Agents use the 'think' method\n            current_data = await step.think(current_data)\n\n        # CASE B: It's a standard Function\n        elif callable(step):\n            # Check if it's async or sync\n            if hasattr(step, '__call__') and  step.__code__.co_flags &amp; 0x80: # Check for coroutine\n                 current_data = await step(current_data)\n            else:\n                current_data = step(current_data)\n\n        print(f\"   \u2705 Step {i+1} complete.\")\n\n    print(f\"\ud83c\udfc1 Workflow {self.name} finished.\")\n    return current_data\n</code></pre>"}]}