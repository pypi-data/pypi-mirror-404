######################################
# Code for building the spreadsheet
######################################
import time

from datetime import timedelta

import pandas as pd

from openpyxl import Workbook
from openpyxl.styles import Alignment, Border, Font, PatternFill, Side
from openpyxl.utils.dataframe import dataframe_to_rows

from metrics_utility.automation_controller_billing.report.base import Base
from metrics_utility.metric_utils import DIRECT, INDIRECT


class ReportCCSPv2(Base):
    def __init__(self, dataframes, extra_params):
        self.wb = Workbook()

        self.dataframes = dataframes
        self.extra_params = extra_params

        self.price_per_node = extra_params['price_per_node']
        self.report_period = extra_params['report_period']

        self.config = {
            'sku': extra_params['report_sku'],
            'h1_heading': {
                'value': extra_params['report_h1_heading'],
            },
            'po_number': {
                'label': 'PO Number',
                'value': extra_params['report_po_number'],
            },
            'header': [
                {
                    'label': 'CCSP Company Name',
                    'value': extra_params['report_company_name'],
                },
                {
                    'label': 'CCSP Email',
                    'value': extra_params['report_email'],
                },
                {
                    'label': 'CCSP RHN Login',
                    'value': extra_params['report_rhn_login'],
                },
                {
                    'label': 'Report Period (YYYY-MM)',
                    'value': '<autogenerated>',
                },
            ],
        }

        default_sku_description = [
            ['SKU', 'SKU Description', '', 'Term', 'Unit of Measure', 'Currency', 'MSRP'],
            [
                extra_params['report_sku'],
                extra_params['report_sku_description'],
                '',
                'MONTH',
                'MANAGED NODE',
                'USD',
                str(extra_params['price_per_node']),
            ],
        ]

        default_column_widths = {1: 40, 2: 25, 3: 15, 4: 15, 5: 15, 6: 20, 7: 15, 8: 30, 9: 20, 10: 20, 11: 20}

        default_data_column_widths = {1: 40, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20}

        default_status_column_widths = {1: 36, 2: 20, 3: 20, 4: 36, 5: 15, 6: 15, 7: 20}

        infrastructure_summary_column_widths = {1: 20, 2: 20, 3: 20, 4: 20, 5: 20}

        self.config['sku_description'] = default_sku_description
        self.config['column_widths'] = default_column_widths
        self.config['data_column_widths'] = default_data_column_widths
        self.config['status_column_widths'] = default_status_column_widths
        self.config['infrastructure_summary_column_widths'] = infrastructure_summary_column_widths

    def _apply_filter(self, job_host_summary_dataframe, events_dataframe):
        if self.extra_params['report_organization_filter'] is not None:
            org_filter = self.extra_params['report_organization_filter'].split(';')
            job_host_summary_dataframe = job_host_summary_dataframe[job_host_summary_dataframe['organization_name'].isin(org_filter)].copy()

            # TODO: not filtering events fight now, but we can filter events by the job_remote_id
            # and install_uuid coming from the filkterd job_host_summary

        return job_host_summary_dataframe, events_dataframe

    def build_spreadsheet(self):
        job_host_summary_dataframe = self.dataframes['job_host_summary']
        events_dataframe = self.dataframes['main_jobevent']
        scope_dataframe = self.dataframes['main_host']
        status_dataframe = self.dataframes['data_collection_status']

        # Fix host names in the event data, to take in account the variables
        events_dataframe = self._fix_event_host_names(job_host_summary_dataframe, events_dataframe)
        # TODO: also apply organization filter
        job_host_summary_dataframe, events_dataframe = self._apply_filter(job_host_summary_dataframe, events_dataframe)

        # Create the workbook and worksheets
        self.wb.remove(self.wb.active)  # delete the default sheet

        # First sheet index
        sheet_index = 0
        directs = job_host_summary_dataframe[job_host_summary_dataframe['managed_node_type'] == DIRECT]
        indirects = job_host_summary_dataframe[job_host_summary_dataframe['managed_node_type'] == INDIRECT]

        if 'ccsp_summary' in self.optional_report_sheets():
            ws = self.add_sheet('Usage Reporting', sheet_index, self.config['column_widths'])
            current_row = self._build_heading_h1(1, ws)
            current_row = self._build_header(current_row, ws)
            current_row = self._build_po_number(current_row, ws)
            current_row = self._build_updated_timestamp(current_row, ws)
            self._build_data_section(current_row, ws, directs)
            sheet_index += 1

        if 'jobs' in self.optional_report_sheets():
            ws = self.add_sheet('Jobs', sheet_index, self.config['data_column_widths'])
            self._build_data_section_usage_by_job(1, ws, job_host_summary_dataframe)
            sheet_index += 1

        # Determine the function to use for managed nodes
        if 'managed_nodes_by_organizations' in self.optional_report_sheets():
            func = self._build_data_section_usage_by_node_with_org_details
        else:
            func = self._build_data_section_usage_by_node

        if 'managed_nodes' in self.optional_report_sheets():
            # Sheet with list of managed nodes
            ws = self.add_sheet('Managed nodes', sheet_index, self.config['data_column_widths'])
            func(1, ws, directs, managed_node_type='direct')
            sheet_index += 1

        if 'indirectly_managed_nodes' in self.optional_report_sheets():
            ws = self.add_sheet('Indirectly Managed nodes', sheet_index, self.config['data_column_widths'])
            ## This function creates the correct columns for this sheet.  Using the func variable from above
            ## can result in the wrong columns for this sheet if `managed_nodes_by_organizations`
            ## exists in the METRICS_UTILITY_OPTIONAL_CCSP_REPORT_SHEETS env var.
            self._build_data_section_usage_by_node(1, ws, indirects, managed_node_type='indirect')
            sheet_index += 1

        if 'inventory_scope' in self.optional_report_sheets():
            ws = self.add_sheet('Inventory Scope', sheet_index, self.config['data_column_widths'])
            scope = scope_dataframe
            self._build_data_section_scope(1, ws, scope)
            sheet_index += 1

        if 'infrastructure_summary' in self.optional_report_sheets():
            ws = self.add_sheet('Infrastructure Summary', sheet_index, self.config['infrastructure_summary_column_widths'])
            self._build_data_section_infrastructure_summary(1, ws, indirects)
            sheet_index += 1

        if 'usage_by_organizations' in self.optional_report_sheets():
            # Sheet with usage by org
            ws = self.add_sheet('Usage by organizations', sheet_index, self.config['data_column_widths'])
            self._build_data_section_usage_by_org(1, ws, job_host_summary_dataframe)
            sheet_index += 1

        if events_dataframe is not None:
            if 'usage_by_collections' in self.optional_report_sheets():
                # Sheet with usage by collections
                ws = self.add_sheet('Usage by collections', sheet_index, self.config['data_column_widths'])
                self._build_data_section_usage_by_collections(1, ws, events_dataframe)
                sheet_index += 1

            if 'usage_by_roles' in self.optional_report_sheets():
                # Sheet with usage by roles
                ws = self.add_sheet('Usage by roles', sheet_index, self.config['data_column_widths'])
                self._build_data_section_usage_by_roles(1, ws, events_dataframe)
                sheet_index += 1

            if 'usage_by_modules' in self.optional_report_sheets():
                # Sheet with usage by modules
                ws = self.add_sheet('Usage by modules', sheet_index, self.config['data_column_widths'])
                self._build_data_section_usage_by_modules(1, ws, events_dataframe)
                sheet_index += 1

        if 'managed_nodes_by_organizations' in self.optional_report_sheets():
            # Sheet with list of managed nodes by organization, this will generate multiple tabs
            organization_names = sorted(job_host_summary_dataframe['organization_name'].unique())
            for organization_name in organization_names:
                ws = self.add_sheet(organization_name, sheet_index, self.config['data_column_widths'])

                # Filter the data for a certain organization
                filtered_job_host_summary_dataframe = job_host_summary_dataframe[job_host_summary_dataframe['organization_name'] == organization_name]
                self._build_data_section_usage_by_node(1, ws, filtered_job_host_summary_dataframe, mode='by_organization')
                sheet_index += 1

        if 'data_collection_status' in self.optional_report_sheets():
            ws = self.add_sheet('Data collection status', sheet_index, self.config['status_column_widths'])
            current_row = self._build_data_section_collection_missing(1, ws, status_dataframe)
            current_row += 1  # gap
            self._build_data_section_collection_status(current_row, ws, status_dataframe)
            sheet_index += 1

        return self.wb

    def _build_table(self, current_row, ws, rows):
        row_counter = 0

        for r_idx, row in enumerate(rows, current_row):
            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx)
                cell.value = value
            row_counter += 1

        return current_row + row_counter

    def _since_until(self):
        # either --month was used, then use [month_since, month_until)
        # or --since & --until was used, then until means end of that day, not start
        since, until = None, None

        if self.extra_params['opt_since']:
            since = self.extra_params['opt_since'].replace(tzinfo=None)
        elif self.extra_params['month_since']:
            since = self.extra_params['month_since'].replace(tzinfo=None)

        if self.extra_params['opt_until']:
            until = self.extra_params['opt_until'].replace(tzinfo=None) + timedelta(days=1)
        elif self.extra_params['month_until']:
            until = self.extra_params['month_until'].replace(tzinfo=None)

        return since, until

    def _build_data_section_collection_missing(self, current_row, ws, df):
        """builds a table showing any gaps not covered by any since-until collection interval"""

        # add artificial 0-interval collects at start & end - to detect gaps between opt_since & first since, and last until & opt_until
        since, until = self._since_until()
        for file_name in df['file_name'].unique().tolist():
            start = {
                'collection_start_timestamp': None,
                'since': since,
                'until': since,  # NOT until
                'file_name': file_name,
                'status': 'ok',
                'elapsed': None,
            }
            end = {
                'collection_start_timestamp': None,
                'since': until,  # NOT since
                'until': until,
                'file_name': file_name,
                'status': 'ok',
                'elapsed': None,
            }

            synthetic = pd.DataFrame([start, end])
            df = pd.concat([synthetic, df], ignore_index=True)

        # skip failed collects
        df = df[df['status'] == 'ok']

        # find gaps between until -> next since
        df = df.sort_values(['file_name', 'since', 'until']).reset_index(drop=True)
        df['next_since'] = df.groupby('file_name')['since'].shift(-1)
        df['gap'] = (df['next_since'] - df['until']).dt.total_seconds()

        # skip if under 2 seconds
        threshold = 2  # seconds
        dataframe = df[df['gap'] > threshold].copy()

        dataframe = dataframe[['file_name', 'until', 'next_since', 'gap']]
        dataframe = dataframe.rename(
            columns={
                'file_name': 'CSV filename',
                'until': 'Missing from',
                'next_since': 'Missing until',
                'gap': 'Gap in seconds',
            }
        )

        rows = dataframe_to_rows(dataframe, index=False)
        return self._build_table(current_row, ws, rows)

    def _build_data_section_collection_status(self, first_row, ws, df):
        # time difference between the current and previous row with the same file_name & sort
        df = df.sort_values(['file_name', 'collection_start_timestamp']).reset_index(drop=True)
        df['time_diff'] = df.groupby('file_name')['collection_start_timestamp'].diff()

        df = df.sort_values('collection_start_timestamp').reset_index(drop=True)

        median_diff = df['time_diff'].median()

        dataframe = df.rename(
            columns={
                'collection_start_timestamp': 'Collection timestamp',
                'since': 'Filter since',
                'until': 'Filter until',
                'file_name': 'CSV filename',
                'status': 'Status',
                'elapsed': 'Elapsed',
                'time_diff': 'Time since\nprevious collection',  # col_index
            }
        )

        rows = dataframe_to_rows(dataframe, index=False)
        next_row = self._build_table(first_row, ws, rows)

        # apply styling to highlight unusual collection intervals

        success_background = PatternFill('solid', fgColor=self.GREEN_COLOR_HEX)
        warning_background = PatternFill('solid', fgColor=self.YELLOW_COLOR_HEX)
        danger_background = PatternFill('solid', fgColor=self.RED_COLOR_HEX)

        threshold_warning = 2 * median_diff
        threshold_danger = 3 * median_diff

        col_index = df.columns.to_list().index('time_diff')

        rows = ws.iter_rows(min_row=first_row + 1, max_row=next_row, min_col=col_index + 1, max_col=col_index + 1)
        for row in rows:
            for cell in row:
                if cell.value is None or pd.isnull(cell.value):
                    continue
                if cell.value >= threshold_danger:
                    cell.fill = danger_background
                elif cell.value >= threshold_warning:
                    cell.fill = warning_background
                else:
                    cell.fill = success_background

        return next_row

    def _build_data_section_usage_by_node_with_org_details(self, current_row, ws, dataframe, mode=None, managed_node_type=None):
        header_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX, bold=True)
        value_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX)

        # Rename the columns based on the template
        ccsp_report_dataframe = dataframe.groupby('host_name', dropna=False).agg(
            organizations=('organization_name', 'nunique'),
            host_runs=('host_name', 'count'),
            task_runs=('task_runs', 'sum'),
            first_automation=('first_automation', 'min'),
            last_automation=('last_automation', 'max'),
        )
        ccsp_report_dataframe = ccsp_report_dataframe.reset_index()
        columns = [
            'host_name',
            'organizations',
            'host_runs',
            'task_runs',
            'first_automation',
            'last_automation',
        ]
        if mode == 'by_organization':
            # Filter some columns out based on mode
            columns = [col for col in columns if col not in ['organizations']]

        ccsp_report_dataframe = ccsp_report_dataframe.reindex(columns=columns)

        # Create dataframe with hostname and orgs as columns, having last automation for each host
        pivoted_dataframe = dataframe.pivot_table(
            index='host_name',
            columns='organization_name',
            values='last_automation',
            aggfunc='max',  # You can use 'max', 'min', 'mean', etc., depending on your needs
        )

        # Set index on host_name for join
        ccsp_report_dataframe.set_index('host_name', inplace=True)

        # Join the list of orgs to the pivoted_dataframe having org last updated as columns
        ccsp_report_dataframe = ccsp_report_dataframe.join(pivoted_dataframe, how='left')
        ccsp_report_dataframe = ccsp_report_dataframe.reset_index()

        labels = {
            'host_name': self.HOST_NAME,
            'organizations': 'Automated by\norganizations',
            'host_runs': self.JOB_RUNS,  # Job runs is the same as host_runs, Non-unique managed nodes automated
            'task_runs': self.NUM_OF_TASKS_OR_RUNS,
            'first_automation': 'First\nautomation',
            'last_automation': 'Last\nautomation',
        }
        labels = {k: v for k, v in labels.items() if k in columns}
        ccsp_report_dataframe = ccsp_report_dataframe.rename(columns=labels)

        row_counter = 0
        rows = dataframe_to_rows(ccsp_report_dataframe, index=False)
        for r_idx, row in enumerate(rows, current_row):
            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx)
                cell.value = value

                if row_counter == 0:
                    # set header style
                    cell.font = header_font
                    rd = ws.row_dimensions[r_idx]
                    rd.height = 25
                else:
                    # set value style
                    cell.font = value_font

            row_counter += 1

        return current_row + row_counter

    def _build_data_section_usage_by_job(self, current_row, ws, dataframe):
        header_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX, bold=True)
        value_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX)

        dataframe['job_remote_id_install_uuid'] = list(zip(dataframe['job_remote_id'], dataframe['install_uuid']))

        # Rename the columns based on the template
        ccsp_report_dataframe = dataframe.groupby(['organization_name', 'job_template_name'], dropna=False).agg(
            job_runs=('job_remote_id_install_uuid', 'nunique'),
            host_runs_unique=('host_name', 'nunique'),
            host_runs=('host_name', 'count'),
            task_runs=('task_runs', 'sum'),
            first_run=('job_created', 'min'),
            last_run=('job_created', 'max'),
        )
        ccsp_report_dataframe = ccsp_report_dataframe.reset_index()
        ccsp_report_dataframe = ccsp_report_dataframe.reindex(
            columns=['job_template_name', 'organization_name', 'job_runs', 'host_runs_unique', 'host_runs', 'task_runs', 'first_run', 'last_run']
        )

        ccsp_report_dataframe = ccsp_report_dataframe.rename(
            columns={
                'job_template_name': 'Job template\nname',
                'organization_name': 'Organization\nname',
                'job_runs': self.JOB_RUNS,
                'host_runs_unique': self.HOST_RUNS_UNIQUE,
                'host_runs': self.HOST_RUNS,
                'task_runs': self.NUM_OF_TASKS_OR_RUNS,
                'first_run': 'First\nrun',
                'last_run': 'Last\nrun',
            }
        )

        row_counter = 0
        rows = dataframe_to_rows(ccsp_report_dataframe, index=False)
        for r_idx, row in enumerate(rows, current_row):
            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx)
                cell.value = value

                if row_counter == 0:
                    # set header style
                    cell.font = header_font
                    rd = ws.row_dimensions[r_idx]
                    rd.height = 25
                else:
                    # set value style
                    cell.font = value_font

            row_counter += 1

        return current_row + row_counter

    def _build_data_section_usage_by_org(self, current_row, ws, dataframe):
        header_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX, bold=True)
        value_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX)

        dataframe['job_remote_id_install_uuid'] = list(zip(dataframe['job_remote_id'], dataframe['install_uuid']))

        agg_dict = {
            'job_runs': ('job_remote_id_install_uuid', 'nunique'),
            # Only count host_name if the managed_node_type is "DIRECT"
            'host_runs_unique': ('host_name', lambda x: x[dataframe.loc[x.index, 'managed_node_type'] == DIRECT].nunique()),
            'host_runs': ('host_name', lambda x: x[dataframe.loc[x.index, 'managed_node_type'] == DIRECT].count()),
            'task_runs': ('task_runs', 'sum'),
        }

        # Add the INDIRECT aggregations only if the condition is met
        if 'indirectly_managed_nodes' in self.optional_report_sheets():
            agg_dict['indirect_host_runs_unique'] = ('host_name', lambda x: x[dataframe.loc[x.index, 'managed_node_type'] == INDIRECT].nunique())
            agg_dict['indirect_host_runs'] = ('host_name', lambda x: x[dataframe.loc[x.index, 'managed_node_type'] == INDIRECT].count())

        # Now pass this dictionary into .agg()
        ccsp_report_dataframe = dataframe.groupby('organization_name', dropna=False).agg(**agg_dict)

        ccsp_report_dataframe = ccsp_report_dataframe.reset_index()

        # Build columns list dynamically
        columns = ['organization_name', 'job_runs', 'host_runs_unique', 'host_runs']
        if 'indirectly_managed_nodes' in self.optional_report_sheets():
            columns.extend(['indirect_host_runs_unique', 'indirect_host_runs'])
        columns.append('task_runs')

        ccsp_report_dataframe = ccsp_report_dataframe.reindex(columns=columns)

        if 'indirectly_managed_nodes' not in self.optional_report_sheets():
            drop_cols = ['indirect_host_runs_unique', 'indirect_host_runs']
            ccsp_report_dataframe.drop([col for col in drop_cols if col in ccsp_report_dataframe.columns], axis=1, inplace=True)

        rename_columns = {
            'organization_name': 'Organization name',
            'job_runs': 'Job runs',
            'host_runs_unique': 'Unique managed nodes\nautomated',
            'host_runs': 'Non-unique managed\nnodes automated',
            'indirect_host_runs_unique': 'Unique indirect managed nodes\nautomated',
            'indirect_host_runs': 'Non-unique indirect managed\nnodes automated',
            'task_runs': 'Number of task\nruns',
        }

        ccsp_report_dataframe = ccsp_report_dataframe.rename(columns=rename_columns)

        row_counter = 0
        rows = dataframe_to_rows(ccsp_report_dataframe, index=False)
        for r_idx, row in enumerate(rows, current_row):
            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx)
                cell.value = value

                if row_counter == 0:
                    # set header style
                    cell.font = header_font
                    rd = ws.row_dimensions[r_idx]
                    rd.height = 25
                else:
                    # set value style
                    cell.font = value_font

            row_counter += 1

        return current_row + row_counter

    def _build_heading_h1(self, current_row, ws):
        # Merge cells and insert the h1 heading
        ws.merge_cells(start_row=current_row, start_column=1, end_row=current_row, end_column=2)
        h1_heading_cell = ws.cell(row=current_row, column=1)
        h1_heading_cell.value = self.config['h1_heading']['value']

        # h1_heading_cell.fill = PatternFill("solid", fgColor=self.BLACK_COLOR_HEX)
        h1_heading_cell.font = Font(
            name=self.FONT,
            size=12,
            bold=True,
        )  # color=self.WHITE_COLOR_HEX)

        # h1_heading_cell.alignment = Alignment(horizontal='center')

        current_row += 1
        return current_row

    def current_date(self):
        return time.strftime('%b %d, %Y')

    def _build_updated_timestamp(self, current_row, ws):
        cell = ws.cell(row=1, column=8)
        cell.value = f'Updated: {self.current_date()}'

        return current_row

    def _build_po_number(self, current_row, ws):
        # Add the h2 heading payment heading
        green_background = PatternFill('solid', fgColor=self.GREEN_COLOR_HEX)

        # PO number heading and value with green background
        cell = ws.cell(row=4, column=5)
        cell.value = self.config['po_number']['label']
        cell.fill = green_background

        cell = ws.cell(row=4, column=6)
        cell.value = self.config['po_number']['value']
        cell.fill = green_background

        return current_row

    def _build_header(self, current_row, ws):
        # Insert the header
        for header_row in self.config['header']:
            header_label_font = Font(name=self.FONT, size=12, color=self.BLACK_COLOR_HEX)
            header_value_font = Font(name=self.FONT, size=12, color=self.BLACK_COLOR_HEX)

            cell = ws.cell(row=current_row, column=1)
            cell.value = header_row['label']
            cell.font = header_label_font

            cell = ws.cell(row=current_row, column=2)
            if header_row['label'] == 'Report Period (YYYY-MM)':
                # Insert dynamic report period into the specific header column
                cell.fill = PatternFill('solid', fgColor=self.GREEN_COLOR_HEX)
                cell.value = self.report_period
            else:
                cell.fill = PatternFill('solid', fgColor=self.GREEN_COLOR_HEX)
                cell.value = header_row['value']
            cell.font = header_value_font
            current_row += 1

        return current_row

    def _build_sku_description(self, current_row, ws):
        # Insert the header
        row_counter = 0
        for header_row in self.config['sku_description']:
            header_font = Font(name=self.FONT, size=11, color=self.BLACK_COLOR_HEX, bold=True)
            header_border = Border(
                left=Side(border_style='thin', color=self.BLACK_COLOR_HEX),
                right=Side(border_style='thin', color=self.BLACK_COLOR_HEX),
                top=Side(border_style='thin', color=self.BLACK_COLOR_HEX),
                bottom=Side(border_style='thin', color=self.BLACK_COLOR_HEX),
            )
            value_font = Font(name=self.FONT, size=11, color=self.BLACK_COLOR_HEX)
            col_counter = 0
            for col_value in header_row:
                col_counter += 1

                cell = ws.cell(row=current_row + row_counter, column=col_counter)
                cell.value = col_value

                if row_counter == 0:
                    # header
                    cell.font = header_font
                    cell.border = header_border
                else:
                    # row
                    cell.font = value_font

            row_counter += 1
        current_row = current_row + row_counter
        # make extra 1 row space
        current_row += 1

        return current_row

    def _build_data_section(self, current_row, ws, dataframe):
        header_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX, bold=True)
        value_font = Font(name=self.FONT, size=10, color=self.BLACK_COLOR_HEX)

        dotted_border = Border(
            left=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
            right=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
            top=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
            bottom=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
        )

        second_line_dotted_border = Border(
            left=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
            right=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
            bottom=Side(border_style='dotted', color=self.BLACK_COLOR_HEX),
        )

        header_border = Border(
            left=Side(border_style='medium', color=self.BLACK_COLOR_HEX),
            right=Side(border_style='medium', color=self.BLACK_COLOR_HEX),
            top=Side(border_style='medium', color=self.BLACK_COLOR_HEX),
            bottom=Side(border_style='medium', color=self.BLACK_COLOR_HEX),
        )

        ccsp_report = {}
        quantity_consumed = dataframe['host_name'].nunique()

        if quantity_consumed > 0:
            # COmpute the unique hostnam count that are in the df index
            ccsp_report['end_user_company_name'] = self.extra_params['report_end_user_company_name']
            ccsp_report['end_user_company_city'] = self.extra_params['report_end_user_company_city']
            ccsp_report['end_user_company_state'] = self.extra_params['report_end_user_company_state']
            ccsp_report['end_user_company_country'] = self.extra_params['report_end_user_company_country']

            ccsp_report['quantity_consumed'] = quantity_consumed
            ccsp_report['mark_x'] = ''
            ccsp_report['sku_number'] = self.extra_params['report_sku']
            ccsp_report['sku_description'] = self.extra_params['report_sku_description']
            ccsp_report['notes'] = ''

            ccsp_report['unit_price'] = round(self.price_per_node, 2)
            ccsp_report['extended_unit_price'] = round((ccsp_report['quantity_consumed'] * ccsp_report['unit_price']), 2)
            ccsp_report = pd.DataFrame([ccsp_report])

            # order the columns right
            ccsp_report = ccsp_report.reset_index()
            ccsp_report = ccsp_report.reindex(
                columns=[
                    'end_user_company_name',
                    'mark_x',
                    'end_user_company_city',
                    'end_user_company_state',
                    'end_user_company_country',
                    'sku_number',
                    'quantity_consumed',
                    'sku_description',
                    'unit_price',
                    'extended_unit_price',
                    'notes',
                ]
            )

        else:
            # Generate empty df if there were no billing data
            ccsp_report = pd.DataFrame([ccsp_report])

        # Rename the columns based on the template
        ccsp_report_dataframe = ccsp_report.rename(
            columns={
                'end_user_company_name': 'End User Company Name',
                'mark_x': "Enter 'X' to indicate\nInteral Usage",
                'end_user_company_city': 'End User\nCity',
                'end_user_company_state': 'End User\nState/Prov',
                'end_user_company_country': 'Country Where\nSKU Consumed',
                'sku_number': 'SKU Number',
                'quantity_consumed': 'Quantity',
                'sku_description': 'SKU Description',
                'unit_price': 'SKU Unit Price',
                'extended_unit_price': 'SKU Extended Unit\nPrice',
                'notes': 'Notes',
            }
        )

        row_counter = 0
        rows = dataframe_to_rows(ccsp_report_dataframe, index=False)
        for r_idx, row in enumerate(rows, current_row):
            if row_counter == 0:
                rd = ws.row_dimensions[r_idx]
                rd.height = 35
            elif row_counter >= 1:
                # Set bigger height of the data columns
                rd = ws.row_dimensions[r_idx]
                rd.height = 25

            for c_idx, value in enumerate(row, 1):
                cell = ws.cell(row=r_idx, column=c_idx)
                cell.value = value

                if row_counter == 0:
                    # set header style
                    cell.font = header_font
                    cell.border = header_border
                    cell.alignment = Alignment(horizontal='center', vertical='center')
                else:
                    if row_counter == 1:
                        # set value style
                        cell.font = value_font
                        cell.border = second_line_dotted_border
                    else:
                        # set value style
                        cell.font = value_font
                        cell.border = dotted_border

                    if c_idx >= 8 and c_idx <= 11:
                        cell.fill = PatternFill('solid', fgColor=self.LIGHT_BLUE_COLOR_HEX)
                    if c_idx >= 9 and c_idx <= 10:
                        # Format all price cols
                        cell.number_format = self.PRICE_FORMAT
                    if c_idx == 10:
                        # Override the value of the extended price (number of nodes X unitp rice)
                        # Multiply columns 3x4 instead of inserting the price per org
                        cell_m_1 = ws.cell(row=r_idx, column=7).column_letter + str(r_idx)
                        cell_m_2 = ws.cell(row=r_idx, column=9).column_letter + str(r_idx)
                        cell.value = f'={cell_m_1}*{cell_m_2}'

            row_counter += 1

        # Generate 5 more blank rows at the end
        for _counter in range(5):
            # Set bigger height of the data columns
            r_idx = current_row + row_counter
            rd = ws.row_dimensions[r_idx]
            rd.height = 25

            for c_counter in range(11):
                c_idx = c_counter + 1
                cell = ws.cell(row=r_idx, column=c_idx)
                cell.border = dotted_border
                cell.font = value_font

                if c_idx >= 8 and c_idx <= 11:
                    cell.fill = PatternFill('solid', fgColor=self.LIGHT_BLUE_COLOR_HEX)
                if c_idx >= 9 and c_idx <= 10:
                    # Format all price cols
                    cell.number_format = self.PRICE_FORMAT
                if c_idx == 10:
                    # Override the value of the extended price (number of nodes X unitp rice)
                    # Multiply columns 3x4 instead of inserting the price per org
                    cell_m_1 = ws.cell(row=r_idx, column=7).column_letter + str(r_idx)
                    cell_m_2 = ws.cell(row=r_idx, column=9).column_letter + str(r_idx)
                    cell.value = f'={cell_m_1}*{cell_m_2}'

            row_counter += 1

        if row_counter >= 2:
            # If there is at least 1 data column, insert the sum:
            first_row = current_row + 1  # ignore the header
            last_row = current_row + row_counter - 1

            # Sum description
            cell = ws.cell(row=2, column=9)
            cell.value = 'Grand total'
            cell.fill = PatternFill('solid', fgColor=self.LIGHT_BLUE_COLOR_HEX)

            # Sum value
            cell = ws.cell(row=2, column=10)
            cell_sum_start = cell.column_letter + str(first_row)
            cell_sum_end = cell.column_letter + str(last_row)
            cell.value = f'=SUM({cell_sum_start}:{cell_sum_end})'
            cell.fill = PatternFill('solid', fgColor=self.LIGHT_BLUE_COLOR_HEX)
            cell.font = Font(name=self.FONT, size=10, color=self.RED_COLOR_HEX)

        return current_row + row_counter
