# TritonParse

[![License: BSD-3](https://img.shields.io/badge/License-BSD--3-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![GitHub Pages](https://img.shields.io/badge/GitHub%20Pages-Deploy-brightgreen)](https://meta-pytorch.org/tritonparse/)

**A comprehensive visualization and analysis tool for Triton kernel compilation and launch** â€” helping developers analyze, debug, and understand Triton kernel compilation processes.

ğŸŒ **[Try it online â†’](https://meta-pytorch.org/tritonparse/?json_url=https://meta-pytorch.org/tritonparse/dedicated_log_triton_trace_findhao__mapped.ndjson.gz)**

## âœ¨ Key Features

### ğŸ” Visualization & Analysis
- **ğŸš€ Launch Difference Analysis** - Detect and visualize kernel launch parameter variations
- **ğŸ“Š IR Code View** - Side-by-side IR viewing with synchronized highlighting and line mapping
- **ğŸ”„ File Diff View** - Compare kernels across different trace files side-by-side
- **ğŸ“ Multi-format IR Support** - View TTGIR, TTIR, LLIR, PTX, and AMDGCN
- **ğŸ¯ Interactive Code Views** - Click-to-highlight corresponding lines across IR stages

### ğŸ”§ Reproducer & Debugging Tools
- **ğŸ”„ Standalone Script Generation** - Extract any kernel into a self-contained Python script
- **ğŸ’¾ Tensor Data Reconstruction** - Preserve actual tensor data or use statistical approximation
- **ğŸ¯ Custom Templates** - Flexible reproducer templates for different workflows
- **ğŸ› Bug Isolation** - Share reproducible test cases for debugging and collaboration

### ğŸ“Š Structured Logging & Analysis
- **ğŸ“ Compilation & Launch Tracing** - Capture detailed events with source mapping
- **ğŸ” Stack Trace Integration** - Full Python stack traces for debugging
- **ğŸ“ˆ Metadata Extraction** - Comprehensive kernel statistics

### ğŸ› ï¸ Developer Tools
- **ğŸŒ Browser-based Interface** - No installation required, works in your browser
- **ğŸ”’ Privacy-first** - All processing happens locally, no data uploaded

## ğŸš€ Quick Start

### 1. Installation

**Four options to install:**
```bash
# install nightly version
pip install -U --pre tritonparse
# install stable version
pip install tritonparse
# install from source
git clone https://github.com/meta-pytorch/tritonparse.git
cd tritonparse
pip install -e .
# pip install the latest version from github
pip install git+https://github.com/meta-pytorch/tritonparse.git
```

**Prerequisites:** Python â‰¥ 3.10, Triton â‰¥ 3.4.0, GPU required (NVIDIA/AMD)

TritonParse relies on new features in Triton. If you're using nightly PyTorch, Triton is already included. Otherwise, install the latest Triton:
```bash
pip install triton
```

### 2. Generate Traces

```python
import tritonparse.structured_logging
import tritonparse.parse.utils

# Initialize logging with full tracing options
tritonparse.structured_logging.init(
    "./logs/",
    enable_trace_launch=True,                 # Capture kernel launch events (enables torch.compile tracing automatically)
    enable_more_tensor_information=True,      # Optional: collect tensor statistics (min/max/mean/std)
)

# Your Triton/PyTorch code here
# ... your kernels ...

# Parse and generate trace files
tritonparse.parse.utils.unified_parse("./logs/", out="./parsed_output")
```

> **ğŸ’¡ Note**: `enable_trace_launch=True` automatically enables tracing for both native Triton kernels (`@triton.jit`) and `torch.compile` / TorchInductor kernels.

<details>
<summary>ğŸ“ Example output (click to expand)</summary>

```bash
================================================================================
ğŸ“ TRITONPARSE PARSING RESULTS
================================================================================
ğŸ“‚ Parsed files directory: /scratch/findhao/tritonparse/tests/parsed_output
ğŸ“Š Total files generated: 2

ğŸ“„ Generated files:
   1. ğŸ“ dedicated_log_triton_trace_findhao__mapped.ndjson.gz (7.2KB)
   2. ğŸ“ log_file_list.json (181B)
================================================================================
âœ… Parsing completed successfully!
================================================================================
```
</details>

### 3. Visualize Results

**Visit [https://meta-pytorch.org/tritonparse/](https://meta-pytorch.org/tritonparse/?json_url=https://meta-pytorch.org/tritonparse/dedicated_log_triton_trace_findhao__mapped.ndjson.gz)** and open your local trace files (.ndjson.gz format).

> **ğŸ”’ Privacy Note**: Your trace files are processed entirely in your browser - nothing is uploaded to any server!

### 4. Generate Reproducers (Optional)

Extract any kernel into a standalone, executable Python script for debugging or testing:

```bash
# Generate reproducer for the first launch event
# (--line is 0-based: line 0 is compilation event, line 1 is first launch event)
tritonparseoss reproduce ./parsed_output/trace.ndjson.gz --line 1 --out-dir repro_output

# Run the generated reproducer
cd repro_output/<kernel_name>/
python repro_*.py
```

**Python API:**
```python
from tritonparse.reproducer.orchestrator import reproduce

result = reproduce(
    input_path="./parsed_output/trace.ndjson.gz",
    line_index=0,           # 0-based index (first event is 0)
    out_dir="repro_output"
)
```

<details>
<summary>ğŸ¯ Common Reproducer Use Cases (click to expand)</summary>

- **ğŸ› Bug Isolation**: Extract a failing kernel into a minimal standalone script
- **âš¡ Performance Testing**: Benchmark specific kernels without running the full application
- **ğŸ¤ Team Collaboration**: Share reproducible test cases with colleagues or in bug reports
- **ğŸ“Š Regression Testing**: Compare kernel behavior and performance across different versions
- **ğŸ” Deep Debugging**: Modify and experiment with kernel parameters in isolation

</details>

## ğŸ“š Complete Documentation

| ğŸ“– Guide | Description |
|----------|-------------|
| **[ğŸ  Wiki Home](https://github.com/meta-pytorch/tritonparse/wiki)** | Complete documentation and quick navigation |
| **[ğŸ“¦ Installation](https://github.com/meta-pytorch/tritonparse/wiki/01.-Installation)** | Setup guide for all scenarios |
| **[ğŸ“‹ Usage Guide](https://github.com/meta-pytorch/tritonparse/wiki/02.-Usage-Guide)** | Complete workflow, reproducer generation, and examples |
| **[ğŸŒ Web Interface](https://github.com/meta-pytorch/tritonparse/wiki/03.-Web-Interface-Guide)** | Master the visualization interface |
| **[ğŸ”§ Developer Guide](https://github.com/meta-pytorch/tritonparse/wiki/04.-Developer-Guide)** | Contributing and architecture overview |
| **[ğŸ“ Code Formatting](https://github.com/meta-pytorch/tritonparse/wiki/05.-Code-Formatting)** | Formatting standards and tools |
| **[â“ FAQ](https://github.com/meta-pytorch/tritonparse/wiki/06.-FAQ)** | Quick answers and troubleshooting |
| **[âš™ï¸ Environment Variables](https://github.com/meta-pytorch/tritonparse/wiki/07.-Environment-Variables-Reference)** | Complete environment variable reference |
| **[ğŸ“– Python API Reference](https://github.com/meta-pytorch/tritonparse/wiki/08.-Python-API-Reference)** | Full API documentation |
| **[ğŸ”„ Reproducer Guide](https://github.com/meta-pytorch/tritonparse/wiki/09.-Reproducer-Guide)** | Comprehensive kernel reproducer guide |

## ğŸ“Š Understanding Triton Compilation

TritonParse visualizes the complete Triton compilation pipeline:

**Python Source** â†’ **TTIR** â†’ **TTGIR** â†’ **LLIR** â†’ **PTX/AMDGCN**

Each stage can be inspected and compared to understand optimization transformations.

## ğŸ¤ Contributing

We welcome contributions! Please see our **[Developer Guide](https://github.com/meta-pytorch/tritonparse/wiki/04.-Developer-Guide)** for:
- Development setup and prerequisites
- Code formatting standards (**[Formatting Guide](https://github.com/meta-pytorch/tritonparse/wiki/05.-Code-Formatting)**)
- Pull request and code review process
- Testing guidelines
- Architecture overview

## ğŸ“ Support & Community

- **ğŸ› Report Issues**: [GitHub Issues](https://github.com/meta-pytorch/tritonparse/issues)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/meta-pytorch/tritonparse/discussions)
- **ğŸ“š Documentation**: [TritonParse Wiki](https://github.com/meta-pytorch/tritonparse/wiki)

## ğŸ“„ License

This project is licensed under the BSD-3 License - see the [LICENSE](LICENSE) file for details.

---

**âœ¨ Ready to get started?** Visit our **[Installation Guide](https://github.com/meta-pytorch/tritonparse/wiki/01.-Installation)** or try the **[online tool](https://meta-pytorch.org/tritonparse/)** directly!
