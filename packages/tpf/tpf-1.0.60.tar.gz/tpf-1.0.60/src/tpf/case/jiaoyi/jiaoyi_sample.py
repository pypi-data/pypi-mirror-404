"""
äº¤æ˜“æ•°æ®é‡‡æ ·è„šæœ¬ - Pythonç‰ˆæœ¬
åŸºäºé«˜æ–¯æ•°æ®åº“SQLè„šæœ¬çš„é€»è¾‘å®ç°

åŠŸèƒ½ï¼š
1. å–ä¸€æ®µæ—¶é—´çš„æ•°æ®ï¼Œæå–å…¶ä¸é‡å¤è´¦æˆ·
2. ä»è¿™äº›è´¦æˆ·ä¸­å»é™¤æ’é™¤è´¦æˆ·å
3. å¾ªç¯æ¯ä¸ªè´¦æˆ·å–å…¶ä¸€ä¸ªæœˆçš„æ•°æ®ï¼Œé™åºæ’åˆ—ï¼Œå–æœ€è¿‘çš„100æ¡æ•°æ®

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2024
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random
import logging
from typing import List, Dict, Optional, Tuple

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TransactionSampler:
    """äº¤æ˜“æ•°æ®é‡‡æ ·å™¨"""

    def __init__(self,
                 start_date: str = '2024-01-01',
                 end_date: str = '2024-02-01',
                 excluded_accounts: List[str] = ['acc1', 'acc2'],
                 sample_size: int = 10000,
                 records_per_account: int = 100):
        """
        åˆå§‹åŒ–äº¤æ˜“æ•°æ®é‡‡æ ·å™¨

        å‚æ•°:
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        excluded_accounts: éœ€è¦æ’é™¤çš„è´¦æˆ·åˆ—è¡¨
        sample_size: é‡‡æ ·è´¦æˆ·æ•°é‡
        records_per_account: æ¯ä¸ªè´¦æˆ·ä¿ç•™çš„äº¤æ˜“è®°å½•æ•°é‡
        """
        self.start_date = pd.to_datetime(start_date)
        self.end_date = pd.to_datetime(end_date)
        self.excluded_accounts = set(excluded_accounts)
        self.sample_size = sample_size
        self.records_per_account = records_per_account

        # é‡‡æ ·ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats = {}

        logger.info(f"åˆå§‹åŒ–äº¤æ˜“é‡‡æ ·å™¨:")
        logger.info(f"  æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        logger.info(f"  æ’é™¤è´¦æˆ·: {excluded_accounts}")
        logger.info(f"  é‡‡æ ·è´¦æˆ·æ•°: {sample_size}")
        logger.info(f"  æ¯è´¦æˆ·è®°å½•æ•°: {records_per_account}")

    def load_data(self, df: pd.DataFrame) -> None:
        """
        åŠ è½½äº¤æ˜“æ•°æ®

        å‚æ•°:
        df: äº¤æ˜“æ•°æ®DataFrameï¼Œåº”åŒ…å«åˆ—: acctt, dt_time, acc2, amount ç­‰
        """
        # æ•°æ®é¢„å¤„ç†
        self.raw_data = df.copy()

        # è½¬æ¢æ—¶é—´åˆ—
        if 'dt_time' in self.raw_data.columns:
            self.raw_data['dt_time'] = pd.to_datetime(self.raw_data['dt_time'])

        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        mask = (self.raw_data['dt_time'] >= self.start_date) & (self.raw_data['dt_time'] < self.end_date)
        self.data = self.raw_data[mask].copy()

        logger.info(f"åŠ è½½æ•°æ®å®Œæˆ:")
        logger.info(f"  åŸå§‹æ•°æ®è¡Œæ•°: {len(self.raw_data)}")
        logger.info(f"  æ—¶é—´èŒƒå›´å†…è¡Œæ•°: {len(self.data)}")
        logger.info(f"  æ•°æ®åˆ—: {list(self.data.columns)}")

    def step1_get_unique_accounts(self) -> pd.DataFrame:
        """
        æ­¥éª¤1ï¼šè·å–æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰ä¸é‡å¤è´¦æˆ·
        """
        logger.info("=" * 60)
        logger.info("æ­¥éª¤1ï¼šè·å–ä¸é‡å¤è´¦æˆ·")

        # è·å–ä¸é‡å¤è´¦æˆ·
        unique_accounts = self.data['acctt'].dropna()
        unique_accounts = unique_accounts[unique_accounts != '']
        unique_accounts = unique_accounts.unique()

        # åˆ›å»ºè´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
        account_stats = self.data.groupby('acctt').agg({
            'dt_time': ['min', 'max', 'count'],
            'amount': ['sum', 'mean', 'std']
        }).round(2)

        # æ‰å¹³åŒ–åˆ—å
        account_stats.columns = ['earliest_transaction', 'latest_transaction',
                                'transaction_count', 'total_amount', 'avg_amount', 'std_amount']
        account_stats = account_stats.reset_index()

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats['total_unique_accounts'] = len(unique_accounts)

        logger.info(f"å‘ç° {len(unique_accounts)} ä¸ªä¸é‡å¤è´¦æˆ·")
        logger.info(f"è´¦æˆ·äº¤æ˜“ç»Ÿè®¡:")
        logger.info(f"  å¹³å‡äº¤æ˜“æ•°: {account_stats['transaction_count'].mean():.1f}")
        logger.info(f"  æœ€å°‘äº¤æ˜“æ•°: {account_stats['transaction_count'].min()}")
        logger.info(f"  æœ€å¤šäº¤æ˜“æ•°: {account_stats['transaction_count'].max()}")

        return account_stats

    def step2_filter_and_sample_accounts(self, account_stats: pd.DataFrame) -> List[str]:
        """
        æ­¥éª¤2ï¼šæ’é™¤æŒ‡å®šè´¦æˆ·å¹¶é‡‡æ ·

        å‚æ•°:
        account_stats: è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯DataFrame

        è¿”å›:
        é‡‡æ ·çš„è´¦æˆ·åˆ—è¡¨
        """
        logger.info("=" * 60)
        logger.info("æ­¥éª¤2ï¼šæ’é™¤æŒ‡å®šè´¦æˆ·å¹¶é‡‡æ ·")

        # è¿‡æ»¤æ‰æ’é™¤çš„è´¦æˆ·
        eligible_accounts = account_stats[~account_stats['acctt'].isin(self.excluded_accounts)]

        logger.info(f"æ’é™¤æŒ‡å®šè´¦æˆ·åå‰©ä½™ {len(eligible_accounts)} ä¸ªè´¦æˆ·")
        logger.info(f"æ’é™¤çš„è´¦æˆ·: {self.excluded_accounts}")

        # å¦‚æœè´¦æˆ·æ•°é‡ä¸è¶³ï¼Œåˆ™å…¨éƒ¨é€‰æ‹©
        if len(eligible_accounts) <= self.sample_size:
            sampled_accounts = eligible_accounts['acctt'].tolist()
            logger.info(f"è´¦æˆ·æ•°é‡ä¸è¶³({len(eligible_accounts)} < {self.sample_size})ï¼Œé€‰æ‹©å…¨éƒ¨è´¦æˆ·")
        else:
            # éšæœºé‡‡æ ·
            sampled_accounts = eligible_accounts['acctt'].sample(n=self.sample_size, random_state=42).tolist()
            logger.info(f"éšæœºé‡‡æ · {len(sampled_accounts)} ä¸ªè´¦æˆ·")

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats['eligible_accounts'] = len(eligible_accounts)
        self.sampling_stats['sampled_accounts'] = len(sampled_accounts)
        self.sampling_stats['sampling_percentage'] = round(
            len(sampled_accounts) / len(eligible_accounts) * 100, 2
        )

        return sampled_accounts

    def step3_sample_transactions_per_account(self, sampled_accounts: List[str]) -> pd.DataFrame:
        """
        æ­¥éª¤3ï¼šå¯¹æ¯ä¸ªé‡‡æ ·è´¦æˆ·ï¼Œè·å–æœ€è¿‘çš„100æ¡äº¤æ˜“è®°å½•

        å‚æ•°:
        sampled_accounts: é‡‡æ ·çš„è´¦æˆ·åˆ—è¡¨

        è¿”å›:
        é‡‡æ ·çš„äº¤æ˜“æ•°æ®DataFrame
        """
        logger.info("=" * 60)
        logger.info("æ­¥éª¤3ï¼šè·å–æ¯ä¸ªè´¦æˆ·çš„æœ€è¿‘äº¤æ˜“è®°å½•")

        sampled_transactions = []

        for i, account in enumerate(sampled_accounts):
            if i % 1000 == 0:
                logger.info(f"å¤„ç†è¿›åº¦: {i+1}/{len(sampled_accounts)}")

            # è·å–è¯¥è´¦æˆ·çš„æ‰€æœ‰äº¤æ˜“
            account_data = self.data[self.data['acctt'] == account].copy()

            if len(account_data) == 0:
                continue

            # æŒ‰æ—¶é—´é™åºæ’åº
            account_data = account_data.sort_values('dt_time', ascending=False)

            # è·å–æœ€è¿‘çš„äº¤æ˜“è®°å½•
            recent_transactions = account_data.head(self.records_per_account).copy()

            # æ·»åŠ æ’åå’Œç»Ÿè®¡ä¿¡æ¯
            recent_transactions['transaction_rank'] = range(1, len(recent_transactions) + 1)
            recent_transactions['total_transactions'] = len(account_data)

            sampled_transactions.append(recent_transactions)

        # åˆå¹¶æ‰€æœ‰é‡‡æ ·çš„äº¤æ˜“è®°å½•
        if sampled_transactions:
            result_df = pd.concat(sampled_transactions, ignore_index=True)
        else:
            result_df = pd.DataFrame()

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats['total_sampled_transactions'] = len(result_df)
        if len(sampled_accounts) > 0:
            self.sampling_stats['avg_transactions_per_account'] = round(
                len(result_df) / len(sampled_accounts), 2
            )
        else:
            self.sampling_stats['avg_transactions_per_account'] = 0

        logger.info(f"é‡‡æ ·å®Œæˆ:")
        logger.info(f"  é‡‡æ ·è´¦æˆ·æ•°: {len(sampled_accounts)}")
        logger.info(f"  é‡‡æ ·äº¤æ˜“è®°å½•æ•°: {len(result_df)}")
        logger.info(f"  å¹³å‡æ¯è´¦æˆ·è®°å½•æ•°: {self.sampling_stats['avg_transactions_per_account']}")

        return result_df

    def sample_transactions(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„äº¤æ˜“æ•°æ®é‡‡æ ·æµç¨‹

        å‚æ•°:
        df: åŸå§‹äº¤æ˜“æ•°æ®DataFrame

        è¿”å›:
        (é‡‡æ ·çš„äº¤æ˜“æ•°æ®, é‡‡æ ·ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info("å¼€å§‹äº¤æ˜“æ•°æ®é‡‡æ ·æµç¨‹")

        # åŠ è½½æ•°æ®
        self.load_data(df)

        # æ­¥éª¤1ï¼šè·å–ä¸é‡å¤è´¦æˆ·
        account_stats = self.step1_get_unique_accounts()

        # æ­¥éª¤2ï¼šæ’é™¤æŒ‡å®šè´¦æˆ·å¹¶é‡‡æ ·
        sampled_accounts = self.step2_filter_and_sample_accounts(account_stats)

        # æ­¥éª¤3ï¼šè·å–æ¯ä¸ªè´¦æˆ·çš„æœ€è¿‘äº¤æ˜“è®°å½•
        sampled_data = self.step3_sample_transactions_per_account(sampled_accounts)

        # æ·»åŠ é‡‡æ ·æ—¶é—´æˆ³
        sampled_data['sample_timestamp'] = datetime.now()

        # ç”Ÿæˆé‡‡æ ·æŠ¥å‘Š
        self.generate_sampling_report(sampled_data)

        return sampled_data, self.sampling_stats

    def generate_sampling_report(self, sampled_data: pd.DataFrame) -> None:
        """ç”Ÿæˆé‡‡æ ·æŠ¥å‘Š"""
        logger.info("=" * 60)
        logger.info("é‡‡æ ·æŠ¥å‘Š")

        print("\n" + "="*60)
        print("äº¤æ˜“æ•°æ®é‡‡æ ·æŠ¥å‘Š")
        print("="*60)

        print(f"\nğŸ“Š é‡‡æ ·å‚æ•°:")
        print(f"  æ—¶é—´èŒƒå›´: {self.start_date.strftime('%Y-%m-%d')} åˆ° {self.end_date.strftime('%Y-%m-%d')}")
        print(f"  æ’é™¤è´¦æˆ·: {list(self.excluded_accounts)}")
        print(f"  ç›®æ ‡é‡‡æ ·æ•°: {self.sample_size}")
        print(f"  æ¯è´¦æˆ·è®°å½•æ•°: {self.records_per_account}")

        print(f"\nğŸ“ˆ é‡‡æ ·ç»Ÿè®¡:")
        print(f"  åŸå§‹æ•°æ®è®°å½•æ•°: {len(self.raw_data):,}")
        print(f"  æ—¶é—´èŒƒå›´å†…è®°å½•æ•°: {len(self.data):,}")
        print(f"  ä¸é‡å¤è´¦æˆ·æ•°: {self.sampling_stats.get('total_unique_accounts', 0):,}")
        print(f"  æœ‰æ•ˆè´¦æˆ·æ•°: {self.sampling_stats.get('eligible_accounts', 0):,}")
        print(f"  é‡‡æ ·è´¦æˆ·æ•°: {self.sampling_stats.get('sampled_accounts', 0):,}")
        print(f"  é‡‡æ ·æ¯”ä¾‹: {self.sampling_stats.get('sampling_percentage', 0):.2f}%")
        print(f"  é‡‡æ ·è®°å½•æ•°: {self.sampling_stats.get('total_sampled_transactions', 0):,}")
        print(f"  å¹³å‡æ¯è´¦æˆ·è®°å½•æ•°: {self.sampling_stats.get('avg_transactions_per_account', 0):.1f}")

        if not sampled_data.empty:
            print(f"\nğŸ’° äº¤æ˜“é‡‘é¢ç»Ÿè®¡:")
            print(f"  æ€»é‡‘é¢: {sampled_data['amount'].sum():,.2f}")
            print(f"  å¹³å‡é‡‘é¢: {sampled_data['amount'].mean():.2f}")
            print(f"  æœ€å¤§é‡‘é¢: {sampled_data['amount'].max():,.2f}")
            print(f"  æœ€å°é‡‘é¢: {sampled_data['amount'].min():,.2f}")

            print(f"\nğŸ“… æ—¶é—´èŒƒå›´:")
            print(f"  æœ€æ—©äº¤æ˜“: {sampled_data['dt_time'].min().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"  æœ€æ–°äº¤æ˜“: {sampled_data['dt_time'].max().strftime('%Y-%m-%d %H:%M:%S')}")

        print("\n" + "="*60)

    def save_sampled_data(self, sampled_data: pd.DataFrame, output_path: str) -> None:
        """
        ä¿å­˜é‡‡æ ·æ•°æ®åˆ°æ–‡ä»¶

        å‚æ•°:
        sampled_data: é‡‡æ ·æ•°æ®DataFrame
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            if output_path.endswith('.csv'):
                sampled_data.to_csv(output_path, index=False)
            elif output_path.endswith('.parquet'):
                sampled_data.to_parquet(output_path, index=False)
            elif output_path.endswith('.xlsx'):
                sampled_data.to_excel(output_path, index=False)
            else:
                # é»˜è®¤ä¿å­˜ä¸ºCSV
                sampled_data.to_csv(output_path + '.csv', index=False)
                output_path += '.csv'

            logger.info(f"é‡‡æ ·æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")
            print(f"\nâŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")


def create_sample_data(num_accounts: int = 50000,
                      transactions_per_account: int = 50,
                      start_date: str = '2024-01-01',
                      end_date: str = '2024-02-01') -> pd.DataFrame:
    """
    åˆ›å»ºç¤ºä¾‹äº¤æ˜“æ•°æ®ç”¨äºæµ‹è¯•

    å‚æ•°:
    num_accounts: è´¦æˆ·æ•°é‡
    transactions_per_account: æ¯è´¦æˆ·å¹³å‡äº¤æ˜“æ•°
    start_date: å¼€å§‹æ—¥æœŸ
    end_date: ç»“æŸæ—¥æœŸ

    è¿”å›:
    ç¤ºä¾‹äº¤æ˜“æ•°æ®DataFrame
    """
    logger.info(f"åˆ›å»ºç¤ºä¾‹æ•°æ®: {num_accounts} è´¦æˆ·, æ¯è´¦æˆ·çº¦ {transactions_per_account} æ¡äº¤æ˜“")

    # ç”Ÿæˆè´¦æˆ·
    accounts = [f'acc_{i:06d}' for i in range(1, num_accounts + 1)]

    # æ·»åŠ ä¸€äº›ç‰¹æ®Šè´¦æˆ·ç”¨äºæµ‹è¯•æ’é™¤åŠŸèƒ½
    accounts.extend(['acc1', 'acc2', 'special_account_1', 'special_account_2'])

    data = []
    start_dt = pd.to_datetime(start_date)
    end_dt = pd.to_datetime(end_date)
    days_diff = (end_dt - start_dt).days

    for account in accounts:
        # ä¸ºæ¯ä¸ªè´¦æˆ·ç”Ÿæˆéšæœºæ•°é‡çš„äº¤æ˜“
        num_transactions = max(1, int(np.random.normal(transactions_per_account, 15)))

        for _ in range(num_transactions):
            # éšæœºç”Ÿæˆäº¤æ˜“æ—¶é—´
            random_days = np.random.randint(0, days_diff)
            random_hours = np.random.randint(0, 24)
            random_minutes = np.random.randint(0, 60)
            transaction_time = start_dt + timedelta(
                days=random_days, hours=random_hours, minutes=random_minutes
            )

            # éšæœºç”Ÿæˆäº¤æ˜“é‡‘é¢
            amount = round(np.random.exponential(1000), 2)

            # éšæœºé€‰æ‹©äº¤æ˜“å¯¹æ‰‹
            counterpart = random.choice(accounts)

            data.append({
                'acctt': account,
                'dt_time': transaction_time,
                'acc2': counterpart,
                'amount': amount
            })

    df = pd.DataFrame(data)
    logger.info(f"ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆ: {len(df)} æ¡äº¤æ˜“è®°å½•")

    return df


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºäº¤æ˜“æ•°æ®é‡‡æ ·æµç¨‹"""

    print("ğŸš€ äº¤æ˜“æ•°æ®é‡‡æ ·è„šæœ¬ - Pythonç‰ˆæœ¬")
    print("=" * 60)

    # å‚æ•°é…ç½®
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-02-01',
        'excluded_accounts': ['acc1', 'acc2'],
        'sample_size': 10000,
        'records_per_account': 100
    }

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    sample_data = create_sample_data(
        num_accounts=50000,
        transactions_per_account=50,
        start_date=config['start_date'],
        end_date=config['end_date']
    )

    # åˆå§‹åŒ–é‡‡æ ·å™¨
    sampler = TransactionSampler(**config)

    # æ‰§è¡Œé‡‡æ ·
    print("\nğŸ”„ å¼€å§‹æ‰§è¡Œæ•°æ®é‡‡æ ·...")
    sampled_data, stats = sampler.sample_transactions(sample_data)

    # ä¿å­˜ç»“æœ
    if not sampled_data.empty:
        output_file = 'sampled_transactions_202401.csv'
        sampler.save_sampled_data(sampled_data, output_file)

        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print(f"\nğŸ“‹ é‡‡æ ·æ•°æ®é¢„è§ˆ (å‰10æ¡):")
        print(sampled_data.head(10)[['acctt', 'dt_time', 'acc2', 'amount', 'transaction_rank']].to_string(index=False))

    print("\nâœ… é‡‡æ ·æµç¨‹å®Œæˆ!")


if __name__ == "__main__":
    main()