"""
äº¤æ˜“æ•°æ®é‡‡æ ·è„šæœ¬ - Pythonç‰ˆæœ¬
åŸºäºé«˜æ–¯æ•°æ®åº“SQLè„šæœ¬çš„é€»è¾‘å®ç°

åŠŸèƒ½ï¼š
1. å–ä¸€æ®µæ—¶é—´çš„æ•°æ®ï¼Œæå–å…¶ä¸é‡å¤è´¦æˆ·
2. ä»è¿™äº›è´¦æˆ·ä¸­å»é™¤æ’é™¤è´¦æˆ·å
3. å¾ªç¯æ¯ä¸ªè´¦æˆ·å–å…¶ä¸€ä¸ªæœˆçš„æ•°æ®ï¼Œé™åºæ’åˆ—ï¼Œå–æœ€è¿‘çš„100æ¡æ•°æ®

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2024
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random
import logging
from typing import List, Dict, Optional, Tuple

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TransactionSampler:
    """äº¤æ˜“æ•°æ®é‡‡æ ·å™¨"""

    def __init__(self,
                 start_date: str = '2024-01-01',
                 end_date: str = '2024-02-01',
                 excluded_accounts: List[str] = ['acc1', 'acc2'],
                 sample_size: int = 10000,
                 records_per_account: int = 100,
                 acc1: str = 'acctt',
                 acc2: str = 'acc2',
                 time_col: str = 'dt_time',
                 amt_col: str = 'amount'):
        """
        åˆå§‹åŒ–äº¤æ˜“æ•°æ®é‡‡æ ·å™¨

        å‚æ•°:
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYY-MM-DD'
        excluded_accounts: éœ€è¦æ’é™¤çš„è´¦æˆ·åˆ—è¡¨
        sample_size: é‡‡æ ·è´¦æˆ·æ•°é‡
        records_per_account: æ¯ä¸ªè´¦æˆ·ä¿ç•™çš„äº¤æ˜“è®°å½•æ•°é‡
        acc1: ä¸»è´¦æˆ·åˆ—å
        acc2: å¯¹æ‰‹è´¦æˆ·åˆ—å
        time_col: æ—¶é—´åˆ—å
        amt_col: é‡‘é¢åˆ—å
        """
        self.start_date = pd.to_datetime(start_date)
        self.end_date = pd.to_datetime(end_date)
        self.excluded_accounts = set(excluded_accounts)
        self.sample_size = sample_size
        self.records_per_account = records_per_account
        self.acc1 = acc1
        self.acc2 = acc2
        self.time_col = time_col
        self.amt_col = amt_col

        # é‡‡æ ·ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats = {}

        logger.info(f"åˆå§‹åŒ–äº¤æ˜“é‡‡æ ·å™¨:")
        logger.info(f"  æ—¶é—´èŒƒå›´: {start_date} åˆ° {end_date}")
        logger.info(f"  æ’é™¤è´¦æˆ·: {excluded_accounts}")
        logger.info(f"  é‡‡æ ·è´¦æˆ·æ•°: {sample_size}")
        logger.info(f"  æ¯è´¦æˆ·è®°å½•æ•°: {records_per_account}")

    def load_data(self, df: pd.DataFrame) -> None:
        """
        åŠ è½½äº¤æ˜“æ•°æ®

        å‚æ•°:
        df: äº¤æ˜“æ•°æ®DataFrameï¼Œåº”åŒ…å«åˆ—: acctt, dt_time, acc2, amount ç­‰
        """
        # æ•°æ®é¢„å¤„ç†
        self.raw_data = df.copy()

        # è½¬æ¢æ—¶é—´åˆ—
        if self.time_col in self.raw_data.columns:
            self.raw_data[self.time_col] = pd.to_datetime(self.raw_data[self.time_col])

        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        mask = (self.raw_data[self.time_col] >= self.start_date) & (self.raw_data[self.time_col] < self.end_date)
        self.data = self.raw_data[mask].copy()

        logger.info(f"åŠ è½½æ•°æ®å®Œæˆ:")
        logger.info(f"  åŸå§‹æ•°æ®è¡Œæ•°: {len(self.raw_data)}")
        logger.info(f"  æ—¶é—´èŒƒå›´å†…è¡Œæ•°: {len(self.data)}")
        logger.info(f"  æ•°æ®åˆ—: {list(self.data.columns)}")

    def step1_get_unique_accounts(self) -> pd.DataFrame:
        """
        æ­¥éª¤1ï¼šè·å–æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰ä¸é‡å¤è´¦æˆ·
        """
        logger.info("=" * 60)
        logger.info("æ­¥éª¤1ï¼šè·å–ä¸é‡å¤è´¦æˆ·")

        # è·å–ä¸é‡å¤è´¦æˆ·
        unique_accounts = self.data[self.acc1].dropna()
        unique_accounts = unique_accounts[unique_accounts != '']
        unique_accounts = unique_accounts.unique()

        # åˆ›å»ºè´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
        account_stats = self.data.groupby(self.acc1).agg({
            self.time_col: ['min', 'max', 'count'],
            self.amt_col: ['sum', 'mean', 'std']
        }).round(2)

        # æ‰å¹³åŒ–åˆ—å
        account_stats.columns = ['earliest_transaction', 'latest_transaction',
                                'transaction_count', 'total_amount', 'avg_amount', 'std_amount']
        account_stats = account_stats.reset_index().rename(columns={'index': self.acc1})

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats['total_unique_accounts'] = len(unique_accounts)

        logger.info(f"å‘ç° {len(unique_accounts)} ä¸ªä¸é‡å¤è´¦æˆ·")
        logger.info(f"è´¦æˆ·äº¤æ˜“ç»Ÿè®¡:")
        logger.info(f"  å¹³å‡äº¤æ˜“æ•°: {account_stats['transaction_count'].mean():.1f}")
        logger.info(f"  æœ€å°‘äº¤æ˜“æ•°: {account_stats['transaction_count'].min()}")
        logger.info(f"  æœ€å¤šäº¤æ˜“æ•°: {account_stats['transaction_count'].max()}")

        return account_stats

    def step2_filter_and_sample_accounts(self, account_stats: pd.DataFrame) -> List[str]:
        """
        æ­¥éª¤2ï¼šæ’é™¤æŒ‡å®šè´¦æˆ·å¹¶é‡‡æ ·

        å‚æ•°:
        account_stats: è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯DataFrame

        è¿”å›:
        é‡‡æ ·çš„è´¦æˆ·åˆ—è¡¨
        """
        logger.info("=" * 60)
        logger.info("æ­¥éª¤2ï¼šæ’é™¤æŒ‡å®šè´¦æˆ·å¹¶é‡‡æ ·")

        # è¿‡æ»¤æ‰æ’é™¤çš„è´¦æˆ·
        eligible_accounts = account_stats[~account_stats[self.acc1].isin(self.excluded_accounts)]

        logger.info(f"æ’é™¤æŒ‡å®šè´¦æˆ·åå‰©ä½™ {len(eligible_accounts)} ä¸ªè´¦æˆ·")
        logger.info(f"æ’é™¤çš„è´¦æˆ·: {self.excluded_accounts}")

        # å¦‚æœè´¦æˆ·æ•°é‡ä¸è¶³ï¼Œåˆ™å…¨éƒ¨é€‰æ‹©
        if len(eligible_accounts) <= self.sample_size:
            sampled_accounts = eligible_accounts[self.acc1].tolist()
            logger.info(f"è´¦æˆ·æ•°é‡ä¸è¶³({len(eligible_accounts)} < {self.sample_size})ï¼Œé€‰æ‹©å…¨éƒ¨è´¦æˆ·")
        else:
            # éšæœºé‡‡æ ·
            sampled_accounts = eligible_accounts[self.acc1].sample(n=self.sample_size, random_state=42).tolist()
            logger.info(f"éšæœºé‡‡æ · {len(sampled_accounts)} ä¸ªè´¦æˆ·")

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats['eligible_accounts'] = len(eligible_accounts)
        self.sampling_stats['sampled_accounts'] = len(sampled_accounts)
        self.sampling_stats['sampling_percentage'] = round(
            len(sampled_accounts) / len(eligible_accounts) * 100, 2
        )

        return sampled_accounts

    def step3_sample_transactions_per_account(self, sampled_accounts: List[str]) -> pd.DataFrame:
        """
        æ­¥éª¤3ï¼šå¯¹æ¯ä¸ªé‡‡æ ·è´¦æˆ·ï¼Œè·å–æœ€è¿‘çš„100æ¡äº¤æ˜“è®°å½•

        å‚æ•°:
        sampled_accounts: é‡‡æ ·çš„è´¦æˆ·åˆ—è¡¨

        è¿”å›:
        é‡‡æ ·çš„äº¤æ˜“æ•°æ®DataFrame
        """
        logger.info("=" * 60)
        logger.info("æ­¥éª¤3ï¼šè·å–æ¯ä¸ªè´¦æˆ·çš„æœ€è¿‘äº¤æ˜“è®°å½•")

        sampled_transactions = []

        for i, account in enumerate(sampled_accounts):
            if i % 1000 == 0:
                logger.info(f"å¤„ç†è¿›åº¦: {i+1}/{len(sampled_accounts)}")

            # è·å–è¯¥è´¦æˆ·çš„æ‰€æœ‰äº¤æ˜“
            account_data = self.data[self.data[self.acc1] == account].copy()

            if len(account_data) == 0:
                continue

            # æŒ‰æ—¶é—´é™åºæ’åº
            account_data = account_data.sort_values(self.time_col, ascending=False)

            # è·å–æœ€è¿‘çš„äº¤æ˜“è®°å½•
            recent_transactions = account_data.head(self.records_per_account).copy()

            # æ·»åŠ æ’åå’Œç»Ÿè®¡ä¿¡æ¯
            recent_transactions['transaction_rank'] = range(1, len(recent_transactions) + 1)
            recent_transactions['total_transactions'] = len(account_data)

            sampled_transactions.append(recent_transactions)

        # åˆå¹¶æ‰€æœ‰é‡‡æ ·çš„äº¤æ˜“è®°å½•
        if sampled_transactions:
            result_df = pd.concat(sampled_transactions, ignore_index=True)
        else:
            result_df = pd.DataFrame()

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        self.sampling_stats['total_sampled_transactions'] = len(result_df)
        if len(sampled_accounts) > 0:
            self.sampling_stats['avg_transactions_per_account'] = round(
                len(result_df) / len(sampled_accounts), 2
            )
        else:
            self.sampling_stats['avg_transactions_per_account'] = 0

        logger.info(f"é‡‡æ ·å®Œæˆ:")
        logger.info(f"  é‡‡æ ·è´¦æˆ·æ•°: {len(sampled_accounts)}")
        logger.info(f"  é‡‡æ ·äº¤æ˜“è®°å½•æ•°: {len(result_df)}")
        logger.info(f"  å¹³å‡æ¯è´¦æˆ·è®°å½•æ•°: {self.sampling_stats['avg_transactions_per_account']}")

        return result_df

    def sample_transactions(self, df: pd.DataFrame,show_report=False) -> Tuple[pd.DataFrame, Dict]:
        """
        æ‰§è¡Œå®Œæ•´çš„äº¤æ˜“æ•°æ®é‡‡æ ·æµç¨‹

        å‚æ•°:
        df: åŸå§‹äº¤æ˜“æ•°æ®DataFrame

        è¿”å›:
        (é‡‡æ ·çš„äº¤æ˜“æ•°æ®, é‡‡æ ·ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info("å¼€å§‹äº¤æ˜“æ•°æ®é‡‡æ ·æµç¨‹")

        # åŠ è½½æ•°æ®
        self.load_data(df)

        # æ­¥éª¤1ï¼šè·å–ä¸é‡å¤è´¦æˆ·
        account_stats = self.step1_get_unique_accounts()

        # æ­¥éª¤2ï¼šæ’é™¤æŒ‡å®šè´¦æˆ·å¹¶é‡‡æ ·
        sampled_accounts = self.step2_filter_and_sample_accounts(account_stats)

        # æ­¥éª¤3ï¼šè·å–æ¯ä¸ªè´¦æˆ·çš„æœ€è¿‘äº¤æ˜“è®°å½•
        sampled_data = self.step3_sample_transactions_per_account(sampled_accounts)

        # æ·»åŠ é‡‡æ ·æ—¶é—´æˆ³
        sampled_data['sample_timestamp'] = datetime.now()

        # ç”Ÿæˆé‡‡æ ·æŠ¥å‘Š
        if show_report:
            self.generate_sampling_report(sampled_data)

        return sampled_data, self.sampling_stats

    def generate_sampling_report(self, sampled_data: pd.DataFrame) -> None:
        """ç”Ÿæˆé‡‡æ ·æŠ¥å‘Š"""
        logger.info("=" * 60)
        logger.info("é‡‡æ ·æŠ¥å‘Š")

        print("\n" + "="*60)
        print("äº¤æ˜“æ•°æ®é‡‡æ ·æŠ¥å‘Š")
        print("="*60)

        print(f"\nğŸ“Š é‡‡æ ·å‚æ•°:")
        print(f"  æ—¶é—´èŒƒå›´: {self.start_date.strftime('%Y-%m-%d')} åˆ° {self.end_date.strftime('%Y-%m-%d')}")
        print(f"  æ’é™¤è´¦æˆ·: {list(self.excluded_accounts)}")
        print(f"  ç›®æ ‡é‡‡æ ·æ•°: {self.sample_size}")
        print(f"  æ¯è´¦æˆ·è®°å½•æ•°: {self.records_per_account}")

        print(f"\nğŸ“ˆ é‡‡æ ·ç»Ÿè®¡:")
        print(f"  åŸå§‹æ•°æ®è®°å½•æ•°: {len(self.raw_data):,}")
        print(f"  æ—¶é—´èŒƒå›´å†…è®°å½•æ•°: {len(self.data):,}")
        print(f"  ä¸é‡å¤è´¦æˆ·æ•°: {self.sampling_stats.get('total_unique_accounts', 0):,}")
        print(f"  æœ‰æ•ˆè´¦æˆ·æ•°: {self.sampling_stats.get('eligible_accounts', 0):,}")
        print(f"  é‡‡æ ·è´¦æˆ·æ•°: {self.sampling_stats.get('sampled_accounts', 0):,}")
        print(f"  é‡‡æ ·æ¯”ä¾‹: {self.sampling_stats.get('sampling_percentage', 0):.2f}%")
        print(f"  é‡‡æ ·è®°å½•æ•°: {self.sampling_stats.get('total_sampled_transactions', 0):,}")
        print(f"  å¹³å‡æ¯è´¦æˆ·è®°å½•æ•°: {self.sampling_stats.get('avg_transactions_per_account', 0):.1f}")

        if not sampled_data.empty:
            print(f"\nğŸ’° äº¤æ˜“é‡‘é¢ç»Ÿè®¡:")
            print(f"  æ€»é‡‘é¢: {sampled_data[self.amt_col].sum():,.2f}")
            print(f"  å¹³å‡é‡‘é¢: {sampled_data[self.amt_col].mean():.2f}")
            print(f"  æœ€å¤§é‡‘é¢: {sampled_data[self.amt_col].max():,.2f}")
            print(f"  æœ€å°é‡‘é¢: {sampled_data[self.amt_col].min():,.2f}")

            print(f"\nğŸ“… æ—¶é—´èŒƒå›´:")
            print(f"  æœ€æ—©äº¤æ˜“: {sampled_data[self.time_col].min().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"  æœ€æ–°äº¤æ˜“: {sampled_data[self.time_col].max().strftime('%Y-%m-%d %H:%M:%S')}")

        print("\n" + "="*60)

    def save_sampled_data(self, sampled_data: pd.DataFrame, output_path: str) -> None:
        """
        ä¿å­˜é‡‡æ ·æ•°æ®åˆ°æ–‡ä»¶

        å‚æ•°:
        sampled_data: é‡‡æ ·æ•°æ®DataFrame
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            if output_path.endswith('.csv'):
                sampled_data.to_csv(output_path, index=False)
            elif output_path.endswith('.parquet'):
                sampled_data.to_parquet(output_path, index=False)
            elif output_path.endswith('.xlsx'):
                sampled_data.to_excel(output_path, index=False)
            else:
                # é»˜è®¤ä¿å­˜ä¸ºCSV
                sampled_data.to_csv(output_path + '.csv', index=False)
                output_path += '.csv'

            logger.info(f"é‡‡æ ·æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            logger.error(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")
            print(f"\nâŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")



class DataSampler(TransactionSampler):
    def __init__(self, start_date = '2024-01-01', end_date = '2024-02-01', 
                 excluded_accounts = ['acc1', 'acc2'], 
                 sample_size = 10000, 
                 records_per_account = 100, 
                 acc1='acctt', acc2='acc2', time_col='dt_time', amt_col='amount'):
        super().__init__(start_date, end_date, excluded_accounts, sample_size, records_per_account, acc1, acc2, time_col, amt_col)
        
    def sample(self, data, show_all_col=False, file_save_path=None,show_report=False):
        """
        æ‰§è¡Œæ•°æ®é‡‡æ ·æµç¨‹

        å‚æ•°:
        data : pd.DataFrame
            è¾“å…¥çš„äº¤æ˜“æ•°æ®è¡¨
        show_all_col : bool, default False
            æ˜¯å¦æ˜¾ç¤ºæ‰€æœ‰åˆ—ï¼ˆåŒ…æ‹¬å†…éƒ¨ç»Ÿè®¡åˆ—ï¼‰
        file_save_path : str, optional
            ä¿å­˜æ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä¿å­˜é‡‡æ ·ç»“æœ
        show_report : bool, default False
            æ˜¯å¦æ˜¾ç¤ºé‡‡æ ·æŠ¥å‘Š

        è¿”å›:
        tuple : (pd.DataFrame, dict)
            é‡‡æ ·çš„æ•°æ®è¡¨å’Œç»Ÿè®¡ä¿¡æ¯

        å¼‚å¸¸:
        ValueError : å½“å¿…éœ€çš„åˆ—åœ¨æ•°æ®è¡¨ä¸­ä¸å­˜åœ¨æ—¶æŠ›å‡º
        TypeError : å½“è¾“å…¥æ•°æ®ç±»å‹ä¸æ­£ç¡®æ—¶æŠ›å‡º
        """
        # éªŒè¯è¾“å…¥æ•°æ®ç±»å‹
        if not isinstance(data, pd.DataFrame):
            raise TypeError(f"è¾“å…¥æ•°æ®å¿…é¡»æ˜¯pandas.DataFrameç±»å‹ï¼Œå½“å‰ç±»å‹: {type(data).__name__}")

        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if data.empty:
            raise ValueError("è¾“å…¥æ•°æ®è¡¨ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œé‡‡æ ·")

        # æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = [self.acc1, self.acc2, self.time_col, self.amt_col]
        missing_columns = []

        for col in required_columns:
            if col not in data.columns:
                missing_columns.append(col)

        # å¦‚æœæœ‰ç¼ºå¤±çš„åˆ—ï¼ŒæŠ›å‡ºè¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯
        if missing_columns:
            error_msg = "æ•°æ®è¡¨ä¸­ç¼ºå°‘ä»¥ä¸‹å¿…éœ€çš„åˆ—:\n"
            error_msg += f"ç¼ºå¤±åˆ—: {missing_columns}\n"
            error_msg += f"æ•°æ®è¡¨å½“å‰åˆ—: {list(data.columns)}\n"
            error_msg += f"æœŸæœ›çš„åˆ—åæ˜ å°„:\n"
            error_msg += f"  - ä¸»è´¦æˆ·åˆ— (acc1): '{self.acc1}'\n"
            error_msg += f"  - å¯¹æ‰‹è´¦æˆ·åˆ— (acc2): '{self.acc2}'\n"
            error_msg += f"  - æ—¶é—´åˆ— (time_col): '{self.time_col}'\n"
            error_msg += f"  - é‡‘é¢åˆ— (amt_col): '{self.amt_col}'\n"
            error_msg += "\nè§£å†³æ–¹æ¡ˆ:\n"
            error_msg += "1. æ£€æŸ¥æ•°æ®è¡¨åˆ—åæ˜¯å¦æ­£ç¡®\n"
            error_msg += "2. åœ¨åˆå§‹åŒ–DataSampleræ—¶æŒ‡å®šæ­£ç¡®çš„åˆ—åå‚æ•°\n"
            error_msg += "3. ä¾‹å¦‚: DataSampler(acc1='your_acc_col', acc2='your_counterparty_col', time_col='your_time_col', amt_col='your_amount_col')"

            raise ValueError(error_msg)

        # æ£€æŸ¥åˆ—ä¸­æ˜¯å¦æœ‰æ•°æ®
        empty_columns = []
        for col in required_columns:
            if data[col].isna().all():
                empty_columns.append(col)

        if empty_columns:
            error_msg = f"ä»¥ä¸‹åˆ—è™½ç„¶å­˜åœ¨ä½†å…¨éƒ¨ä¸ºç©ºå€¼: {empty_columns}"
            raise ValueError(error_msg)

        # è®°å½•éªŒè¯é€šè¿‡çš„æ—¥å¿—
        logger.info(f"æ•°æ®éªŒè¯é€šè¿‡:")
        logger.info(f"  æ•°æ®è¡Œæ•°: {len(data):,}")
        logger.info(f"  æ•°æ®åˆ—æ•°: {len(data.columns)}")
        logger.info(f"  å¿…éœ€åˆ—éªŒè¯: âœ“")

        # æ‰§è¡Œé‡‡æ ·æµç¨‹
        try:
            df, stat = self.sample_transactions(data, show_report=show_report)
        except Exception as e:
            logger.error(f"æ•°æ®é‡‡æ ·è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise RuntimeError(f"æ•°æ®é‡‡æ ·å¤±è´¥: {e}") from e

        # å¤„ç†æ˜¾ç¤ºåˆ—çš„é€‰é¡¹
        if not show_all_col and not df.empty:
            columns_to_drop = []
            for col in ['transaction_rank', 'total_transactions', 'sample_timestamp']:
                if col in df.columns:
                    columns_to_drop.append(col)

            if columns_to_drop:
                df = df.drop(columns=columns_to_drop)
                logger.info(f"å·²ç§»é™¤å†…éƒ¨ç»Ÿè®¡åˆ—: {columns_to_drop}")

        # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼‰
        if file_save_path and not df.empty:
            try:
                self.save_sampled_data(df, file_save_path)
            except Exception as e:
                logger.error(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                raise RuntimeError(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}") from e

        logger.info(f"é‡‡æ ·å®Œæˆï¼Œè¿”å› {len(df)} æ¡è®°å½•")
        return df, stat


def create_sample_data(num_accounts: int = 50000,
                      transactions_per_account: int = 50,
                      start_date: str = '2024-01-01',
                      end_date: str = '2024-02-01',
                      acc1: str = 'acctt',
                      acc2: str = 'acc2',
                      time_col: str = 'dt_time',
                      amt_col: str = 'amount') -> pd.DataFrame:
    """
    åˆ›å»ºç¤ºä¾‹äº¤æ˜“æ•°æ®ç”¨äºæµ‹è¯•

    å‚æ•°:
    num_accounts: è´¦æˆ·æ•°é‡
    transactions_per_account: æ¯è´¦æˆ·å¹³å‡äº¤æ˜“æ•°
    start_date: å¼€å§‹æ—¥æœŸ
    end_date: ç»“æŸæ—¥æœŸ
    acc1: ä¸»è´¦æˆ·åˆ—å
    acc2: å¯¹æ‰‹è´¦æˆ·åˆ—å
    time_col: æ—¶é—´åˆ—å
    amt_col: é‡‘é¢åˆ—å

    è¿”å›:
    ç¤ºä¾‹äº¤æ˜“æ•°æ®DataFrame
    """
    logger.info(f"åˆ›å»ºç¤ºä¾‹æ•°æ®: {num_accounts} è´¦æˆ·, æ¯è´¦æˆ·çº¦ {transactions_per_account} æ¡äº¤æ˜“")

    # ç”Ÿæˆè´¦æˆ·
    accounts = [f'acc_{i:06d}' for i in range(1, num_accounts + 1)]

    # æ·»åŠ ä¸€äº›ç‰¹æ®Šè´¦æˆ·ç”¨äºæµ‹è¯•æ’é™¤åŠŸèƒ½
    accounts.extend(['acc1', 'acc2', 'special_account_1', 'special_account_2'])

    data = []
    start_dt = pd.to_datetime(start_date)
    end_dt = pd.to_datetime(end_date)
    days_diff = (end_dt - start_dt).days

    for account in accounts:
        # ä¸ºæ¯ä¸ªè´¦æˆ·ç”Ÿæˆéšæœºæ•°é‡çš„äº¤æ˜“
        num_transactions = max(1, int(np.random.normal(transactions_per_account, 15)))

        for _ in range(num_transactions):
            # éšæœºç”Ÿæˆäº¤æ˜“æ—¶é—´
            random_days = np.random.randint(0, days_diff)
            random_hours = np.random.randint(0, 24)
            random_minutes = np.random.randint(0, 60)
            transaction_time = start_dt + timedelta(
                days=random_days, hours=random_hours, minutes=random_minutes
            )

            # éšæœºç”Ÿæˆäº¤æ˜“é‡‘é¢
            amount = round(np.random.exponential(1000), 2)

            # éšæœºé€‰æ‹©äº¤æ˜“å¯¹æ‰‹
            counterpart = random.choice(accounts)

            data.append({
                acc1: account,
                time_col: transaction_time,
                acc2: counterpart,
                amt_col: amount
            })

    df = pd.DataFrame(data)
    logger.info(f"ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆ: {len(df)} æ¡äº¤æ˜“è®°å½•")

    return df


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºäº¤æ˜“æ•°æ®é‡‡æ ·æµç¨‹"""

    print("ğŸš€ äº¤æ˜“æ•°æ®é‡‡æ ·è„šæœ¬ - Pythonç‰ˆæœ¬")
    print("=" * 60)

    # å‚æ•°é…ç½®
    config = {
        'start_date': '2024-01-01',
        'end_date': '2024-02-01',
        'excluded_accounts': ['acc1', 'acc2'],
        'sample_size': 10000,
        'records_per_account': 100
    }

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    sample_data = create_sample_data(
        num_accounts=50000,
        transactions_per_account=50,
        start_date=config['start_date'],
        end_date=config['end_date']
    )

    # åˆå§‹åŒ–é‡‡æ ·å™¨
    sampler = TransactionSampler(**config)

    # æ‰§è¡Œé‡‡æ ·
    print("\nğŸ”„ å¼€å§‹æ‰§è¡Œæ•°æ®é‡‡æ ·...")
    sampled_data, stats = sampler.sample_transactions(sample_data)

    # ä¿å­˜ç»“æœ
    if not sampled_data.empty:
        output_file = 'sampled_transactions_202401.csv'
        sampler.save_sampled_data(sampled_data, output_file)

        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print(f"\nğŸ“‹ é‡‡æ ·æ•°æ®é¢„è§ˆ (å‰10æ¡):")
        # ä½¿ç”¨samplerçš„åˆ—åå‚æ•°æ¥æ˜¾ç¤ºæ­£ç¡®çš„åˆ—
        display_cols = [sampler.acc1, sampler.time_col, sampler.acc2, sampler.amt_col, 'transaction_rank']
        available_cols = [col for col in display_cols if col in sampled_data.columns]
        print(sampled_data.head(10)[available_cols].to_string(index=False))

    print("\nâœ… é‡‡æ ·æµç¨‹å®Œæˆ!")


if __name__ == "__main__":
    main()