//! Model Detection CLI Tool
//!
//! Usage: detect_model <model_path> [--vram <mb>] [--json] [--config]
//!
//! Detects model architecture, quantization type, and generates
//! optimal inference configuration.

use anyhow::Result;
use cortex_rust::model::{ModelDetector, OptimalConfig};
use std::env;

fn main() -> Result<()> {
    let args: Vec<String> = env::args().collect();

    if args.len() < 2 {
        eprintln!(
            "Usage: {} <model_path> [--vram <mb>] [--json] [--config]",
            args[0]
        );
        eprintln!();
        eprintln!("Options:");
        eprintln!("  --vram <mb>   Available VRAM in MB (default: 8000)");
        eprintln!("  --json        Output in JSON format");
        eprintln!("  --config      Show optimal configuration");
        std::process::exit(1);
    }

    let model_path = &args[1];
    let mut vram_mb = 8000u64;
    let mut json_format = false;
    let mut show_config = false;

    let mut i = 2;
    while i < args.len() {
        match args[i].as_str() {
            "--vram" => {
                i += 1;
                if i < args.len() {
                    vram_mb = args[i].parse().unwrap_or(8000);
                }
            }
            "--json" => json_format = true,
            "--config" => show_config = true,
            _ => {}
        }
        i += 1;
    }

    println!("ğŸ” Detecting model at: {}", model_path);
    println!();

    // Detect model
    let info = ModelDetector::detect(model_path)?;

    if json_format {
        let json = serde_json::to_string_pretty(&info)?;
        println!("{}", json);
    } else {
        // Text format
        ModelDetector::print_summary(&info);

        if show_config {
            println!();
            let config = ModelDetector::generate_optimal_config(&info, vram_mb);
            print_optimal_config(&config, vram_mb);
        }
    }

    Ok(())
}

fn print_optimal_config(config: &OptimalConfig, vram_mb: u64) {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!(
        "â•‘               OPTIMAL CONFIGURATION ({}MB VRAM)           â•‘",
        vram_mb
    );
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    println!(
        "â•‘ Flash Attention:   {:>43} â•‘",
        if config.use_flash_attention {
            "âœ“"
        } else {
            "âœ—"
        }
    );
    println!(
        "â•‘ Paged Attention:   {:>43} â•‘",
        if config.use_paged_attention {
            "âœ“"
        } else {
            "âœ—"
        }
    );
    println!(
        "â•‘ KV Cache:          {:>43} â•‘",
        if config.use_kv_cache { "âœ“" } else { "âœ—" }
    );
    println!(
        "â•‘ Sliding Window:    {:>43} â•‘",
        if config.use_sliding_window {
            "âœ“"
        } else {
            "âœ—"
        }
    );
    if let Some(window_size) = config.sliding_window_size {
        println!("â•‘   Window Size:     {:>43} â•‘", window_size);
    }
    println!("â•‘ Batch Size:        {:>43} â•‘", config.batch_size);
    println!("â•‘ Max Context:       {:>43} â•‘", config.max_context_length);
    println!("â•‘ GPU Layers:        {:>43} â•‘", config.n_gpu_layers);
    println!(
        "â•‘ Temperature:       {:>43.1} â•‘",
        config.recommended_temperature
    );
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}
