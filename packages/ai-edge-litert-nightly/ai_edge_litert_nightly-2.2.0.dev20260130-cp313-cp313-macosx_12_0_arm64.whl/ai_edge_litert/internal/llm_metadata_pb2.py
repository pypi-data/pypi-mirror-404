# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: litert/python/internal/llm_metadata.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'litert/python/internal/llm_metadata.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from ai_edge_litert.internal import llm_model_type_pb2 as litert_dot_python_dot_internal_dot_llm__model__type__pb2
from ai_edge_litert.internal import sampler_params_pb2 as litert_dot_python_dot_internal_dot_sampler__params__pb2
from ai_edge_litert.internal import token_pb2 as litert_dot_python_dot_internal_dot_token__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n)litert/python/internal/llm_metadata.proto\x12\x0flitert.lm.proto\x1a+litert/python/internal/llm_model_type.proto\x1a+litert/python/internal/sampler_params.proto\x1a\"litert/python/internal/token.proto\"/\n\rPromptAffixes\x12\x0e\n\x06prefix\x18\x01 \x01(\t\x12\x0e\n\x06suffix\x18\x02 \x01(\t\"\xcb\x01\n\x0fPromptTemplates\x12\x31\n\x04user\x18\x01 \x01(\x0b\x32\x1e.litert.lm.proto.PromptAffixesH\x00\x88\x01\x01\x12\x32\n\x05model\x18\x02 \x01(\x0b\x32\x1e.litert.lm.proto.PromptAffixesH\x01\x88\x01\x01\x12\x33\n\x06system\x18\x03 \x01(\x0b\x32\x1e.litert.lm.proto.PromptAffixesH\x02\x88\x01\x01\x42\x07\n\x05_userB\x08\n\x06_modelB\t\n\x07_system\"\xac\x03\n\x0bLlmMetadata\x12\x30\n\x0bstart_token\x18\x01 \x01(\x0b\x32\x1b.litert.lm.proto.TokenUnion\x12\x30\n\x0bstop_tokens\x18\x02 \x03(\x0b\x32\x1b.litert.lm.proto.TokenUnion\x12\x43\n\x10prompt_templates\x18\x03 \x01(\x0b\x32 .litert.lm.proto.PromptTemplatesB\x02\x18\x01H\x00\x88\x01\x01\x12?\n\x0esampler_params\x18\x04 \x01(\x0b\x32\".litert.lm.proto.SamplerParametersH\x01\x88\x01\x01\x12\x16\n\x0emax_num_tokens\x18\x05 \x01(\x05\x12\x35\n\x0ellm_model_type\x18\x06 \x01(\x0b\x32\x1d.litert.lm.proto.LlmModelType\x12\"\n\x15jinja_prompt_template\x18\x07 \x01(\tH\x02\x88\x01\x01\x42\x13\n\x11_prompt_templatesB\x11\n\x0f_sampler_paramsB\x18\n\x16_jinja_prompt_templateb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'litert.python.internal.llm_metadata_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_LLMMETADATA'].fields_by_name['prompt_templates']._loaded_options = None
  _globals['_LLMMETADATA'].fields_by_name['prompt_templates']._serialized_options = b'\030\001'
  _globals['_PROMPTAFFIXES']._serialized_start=188
  _globals['_PROMPTAFFIXES']._serialized_end=235
  _globals['_PROMPTTEMPLATES']._serialized_start=238
  _globals['_PROMPTTEMPLATES']._serialized_end=441
  _globals['_LLMMETADATA']._serialized_start=444
  _globals['_LLMMETADATA']._serialized_end=872
# @@protoc_insertion_point(module_scope)
