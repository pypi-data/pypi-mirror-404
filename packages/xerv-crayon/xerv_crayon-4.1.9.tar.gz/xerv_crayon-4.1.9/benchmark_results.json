{
  "date": "2026-01-25T23:32:20.669370",
  "test_text_bytes": 30800,
  "iterations": 10,
  "results": [
    {
      "name": "CRAYON (CPU - science)",
      "status": "OK",
      "vocab_size": "~250k",
      "avg_tokens": 24900.0,
      "token_count": 24900,
      "load_time_ms": 0.7735000690445304,
      "avg_time_ms": 1.1799499741755426,
      "min_time_ms": 1.0254000080749393,
      "max_time_ms": 1.4116999227553606,
      "tokens_per_sec": 21102589.554610725,
      "mb_per_sec": 24.893571412496694
    },
    {
      "name": "CRAYON (CPU - code)",
      "status": "OK",
      "vocab_size": "~250k",
      "avg_tokens": 22100.0,
      "token_count": 22100,
      "load_time_ms": 0.5583000602200627,
      "avg_time_ms": 1.5503000118769705,
      "min_time_ms": 1.3770000077784061,
      "max_time_ms": 1.7841000808402896,
      "tokens_per_sec": 14255305.31554548,
      "mb_per_sec": 18.946764316766007
    },
    {
      "name": "CRAYON (CPU - lite)",
      "status": "OK",
      "vocab_size": "50k",
      "avg_tokens": 15700.0,
      "token_count": 15700,
      "load_time_ms": 0.9637000039219856,
      "avg_time_ms": 1.5315299853682518,
      "min_time_ms": 1.0757999261841178,
      "max_time_ms": 1.921099959872663,
      "tokens_per_sec": 10251186.81971152,
      "mb_per_sec": 19.178970850022115
    },
    {
      "name": "tiktoken (p50k/GPT-3)",
      "status": "OK",
      "vocab_size": 50000,
      "avg_tokens": 11900.0,
      "token_count": 11900,
      "load_time_ms": 0.005600042641162872,
      "avg_time_ms": 33.36473002564162,
      "min_time_ms": 27.524500037543476,
      "max_time_ms": 50.97740003839135,
      "tokens_per_sec": 356664.0578495482,
      "mb_per_sec": 0.8803658510870158
    },
    {
      "name": "tiktoken (cl100k/GPT-4)",
      "status": "OK",
      "vocab_size": 100000,
      "avg_tokens": 9000.0,
      "token_count": 9000,
      "load_time_ms": 0.007899943739175797,
      "avg_time_ms": 28.565260011237115,
      "min_time_ms": 22.96640002168715,
      "max_time_ms": 49.08689996227622,
      "tokens_per_sec": 315068.0230622632,
      "mb_per_sec": 1.028282918963719
    },
    {
      "name": "HF GPT-2 (BPE)",
      "status": "OK",
      "vocab_size": 50257,
      "avg_tokens": 15700.0,
      "token_count": 15700,
      "load_time_ms": 1755.1474999636412,
      "avg_time_ms": 54.14273998467252,
      "min_time_ms": 45.86610000114888,
      "max_time_ms": 60.17670000437647,
      "tokens_per_sec": 289974.2422427194,
      "mb_per_sec": 0.5425135291200236
    },
    {
      "name": "HF LLaMA (SP-BPE)",
      "status": "OK",
      "vocab_size": 32000,
      "avg_tokens": 11401.0,
      "token_count": 11401,
      "load_time_ms": 1712.584999972023,
      "avg_time_ms": 54.19678996549919,
      "min_time_ms": 44.12639990914613,
      "max_time_ms": 75.18829999025911,
      "tokens_per_sec": 210363.0124082569,
      "mb_per_sec": 0.5419724851603017
    },
    {
      "name": "HF T5 (SentencePiece)",
      "status": "OK",
      "vocab_size": 32000,
      "avg_tokens": 12601.0,
      "token_count": 12601,
      "load_time_ms": 1844.303600024432,
      "avg_time_ms": 68.39936999604106,
      "min_time_ms": 53.734099958091974,
      "max_time_ms": 93.08540006168187,
      "tokens_per_sec": 184226.8430356792,
      "mb_per_sec": 0.4294362498808485
    },
    {
      "name": "HF BERT (WordPiece)",
      "status": "OK",
      "vocab_size": 30522,
      "avg_tokens": 11402.0,
      "token_count": 11402,
      "load_time_ms": 1531.154999975115,
      "avg_time_ms": 68.3790200157091,
      "min_time_ms": 41.35249997489154,
      "max_time_ms": 109.04680006206036,
      "tokens_per_sec": 166747.05190832735,
      "mb_per_sec": 0.4295640525202677
    }
  ]
}