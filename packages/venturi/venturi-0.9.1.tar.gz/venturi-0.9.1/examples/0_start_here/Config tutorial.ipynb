{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a72242f",
   "metadata": {},
   "source": [
    "# Configuration tutorial\n",
    "\n",
    "This notebook shows the flexibility of the Config class and instantiate function in venturi, which allows instantiating any Python object you want inside a Python script from a yaml file or dictionary.\n",
    "\n",
    "Usually, the Config class loads a configuration from a yaml file. But here we use a dictionary for better understanding of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218349b0",
   "metadata": {},
   "source": [
    "## Using as a simple namespace\n",
    "\n",
    "A config object created from a dictionary or yaml file behaves like a Namespace object from argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01413a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from venturi import Config, instantiate\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Simple CNN model.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, base_channels=16, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_channels, kernel_size),\n",
    "            nn.Conv2d(base_channels, base_channels * 2, kernel_size),\n",
    "            nn.Conv2d(base_channels * 2, out_channels, kernel_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "args_dict = {\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 10,\n",
    "    \"base_channels\": 16,\n",
    "    \"kernel_size\": 3,\n",
    "}\n",
    "args = Config(args_dict)\n",
    "\n",
    "\n",
    "model = SimpleCNN(\n",
    "    in_channels=args.in_channels,\n",
    "    out_channels=args.out_channels,\n",
    "    base_channels=args.base_channels,\n",
    "    kernel_size=args.kernel_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91edfe68",
   "metadata": {},
   "source": [
    "You can access elements with dot notation or use the object as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5f02e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(args[\"kernel_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09371b0c",
   "metadata": {},
   "source": [
    "## Instantiating objects\n",
    "\n",
    "The special key *_target_* can be used to instantiate any class or function using the provided parameters at the same level of the key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287ba959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_dict = {\n",
    "    \"_target_\": \"SimpleCNN\",\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 10,\n",
    "    \"base_channels\": 16,\n",
    "    \"kernel_size\": 3,\n",
    "}\n",
    "\n",
    "cfg = Config(args_dict)\n",
    "model = instantiate(cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894438d",
   "metadata": {},
   "source": [
    "You can even create complex nested objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e123cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): SimpleCNN(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (2): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"A simple classifier model that receives a CNN backbone in the constructor.\"\"\"\n",
    "\n",
    "    def __init__(self, cnn_model: nn.Module, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv = cnn_model\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(cnn_model.layers[-1].out_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "args_dict = {\n",
    "    \"_target_\": \"Classifier\",  # Top class\n",
    "    \"cnn_model\": {\n",
    "        \"_target_\": \"SimpleCNN\",  # First argument of the Classifier class\n",
    "        \"in_channels\": 3,\n",
    "        \"out_channels\": 10,\n",
    "    },\n",
    "    \"num_classes\": 10,\n",
    "}\n",
    "\n",
    "cfg = Config(args_dict)\n",
    "model = instantiate(cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3ac64",
   "metadata": {},
   "source": [
    "Note that this makes the dictionary define ALL information required to create the object. If you want to instantiate another class, **no code changes are required**. Just change the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0813793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_dict = {\n",
    "    \"_target_\": \"torch.nn.Conv2d\",\n",
    "    \"in_channels\": 3,\n",
    "    \"out_channels\": 10,\n",
    "    \"kernel_size\": 3,\n",
    "}\n",
    "\n",
    "cfg = Config(args_dict)\n",
    "model = instantiate(cfg)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235b7a2",
   "metadata": {},
   "source": [
    "This allows separating the specific classes, functions and parameters used in an experiment from the training loop. Is also allows the registration of every relevant information used in an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46449b62",
   "metadata": {},
   "source": [
    "## Example: Data augmentation\n",
    "\n",
    "For example, you can construct an entire image augmentation pypeline from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be255ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "class SegmentationTransform:\n",
    "    \"\"\"Image augmentation pipeline.\"\"\"\n",
    "\n",
    "    def __init__(self, cfg_transforms: Config):\n",
    "        # Instantiate each transform and add to list\n",
    "        transforms_list = []\n",
    "        for t in cfg_transforms.values():\n",
    "            transforms_list.append(instantiate(t))\n",
    "        transforms = v2.Compose(transforms_list)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transforms(image)\n",
    "\n",
    "\n",
    "# Define the transforms and their parameters\n",
    "transforms = {\n",
    "    \"_target_\": \"SegmentationTransform\",\n",
    "    \"cfg_transforms\": {\n",
    "        \"rrc\": {\n",
    "            \"_target_\": \"torchvision.transforms.v2.RandomResizedCrop\",\n",
    "            \"size\": [64, 64],\n",
    "            \"scale\": [0.6, 1.0],\n",
    "            \"ratio\": [0.75, 1.33],\n",
    "            \"antialias\": True,\n",
    "        },\n",
    "        \"rhf\": {\"_target_\": \"torchvision.transforms.v2.RandomHorizontalFlip\", \"p\": 0.5},\n",
    "        \"rvf\": {\"_target_\": \"torchvision.transforms.v2.RandomVerticalFlip\", \"p\": 0.5},\n",
    "    },\n",
    "}\n",
    "\n",
    "trans_dict = Config(transforms)\n",
    "transform_pipeline = instantiate(trans_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26930aa7",
   "metadata": {},
   "source": [
    "It is also possible to do *lazy instantiation*, that is, create an object with *some* given parameters but only instatiate it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf47839",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"_target_\": \"torch.optim.SGD\",\n",
    "    \"lr\": 0.01,\n",
    "    \"momentum\": 0.9,\n",
    "}\n",
    "cfg = Config(args_dict)\n",
    "# Create a partial optimizer factory\n",
    "optimizer_factory = instantiate(cfg, partial=True)\n",
    "# Do whatever you want with it\n",
    "...\n",
    "# Actually create the optimizer with model parameters\n",
    "optimizer = optimizer_factory(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec2713",
   "metadata": {},
   "source": [
    "Lazy instantiation also allows creating new functions by fixing some parameters of a given function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f3ca281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def power(x, exponent):\n",
    "    return x**exponent\n",
    "\n",
    "\n",
    "arg_dict = {\"_target_\": \"power\", \"exponent\": 2}\n",
    "\n",
    "cfg = Config(arg_dict)\n",
    "square_func = instantiate(cfg, partial=True)\n",
    "# The line above is equivalent to:\n",
    "# def square_func(x):\n",
    "#     return power(x, exponent=2)\n",
    "square_func(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b27894",
   "metadata": {},
   "source": [
    "## Mixing configurations\n",
    "\n",
    "Configurations can be easily mixed with other yaml files or dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23a08574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base configuration\n",
      "dataset:\n",
      "  setup:\n",
      "    _target_: MyDataset\n",
      "  params:\n",
      "    num_train_samples: 100\n",
      "    num_val_samples: 20\n",
      "    num_classes: 10\n",
      "    img_size:\n",
      "    - 224\n",
      "    - 224\n",
      "model:\n",
      "  setup:\n",
      "    _target_: MyCNNModel\n",
      "  params:\n",
      "    num_input_channels: 3\n",
      "    num_classes: 10\n",
      "    base_filters: 128\n",
      "    num_layers: 50\n",
      "    kernel_size: 3\n",
      "losses:\n",
      "  cross_entropy:\n",
      "    instance:\n",
      "      _target_: scripts.metrics.WeightedBCEWithLogitsLoss\n",
      "\n",
      "New configuration\n",
      "dataset:\n",
      "  setup:\n",
      "    _target_: MyDataset\n",
      "  params:\n",
      "    num_train_samples: 100\n",
      "    num_val_samples: 20\n",
      "    num_classes: 10\n",
      "    img_size:\n",
      "    - 224\n",
      "    - 224\n",
      "model:\n",
      "  setup:\n",
      "    _target_: MyViTModel\n",
      "  params:\n",
      "    num_input_channels: 3\n",
      "    num_classes: 10\n",
      "    hidden_size: 768\n",
      "    patch_size: 16\n",
      "    num_attention_heads: 12\n",
      "losses:\n",
      "  cross_entropy:\n",
      "    instance:\n",
      "      _target_: scripts.metrics.WeightedBCEWithLogitsLoss\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = Config(\"config/example_config.yaml\")\n",
    "print(\"Base configuration\")\n",
    "print(cfg)\n",
    "\n",
    "# Change the model to a Vision Transformer\n",
    "cfg.model = Config(\"config/vit_config.yaml\").model\n",
    "print(\"New configuration\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d7dbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>dataset:\n",
       "  setup:\n",
       "    _target_: MyDataset\n",
       "  params:\n",
       "    num_train_samples: 100\n",
       "    num_val_samples: 20\n",
       "    num_classes: 10\n",
       "    img_size:\n",
       "    - 224\n",
       "    - 224\n",
       "model:\n",
       "  setup:\n",
       "    _target_: MyViTModel\n",
       "  params:\n",
       "    num_input_channels: 3\n",
       "    num_classes: 10\n",
       "    hidden_size: 2048\n",
       "    patch_size: 16\n",
       "    num_attention_heads: 36\n",
       "losses:\n",
       "  cross_entropy:\n",
       "    instance:\n",
       "      _target_: scripts.metrics.WeightedBCEWithLogitsLoss\n",
       "</pre>"
      ],
      "text/plain": [
       "Config({'dataset': Config({'setup': Config({'_target_': 'MyDataset'}), 'params': Config({'num_train_samples': 100, 'num_val_samples': 20, 'num_classes': 10, 'img_size': [224, 224]})}), 'model': Config({'setup': Config({'_target_': 'MyViTModel'}), 'params': Config({'num_input_channels': 3, 'num_classes': 10, 'hidden_size': 2048, 'patch_size': 16, 'num_attention_heads': 36})}), 'losses': Config({'cross_entropy': Config({'instance': Config({'_target_': 'scripts.metrics.WeightedBCEWithLogitsLoss'})})})})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change some parameters of the ViT model. The full hierarchy of the configuration must be\n",
    "# respected.\n",
    "new_args = {\"model\": {\"params\": {\"hidden_size\": 2048, \"num_attention_heads\": 36}}}\n",
    "cfg.update_from_dict(new_args)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee15579",
   "metadata": {},
   "source": [
    "The final configuration can be saved to a yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fca134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.save(\"config/final_config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d307e",
   "metadata": {},
   "source": [
    "It is possible to define a configuration object with multiple models, and instantiate each inside a hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceca7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    \"models\": {\n",
    "        \"resnet18\": {\n",
    "            \"_target_\": \"torchvision.models.resnet18\"\n",
    "            # Model parameters can be added here\n",
    "        },\n",
    "        \"vit\": {\n",
    "            \"_target_\": \"torchvision.models.vit_b_16\"\n",
    "            # Model parameters can be added here\n",
    "        },\n",
    "    }\n",
    "}\n",
    "cfg = Config(args_dict)\n",
    "for model_cfg in cfg.models.values():\n",
    "    model = instantiate(model_cfg)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75afcfa",
   "metadata": {},
   "source": [
    "Note that this allows adding or removing models with no code changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venturi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
