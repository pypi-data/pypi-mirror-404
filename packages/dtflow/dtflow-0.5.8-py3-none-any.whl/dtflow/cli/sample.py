"""
CLI é‡‡æ ·ç›¸å…³å‘½ä»¤
"""

import re
from pathlib import Path
from typing import Any, Callable, Dict, List, Literal, Optional

import orjson

from ..storage.io import load_data, sample_file, save_data
from ..utils.field_path import get_field_with_spec
from .common import (
    _check_file_format,
    _get_file_row_count,
    _parse_field_list,
    _print_samples,
)

# where æ¡ä»¶è§£ææ­£åˆ™ï¼šfield op value
_WHERE_PATTERN = re.compile(r"^(.+?)(!=|~=|>=|<=|>|<|=)(.*)$")


def _parse_where(condition: str) -> Callable[[dict], bool]:
    """
    è§£æ where æ¡ä»¶å­—ç¬¦ä¸²ï¼Œè¿”å›ç­›é€‰å‡½æ•°ã€‚

    æ”¯æŒçš„æ“ä½œç¬¦:
        =   ç­‰äº
        !=  ä¸ç­‰äº
        ~=  åŒ…å«ï¼ˆå­—ç¬¦ä¸²ï¼‰
        >   å¤§äº
        >=  å¤§äºç­‰äº
        <   å°äº
        <=  å°äºç­‰äº

    Examples:
        _parse_where("category=tech")
        _parse_where("meta.source!=wiki")
        _parse_where("content~=æœºå™¨å­¦ä¹ ")
        _parse_where("messages.#>=2")
    """
    match = _WHERE_PATTERN.match(condition)
    if not match:
        raise ValueError(f"æ— æ•ˆçš„ where æ¡ä»¶: {condition}")

    field, op, value = match.groups()

    # å°è¯•è½¬æ¢ value ä¸ºæ•°å€¼
    def parse_value(v: str) -> Any:
        if v.lower() == "true":
            return True
        if v.lower() == "false":
            return False
        try:
            return int(v)
        except ValueError:
            try:
                return float(v)
            except ValueError:
                return v

    parsed_value = parse_value(value)

    def filter_fn(item: dict) -> bool:
        field_value = get_field_with_spec(item, field)

        if op == "=":
            # å­—ç¬¦ä¸²æ¯”è¾ƒæˆ–æ•°å€¼æ¯”è¾ƒ
            if field_value is None:
                return value == "" or value.lower() == "none"
            return str(field_value) == value or field_value == parsed_value
        elif op == "!=":
            if field_value is None:
                return value != "" and value.lower() != "none"
            return str(field_value) != value and field_value != parsed_value
        elif op == "~=":
            # åŒ…å«
            if field_value is None:
                return False
            return value in str(field_value)
        elif op in (">", ">=", "<", "<="):
            # æ•°å€¼æ¯”è¾ƒ
            if field_value is None:
                return False
            try:
                num_field = float(field_value)
                num_value = float(value)
                if op == ">":
                    return num_field > num_value
                elif op == ">=":
                    return num_field >= num_value
                elif op == "<":
                    return num_field < num_value
                else:  # <=
                    return num_field <= num_value
            except (ValueError, TypeError):
                return False
        return False

    return filter_fn


def _apply_where_filters(data: List[Dict], where_conditions: List[str]) -> List[Dict]:
    """åº”ç”¨å¤šä¸ª where æ¡ä»¶ï¼ˆAND å…³ç³»ï¼‰"""
    if not where_conditions:
        return data

    filters = [_parse_where(cond) for cond in where_conditions]
    return [item for item in data if all(f(item) for f in filters)]


def _sample_from_list(
    data: List[Dict],
    num: int,
    sample_type: str,
    seed: Optional[int] = None,
) -> List[Dict]:
    """ä»åˆ—è¡¨ä¸­é‡‡æ ·"""
    import random

    if seed is not None:
        random.seed(seed)

    total = len(data)
    if num <= 0 or num > total:
        num = total

    if sample_type == "random":
        return random.sample(data, num)
    elif sample_type == "head":
        return data[:num]
    else:  # tail
        return data[-num:]


def sample(
    filename: str,
    num: int = 10,
    type: Literal["random", "head", "tail"] = "random",
    output: Optional[str] = None,
    seed: Optional[int] = None,
    by: Optional[str] = None,
    uniform: bool = False,
    fields: Optional[str] = None,
    raw: bool = False,
    where: Optional[List[str]] = None,
) -> None:
    """
    ä»æ•°æ®æ–‡ä»¶ä¸­é‡‡æ ·æŒ‡å®šæ•°é‡çš„æ•°æ®ã€‚

    Args:
        filename: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ csv/excel/jsonl/json/parquet/arrow/feather æ ¼å¼
        num: é‡‡æ ·æ•°é‡ï¼Œé»˜è®¤ 10
            - num > 0: é‡‡æ ·æŒ‡å®šæ•°é‡
            - num = 0: é‡‡æ ·æ‰€æœ‰æ•°æ®
            - num < 0: Python åˆ‡ç‰‡é£æ ¼ï¼ˆå¦‚ -1 è¡¨ç¤ºæœ€å 1 æ¡ï¼Œ-10 è¡¨ç¤ºæœ€å 10 æ¡ï¼‰
        type: é‡‡æ ·æ–¹å¼ï¼Œå¯é€‰ random/head/tailï¼Œé»˜è®¤ random
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™æ‰“å°åˆ°æ§åˆ¶å°
        seed: éšæœºç§å­ï¼ˆä»…åœ¨ type=random æ—¶æœ‰æ•ˆï¼‰
        by: åˆ†å±‚é‡‡æ ·å­—æ®µåï¼ŒæŒ‰è¯¥å­—æ®µçš„å€¼åˆ†ç»„é‡‡æ ·
        uniform: å‡åŒ€é‡‡æ ·æ¨¡å¼ï¼ˆéœ€é…åˆ --by ä½¿ç”¨ï¼‰ï¼Œå„ç»„é‡‡æ ·ç›¸åŒæ•°é‡
        fields: åªæ˜¾ç¤ºæŒ‡å®šå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä»…åœ¨é¢„è§ˆæ¨¡å¼ä¸‹æœ‰æ•ˆ
        raw: è¾“å‡ºåŸå§‹ JSON æ ¼å¼ï¼ˆä¸æˆªæ–­ï¼Œå®Œæ•´æ˜¾ç¤ºæ‰€æœ‰å†…å®¹ï¼‰
        where: ç­›é€‰æ¡ä»¶åˆ—è¡¨ï¼Œæ”¯æŒ =, !=, ~=, >, >=, <, <= æ“ä½œç¬¦

    Examples:
        dt sample data.jsonl 5
        dt sample data.csv 100 --type=head
        dt sample data.xlsx 50 --output=sampled.jsonl
        dt sample data.jsonl 0   # é‡‡æ ·æ‰€æœ‰æ•°æ®
        dt sample data.jsonl -10 # æœ€å 10 æ¡æ•°æ®
        dt sample data.jsonl 1000 --by=category           # æŒ‰æ¯”ä¾‹åˆ†å±‚é‡‡æ ·
        dt sample data.jsonl 1000 --by=category --uniform # å‡åŒ€åˆ†å±‚é‡‡æ ·
        dt sample data.jsonl --fields=question,answer     # åªæ˜¾ç¤ºæŒ‡å®šå­—æ®µ
        dt sample data.jsonl --where="category=tech"      # ç­›é€‰ category ä¸º tech çš„æ•°æ®
        dt sample data.jsonl --where="meta.source~=wiki"  # ç­›é€‰ meta.source åŒ…å« wiki
        dt sample data.jsonl --where="messages.#>=2"      # ç­›é€‰æ¶ˆæ¯æ•°é‡ >= 2
    """
    filepath = Path(filename)

    if not filepath.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {filename}")
        return

    if not _check_file_format(filepath):
        return

    # uniform å¿…é¡»é…åˆ by ä½¿ç”¨
    if uniform and not by:
        print("é”™è¯¯: --uniform å¿…é¡»é…åˆ --by ä½¿ç”¨")
        return

    # å¤„ç† where ç­›é€‰
    where_conditions = where or []
    filtered_data = None
    original_count = None

    if where_conditions:
        # æœ‰ where æ¡ä»¶æ—¶ï¼Œå…ˆåŠ è½½å…¨éƒ¨æ•°æ®å†ç­›é€‰
        try:
            all_data = load_data(str(filepath))
            original_count = len(all_data)
            filtered_data = _apply_where_filters(all_data, where_conditions)
            print(f"ğŸ” ç­›é€‰: {original_count} â†’ {len(filtered_data)} æ¡")
            if not filtered_data:
                print("âš ï¸  ç­›é€‰åæ— æ•°æ®")
                return
        except ValueError as e:
            print(f"é”™è¯¯: {e}")
            return

    # åˆ†å±‚é‡‡æ ·æ¨¡å¼
    if by:
        try:
            sampled = _stratified_sample(filepath, num, by, uniform, seed, type, data=filtered_data)
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            return
    else:
        # æ™®é€šé‡‡æ ·
        try:
            if filtered_data is not None:
                # å·²ç­›é€‰çš„æ•°æ®ï¼Œç›´æ¥é‡‡æ ·
                sampled = _sample_from_list(filtered_data, num, type, seed)
            else:
                sampled = sample_file(
                    str(filepath),
                    num=num,
                    sample_type=type,
                    seed=seed,
                    output=None,  # å…ˆä¸ä¿å­˜ï¼Œç»Ÿä¸€åœ¨æœ€åå¤„ç†
                )
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            return

    # è¾“å‡ºç»“æœ
    if output:
        save_data(sampled, output)
        print(f"å·²ä¿å­˜ {len(sampled)} æ¡æ•°æ®åˆ° {output}")
    elif raw:
        # åŸå§‹ JSON è¾“å‡ºï¼ˆä¸æˆªæ–­ï¼‰
        for item in sampled:
            print(orjson.dumps(item, option=orjson.OPT_INDENT_2).decode("utf-8"))
    else:
        # å¤§æ–‡ä»¶è·³è¿‡è¡Œæ•°ç»Ÿè®¡ï¼ˆ50MB é˜ˆå€¼ï¼‰
        file_size = filepath.stat().st_size
        if file_size < 50 * 1024 * 1024:
            total_count = _get_file_row_count(filepath)
        else:
            total_count = None
        # è§£æ fields å‚æ•°
        field_list = _parse_field_list(fields) if fields else None
        _print_samples(sampled, filepath.name, total_count, field_list, file_size)


def _stratified_sample(
    filepath: Path,
    num: int,
    stratify_field: str,
    uniform: bool,
    seed: Optional[int],
    sample_type: str,
    data: Optional[List[Dict]] = None,
) -> List[Dict]:
    """
    åˆ†å±‚é‡‡æ ·å®ç°ã€‚

    Args:
        filepath: æ–‡ä»¶è·¯å¾„
        num: ç›®æ ‡é‡‡æ ·æ€»æ•°
        stratify_field: åˆ†å±‚å­—æ®µï¼Œæ”¯æŒåµŒå¥—è·¯å¾„è¯­æ³•ï¼š
            - meta.source        åµŒå¥—å­—æ®µ
            - messages[0].role   æ•°ç»„ç´¢å¼•
            - messages[-1].role  è´Ÿç´¢å¼•
            - messages.#         æ•°ç»„é•¿åº¦
            - messages[*].role   å±•å¼€æ‰€æœ‰å…ƒç´ ï¼ˆå¯åŠ  :join/:unique æ¨¡å¼ï¼‰
        uniform: æ˜¯å¦å‡åŒ€é‡‡æ ·ï¼ˆå„ç»„ç›¸åŒæ•°é‡ï¼‰
        seed: éšæœºç§å­
        sample_type: é‡‡æ ·æ–¹å¼ï¼ˆç”¨äºç»„å†…é‡‡æ ·ï¼‰
        data: é¢„ç­›é€‰çš„æ•°æ®ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¸ä»æ–‡ä»¶åŠ è½½ï¼‰

    Returns:
        é‡‡æ ·åçš„æ•°æ®åˆ—è¡¨
    """
    import random
    from collections import defaultdict

    if seed is not None:
        random.seed(seed)

    # åŠ è½½æ•°æ®ï¼ˆå¦‚æœæ²¡æœ‰é¢„ç­›é€‰æ•°æ®ï¼‰
    if data is None:
        data = load_data(str(filepath))
    total = len(data)

    if num <= 0 or num > total:
        num = total

    # æŒ‰å­—æ®µåˆ†ç»„ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„è¯­æ³•ï¼‰
    groups: Dict[Any, List[Dict]] = defaultdict(list)
    for item in data:
        key = get_field_with_spec(item, stratify_field, default="__null__")
        # ç¡®ä¿ key å¯å“ˆå¸Œ
        if isinstance(key, list):
            key = tuple(key)
        groups[key].append(item)

    group_keys = list(groups.keys())
    num_groups = len(group_keys)

    # æ‰“å°åˆ†ç»„ä¿¡æ¯
    print(f"ğŸ“Š åˆ†å±‚é‡‡æ ·: å­—æ®µ={stratify_field}, å…± {num_groups} ç»„")
    for key in sorted(group_keys, key=lambda x: -len(groups[x])):
        count = len(groups[key])
        pct = count / total * 100
        display_key = key if key != "__null__" else "[ç©ºå€¼]"
        print(f"   {display_key}: {count} æ¡ ({pct:.1f}%)")

    # è®¡ç®—å„ç»„é‡‡æ ·æ•°é‡
    if uniform:
        # å‡åŒ€é‡‡æ ·ï¼šå„ç»„æ•°é‡ç›¸ç­‰
        per_group = num // num_groups
        remainder = num % num_groups
        sample_counts = {key: per_group for key in group_keys}
        # ä½™æ•°åˆ†é…ç»™æ•°æ®é‡æœ€å¤šçš„ç»„
        for key in sorted(group_keys, key=lambda x: -len(groups[x]))[:remainder]:
            sample_counts[key] += 1
    else:
        # æŒ‰æ¯”ä¾‹é‡‡æ ·ï¼šä¿æŒåŸæœ‰æ¯”ä¾‹
        sample_counts = {}
        allocated = 0
        # æŒ‰ç»„å¤§å°é™åºå¤„ç†ï¼Œç¡®ä¿å°ç»„ä¹Ÿèƒ½åˆ†åˆ°
        sorted_keys = sorted(group_keys, key=lambda x: -len(groups[x]))
        for i, key in enumerate(sorted_keys):
            if i == len(sorted_keys) - 1:
                # æœ€åä¸€ç»„åˆ†é…å‰©ä½™
                sample_counts[key] = num - allocated
            else:
                # æŒ‰æ¯”ä¾‹è®¡ç®—
                ratio = len(groups[key]) / total
                count = int(num * ratio)
                # ç¡®ä¿è‡³å°‘ 1 æ¡ï¼ˆå¦‚æœç»„æœ‰æ•°æ®ï¼‰
                count = max(1, count) if groups[key] else 0
                sample_counts[key] = count
                allocated += count

    # æ‰§è¡Œå„ç»„é‡‡æ ·
    result = []
    print("ğŸ”„ æ‰§è¡Œé‡‡æ ·...")
    for key in group_keys:
        group_data = groups[key]
        target = min(sample_counts[key], len(group_data))

        if target <= 0:
            continue

        # ç»„å†…é‡‡æ ·
        if sample_type == "random":
            sampled = random.sample(group_data, target)
        elif sample_type == "head":
            sampled = group_data[:target]
        else:  # tail
            sampled = group_data[-target:]

        result.extend(sampled)

    # æ‰“å°é‡‡æ ·ç»“æœ
    print("\nğŸ“‹ é‡‡æ ·ç»“æœ:")
    result_groups: Dict[Any, int] = defaultdict(int)
    for item in result:
        key = item.get(stratify_field, "__null__")
        result_groups[key] += 1

    for key in sorted(group_keys, key=lambda x: -len(groups[x])):
        orig = len(groups[key])
        sampled_count = result_groups.get(key, 0)
        display_key = key if key != "__null__" else "[ç©ºå€¼]"
        print(f"   {display_key}: {orig} â†’ {sampled_count}")

    print(f"\nâœ… æ€»è®¡: {total} â†’ {len(result)} æ¡")

    return result


def head(
    filename: str,
    num: int = 10,
    output: Optional[str] = None,
    fields: Optional[str] = None,
    raw: bool = False,
) -> None:
    """
    æ˜¾ç¤ºæ–‡ä»¶çš„å‰ N æ¡æ•°æ®ï¼ˆdt sample --type=head çš„å¿«æ·æ–¹å¼ï¼‰ã€‚

    Args:
        filename: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ csv/excel/jsonl/json/parquet/arrow/feather æ ¼å¼
        num: æ˜¾ç¤ºæ•°é‡ï¼Œé»˜è®¤ 10
            - num > 0: æ˜¾ç¤ºæŒ‡å®šæ•°é‡
            - num = 0: æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
            - num < 0: Python åˆ‡ç‰‡é£æ ¼ï¼ˆå¦‚ -10 è¡¨ç¤ºæœ€å 10 æ¡ï¼‰
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™æ‰“å°åˆ°æ§åˆ¶å°
        fields: åªæ˜¾ç¤ºæŒ‡å®šå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä»…åœ¨é¢„è§ˆæ¨¡å¼ä¸‹æœ‰æ•ˆ
        raw: è¾“å‡ºåŸå§‹ JSON æ ¼å¼ï¼ˆä¸æˆªæ–­ï¼Œå®Œæ•´æ˜¾ç¤ºæ‰€æœ‰å†…å®¹ï¼‰

    Examples:
        dt head data.jsonl          # æ˜¾ç¤ºå‰ 10 æ¡
        dt head data.jsonl 20       # æ˜¾ç¤ºå‰ 20 æ¡
        dt head data.csv 0          # æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
        dt head data.xlsx --output=head.jsonl
        dt head data.jsonl --fields=question,answer
        dt head data.jsonl 1 --raw  # å®Œæ•´ JSON è¾“å‡º
    """
    sample(filename, num=num, type="head", output=output, fields=fields, raw=raw)


def tail(
    filename: str,
    num: int = 10,
    output: Optional[str] = None,
    fields: Optional[str] = None,
    raw: bool = False,
) -> None:
    """
    æ˜¾ç¤ºæ–‡ä»¶çš„å N æ¡æ•°æ®ï¼ˆdt sample --type=tail çš„å¿«æ·æ–¹å¼ï¼‰ã€‚

    Args:
        filename: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ csv/excel/jsonl/json/parquet/arrow/feather æ ¼å¼
        num: æ˜¾ç¤ºæ•°é‡ï¼Œé»˜è®¤ 10
            - num > 0: æ˜¾ç¤ºæŒ‡å®šæ•°é‡
            - num = 0: æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
            - num < 0: Python åˆ‡ç‰‡é£æ ¼ï¼ˆå¦‚ -10 è¡¨ç¤ºæœ€å 10 æ¡ï¼‰
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™æ‰“å°åˆ°æ§åˆ¶å°
        fields: åªæ˜¾ç¤ºæŒ‡å®šå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä»…åœ¨é¢„è§ˆæ¨¡å¼ä¸‹æœ‰æ•ˆ
        raw: è¾“å‡ºåŸå§‹ JSON æ ¼å¼ï¼ˆä¸æˆªæ–­ï¼Œå®Œæ•´æ˜¾ç¤ºæ‰€æœ‰å†…å®¹ï¼‰

    Examples:
        dt tail data.jsonl          # æ˜¾ç¤ºå 10 æ¡
        dt tail data.jsonl 20       # æ˜¾ç¤ºå 20 æ¡
        dt tail data.csv 0          # æ˜¾ç¤ºæ‰€æœ‰æ•°æ®
        dt tail data.xlsx --output=tail.jsonl
        dt tail data.jsonl --fields=question,answer
        dt tail data.jsonl 1 --raw  # å®Œæ•´ JSON è¾“å‡º
    """
    sample(filename, num=num, type="tail", output=output, fields=fields, raw=raw)
