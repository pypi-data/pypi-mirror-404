"""
CLI Schema éªŒè¯å‘½ä»¤
"""

from pathlib import Path
from typing import Optional

from ..schema import (
    alpaca_schema,
    dpo_schema,
    openai_chat_schema,
    sharegpt_schema,
)
from ..storage.io import load_data, save_data
from .common import _check_file_format

# é¢„è®¾ Schema æ˜ å°„
PRESET_SCHEMAS = {
    "openai_chat": openai_chat_schema,
    "openai-chat": openai_chat_schema,
    "chat": openai_chat_schema,
    "alpaca": alpaca_schema,
    "dpo": dpo_schema,
    "dpo_pair": dpo_schema,
    "sharegpt": sharegpt_schema,
}


def validate(
    filename: str,
    preset: Optional[str] = None,
    output: Optional[str] = None,
    filter_invalid: bool = False,
    max_errors: int = 20,
    verbose: bool = False,
    workers: Optional[int] = None,
) -> None:
    """
    ä½¿ç”¨ Schema éªŒè¯æ•°æ®æ–‡ä»¶ã€‚

    Args:
        filename: è¾“å…¥æ–‡ä»¶è·¯å¾„
        preset: é¢„è®¾ Schema åç§° (openai_chat, alpaca, dpo, sharegpt)
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜æœ‰æ•ˆæ•°æ®ï¼‰
        filter_invalid: è¿‡æ»¤æ— æ•ˆæ•°æ®å¹¶ä¿å­˜
        max_errors: æœ€å¤šæ˜¾ç¤ºçš„é”™è¯¯æ•°é‡
        verbose: æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        workers: å¹¶è¡Œè¿›ç¨‹æ•°ï¼ŒNone è‡ªåŠ¨æ£€æµ‹ï¼Œ1 ç¦ç”¨å¹¶è¡Œ

    Examples:
        dt validate data.jsonl --preset=openai_chat
        dt validate data.jsonl --preset=alpaca -o valid.jsonl
        dt validate data.jsonl --preset=chat --filter
        dt validate data.jsonl --preset=chat --workers=4
    """
    filepath = Path(filename)

    if not filepath.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {filename}")
        return

    if not _check_file_format(filepath):
        return

    # ç¡®å®š Schema
    if preset is None:
        # åˆ—å‡ºå¯ç”¨çš„é¢„è®¾
        print("è¯·æŒ‡å®šé¢„è®¾ Schema (--preset):")
        print()
        for name in ["openai_chat", "alpaca", "dpo", "sharegpt"]:
            print(f"  --preset={name}")
        print()
        print("ç¤ºä¾‹:")
        print(f"  dt validate {filename} --preset=openai_chat")
        return

    preset_lower = preset.lower().replace("-", "_")
    if preset_lower not in PRESET_SCHEMAS:
        print(f"é”™è¯¯: æœªçŸ¥çš„é¢„è®¾ Schema '{preset}'")
        print(f"å¯ç”¨é¢„è®¾: {', '.join(['openai_chat', 'alpaca', 'dpo', 'sharegpt'])}")
        return

    schema = PRESET_SCHEMAS[preset_lower]()

    # åŠ è½½æ•°æ®
    try:
        data = load_data(str(filepath))
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ - {e}")
        return

    if not data:
        print("æ–‡ä»¶ä¸ºç©º")
        return

    total = len(data)
    print(f"éªŒè¯æ–‡ä»¶: {filepath.name}")
    print(f"é¢„è®¾ Schema: {preset}")
    print(f"æ€»è®°å½•æ•°: {total}")
    print()

    # éªŒè¯ï¼ˆä½¿ç”¨å¹¶è¡Œæˆ–ä¸²è¡Œï¼‰
    use_parallel = workers != 1 and total >= 1000

    if use_parallel:
        # ä½¿ç”¨è¿›åº¦æ¡ï¼ˆå¦‚æœæœ‰ richï¼‰
        try:
            from rich.progress import (
                BarColumn,
                Progress,
                SpinnerColumn,
                TaskProgressColumn,
                TextColumn,
            )

            with Progress(
                SpinnerColumn(),
                TextColumn("[bold blue]éªŒè¯æ•°æ®"),
                BarColumn(),
                TaskProgressColumn(),
            ) as progress:
                task = progress.add_task("", total=total)

                def update_progress(current: int, total_count: int):
                    progress.update(task, completed=current)

                valid_data, invalid_results = schema.validate_parallel(
                    data, workers=workers, progress_callback=update_progress
                )
        except ImportError:
            print("ğŸ” éªŒè¯æ•°æ®...")
            valid_data, invalid_results = schema.validate_parallel(data, workers=workers)

        invalid_count = len(invalid_results)
        error_samples = invalid_results[:max_errors]
    else:
        # ä¸²è¡ŒéªŒè¯
        valid_data = []
        invalid_count = 0
        error_samples = []

        for i, item in enumerate(data):
            result = schema.validate(item)
            if result.valid:
                valid_data.append(item)
            else:
                invalid_count += 1
                if len(error_samples) < max_errors:
                    error_samples.append((i, result))

    valid_count = len(valid_data)
    valid_ratio = valid_count / total * 100 if total > 0 else 0

    # è¾“å‡ºç»“æœ
    if invalid_count == 0:
        print(f"âœ… å…¨éƒ¨é€šè¿‡! {valid_count}/{total} æ¡è®°å½•æœ‰æ•ˆ (100%)")
    else:
        print(f"âš ï¸ éªŒè¯ç»“æœ: {valid_count}/{total} æ¡æœ‰æ•ˆ ({valid_ratio:.1f}%)")
        print(f"   æ— æ•ˆè®°å½•: {invalid_count} æ¡")
        print()

        # æ˜¾ç¤ºé”™è¯¯ç¤ºä¾‹
        print(f"é”™è¯¯ç¤ºä¾‹ (æœ€å¤šæ˜¾ç¤º {max_errors} æ¡):")
        print("-" * 60)

        for idx, result in error_samples:
            print(f"[ç¬¬ {idx} è¡Œ]")
            for err in result.errors[:3]:  # æ¯æ¡è®°å½•æœ€å¤šæ˜¾ç¤º 3 ä¸ªé”™è¯¯
                print(f"  - {err}")
            if len(result.errors) > 3:
                print(f"  ... è¿˜æœ‰ {len(result.errors) - 3} ä¸ªé”™è¯¯")
            print()

    # ä¿å­˜æœ‰æ•ˆæ•°æ®
    if output or filter_invalid:
        output_path = output or str(filepath).replace(filepath.suffix, f"_valid{filepath.suffix}")
        save_data(valid_data, output_path)
        print(f"âœ… æœ‰æ•ˆæ•°æ®å·²ä¿å­˜: {output_path} ({valid_count} æ¡)")

    # è¯¦ç»†æ¨¡å¼ï¼šæ˜¾ç¤º Schema å®šä¹‰
    if verbose:
        print()
        print("Schema å®šä¹‰:")
        print("-" * 40)
        print(schema)
