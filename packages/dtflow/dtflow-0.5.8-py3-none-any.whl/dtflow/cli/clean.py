"""
CLI æ•°æ®æ¸…æ´—å’Œå»é‡ç›¸å…³å‘½ä»¤
"""

import os
import shutil
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional

from ..core import DataTransformer
from ..storage.io import save_data
from ..streaming import load_stream
from ..utils.field_path import get_field_with_spec
from .common import (
    _check_file_format,
    _get_value_len,
    _is_empty_value,
    _is_streaming_supported,
    _parse_field_list,
)


def dedupe(
    filename: str,
    key: Optional[str] = None,
    similar: Optional[float] = None,
    output: Optional[str] = None,
) -> None:
    """
    æ•°æ®å»é‡ã€‚

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. ç²¾ç¡®å»é‡ï¼ˆé»˜è®¤ï¼‰ï¼šå®Œå…¨ç›¸åŒçš„æ•°æ®æ‰å»é‡
    2. ç›¸ä¼¼åº¦å»é‡ï¼šä½¿ç”¨ MinHash+LSH ç®—æ³•ï¼Œç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼åˆ™å»é‡

    Args:
        filename: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ csv/excel/jsonl/json/parquet/arrow/feather æ ¼å¼
        key: å»é‡ä¾æ®å­—æ®µï¼Œæ”¯æŒåµŒå¥—è·¯å¾„è¯­æ³•ï¼š
            - meta.source        åµŒå¥—å­—æ®µ
            - messages[0].role   æ•°ç»„ç´¢å¼•
            - messages[-1].content  è´Ÿç´¢å¼•
            - messages.#         æ•°ç»„é•¿åº¦
            - messages[*].role:join  å±•å¼€æ‰€æœ‰å…ƒç´ 
            å¤šä¸ªå­—æ®µç”¨é€—å·åˆ†éš”ã€‚ä¸æŒ‡å®šåˆ™å…¨é‡å»é‡
        similar: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼ŒæŒ‡å®šåå¯ç”¨ç›¸ä¼¼åº¦å»é‡æ¨¡å¼ï¼Œéœ€è¦æŒ‡å®š --key
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™è¦†ç›–åŸæ–‡ä»¶

    Examples:
        dt dedupe data.jsonl                       # å…¨é‡ç²¾ç¡®å»é‡
        dt dedupe data.jsonl --key=text            # æŒ‰ text å­—æ®µç²¾ç¡®å»é‡
        dt dedupe data.jsonl --key=user,timestamp  # æŒ‰å¤šå­—æ®µç»„åˆç²¾ç¡®å»é‡
        dt dedupe data.jsonl --key=meta.id         # æŒ‰åµŒå¥—å­—æ®µå»é‡
        dt dedupe data.jsonl --key=messages[0].content   # æŒ‰ç¬¬ä¸€æ¡æ¶ˆæ¯å†…å®¹å»é‡
        dt dedupe data.jsonl --key=text --similar=0.8    # ç›¸ä¼¼åº¦å»é‡
    """
    filepath = Path(filename)

    if not filepath.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {filename}")
        return

    if not _check_file_format(filepath):
        return

    # ç›¸ä¼¼åº¦å»é‡æ¨¡å¼å¿…é¡»æŒ‡å®š key
    if similar is not None and not key:
        print("é”™è¯¯: ç›¸ä¼¼åº¦å»é‡éœ€è¦æŒ‡å®š --key å‚æ•°")
        return

    if similar is not None and (similar <= 0 or similar > 1):
        print("é”™è¯¯: --similar å‚æ•°å¿…é¡»åœ¨ 0-1 ä¹‹é—´")
        return

    # åŠ è½½æ•°æ®
    print(f"ğŸ“Š åŠ è½½æ•°æ®: {filepath}")
    try:
        dt = DataTransformer.load(str(filepath))
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ - {e}")
        return

    original_count = len(dt)
    print(f"   å…± {original_count} æ¡æ•°æ®")

    # æ‰§è¡Œå»é‡
    if similar is not None:
        # ç›¸ä¼¼åº¦å»é‡æ¨¡å¼
        print(f"ğŸ”‘ ç›¸ä¼¼åº¦å»é‡: å­—æ®µ={key}, é˜ˆå€¼={similar}")
        print("ğŸ”„ æ‰§è¡Œå»é‡ï¼ˆMinHash+LSHï¼‰...")
        try:
            result = dt.dedupe_similar(key, threshold=similar)
        except ImportError as e:
            print(f"é”™è¯¯: {e}")
            return
    else:
        # ç²¾ç¡®å»é‡æ¨¡å¼
        dedupe_key: Any = None
        if key:
            keys = [k.strip() for k in key.split(",")]
            if len(keys) == 1:
                dedupe_key = keys[0]
                print(f"ğŸ”‘ æŒ‰å­—æ®µç²¾ç¡®å»é‡: {dedupe_key}")
            else:
                dedupe_key = keys
                print(f"ğŸ”‘ æŒ‰å¤šå­—æ®µç»„åˆç²¾ç¡®å»é‡: {', '.join(dedupe_key)}")
        else:
            print("ğŸ”‘ å…¨é‡ç²¾ç¡®å»é‡")

        print("ğŸ”„ æ‰§è¡Œå»é‡...")
        result = dt.dedupe(dedupe_key)

    dedupe_count = len(result)
    removed_count = original_count - dedupe_count

    # ä¿å­˜ç»“æœ
    output_path = output or str(filepath)
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")
    try:
        result.save(output_path)
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•ä¿å­˜æ–‡ä»¶ - {e}")
        return

    print(f"\nâœ… å®Œæˆ! å»é™¤ {removed_count} æ¡é‡å¤æ•°æ®ï¼Œå‰©ä½™ {dedupe_count} æ¡")


def clean(
    filename: str,
    drop_empty: Optional[str] = None,
    min_len: Optional[str] = None,
    max_len: Optional[str] = None,
    keep: Optional[str] = None,
    drop: Optional[str] = None,
    rename: Optional[str] = None,
    promote: Optional[str] = None,
    add_field: Optional[str] = None,
    fill: Optional[str] = None,
    reorder: Optional[str] = None,
    strip: bool = False,
    output: Optional[str] = None,
) -> None:
    """
    æ•°æ®æ¸…æ´—ï¼ˆé»˜è®¤æµå¼å¤„ç†ï¼‰ã€‚

    Args:
        filename: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ csv/excel/jsonl/json/parquet/arrow/feather æ ¼å¼
        drop_empty: åˆ é™¤ç©ºå€¼è®°å½•ï¼Œæ”¯æŒåµŒå¥—è·¯å¾„è¯­æ³•
            - ä¸å¸¦å€¼ï¼šåˆ é™¤ä»»æ„å­—æ®µä¸ºç©ºçš„è®°å½•
            - æŒ‡å®šå­—æ®µï¼šåˆ é™¤æŒ‡å®šå­—æ®µä¸ºç©ºçš„è®°å½•ï¼ˆé€—å·åˆ†éš”ï¼‰
        min_len: æœ€å°é•¿åº¦è¿‡æ»¤ï¼Œæ ¼å¼ "å­—æ®µ:é•¿åº¦"ï¼Œå­—æ®µæ”¯æŒåµŒå¥—è·¯å¾„
        max_len: æœ€å¤§é•¿åº¦è¿‡æ»¤ï¼Œæ ¼å¼ "å­—æ®µ:é•¿åº¦"ï¼Œå­—æ®µæ”¯æŒåµŒå¥—è·¯å¾„
        keep: åªä¿ç•™æŒ‡å®šå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼Œä»…æ”¯æŒé¡¶å±‚å­—æ®µï¼‰
        drop: åˆ é™¤æŒ‡å®šå­—æ®µï¼ˆé€—å·åˆ†éš”ï¼Œä»…æ”¯æŒé¡¶å±‚å­—æ®µï¼‰
        rename: é‡å‘½åå­—æ®µï¼Œæ ¼å¼ "old:new" æˆ– "old1:new1,old2:new2"
        promote: æå‡åµŒå¥—å­—æ®µåˆ°é¡¶å±‚ï¼Œæ ¼å¼ "path" æˆ– "path:name"ï¼ˆé€—å·åˆ†éš”å¤šä¸ªï¼‰
        add_field: æ·»åŠ å¸¸é‡å­—æ®µï¼Œæ ¼å¼ "key:value"ï¼ˆé€—å·åˆ†éš”å¤šä¸ªï¼‰
        fill: å¡«å……ç©ºå€¼ï¼Œæ ¼å¼ "field:default_value"ï¼ˆé€—å·åˆ†éš”å¤šä¸ªï¼‰
        reorder: æ§åˆ¶å­—æ®µé¡ºåºï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œæœªåˆ—å‡ºçš„å­—æ®µè¿½åŠ åœ¨åé¢
        strip: å»é™¤æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µçš„é¦–å°¾ç©ºç™½
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™è¦†ç›–åŸæ–‡ä»¶

    Examples:
        dt clean data.jsonl --drop-empty                    # åˆ é™¤ä»»æ„ç©ºå€¼è®°å½•
        dt clean data.jsonl --drop-empty=text,answer        # åˆ é™¤æŒ‡å®šå­—æ®µä¸ºç©ºçš„è®°å½•
        dt clean data.jsonl --min-len=text:10               # text å­—æ®µæœ€å°‘ 10 å­—ç¬¦
        dt clean data.jsonl --keep=question,answer          # åªä¿ç•™è¿™äº›å­—æ®µ
        dt clean data.jsonl --drop=metadata,timestamp       # åˆ é™¤è¿™äº›å­—æ®µ
        dt clean data.jsonl --rename=question:instruction   # é‡å‘½åå­—æ®µ
        dt clean data.jsonl --promote=meta.label            # æå‡åµŒå¥—å­—æ®µåˆ°é¡¶å±‚
        dt clean data.jsonl --promote=meta.label:tag        # æå‡å¹¶è‡ªå®šä¹‰åç§°
        dt clean data.jsonl --add-field=source:web          # æ·»åŠ å¸¸é‡å­—æ®µ
        dt clean data.jsonl --fill=label:unknown            # å¡«å……ç©ºå€¼
        dt clean data.jsonl --reorder=id,text,label         # æ§åˆ¶å­—æ®µé¡ºåº
        dt clean data.jsonl --strip                         # å»é™¤å­—ç¬¦ä¸²é¦–å°¾ç©ºç™½
    """
    filepath = Path(filename)

    if not filepath.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {filename}")
        return

    if not _check_file_format(filepath):
        return

    # è§£æå‚æ•°
    min_len_field, min_len_value = _parse_len_param(min_len) if min_len else (None, None)
    max_len_field, max_len_value = _parse_len_param(max_len) if max_len else (None, None)
    keep_fields = _parse_field_list(keep) if keep else None
    drop_fields_set = set(_parse_field_list(drop)) if drop else None
    rename_map = _parse_rename_param(rename) if rename else None
    promote_list = _parse_promote_param(promote) if promote else None
    add_field_map = _parse_kv_param(add_field, "add-field") if add_field else None
    fill_map = _parse_kv_param(fill, "fill") if fill else None
    reorder_fields = _parse_field_list(reorder) if reorder else None
    keep_set = set(keep_fields) if keep_fields else None

    # æ„å»ºæ¸…æ´—é…ç½®
    empty_fields = None
    if drop_empty is not None:
        if drop_empty == "" or drop_empty is True:
            print("ğŸ”„ åˆ é™¤ä»»æ„å­—æ®µä¸ºç©ºçš„è®°å½•...")
            empty_fields = []
        else:
            empty_fields = _parse_field_list(drop_empty)
            print(f"ğŸ”„ åˆ é™¤å­—æ®µä¸ºç©ºçš„è®°å½•: {', '.join(empty_fields)}")

    if strip:
        print("ğŸ”„ å»é™¤å­—ç¬¦ä¸²é¦–å°¾ç©ºç™½...")
    if min_len_field:
        print(f"ğŸ”„ è¿‡æ»¤ {min_len_field} é•¿åº¦ < {min_len_value} çš„è®°å½•...")
    if max_len_field:
        print(f"ğŸ”„ è¿‡æ»¤ {max_len_field} é•¿åº¦ > {max_len_value} çš„è®°å½•...")
    if keep_fields:
        print(f"ğŸ”„ åªä¿ç•™å­—æ®µ: {', '.join(keep_fields)}")
    if drop_fields_set:
        print(f"ğŸ”„ åˆ é™¤å­—æ®µ: {', '.join(drop_fields_set)}")
    if rename_map:
        rename_desc = ", ".join(f"{k} â†’ {v}" for k, v in rename_map.items())
        print(f"ğŸ”„ é‡å‘½åå­—æ®µ: {rename_desc}")
    if promote_list:
        promote_desc = ", ".join(f"{src} â†’ {dst}" for src, dst in promote_list)
        print(f"ğŸ”„ æå‡å­—æ®µ: {promote_desc}")
    if add_field_map:
        add_desc = ", ".join(f"{k}={v}" for k, v in add_field_map.items())
        print(f"ğŸ”„ æ·»åŠ å­—æ®µ: {add_desc}")
    if fill_map:
        fill_desc = ", ".join(f"{k}={v}" for k, v in fill_map.items())
        print(f"ğŸ”„ å¡«å……ç©ºå€¼: {fill_desc}")
    if reorder_fields:
        print(f"ğŸ”„ å­—æ®µæ’åº: {', '.join(reorder_fields)}")

    output_path = output or str(filepath)

    # æ£€æŸ¥è¾“å…¥è¾“å‡ºæ˜¯å¦ç›¸åŒï¼ˆæµå¼å¤„ç†éœ€è¦ä¸´æ—¶æ–‡ä»¶ï¼‰
    input_resolved = filepath.resolve()
    output_resolved = Path(output_path).resolve()
    use_temp_file = input_resolved == output_resolved

    # å¯¹äº JSONL æ–‡ä»¶ä½¿ç”¨æµå¼å¤„ç†
    if _is_streaming_supported(filepath):
        print(f"ğŸ“Š æµå¼åŠ è½½: {filepath}")

        # å¦‚æœè¾“å…¥è¾“å‡ºç›¸åŒï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
        if use_temp_file:
            print("âš  æ£€æµ‹åˆ°è¾“å‡ºæ–‡ä»¶ä¸è¾“å…¥æ–‡ä»¶ç›¸åŒï¼Œå°†ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶")
            temp_fd, temp_path = tempfile.mkstemp(
                suffix=output_resolved.suffix,
                prefix=".tmp_",
                dir=output_resolved.parent,
            )
            os.close(temp_fd)
            actual_output = temp_path
        else:
            actual_output = output_path

        try:
            count = _clean_streaming(
                str(filepath),
                actual_output,
                strip=strip,
                empty_fields=empty_fields,
                min_len_field=min_len_field,
                min_len_value=min_len_value,
                max_len_field=max_len_field,
                max_len_value=max_len_value,
                keep_set=keep_set,
                drop_fields_set=drop_fields_set,
                rename_map=rename_map,
                promote_list=promote_list,
                add_field_map=add_field_map,
                fill_map=fill_map,
                reorder_fields=reorder_fields,
            )

            # å¦‚æœä½¿ç”¨äº†ä¸´æ—¶æ–‡ä»¶ï¼Œç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            if use_temp_file:
                shutil.move(temp_path, output_path)

            print(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")
            print(f"\nâœ… å®Œæˆ! æ¸…æ´—å {count} æ¡æ•°æ®")
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if use_temp_file and os.path.exists(temp_path):
                os.unlink(temp_path)
            print(f"é”™è¯¯: æ¸…æ´—å¤±è´¥ - {e}")
            import traceback

            traceback.print_exc()
        return

    # é JSONL æ–‡ä»¶ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
    print(f"ğŸ“Š åŠ è½½æ•°æ®: {filepath}")
    try:
        dt = DataTransformer.load(str(filepath))
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ - {e}")
        return

    original_count = len(dt)
    print(f"   å…± {original_count} æ¡æ•°æ®")

    # å•æ¬¡éå†æ‰§è¡Œæ‰€æœ‰æ¸…æ´—æ“ä½œ
    data, step_stats = _clean_data_single_pass(
        dt.data,
        strip=strip,
        empty_fields=empty_fields,
        min_len_field=min_len_field,
        min_len_value=min_len_value,
        max_len_field=max_len_field,
        max_len_value=max_len_value,
        keep_fields=keep_fields,
        drop_fields=drop_fields_set,
        rename_map=rename_map,
        promote_list=promote_list,
        add_field_map=add_field_map,
        fill_map=fill_map,
        reorder_fields=reorder_fields,
    )

    # ä¿å­˜ç»“æœ
    final_count = len(data)
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")

    try:
        save_data(data, output_path)
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•ä¿å­˜æ–‡ä»¶ - {e}")
        return

    # æ‰“å°ç»Ÿè®¡
    removed_count = original_count - final_count
    print("\nâœ… å®Œæˆ!")
    print(f"   åŸå§‹: {original_count} æ¡ -> æ¸…æ´—å: {final_count} æ¡ (åˆ é™¤ {removed_count} æ¡)")
    if step_stats:
        print(f"   æ­¥éª¤: {' | '.join(step_stats)}")


def _parse_rename_param(param: str) -> Dict[str, str]:
    """è§£æé‡å‘½åå‚æ•°ï¼Œæ ¼å¼ 'old:new' æˆ– 'old1:new1,old2:new2'"""
    rename_map = {}
    for pair in param.split(","):
        pair = pair.strip()
        if ":" not in pair:
            raise ValueError(f"é‡å‘½åå‚æ•°æ ¼å¼é”™è¯¯: {pair}ï¼Œåº”ä¸º 'old:new'")
        old, new = pair.split(":", 1)
        old, new = old.strip(), new.strip()
        if not old or not new:
            raise ValueError(f"é‡å‘½åå‚æ•°æ ¼å¼é”™è¯¯: {pair}ï¼Œå­—æ®µåä¸èƒ½ä¸ºç©º")
        rename_map[old] = new
    return rename_map


def _parse_promote_param(param: str) -> List[tuple]:
    """
    è§£ææå‡å‚æ•°ï¼Œæ ¼å¼ 'path' æˆ– 'path:name'ï¼ˆé€—å·åˆ†éš”å¤šä¸ªï¼‰ã€‚

    Returns:
        [(source_path, target_name), ...]
    """
    result = []
    for item in param.split(","):
        item = item.strip()
        if ":" in item:
            src, dst = item.split(":", 1)
            src, dst = src.strip(), dst.strip()
        else:
            src = item
            # é»˜è®¤ç”¨è·¯å¾„æœ€åä¸€æ®µä½œä¸ºç›®æ ‡å
            dst = src.rsplit(".", 1)[-1] if "." in src else src
        if not src or not dst:
            raise ValueError(f"promote å‚æ•°æ ¼å¼é”™è¯¯: {item}")
        result.append((src, dst))
    return result


def _parse_kv_param(param: str, param_name: str) -> Dict[str, str]:
    """è§£æ key:value æ ¼å¼å‚æ•°ï¼ˆé€šç”¨ï¼‰ï¼Œç”¨äº --add-field å’Œ --fill"""
    kv_map = {}
    for pair in param.split(","):
        pair = pair.strip()
        if ":" not in pair:
            raise ValueError(f"{param_name} å‚æ•°æ ¼å¼é”™è¯¯: {pair}ï¼Œåº”ä¸º 'key:value'")
        key, value = pair.split(":", 1)
        key, value = key.strip(), value.strip()
        if not key:
            raise ValueError(f"{param_name} å‚æ•°æ ¼å¼é”™è¯¯: {pair}ï¼Œkey ä¸èƒ½ä¸ºç©º")
        kv_map[key] = value
    return kv_map


def _rename_item(item: Dict, rename_map: Dict[str, str]) -> Dict:
    """é‡å‘½åå­—æ®µï¼Œä¿æŒå­—æ®µé¡ºåº"""
    return {rename_map.get(k, k): v for k, v in item.items()}


def _promote_fields(item: Dict, promote_list: List[tuple]) -> Dict:
    """æå‡åµŒå¥—å­—æ®µåˆ°é¡¶å±‚ï¼ˆå§‹ç»ˆæ·»åŠ å­—æ®µï¼Œå³ä½¿å€¼ä¸º Noneï¼‰"""
    item = dict(item)
    for src_path, dst_name in promote_list:
        item[dst_name] = get_field_with_spec(item, src_path)
    return item


def _add_fields(item: Dict, add_field_map: Dict[str, str]) -> Dict:
    """æ·»åŠ å¸¸é‡å­—æ®µ"""
    item = dict(item)
    item.update(add_field_map)
    return item


def _fill_empty(item: Dict, fill_map: Dict[str, str]) -> Dict:
    """å¡«å……ç©ºå€¼ï¼ˆå­—æ®µä¸å­˜åœ¨æ—¶ä¹Ÿä¼šæ·»åŠ ï¼‰"""
    item = dict(item)
    for field, default in fill_map.items():
        if field not in item or _is_empty_value(item[field]):
            item[field] = default
    return item


def _reorder_item(item: Dict, reorder_fields: List[str]) -> Dict:
    """æŒ‰æŒ‡å®šé¡ºåºé‡æ’å­—æ®µï¼Œæœªåˆ—å‡ºçš„å­—æ®µè¿½åŠ åœ¨åé¢"""
    ordered = {}
    for f in reorder_fields:
        if f in item:
            ordered[f] = item[f]
    for k, v in item.items():
        if k not in ordered:
            ordered[k] = v
    return ordered


def _parse_len_param(param: str) -> tuple:
    """è§£æé•¿åº¦å‚æ•°ï¼Œæ ¼å¼ 'field:length'"""
    if ":" not in param:
        raise ValueError(f"é•¿åº¦å‚æ•°æ ¼å¼é”™è¯¯: {param}ï¼Œåº”ä¸º 'å­—æ®µ:é•¿åº¦'")
    parts = param.split(":", 1)
    field = parts[0].strip()
    try:
        length = int(parts[1].strip())
    except ValueError as e:
        raise ValueError(f"é•¿åº¦å¿…é¡»æ˜¯æ•´æ•°: {parts[1]}") from e
    return field, length


def _clean_data_single_pass(
    data: List[Dict],
    strip: bool = False,
    empty_fields: Optional[List[str]] = None,
    min_len_field: Optional[str] = None,
    min_len_value: Optional[int] = None,
    max_len_field: Optional[str] = None,
    max_len_value: Optional[int] = None,
    keep_fields: Optional[List[str]] = None,
    drop_fields: Optional[set] = None,
    rename_map: Optional[Dict[str, str]] = None,
    promote_list: Optional[List[tuple]] = None,
    add_field_map: Optional[Dict[str, str]] = None,
    fill_map: Optional[Dict[str, str]] = None,
    reorder_fields: Optional[List[str]] = None,
) -> tuple:
    """
    å•æ¬¡éå†æ‰§è¡Œæ‰€æœ‰æ¸…æ´—æ“ä½œã€‚

    Args:
        data: åŸå§‹æ•°æ®åˆ—è¡¨
        strip: æ˜¯å¦å»é™¤å­—ç¬¦ä¸²é¦–å°¾ç©ºç™½
        empty_fields: æ£€æŸ¥ç©ºå€¼çš„å­—æ®µåˆ—è¡¨ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºæ£€æŸ¥æ‰€æœ‰å­—æ®µï¼ŒNone è¡¨ç¤ºä¸æ£€æŸ¥
        min_len_field: æœ€å°é•¿åº¦æ£€æŸ¥çš„å­—æ®µï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        min_len_value: æœ€å°é•¿åº¦å€¼
        max_len_field: æœ€å¤§é•¿åº¦æ£€æŸ¥çš„å­—æ®µï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        max_len_value: æœ€å¤§é•¿åº¦å€¼
        keep_fields: åªä¿ç•™çš„å­—æ®µåˆ—è¡¨ï¼ˆä»…æ”¯æŒé¡¶å±‚å­—æ®µï¼‰
        drop_fields: è¦åˆ é™¤çš„å­—æ®µé›†åˆï¼ˆä»…æ”¯æŒé¡¶å±‚å­—æ®µï¼‰

    Returns:
        (æ¸…æ´—åçš„æ•°æ®, ç»Ÿè®¡ä¿¡æ¯åˆ—è¡¨)
    """
    result = []
    stats = {
        "drop_empty": 0,
        "min_len": 0,
        "max_len": 0,
    }

    # é¢„å…ˆè®¡ç®— keep_fields é›†åˆï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    keep_set = set(keep_fields) if keep_fields else None

    for item in data:
        # 1. strip å¤„ç†ï¼ˆåœ¨è¿‡æ»¤å‰æ‰§è¡Œï¼Œè¿™æ ·ç©ºå€¼æ£€æµ‹æ›´å‡†ç¡®ï¼‰
        if strip:
            item = {k: v.strip() if isinstance(v, str) else v for k, v in item.items()}

        # 2. ç©ºå€¼è¿‡æ»¤
        if empty_fields is not None:
            if len(empty_fields) == 0:
                # æ£€æŸ¥æ‰€æœ‰å­—æ®µ
                if any(_is_empty_value(v) for v in item.values()):
                    stats["drop_empty"] += 1
                    continue
            else:
                # æ£€æŸ¥æŒ‡å®šå­—æ®µï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
                if any(_is_empty_value(get_field_with_spec(item, f)) for f in empty_fields):
                    stats["drop_empty"] += 1
                    continue

        # 3. æœ€å°é•¿åº¦è¿‡æ»¤ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        if min_len_field is not None:
            if _get_value_len(get_field_with_spec(item, min_len_field, default="")) < min_len_value:
                stats["min_len"] += 1
                continue

        # 4. æœ€å¤§é•¿åº¦è¿‡æ»¤ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        if max_len_field is not None:
            if _get_value_len(get_field_with_spec(item, max_len_field, default="")) > max_len_value:
                stats["max_len"] += 1
                continue

        # 5. æå‡åµŒå¥—å­—æ®µï¼ˆåœ¨ drop ä¹‹å‰ï¼Œå¦åˆ™çˆ¶å­—æ®µè¢«åˆ åæ— æ³•æå–ï¼‰
        if promote_list is not None:
            item = _promote_fields(item, promote_list)

        # 6. å­—æ®µç®¡ç†ï¼ˆkeep/dropï¼‰
        if keep_set is not None:
            item = {k: v for k, v in item.items() if k in keep_set}
        elif drop_fields is not None:
            item = {k: v for k, v in item.items() if k not in drop_fields}

        # 7. å­—æ®µé‡å‘½å
        if rename_map is not None:
            item = _rename_item(item, rename_map)

        # 8. æ·»åŠ å¸¸é‡å­—æ®µ
        if add_field_map is not None:
            item = _add_fields(item, add_field_map)

        # 9. å¡«å……ç©ºå€¼
        if fill_map is not None:
            item = _fill_empty(item, fill_map)

        # 10. å­—æ®µæ’åºï¼ˆæœ€åæ‰§è¡Œï¼‰
        if reorder_fields is not None:
            item = _reorder_item(item, reorder_fields)

        result.append(item)

    # æ„å»ºç»Ÿè®¡ä¿¡æ¯å­—ç¬¦ä¸²åˆ—è¡¨
    step_stats = []
    if strip:
        step_stats.append("strip")
    if stats["drop_empty"] > 0:
        step_stats.append(f"drop-empty: -{stats['drop_empty']}")
    if stats["min_len"] > 0:
        step_stats.append(f"min-len: -{stats['min_len']}")
    if stats["max_len"] > 0:
        step_stats.append(f"max-len: -{stats['max_len']}")
    if keep_fields:
        step_stats.append(f"keep: {len(keep_fields)} å­—æ®µ")
    if drop_fields:
        step_stats.append(f"drop: {len(drop_fields)} å­—æ®µ")
    if rename_map:
        step_stats.append(f"rename: {len(rename_map)} å­—æ®µ")
    if promote_list:
        step_stats.append(f"promote: {len(promote_list)} å­—æ®µ")
    if add_field_map:
        step_stats.append(f"add-field: {len(add_field_map)} å­—æ®µ")
    if fill_map:
        step_stats.append(f"fill: {len(fill_map)} å­—æ®µ")
    if reorder_fields:
        step_stats.append("reorder")

    return result, step_stats


def _clean_streaming(
    input_path: str,
    output_path: str,
    strip: bool = False,
    empty_fields: Optional[List[str]] = None,
    min_len_field: Optional[str] = None,
    min_len_value: Optional[int] = None,
    max_len_field: Optional[str] = None,
    max_len_value: Optional[int] = None,
    keep_set: Optional[set] = None,
    drop_fields_set: Optional[set] = None,
    rename_map: Optional[Dict[str, str]] = None,
    promote_list: Optional[List[tuple]] = None,
    add_field_map: Optional[Dict[str, str]] = None,
    fill_map: Optional[Dict[str, str]] = None,
    reorder_fields: Optional[List[str]] = None,
) -> int:
    """
    æµå¼æ¸…æ´—æ•°æ®ã€‚

    Returns:
        å¤„ç†åçš„æ•°æ®æ¡æ•°
    """

    def clean_filter(item: Dict) -> bool:
        """è¿‡æ»¤å‡½æ•°ï¼šè¿”å› True ä¿ç•™ï¼ŒFalse è¿‡æ»¤ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰"""
        # ç©ºå€¼è¿‡æ»¤
        if empty_fields is not None:
            if len(empty_fields) == 0:
                if any(_is_empty_value(v) for v in item.values()):
                    return False
            else:
                # æ”¯æŒåµŒå¥—è·¯å¾„
                if any(_is_empty_value(get_field_with_spec(item, f)) for f in empty_fields):
                    return False

        # æœ€å°é•¿åº¦è¿‡æ»¤ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        if min_len_field is not None:
            if _get_value_len(get_field_with_spec(item, min_len_field, default="")) < min_len_value:
                return False

        # æœ€å¤§é•¿åº¦è¿‡æ»¤ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        if max_len_field is not None:
            if _get_value_len(get_field_with_spec(item, max_len_field, default="")) > max_len_value:
                return False

        return True

    def clean_transform(item: Dict) -> Dict:
        """è½¬æ¢å‡½æ•°ï¼šstrip + å­—æ®µç®¡ç†"""
        # strip å¤„ç†
        if strip:
            item = {k: v.strip() if isinstance(v, str) else v for k, v in item.items()}

        # å­—æ®µç®¡ç†
        if keep_set is not None:
            item = {k: v for k, v in item.items() if k in keep_set}
        elif drop_fields_set is not None:
            item = {k: v for k, v in item.items() if k not in drop_fields_set}

        return item

    # æ„å»ºæµå¼å¤„ç†é“¾
    st = load_stream(input_path)

    # å¦‚æœéœ€è¦ stripï¼Œå…ˆæ‰§è¡Œ strip è½¬æ¢ï¼ˆåœ¨è¿‡æ»¤ä¹‹å‰ï¼Œè¿™æ ·ç©ºå€¼æ£€æµ‹æ›´å‡†ç¡®ï¼‰
    if strip:
        st = st.transform(
            lambda x: {k: v.strip() if isinstance(v, str) else v for k, v in x.items()}
        )

    # æ‰§è¡Œè¿‡æ»¤
    if empty_fields is not None or min_len_field is not None or max_len_field is not None:
        st = st.filter(clean_filter)

    # æå‡åµŒå¥—å­—æ®µï¼ˆåœ¨ drop ä¹‹å‰ï¼Œå¦åˆ™çˆ¶å­—æ®µè¢«åˆ åæ— æ³•æå–ï¼‰
    if promote_list is not None:
        st = st.transform(lambda item: _promote_fields(item, promote_list))

    # æ‰§è¡Œå­—æ®µç®¡ç†ï¼ˆkeep/dropï¼‰
    if keep_set is not None or drop_fields_set is not None:

        def field_transform(item):
            if keep_set is not None:
                return {k: v for k, v in item.items() if k in keep_set}
            elif drop_fields_set is not None:
                return {k: v for k, v in item.items() if k not in drop_fields_set}
            return item

        st = st.transform(field_transform)

    # æ‰§è¡Œå­—æ®µé‡å‘½å
    if rename_map is not None:
        st = st.transform(lambda item: _rename_item(item, rename_map))

    # æ·»åŠ å¸¸é‡å­—æ®µ
    if add_field_map is not None:
        st = st.transform(lambda item: _add_fields(item, add_field_map))

    # å¡«å……ç©ºå€¼
    if fill_map is not None:
        st = st.transform(lambda item: _fill_empty(item, fill_map))

    # å­—æ®µæ’åºï¼ˆæœ€åæ‰§è¡Œï¼‰
    if reorder_fields is not None:
        st = st.transform(lambda item: _reorder_item(item, reorder_fields))

    return st.save(output_path)
