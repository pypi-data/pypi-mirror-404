"""
DataTransformer æ ¸å¿ƒæ¨¡å—

ä¸“æ³¨äºæ•°æ®æ ¼å¼è½¬æ¢ï¼Œæä¾›ç®€æ´çš„ APIã€‚
"""

from copy import deepcopy
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Literal, Optional, Tuple, Union

import orjson

from .lineage import LineageTracker
from .storage.io import load_data, save_data
from .utils.field_path import get_field_with_spec


def _fast_json_dumps(obj: Any) -> str:
    """å¿«é€Ÿ JSON åºåˆ—åŒ–ï¼ˆä½¿ç”¨ orjsonï¼Œæ¯”æ ‡å‡† json å¿«çº¦ 10 å€ï¼‰"""
    return orjson.dumps(obj, option=orjson.OPT_SORT_KEYS).decode("utf-8")


# ============ é”™è¯¯å¤„ç† ============


@dataclass
class TransformError:
    """è½¬æ¢é”™è¯¯ä¿¡æ¯"""

    index: int  # åŸå§‹æ•°æ®ç´¢å¼•
    item: Dict  # åŸå§‹æ•°æ®é¡¹
    error: Exception  # å¼‚å¸¸å¯¹è±¡

    def __repr__(self) -> str:
        return f"TransformError(index={self.index}, error={self.error!r})"

    def __str__(self) -> str:
        # æˆªæ–­è¿‡é•¿çš„æ•°æ®å±•ç¤º
        item_str = str(self.item)
        if len(item_str) > 100:
            item_str = item_str[:100] + "..."
        return f"ç¬¬ {self.index} è¡Œè½¬æ¢å¤±è´¥: {self.error}\n  æ•°æ®: {item_str}"


class TransformErrors(Exception):
    """æ‰¹é‡è½¬æ¢é”™è¯¯ï¼ŒåŒ…å«æ‰€æœ‰å¤±è´¥çš„è®°å½•"""

    def __init__(self, errors: List[TransformError]):
        self.errors = errors
        super().__init__(self._build_message())

    def _build_message(self) -> str:
        if len(self.errors) == 1:
            return str(self.errors[0])
        return (
            f"è½¬æ¢å¤±è´¥ {len(self.errors)} æ¡è®°å½•:\n"
            + "\n".join(f"  [{e.index}] {e.error}" for e in self.errors[:5])
            + (f"\n  ... è¿˜æœ‰ {len(self.errors) - 5} æ¡é”™è¯¯" if len(self.errors) > 5 else "")
        )

    def __iter__(self):
        return iter(self.errors)

    def __len__(self):
        return len(self.errors)


def _print_error_summary(errors: List[TransformError], total: int) -> None:
    """æ‰“å°é”™è¯¯æ‘˜è¦åˆ° stderr"""
    import sys

    error_count = len(errors)
    success_count = total - error_count

    # ç®€æ´çš„è­¦å‘Šä¿¡æ¯
    print(f"âš  è½¬æ¢å®Œæˆ: {success_count}/{total} æˆåŠŸ, {error_count} å¤±è´¥", file=sys.stderr)

    # æ˜¾ç¤ºå‰å‡ æ¡é”™è¯¯è¯¦æƒ…
    show_count = min(3, error_count)
    for err in errors[:show_count]:
        print(f"  [{err.index}] {err.error}", file=sys.stderr)

    if error_count > show_count:
        print(f"  ... è¿˜æœ‰ {error_count - show_count} æ¡é”™è¯¯", file=sys.stderr)


class DataTransformer:
    """
    æ•°æ®æ ¼å¼è½¬æ¢å·¥å…·ã€‚

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - load/save: åŠ è½½å’Œä¿å­˜æ•°æ®
    - to/transform: æ ¼å¼è½¬æ¢
    - filter/sample: æ•°æ®ç­›é€‰
    - fields/stats: æ•°æ®ä¿¡æ¯
    """

    def __init__(
        self,
        data: Optional[List[Dict[str, Any]]] = None,
        _source_path: Optional[str] = None,
        _lineage_tracker: Optional[LineageTracker] = None,
    ):
        self._data = data if data is not None else []
        self._source_path = _source_path
        self._lineage_tracker = _lineage_tracker

    @property
    def data(self) -> List[Dict[str, Any]]:
        """è·å–åŸå§‹æ•°æ®"""
        return self._data

    def __len__(self) -> int:
        return len(self._data)

    def __getitem__(self, idx: Union[int, slice]) -> Union[Dict[str, Any], List[Dict[str, Any]]]:
        return self._data[idx]

    def __repr__(self) -> str:
        return f"DataTransformer({len(self._data)} items)"

    # ============ åŠ è½½/ä¿å­˜ ============

    @classmethod
    def load(cls, filepath: str, track_lineage: bool = False) -> "DataTransformer":
        """
        ä»æ–‡ä»¶åŠ è½½æ•°æ®ã€‚

        æ”¯æŒæ ¼å¼: jsonl, json, csv, parquetï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            track_lineage: æ˜¯å¦è¿½è¸ªè¡€ç¼˜ï¼ˆé»˜è®¤ Falseï¼‰
        """
        data = load_data(filepath)
        tracker = LineageTracker(filepath) if track_lineage else None
        return cls(data, _source_path=filepath, _lineage_tracker=tracker)

    def save(self, filepath: str, lineage: bool = False) -> None:
        """
        ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶ã€‚

        æ”¯æŒæ ¼å¼: jsonl, json, csv, parquetï¼ˆæ ¹æ®æ‰©å±•åï¼‰

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            lineage: æ˜¯å¦ä¿å­˜è¡€ç¼˜å…ƒæ•°æ®ï¼ˆé»˜è®¤ Falseï¼‰
        """
        save_data(self._data, filepath)

        # ä¿å­˜è¡€ç¼˜è®°å½•
        if lineage and self._lineage_tracker:
            lineage_path = self._lineage_tracker.save(filepath, len(self._data))
            import sys

            print(f"ğŸ“œ è¡€ç¼˜è®°å½•å·²ä¿å­˜: {lineage_path}", file=sys.stderr)

    # ============ æ ¸å¿ƒè½¬æ¢ ============

    def to(
        self,
        func: Callable[[Any], Any],
        on_error: Literal["skip", "raise", "null"] = "skip",
        return_errors: bool = False,
        raw: bool = False,
    ) -> Union[List[Any], Tuple[List[Any], List[TransformError]]]:
        """
        ä½¿ç”¨å‡½æ•°è½¬æ¢æ•°æ®æ ¼å¼ã€‚

        Args:
            func: è½¬æ¢å‡½æ•°ï¼Œå‚æ•°æ”¯æŒå±æ€§è®¿é—® (item.field)
            on_error: é”™è¯¯å¤„ç†ç­–ç•¥
                - "skip": è·³è¿‡é”™è¯¯è¡Œï¼Œæ‰“å°è­¦å‘Šï¼ˆé»˜è®¤ï¼‰
                - "raise": é‡åˆ°é”™è¯¯ç«‹å³æŠ›å‡ºå¼‚å¸¸
                - "null": é”™è¯¯è¡Œè¿”å› None
            return_errors: æ˜¯å¦è¿”å›é”™è¯¯åˆ—è¡¨ï¼ˆä»…å½“ on_error != "raise" æ—¶æœ‰æ•ˆï¼‰
            raw: åŸå§‹æ¨¡å¼ï¼Œç›´æ¥ä¼ é€’ dict è€Œä¸åŒ…è£…ä¸º DictWrapperï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

        Returns:
            - é»˜è®¤è¿”å›è½¬æ¢åçš„æ•°æ®åˆ—è¡¨
            - å¦‚æœ return_errors=Trueï¼Œè¿”å› (ç»“æœåˆ—è¡¨, é”™è¯¯åˆ—è¡¨)

        Raises:
            TransformErrors: å½“ on_error="raise" ä¸”æœ‰è½¬æ¢å¤±è´¥æ—¶

        Examples:
            >>> dt = DataTransformer([{"q": "é—®é¢˜", "a": "å›ç­”"}])
            >>> dt.to(lambda x: {"instruction": x.q, "output": x.a})
            [{"instruction": "é—®é¢˜", "output": "å›ç­”"}]

            >>> # ä¸¥æ ¼æ¨¡å¼ï¼šé‡é”™å³åœ
            >>> results = dt.to(transform_func, on_error="raise")

            >>> # è·å–é”™è¯¯è¯¦æƒ…
            >>> results, errors = dt.to(transform_func, return_errors=True)

            >>> # åŸå§‹æ¨¡å¼ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼Œå¤§æ•°æ®é›†æ¨èï¼‰
            >>> dt.to(lambda x: {"q": x["q"]}, raw=True)
        """
        results = []
        errors = []

        # raw æ¨¡å¼ï¼šç›´æ¥ä¼ é€’ dictï¼Œè·³è¿‡ DictWrapper åŒ…è£…
        wrapper_func = (lambda x: x) if raw else DictWrapper

        for i, item in enumerate(self._data):
            try:
                result = func(wrapper_func(item))
                results.append(result)
            except Exception as e:
                err = TransformError(index=i, item=item, error=e)

                if on_error == "raise":
                    raise TransformErrors([err]) from e
                elif on_error == "skip":
                    errors.append(err)
                elif on_error == "null":
                    results.append(None)
                    errors.append(err)

        # æ‰“å°é”™è¯¯æ‘˜è¦
        if errors and not return_errors:
            _print_error_summary(errors, len(self._data))

        if return_errors:
            return results, errors
        return results

    def transform(
        self,
        func: Callable[[Any], Any],
        on_error: Literal["skip", "raise", "null"] = "skip",
        raw: bool = False,
    ) -> "DataTransformer":
        """
        è½¬æ¢æ•°æ®å¹¶è¿”å›æ–°çš„ DataTransformerï¼ˆæ”¯æŒé“¾å¼è°ƒç”¨ï¼‰ã€‚

        Args:
            func: è½¬æ¢å‡½æ•°
            on_error: é”™è¯¯å¤„ç†ç­–ç•¥ï¼ˆåŒ to() æ–¹æ³•ï¼‰
            raw: åŸå§‹æ¨¡å¼ï¼Œç›´æ¥ä¼ é€’ dict è€Œä¸åŒ…è£…ä¸º DictWrapperï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

        Examples:
            >>> dt.transform(lambda x: {"q": x.q}).save("output.jsonl")
            >>> dt.transform(transform_func, on_error="raise").save("output.jsonl")
            >>> # åŸå§‹æ¨¡å¼ï¼ˆå¤§æ•°æ®é›†æ¨èï¼‰
            >>> dt.transform(lambda x: {"q": x["q"]}, raw=True).save("output.jsonl")
        """
        input_count = len(self._data)
        result = self.to(func, on_error=on_error, raw=raw)
        output_count = len(result)

        # ä¼ é€’è¡€ç¼˜è¿½è¸ªå™¨å¹¶è®°å½•æ“ä½œ
        tracker = self._lineage_tracker
        if tracker:
            tracker.record("transform", {"func": func}, input_count, output_count)

        return DataTransformer(result, _lineage_tracker=tracker)

    # ============ æ•°æ®ç­›é€‰ ============

    def filter(
        self,
        func: Callable[[Any], bool],
        on_error: Literal["skip", "raise", "keep"] = "skip",
        raw: bool = False,
    ) -> "DataTransformer":
        """
        ç­›é€‰æ•°æ®ã€‚

        Args:
            func: ç­›é€‰å‡½æ•°ï¼Œè¿”å› True ä¿ç•™ï¼Œå‚æ•°æ”¯æŒå±æ€§è®¿é—®
            on_error: é”™è¯¯å¤„ç†ç­–ç•¥
                - "skip": è·³è¿‡é”™è¯¯è¡Œï¼Œæ‰“å°è­¦å‘Šï¼ˆé»˜è®¤ï¼Œä¸ä¿ç•™é”™è¯¯è¡Œï¼‰
                - "raise": é‡åˆ°é”™è¯¯ç«‹å³æŠ›å‡ºå¼‚å¸¸
                - "keep": ä¿ç•™é”™è¯¯è¡Œ
            raw: åŸå§‹æ¨¡å¼ï¼Œç›´æ¥ä¼ é€’ dict è€Œä¸åŒ…è£…ä¸º DictWrapperï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰

        Examples:
            >>> dt.filter(lambda x: len(x.text) > 10)
            >>> dt.filter(lambda x: x.score > 0.5, on_error="raise")
            >>> # åŸå§‹æ¨¡å¼ï¼ˆå¤§æ•°æ®é›†æ¨èï¼‰
            >>> dt.filter(lambda x: len(x["text"]) > 10, raw=True)
        """
        filtered = []
        errors = []

        # raw æ¨¡å¼ï¼šç›´æ¥ä¼ é€’ dictï¼Œè·³è¿‡ DictWrapper åŒ…è£…
        wrapper_func = (lambda x: x) if raw else DictWrapper

        for i, item in enumerate(self._data):
            try:
                if func(wrapper_func(item)):
                    filtered.append(item)
            except Exception as e:
                err = TransformError(index=i, item=item, error=e)
                if on_error == "raise":
                    raise TransformErrors([err]) from e
                elif on_error == "keep":
                    filtered.append(item)
                    errors.append(err)
                else:  # skip
                    errors.append(err)

        # æ‰“å°é”™è¯¯æ‘˜è¦
        if errors:
            _print_error_summary(errors, len(self._data))

        # ä¼ é€’è¡€ç¼˜è¿½è¸ªå™¨å¹¶è®°å½•æ“ä½œ
        tracker = self._lineage_tracker
        if tracker:
            tracker.record("filter", {"func": func}, len(self._data), len(filtered))

        return DataTransformer(filtered, _lineage_tracker=tracker)

    def sample(self, n: int, seed: Optional[int] = None) -> "DataTransformer":
        """
        éšæœºé‡‡æ · n æ¡æ•°æ®ã€‚

        Args:
            n: é‡‡æ ·æ•°é‡
            seed: éšæœºç§å­
        """
        import random

        if seed is not None:
            random.seed(seed)

        input_count = len(self._data)
        data = self._data[:] if n >= len(self._data) else random.sample(self._data, n)

        tracker = self._lineage_tracker
        if tracker:
            tracker.record("sample", {"n": n, "seed": seed}, input_count, len(data))

        return DataTransformer(data, _lineage_tracker=tracker)

    def head(self, n: int = 10) -> "DataTransformer":
        """å–å‰ n æ¡"""
        data = self._data[:n]
        tracker = self._lineage_tracker
        if tracker:
            tracker.record("head", {"n": n}, len(self._data), len(data))
        return DataTransformer(data, _lineage_tracker=tracker)

    def tail(self, n: int = 10) -> "DataTransformer":
        """å–å n æ¡"""
        data = self._data[-n:]
        tracker = self._lineage_tracker
        if tracker:
            tracker.record("tail", {"n": n}, len(self._data), len(data))
        return DataTransformer(data, _lineage_tracker=tracker)

    def validate(
        self,
        func: Callable[[Any], bool],
        raw: bool = False,
    ) -> List[TransformError]:
        """
        éªŒè¯æ•°æ®ï¼Œè¿”å›ä¸é€šè¿‡çš„è®°å½•åˆ—è¡¨ã€‚

        Args:
            func: éªŒè¯å‡½æ•°ï¼Œè¿”å› True è¡¨ç¤ºé€šè¿‡ï¼ŒFalse è¡¨ç¤ºå¤±è´¥
            raw: åŸå§‹æ¨¡å¼ï¼Œè·³è¿‡ DictWrapper åŒ…è£…

        Returns:
            éªŒè¯å¤±è´¥çš„è®°å½•åˆ—è¡¨ï¼ˆTransformErrorï¼‰

        Examples:
            >>> dt = DataTransformer([{"a": 1}, {"a": -1}])
            >>> errors = dt.validate(lambda x: x.a > 0)
            >>> len(errors)  # 1
            >>> errors[0].index  # 1
        """
        errors = []
        wrapper_func = (lambda x: x) if raw else DictWrapper

        for i, item in enumerate(self._data):
            try:
                if not func(wrapper_func(item)):
                    errors.append(
                        TransformError(index=i, item=item, error=ValueError("éªŒè¯æœªé€šè¿‡"))
                    )
            except Exception as e:
                errors.append(TransformError(index=i, item=item, error=e))

        return errors

    def validate_schema(
        self,
        schema: "Schema",
        on_error: Literal["skip", "raise", "filter"] = "skip",
        max_errors: int = 100,
    ) -> Union["DataTransformer", List[tuple]]:
        """
        ä½¿ç”¨ Schema éªŒè¯æ•°æ®ç»“æ„ã€‚

        Args:
            schema: Schema å¯¹è±¡ï¼Œå®šä¹‰æ•°æ®ç»“æ„éªŒè¯è§„åˆ™
            on_error: é”™è¯¯å¤„ç†æ–¹å¼
                - "skip": æ‰“å°è­¦å‘Šï¼Œè¿”å›éªŒè¯å¤±è´¥çš„è®°å½•åˆ—è¡¨
                - "raise": ç¬¬ä¸€ä¸ªé”™è¯¯æ—¶æŠ›å‡ºå¼‚å¸¸
                - "filter": è¿‡æ»¤æ‰éªŒè¯å¤±è´¥çš„è®°å½•ï¼Œè¿”å›æ–°çš„ DataTransformer
            max_errors: æœ€å¤§é”™è¯¯æ•°é‡ï¼ˆon_error="skip" æ—¶ç”Ÿæ•ˆï¼‰

        Returns:
            - on_error="skip": è¿”å› [(index, ValidationResult), ...] å¤±è´¥è®°å½•åˆ—è¡¨
            - on_error="raise": æ— è¿”å›ï¼ˆæˆåŠŸï¼‰æˆ–æŠ›å‡º ValueError
            - on_error="filter": è¿”å›è¿‡æ»¤åçš„æ–° DataTransformer

        Examples:
            >>> from dtflow import Schema, Field
            >>> schema = Schema({
            ...     "messages": Field(type="list", required=True, min_length=1),
            ...     "messages[*].role": Field(type="str", choices=["user", "assistant"]),
            ... })

            >>> # è·å–éªŒè¯å¤±è´¥çš„è®°å½•
            >>> errors = dt.validate_schema(schema)
            >>> for idx, result in errors:
            ...     print(f"ç¬¬ {idx} è¡ŒéªŒè¯å¤±è´¥: {result.errors}")

            >>> # è¿‡æ»¤æ‰æ— æ•ˆè®°å½•
            >>> valid_dt = dt.validate_schema(schema, on_error="filter")

            >>> # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢
            >>> dt.validate_schema(schema, on_error="raise")
        """
        from .schema import Schema, ValidationResult

        failed: List[tuple] = []
        valid_data: List[dict] = []
        error_count = 0

        for i, item in enumerate(self._data):
            result = schema.validate(item)
            if result.valid:
                valid_data.append(item)
            else:
                failed.append((i, result))
                error_count += len(result.errors)

                if on_error == "raise":
                    error_msgs = [str(e) for e in result.errors[:3]]
                    raise ValueError(
                        f"ç¬¬ {i} è¡ŒéªŒè¯å¤±è´¥:\n  " + "\n  ".join(error_msgs)
                    )

                if on_error == "skip" and error_count >= max_errors:
                    print(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§é”™è¯¯æ•° {max_errors}ï¼Œåœæ­¢éªŒè¯")
                    break

        if on_error == "skip":
            if failed:
                print(f"âš ï¸ éªŒè¯å¤±è´¥ {len(failed)} æ¡è®°å½•ï¼ˆå…± {error_count} ä¸ªé”™è¯¯ï¼‰")
            return failed

        if on_error == "filter":
            tracker = self._lineage_tracker
            if tracker:
                tracker.record(
                    "validate_schema",
                    {"schema": repr(schema), "on_error": on_error},
                    len(self._data),
                    len(valid_data),
                )
            return DataTransformer(valid_data, _lineage_tracker=tracker)

        return failed

    def dedupe(
        self,
        key: Union[None, str, List[str], Callable[[Any], Any]] = None,
    ) -> "DataTransformer":
        """
        æ•°æ®å»é‡ã€‚

        Args:
            key: å»é‡ä¾æ®ï¼Œå¯ä»¥æ˜¯ï¼š
                - None: å…¨é‡å»é‡ï¼ˆæ•´æ¡æ•°æ®æ¯”è¾ƒï¼‰
                - str: æŒ‰å•ä¸ªå­—æ®µå»é‡
                - list[str]: æŒ‰å¤šä¸ªå­—æ®µç»„åˆå»é‡
                - callable: è‡ªå®šä¹‰ key å‡½æ•°

        Returns:
            å»é‡åçš„æ–° DataTransformer

        Examples:
            >>> dt.dedupe()                            # å…¨é‡å»é‡
            >>> dt.dedupe('text')                      # æŒ‰ text å­—æ®µå»é‡
            >>> dt.dedupe(['user', 'timestamp'])       # æŒ‰å¤šå­—æ®µç»„åˆå»é‡
            >>> dt.dedupe(lambda x: x.text.lower())    # è‡ªå®šä¹‰ key
        """
        seen = set()
        result = []

        for item in self._data:
            k = self._get_dedupe_key(item, key)
            if k not in seen:
                seen.add(k)
                result.append(item)

        tracker = self._lineage_tracker
        if tracker:
            tracker.record("dedupe", {"key": key}, len(self._data), len(result))

        return DataTransformer(result, _lineage_tracker=tracker)

    def _get_dedupe_key(
        self,
        item: Dict[str, Any],
        key: Union[None, str, List[str], Callable[[Any], Any]],
    ) -> Any:
        """
        è·å–å»é‡ç”¨çš„ keyã€‚

        æ”¯æŒå­—æ®µè·¯å¾„è¯­æ³•ï¼š
            - meta.source        åµŒå¥—å­—æ®µ
            - messages[0].role   æ•°ç»„ç´¢å¼•
            - messages[-1].role  è´Ÿç´¢å¼•
            - messages.#         æ•°ç»„é•¿åº¦
            - messages[*].role   å±•å¼€æ‰€æœ‰å…ƒç´ ï¼ˆå¯åŠ  :join/:unique æ¨¡å¼ï¼‰
        """
        if key is None:
            # å…¨é‡å»é‡ï¼šä½¿ç”¨å¿«é€Ÿ JSON åºåˆ—åŒ–
            return _fast_json_dumps(item)
        elif isinstance(key, str):
            # å•å­—æ®µï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
            val = get_field_with_spec(item, key)
            # ç¡®ä¿å¯å“ˆå¸Œ
            if isinstance(val, list):
                return tuple(val)
            return val
        elif isinstance(key, list):
            # å¤šå­—æ®µç»„åˆï¼ˆæ¯ä¸ªå­—æ®µéƒ½æ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
            vals = []
            for k in key:
                v = get_field_with_spec(item, k)
                if isinstance(v, list):
                    v = tuple(v)
                vals.append(v)
            return tuple(vals)
        elif callable(key):
            # è‡ªå®šä¹‰å‡½æ•°
            return key(DictWrapper(item))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ key ç±»å‹: {type(key)}")

    def dedupe_similar(
        self,
        key: Union[str, Callable[[Any], str]],
        threshold: float = 0.8,
        num_perm: int = 128,
        ngram: int = 3,
    ) -> "DataTransformer":
        """
        åŸºäº MinHash + LSH çš„ç›¸ä¼¼åº¦å»é‡ã€‚

        Args:
            key: ç”¨äºæ¯”è¾ƒçš„æ–‡æœ¬å­—æ®µï¼Œå¯ä»¥æ˜¯å­—æ®µåæˆ–æå–å‡½æ•°
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œ0-1 ä¹‹é—´ï¼Œé»˜è®¤ 0.8
            num_perm: MinHash ç­¾åé•¿åº¦ï¼Œè¶Šå¤§è¶Šç²¾ç¡®ä½†è¶Šæ…¢ï¼Œé»˜è®¤ 128
            ngram: n-gram å¤§å°ï¼Œé»˜è®¤ 3ï¼ˆå­—ç¬¦çº§ï¼‰

        Returns:
            å»é‡åçš„æ–° DataTransformer

        Examples:
            >>> dt.dedupe_similar('text')                    # æŒ‰ text å­—æ®µç›¸ä¼¼åº¦å»é‡
            >>> dt.dedupe_similar('text', threshold=0.9)     # æ›´ä¸¥æ ¼çš„é˜ˆå€¼
            >>> dt.dedupe_similar(lambda x: x.title + x.content)  # è‡ªå®šä¹‰æ–‡æœ¬
        """
        try:
            from datasketch import MinHash, MinHashLSH
        except ImportError:
            raise ImportError("ç›¸ä¼¼åº¦å»é‡éœ€è¦ datasketch åº“ï¼Œè¯·å®‰è£…: pip install datasketch")

        if not self._data:
            return DataTransformer([])

        # éªŒè¯å¹¶è°ƒæ•´å‚æ•°
        # MinHashLSH åœ¨é«˜é˜ˆå€¼æ—¶éœ€è¦æ›´å¤§çš„ num_permï¼Œå¦åˆ™ bands æ•°é‡ä¼šè¿‡å°
        # threshold=0.99 éœ€è¦ num_perm>=512ï¼Œthreshold>=0.999 ä¼šéœ€è¦æå¤§çš„å€¼(4096+)
        if threshold >= 0.999:
            import warnings

            warnings.warn(
                f"é˜ˆå€¼ {threshold} è¿‡é«˜ï¼Œå·²è‡ªåŠ¨è°ƒæ•´ä¸º 0.99ã€‚"
                f"å¦‚éœ€æ›´é«˜ç²¾åº¦ï¼Œå»ºè®®ä½¿ç”¨ dedupe() ç²¾ç¡®å»é‡ã€‚",
                UserWarning,
            )
            threshold = 0.99

        if threshold >= 0.99 and num_perm < 512:
            num_perm = 512
        elif threshold >= 0.95 and num_perm < 256:
            num_perm = 256

        # åˆ›å»º LSH ç´¢å¼•
        lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)
        minhashes = []

        # ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ›å»º MinHash
        for i, item in enumerate(self._data):
            text = self._get_text_for_similarity(item, key)
            m = self._create_minhash(text, num_perm, ngram)
            minhashes.append(m)
            lsh.insert(str(i), m)

        # æ‰¾å‡ºè¦ä¿ç•™çš„ç´¢å¼•ï¼ˆæ¯ä¸ªç›¸ä¼¼ç»„ä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
        keep_indices = set()
        removed_indices = set()

        for i in range(len(self._data)):
            if i in removed_indices:
                continue

            keep_indices.add(i)

            # æŸ¥è¯¢ç›¸ä¼¼æ–‡æ¡£
            similar = lsh.query(minhashes[i])
            for idx_str in similar:
                idx = int(idx_str)
                if idx != i and idx not in keep_indices:
                    removed_indices.add(idx)

        # æŒ‰åŸé¡ºåºä¿ç•™æ•°æ®
        result = [self._data[i] for i in sorted(keep_indices)]

        tracker = self._lineage_tracker
        if tracker:
            tracker.record(
                "dedupe_similar",
                {"key": key, "threshold": threshold, "num_perm": num_perm, "ngram": ngram},
                len(self._data),
                len(result),
            )

        return DataTransformer(result, _lineage_tracker=tracker)

    def _get_text_for_similarity(
        self,
        item: Dict[str, Any],
        key: Union[str, Callable[[Any], str]],
    ) -> str:
        """
        è·å–ç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒçš„æ–‡æœ¬ã€‚

        æ”¯æŒå­—æ®µè·¯å¾„è¯­æ³•ï¼ˆåŒ _get_dedupe_keyï¼‰ã€‚
        """
        if isinstance(key, str):
            val = get_field_with_spec(item, key, default="")
            return str(val) if val else ""
        elif callable(key):
            return str(key(DictWrapper(item)))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ key ç±»å‹: {type(key)}")

    def _create_minhash(self, text: str, num_perm: int, ngram: int) -> "MinHash":
        """åˆ›å»ºæ–‡æœ¬çš„ MinHash ç­¾å"""
        from datasketch import MinHash

        m = MinHash(num_perm=num_perm)
        # ä½¿ç”¨å­—ç¬¦çº§ n-gramï¼ˆå¯¹ä¸­è‹±æ–‡éƒ½é€‚ç”¨ï¼‰
        for i in range(len(text) - ngram + 1):
            m.update(text[i : i + ngram].encode("utf-8"))
        return m

    # ============ æ•°æ®ä¿¡æ¯ ============

    def fields(self) -> List[str]:
        """
        è·å–æ‰€æœ‰å­—æ®µåã€‚

        Returns:
            å­—æ®µååˆ—è¡¨ï¼ˆæŒ‰å­—æ¯æ’åºï¼‰
        """
        if not self._data:
            return []

        all_fields = set()
        for item in self._data:
            all_fields.update(self._extract_fields(item))

        return sorted(all_fields)

    def _extract_fields(self, obj: Any, prefix: str = "") -> List[str]:
        """é€’å½’æå–å­—æ®µå"""
        fields = []
        if isinstance(obj, dict):
            for key, value in obj.items():
                field_path = f"{prefix}.{key}" if prefix else key
                fields.append(field_path)
                if isinstance(value, dict):
                    fields.extend(self._extract_fields(value, field_path))
        return fields

    def stats(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯ã€‚

        Returns:
            åŒ…å« total, fields, field_stats çš„å­—å…¸
        """
        if not self._data:
            return {"total": 0, "fields": []}

        all_keys = set()
        for item in self._data:
            all_keys.update(item.keys())

        field_stats = {}
        for key in all_keys:
            values = [item.get(key) for item in self._data if key in item]
            field_stats[key] = {
                "count": len(values),
                "missing": len(self._data) - len(values),
                "type": type(values[0]).__name__ if values else "unknown",
            }

        return {"total": len(self._data), "fields": sorted(all_keys), "field_stats": field_stats}

    # ============ å·¥å…·æ–¹æ³• ============

    def copy(self) -> "DataTransformer":
        """æ·±æ‹·è´"""
        return DataTransformer(deepcopy(self._data))

    # ============ æ•°æ®åˆå¹¶ ============

    @classmethod
    def concat(cls, *sources: Union[str, "DataTransformer"]) -> "DataTransformer":
        """
        æ‹¼æ¥å¤šä¸ªæ•°æ®æºã€‚

        Args:
            *sources: æ•°æ®æºï¼Œå¯ä»¥æ˜¯æ–‡ä»¶è·¯å¾„æˆ– DataTransformer å®ä¾‹

        Returns:
            åˆå¹¶åçš„ DataTransformer

        Examples:
            >>> DataTransformer.concat("a.jsonl", "b.jsonl")
            >>> DataTransformer.concat(dt1, dt2, dt3)
            >>> DataTransformer.concat("a.jsonl", dt2)
        """
        if not sources:
            return cls([])

        all_data = []
        for source in sources:
            if isinstance(source, str):
                data = load_data(source)
            elif isinstance(source, DataTransformer):
                data = source.data
            else:
                raise TypeError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {type(source)}")
            all_data.extend(data)

        return cls(all_data)

    def __add__(self, other: Union[str, "DataTransformer"]) -> "DataTransformer":
        """
        ä½¿ç”¨ + è¿ç®—ç¬¦æ‹¼æ¥æ•°æ®ã€‚

        Examples:
            >>> merged = dt1 + dt2
            >>> merged = dt1 + "other.jsonl"
        """
        return DataTransformer.concat(self, other)

    def shuffle(self, seed: Optional[int] = None) -> "DataTransformer":
        """æ‰“ä¹±é¡ºåºï¼ˆè¿”å›æ–°å®ä¾‹ï¼‰"""
        import random

        data = self._data[:]
        if seed is not None:
            random.seed(seed)
        random.shuffle(data)

        tracker = self._lineage_tracker
        if tracker:
            tracker.record("shuffle", {"seed": seed}, len(self._data), len(data))

        return DataTransformer(data, _lineage_tracker=tracker)

    def split(self, ratio: float = 0.8, seed: Optional[int] = None) -> tuple:
        """
        åˆ†å‰²æ•°æ®é›†ã€‚

        Args:
            ratio: ç¬¬ä¸€éƒ¨åˆ†çš„æ¯”ä¾‹
            seed: éšæœºç§å­

        Returns:
            (train, test) ä¸¤ä¸ª DataTransformerï¼Œå„è‡ªæ‹¥æœ‰ç‹¬ç«‹çš„è¡€ç¼˜è¿½è¸ªå™¨
        """
        data = self.shuffle(seed).data
        split_idx = int(len(data) * ratio)

        # åˆ†å‰²åè¡€ç¼˜è¿½è¸ªå™¨å„è‡ªç‹¬ç«‹ï¼ˆä½¿ç”¨æ·±æ‹·è´é¿å…ç›¸äº’å½±å“ï¼‰
        tracker = self._lineage_tracker
        train_tracker = None
        test_tracker = None

        if tracker:
            tracker.record("split", {"ratio": ratio, "seed": seed}, len(self._data), len(data))
            # ä¸ºæ¯ä¸ªå­æ•°æ®é›†åˆ›å»ºç‹¬ç«‹çš„è¿½è¸ªå™¨å‰¯æœ¬
            train_tracker = tracker.copy()
            train_tracker.record("split_part", {"part": "train", "ratio": ratio}, len(data), split_idx)
            test_tracker = tracker.copy()
            test_tracker.record(
                "split_part", {"part": "test", "ratio": 1 - ratio}, len(data), len(data) - split_idx
            )

        return (
            DataTransformer(data[:split_idx], _lineage_tracker=train_tracker),
            DataTransformer(data[split_idx:], _lineage_tracker=test_tracker),
        )

    # ============ å¹¶è¡Œå¤„ç† ============

    def map_parallel(
        self,
        func: Callable[[Dict], Any],
        workers: Optional[int] = None,
        chunksize: int = 1000,
        timeout: Optional[float] = None,
    ) -> List[Any]:
        """
        å¹¶è¡Œæ‰§è¡Œè½¬æ¢å‡½æ•°ï¼ˆä½¿ç”¨å¤šè¿›ç¨‹ï¼‰ã€‚

        æ³¨æ„ï¼šfunc å¿…é¡»æ˜¯å¯ pickle çš„ï¼ˆä¸èƒ½æ˜¯ lambdaï¼Œéœ€è¦æ˜¯æ¨¡å—çº§å‡½æ•°ï¼‰ã€‚

        Args:
            func: è½¬æ¢å‡½æ•°ï¼Œæ¥æ”¶åŸå§‹ dictï¼Œè¿”å›è½¬æ¢ç»“æœ
            workers: è¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°
            chunksize: æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ•°æ®å—å¤§å°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone è¡¨ç¤ºæ— è¶…æ—¶

        Returns:
            è½¬æ¢åçš„ç»“æœåˆ—è¡¨

        Raises:
            TypeError: å¦‚æœ func æ— æ³•è¢« pickleï¼ˆå¦‚ lambda å‡½æ•°ï¼‰
            RuntimeError: å¦‚æœå­è¿›ç¨‹æ‰§è¡Œå‡ºé”™æˆ–è¶…æ—¶

        Examples:
            >>> def transform(item):
            ...     return {"id": item["id"], "text": item["text"].upper()}
            >>> results = dt.map_parallel(transform)
        """
        from multiprocessing import Pool, TimeoutError, cpu_count
        import pickle

        if not self._data:
            return []

        # æ£€æŸ¥å‡½æ•°æ˜¯å¦å¯ pickle
        try:
            pickle.dumps(func)
        except (pickle.PicklingError, AttributeError, TypeError) as e:
            func_name = getattr(func, "__name__", str(func))
            raise TypeError(
                f"å‡½æ•° '{func_name}' æ— æ³•è¢« pickleï¼Œä¸èƒ½ç”¨äºå¹¶è¡Œå¤„ç†ã€‚"
                f"è¯·ä½¿ç”¨æ¨¡å—çº§å‡½æ•°è€Œé lambda æˆ–é—­åŒ…ã€‚é”™è¯¯: {e}"
            ) from e

        workers = workers or cpu_count()

        try:
            with Pool(workers) as pool:
                async_result = pool.map_async(func, self._data, chunksize=chunksize)
                results = async_result.get(timeout=timeout)
        except TimeoutError:
            raise RuntimeError(f"å¹¶è¡Œå¤„ç†è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
        except Exception as e:
            raise RuntimeError(f"å¹¶è¡Œå¤„ç†å¤±è´¥: {type(e).__name__}: {e}") from e

        return results

    def filter_parallel(
        self,
        func: Callable[[Dict], bool],
        workers: Optional[int] = None,
        chunksize: int = 1000,
        timeout: Optional[float] = None,
    ) -> "DataTransformer":
        """
        å¹¶è¡Œæ‰§è¡Œè¿‡æ»¤å‡½æ•°ï¼ˆä½¿ç”¨å¤šè¿›ç¨‹ï¼‰ã€‚

        æ³¨æ„ï¼šfunc å¿…é¡»æ˜¯å¯ pickle çš„ï¼ˆä¸èƒ½æ˜¯ lambdaï¼Œéœ€è¦æ˜¯æ¨¡å—çº§å‡½æ•°ï¼‰ã€‚

        Args:
            func: è¿‡æ»¤å‡½æ•°ï¼Œæ¥æ”¶åŸå§‹ dictï¼Œè¿”å› True ä¿ç•™
            workers: è¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°
            chunksize: æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ•°æ®å—å¤§å°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone è¡¨ç¤ºæ— è¶…æ—¶

        Returns:
            è¿‡æ»¤åçš„æ–° DataTransformer

        Raises:
            TypeError: å¦‚æœ func æ— æ³•è¢« pickleï¼ˆå¦‚ lambda å‡½æ•°ï¼‰
            RuntimeError: å¦‚æœå­è¿›ç¨‹æ‰§è¡Œå‡ºé”™æˆ–è¶…æ—¶

        Examples:
            >>> def is_valid(item):
            ...     return len(item["text"]) > 10
            >>> filtered = dt.filter_parallel(is_valid)
        """
        from multiprocessing import Pool, TimeoutError, cpu_count
        import pickle

        if not self._data:
            return DataTransformer([])

        # æ£€æŸ¥å‡½æ•°æ˜¯å¦å¯ pickle
        try:
            pickle.dumps(func)
        except (pickle.PicklingError, AttributeError, TypeError) as e:
            func_name = getattr(func, "__name__", str(func))
            raise TypeError(
                f"å‡½æ•° '{func_name}' æ— æ³•è¢« pickleï¼Œä¸èƒ½ç”¨äºå¹¶è¡Œå¤„ç†ã€‚"
                f"è¯·ä½¿ç”¨æ¨¡å—çº§å‡½æ•°è€Œé lambda æˆ–é—­åŒ…ã€‚é”™è¯¯: {e}"
            ) from e

        workers = workers or cpu_count()

        try:
            with Pool(workers) as pool:
                async_result = pool.map_async(func, self._data, chunksize=chunksize)
                mask = async_result.get(timeout=timeout)
        except TimeoutError:
            raise RuntimeError(f"å¹¶è¡Œå¤„ç†è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
        except Exception as e:
            raise RuntimeError(f"å¹¶è¡Œå¤„ç†å¤±è´¥: {type(e).__name__}: {e}") from e

        filtered = [item for item, keep in zip(self._data, mask) if keep]
        return DataTransformer(filtered)

    # ============ è®­ç»ƒæ¡†æ¶é›†æˆ ============

    def check_compatibility(
        self,
        framework: Literal["llama-factory", "swift", "axolotl"],
    ) -> "CompatibilityResult":
        """
        æ£€æŸ¥æ•°æ®ä¸ç›®æ ‡è®­ç»ƒæ¡†æ¶çš„å…¼å®¹æ€§ã€‚

        Args:
            framework: ç›®æ ‡æ¡†æ¶åç§°
                - "llama-factory": LLaMA-Factory
                - "swift": ms-swift (ModelScope)
                - "axolotl": Axolotl

        Returns:
            CompatibilityResult å¯¹è±¡ï¼ŒåŒ…å« valid, errors, warnings, suggestions

        Examples:
            >>> result = dt.check_compatibility("llama-factory")
            >>> if result.valid:
            ...     print("å…¼å®¹!")
            >>> else:
            ...     print(result.errors)
        """
        from .framework import check_compatibility

        return check_compatibility(self._data, framework)

    def export_for(
        self,
        framework: Literal["llama-factory", "swift", "axolotl"],
        output_dir: str,
        dataset_name: str = "custom_dataset",
        **kwargs,
    ) -> Dict[str, str]:
        """
        ä¸€é”®å¯¼å‡ºæ•°æ®å’Œé…ç½®æ–‡ä»¶åˆ°ç›®æ ‡è®­ç»ƒæ¡†æ¶ã€‚

        Args:
            framework: ç›®æ ‡æ¡†æ¶åç§°
            output_dir: è¾“å‡ºç›®å½•
            dataset_name: æ•°æ®é›†åç§°
            **kwargs: æ¡†æ¶ç‰¹å®šå‚æ•°ï¼ˆå¦‚ model_nameï¼‰

        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„å­—å…¸ {"data": "...", "config": "...", ...}

        Examples:
            >>> # å¯¼å‡ºåˆ° LLaMA-Factory
            >>> dt.export_for("llama-factory", "./llama_ready")
            # ç”Ÿæˆ:
            # - ./llama_ready/custom_dataset.json
            # - ./llama_ready/dataset_info.json
            # - ./llama_ready/train_args.yaml

            >>> # å¯¼å‡ºåˆ° ms-swift
            >>> dt.export_for("swift", "./swift_ready", dataset_name="my_data")

            >>> # å¯¼å‡ºåˆ° Axolotl
            >>> dt.export_for("axolotl", "./axolotl_ready")
        """
        from .framework import export_for

        return export_for(
            self._data,
            framework,
            output_dir,
            dataset_name=dataset_name,
            **kwargs,
        )


def _sanitize_key(name: str) -> str:
    """å°†å­—æ®µåè§„èŒƒåŒ–ä¸ºåˆæ³•çš„ Python æ ‡è¯†ç¬¦"""
    if name.isidentifier():
        return name
    sanitized = name.replace("-", "_").replace(" ", "_").replace(".", "_")
    if sanitized and sanitized[0].isdigit():
        sanitized = "f_" + sanitized
    sanitized = "".join(c if c.isalnum() or c == "_" else "_" for c in sanitized)
    return sanitized or "field"


class DictWrapper:
    """
    å­—å…¸åŒ…è£…å™¨ï¼Œæ”¯æŒå±æ€§è®¿é—®ã€‚

    æ”¯æŒé€šè¿‡è§„èŒƒåŒ–åçš„å­—æ®µåè®¿é—®åŸå§‹é”®ï¼ˆå¦‚ item.åŸå§‹_é£é™©å¤§ç±» è®¿é—® "åŸå§‹-é£é™©å¤§ç±»"ï¼‰ã€‚

    Examples:
        >>> w = DictWrapper({"a": {"b": 1}})
        >>> w.a.b  # 1
        >>> w["a"]["b"]  # 1
        >>> w = DictWrapper({"åŸå§‹-é£é™©": "å€¼"})
        >>> w.åŸå§‹_é£é™©  # "å€¼"
    """

    def __init__(self, data: Dict[str, Any]):
        object.__setattr__(self, "_data", data)
        # æ„å»ºè§„èŒƒåŒ–åç§°åˆ°åŸå§‹åç§°çš„æ˜ å°„
        alias_map = {}
        for key in data.keys():
            sanitized = _sanitize_key(key)
            if sanitized != key:
                alias_map[sanitized] = key
        object.__setattr__(self, "_alias_map", alias_map)

    def __getattr__(self, name: str) -> Any:
        data = object.__getattribute__(self, "_data")
        alias_map = object.__getattribute__(self, "_alias_map")

        # å…ˆå°è¯•ç›´æ¥åŒ¹é…
        if name in data:
            value = data[name]
            if isinstance(value, dict):
                return DictWrapper(value)
            return value

        # å†å°è¯•é€šè¿‡åˆ«åæ˜ å°„
        if name in alias_map:
            value = data[alias_map[name]]
            if isinstance(value, dict):
                return DictWrapper(value)
            return value

        raise AttributeError(f"å­—æ®µä¸å­˜åœ¨: {name}")

    def __getitem__(self, key: str) -> Any:
        data = object.__getattribute__(self, "_data")
        value = data[key]
        if isinstance(value, dict):
            return DictWrapper(value)
        return value

    def __contains__(self, key: str) -> bool:
        data = object.__getattribute__(self, "_data")
        return key in data

    def __repr__(self) -> str:
        data = object.__getattribute__(self, "_data")
        return repr(data)

    def get(self, key: str, default: Any = None) -> Any:
        """å®‰å…¨è·å–å­—æ®µå€¼"""
        data = object.__getattribute__(self, "_data")
        value = data.get(key, default)
        if isinstance(value, dict):
            return DictWrapper(value)
        return value

    def to_dict(self) -> Dict[str, Any]:
        """è¿”å›åŸå§‹å­—å…¸"""
        return object.__getattribute__(self, "_data")
