"""
CLI IO æ“ä½œç›¸å…³å‘½ä»¤ (concat, diff)
"""

import os
import shutil
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional

import orjson

from ..storage.io import load_data, save_data
from ..streaming import load_stream
from ..utils.field_path import get_field_with_spec
from .common import _check_file_format, _is_streaming_supported


def concat(
    *files: str,
    output: Optional[str] = None,
    strict: bool = False,
) -> None:
    """
    æ‹¼æ¥å¤šä¸ªæ•°æ®æ–‡ä»¶ï¼ˆæµå¼å¤„ç†ï¼Œå†…å­˜å ç”¨ O(1)ï¼‰ã€‚

    Args:
        *files: è¾“å…¥æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œæ”¯æŒ csv/excel/jsonl/json/parquet/arrow/feather æ ¼å¼
        output: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¿…é¡»æŒ‡å®š
        strict: ä¸¥æ ¼æ¨¡å¼ï¼Œå­—æ®µå¿…é¡»å®Œå…¨ä¸€è‡´ï¼Œå¦åˆ™æŠ¥é”™

    Examples:
        dt concat a.jsonl b.jsonl -o merged.jsonl
        dt concat data1.csv data2.csv data3.csv -o all.jsonl
        dt concat a.jsonl b.jsonl --strict -o merged.jsonl
    """
    if len(files) < 2:
        print("é”™è¯¯: è‡³å°‘éœ€è¦ä¸¤ä¸ªæ–‡ä»¶")
        return

    if not output:
        print("é”™è¯¯: å¿…é¡»æŒ‡å®šè¾“å‡ºæ–‡ä»¶ (-o/--output)")
        return

    # éªŒè¯æ‰€æœ‰æ–‡ä»¶
    file_paths = []
    for f in files:
        filepath = Path(f).resolve()  # ä½¿ç”¨ç»å¯¹è·¯å¾„è¿›è¡Œæ¯”è¾ƒ
        if not filepath.exists():
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {f}")
            return
        if not _check_file_format(filepath):
            return
        file_paths.append(filepath)

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦ä¸è¾“å…¥æ–‡ä»¶å†²çª
    output_path = Path(output).resolve()
    use_temp_file = output_path in file_paths
    if use_temp_file:
        print("âš  æ£€æµ‹åˆ°è¾“å‡ºæ–‡ä»¶ä¸è¾“å…¥æ–‡ä»¶ç›¸åŒï¼Œå°†ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶")

    # æµå¼åˆ†æå­—æ®µï¼ˆåªè¯»å–æ¯ä¸ªæ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼‰
    print("ğŸ“Š æ–‡ä»¶å­—æ®µåˆ†æ:")
    file_fields = []  # [(filepath, fields)]

    for filepath in file_paths:
        try:
            # åªè¯»å–ç¬¬ä¸€è¡Œæ¥è·å–å­—æ®µï¼ˆæ ¹æ®æ ¼å¼é€‰æ‹©åŠ è½½æ–¹å¼ï¼‰
            if _is_streaming_supported(filepath):
                first_row = load_stream(str(filepath)).head(1).collect()
            else:
                # éæµå¼æ ¼å¼ï¼ˆå¦‚ .json, .xlsxï¼‰ä½¿ç”¨å…¨é‡åŠ è½½
                data = load_data(str(filepath))
                first_row = data[:1] if data else []
            if not first_row:
                print(f"è­¦å‘Š: æ–‡ä»¶ä¸ºç©º - {filepath}")
                fields = set()
            else:
                fields = set(first_row[0].keys())
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ {filepath} - {e}")
            return

        file_fields.append((filepath, fields))
        fields_str = ", ".join(sorted(fields)) if fields else "(ç©º)"
        print(f"   {filepath.name}: {fields_str}")

    # åˆ†æå­—æ®µå·®å¼‚
    all_fields = set()
    common_fields = None
    for _, fields in file_fields:
        all_fields.update(fields)
        if common_fields is None:
            common_fields = fields.copy()
        else:
            common_fields &= fields

    common_fields = common_fields or set()
    diff_fields = all_fields - common_fields

    if diff_fields:
        if strict:
            print(f"\nâŒ ä¸¥æ ¼æ¨¡å¼: å­—æ®µä¸ä¸€è‡´")
            print(f"   å…±åŒå­—æ®µ: {', '.join(sorted(common_fields)) or '(æ— )'}")
            print(f"   å·®å¼‚å­—æ®µ: {', '.join(sorted(diff_fields))}")
            return
        else:
            print(f"\nâš  å­—æ®µå·®å¼‚: {', '.join(sorted(diff_fields))} ä»…åœ¨éƒ¨åˆ†æ–‡ä»¶ä¸­å­˜åœ¨")

    # æµå¼æ‹¼æ¥
    print("\nğŸ”„ æµå¼æ‹¼æ¥...")

    # å¦‚æœè¾“å‡ºæ–‡ä»¶ä¸è¾“å…¥æ–‡ä»¶å†²çªï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼ˆåœ¨è¾“å‡ºæ–‡ä»¶åŒä¸€ç›®å½•ä¸‹ï¼‰
    if use_temp_file:
        output_dir = output_path.parent
        temp_fd, temp_path = tempfile.mkstemp(
            suffix=output_path.suffix,
            prefix=".tmp_",
            dir=output_dir,
        )
        os.close(temp_fd)
        actual_output = temp_path
        print(f"ğŸ’¾ å†™å…¥ä¸´æ—¶æ–‡ä»¶: {temp_path}")
    else:
        actual_output = output
        print(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output}")

    try:
        total_count = _concat_streaming(file_paths, actual_output)

        # å¦‚æœä½¿ç”¨äº†ä¸´æ—¶æ–‡ä»¶ï¼Œé‡å‘½åä¸ºç›®æ ‡æ–‡ä»¶
        if use_temp_file:
            shutil.move(temp_path, output)
            print(f"ğŸ’¾ ç§»åŠ¨åˆ°ç›®æ ‡æ–‡ä»¶: {output}")
    except Exception as e:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if use_temp_file and os.path.exists(temp_path):
            os.unlink(temp_path)
        print(f"é”™è¯¯: æ‹¼æ¥å¤±è´¥ - {e}")
        return

    file_count = len(files)
    print(f"\nâœ… å®Œæˆ! å·²åˆå¹¶ {file_count} ä¸ªæ–‡ä»¶ï¼Œå…± {total_count} æ¡æ•°æ®åˆ° {output}")


def _concat_streaming(file_paths: List[Path], output: str) -> int:
    """æµå¼æ‹¼æ¥å¤šä¸ªæ–‡ä»¶"""
    from ..streaming import (
        StreamingTransformer,
        _stream_arrow,
        _stream_csv,
        _stream_jsonl,
        _stream_parquet,
    )

    def generator():
        for filepath in file_paths:
            ext = filepath.suffix.lower()
            if ext == ".jsonl":
                yield from _stream_jsonl(str(filepath))
            elif ext == ".csv":
                yield from _stream_csv(str(filepath))
            elif ext == ".parquet":
                yield from _stream_parquet(str(filepath))
            elif ext in (".arrow", ".feather"):
                yield from _stream_arrow(str(filepath))
            elif ext in (".json",):
                # JSON éœ€è¦å…¨é‡åŠ è½½
                data = load_data(str(filepath))
                yield from data
            elif ext in (".xlsx", ".xls"):
                # Excel éœ€è¦å…¨é‡åŠ è½½
                data = load_data(str(filepath))
                yield from data
            else:
                yield from _stream_jsonl(str(filepath))

    st = StreamingTransformer(generator())
    return st.save(output, show_progress=True)


def diff(
    file1: str,
    file2: str,
    key: Optional[str] = None,
    output: Optional[str] = None,
) -> None:
    """
    å¯¹æ¯”ä¸¤ä¸ªæ•°æ®é›†çš„å·®å¼‚ã€‚

    Args:
        file1: ç¬¬ä¸€ä¸ªæ–‡ä»¶è·¯å¾„
        file2: ç¬¬äºŒä¸ªæ–‡ä»¶è·¯å¾„
        key: ç”¨äºåŒ¹é…çš„é”®å­—æ®µï¼Œæ”¯æŒåµŒå¥—è·¯å¾„è¯­æ³•ï¼ˆå¯é€‰ï¼‰
        output: å·®å¼‚æŠ¥å‘Šè¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰

    Examples:
        dt diff v1/train.jsonl v2/train.jsonl
        dt diff a.jsonl b.jsonl --key=id
        dt diff a.jsonl b.jsonl --key=meta.uuid   # æŒ‰åµŒå¥—å­—æ®µåŒ¹é…
        dt diff a.jsonl b.jsonl --output=diff_report.json
    """
    path1 = Path(file1)
    path2 = Path(file2)

    # éªŒè¯æ–‡ä»¶
    for p, name in [(path1, "file1"), (path2, "file2")]:
        if not p.exists():
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {p}")
            return
        if not _check_file_format(p):
            return

    # åŠ è½½æ•°æ®
    print(f"ğŸ“Š åŠ è½½æ•°æ®...")
    try:
        data1 = load_data(str(path1))
        data2 = load_data(str(path2))
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶ - {e}")
        return

    print(f"   æ–‡ä»¶1: {path1.name} ({len(data1)} æ¡)")
    print(f"   æ–‡ä»¶2: {path2.name} ({len(data2)} æ¡)")

    # è®¡ç®—å·®å¼‚
    print("ğŸ” è®¡ç®—å·®å¼‚...")
    diff_result = _compute_diff(data1, data2, key)

    # æ‰“å°å·®å¼‚æŠ¥å‘Š
    _print_diff_report(diff_result, path1.name, path2.name)

    # ä¿å­˜æŠ¥å‘Š
    if output:
        print(f"\nğŸ’¾ ä¿å­˜æŠ¥å‘Š: {output}")
        save_data([diff_result], output)


def _compute_diff(
    data1: List[Dict],
    data2: List[Dict],
    key: Optional[str] = None,
) -> Dict[str, Any]:
    """è®¡ç®—ä¸¤ä¸ªæ•°æ®é›†çš„å·®å¼‚"""
    result = {
        "summary": {
            "file1_count": len(data1),
            "file2_count": len(data2),
            "added": 0,
            "removed": 0,
            "modified": 0,
            "unchanged": 0,
        },
        "field_changes": {},
        "details": {
            "added": [],
            "removed": [],
            "modified": [],
        },
    }

    if key:
        # åŸºäº key çš„ç²¾ç¡®åŒ¹é…ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        dict1 = {get_field_with_spec(item, key): item for item in data1 if get_field_with_spec(item, key) is not None}
        dict2 = {get_field_with_spec(item, key): item for item in data2 if get_field_with_spec(item, key) is not None}

        keys1 = set(dict1.keys())
        keys2 = set(dict2.keys())

        # æ–°å¢
        added_keys = keys2 - keys1
        result["summary"]["added"] = len(added_keys)
        result["details"]["added"] = [dict2[k] for k in list(added_keys)[:10]]  # æœ€å¤šæ˜¾ç¤º 10 æ¡

        # åˆ é™¤
        removed_keys = keys1 - keys2
        result["summary"]["removed"] = len(removed_keys)
        result["details"]["removed"] = [dict1[k] for k in list(removed_keys)[:10]]

        # ä¿®æ”¹/æœªå˜
        common_keys = keys1 & keys2
        for k in common_keys:
            if dict1[k] == dict2[k]:
                result["summary"]["unchanged"] += 1
            else:
                result["summary"]["modified"] += 1
                if len(result["details"]["modified"]) < 10:
                    result["details"]["modified"].append(
                        {
                            "key": k,
                            "before": dict1[k],
                            "after": dict2[k],
                        }
                    )
    else:
        # åŸºäºå“ˆå¸Œçš„æ¯”è¾ƒ
        def _hash_item(item):
            return orjson.dumps(item, option=orjson.OPT_SORT_KEYS)

        set1 = {_hash_item(item) for item in data1}
        set2 = {_hash_item(item) for item in data2}

        added = set2 - set1
        removed = set1 - set2
        unchanged = set1 & set2

        result["summary"]["added"] = len(added)
        result["summary"]["removed"] = len(removed)
        result["summary"]["unchanged"] = len(unchanged)

        # è¯¦æƒ…
        result["details"]["added"] = [orjson.loads(h) for h in list(added)[:10]]
        result["details"]["removed"] = [orjson.loads(h) for h in list(removed)[:10]]

    # å­—æ®µå˜åŒ–åˆ†æ
    fields1 = set()
    fields2 = set()
    for item in data1[:1000]:  # é‡‡æ ·åˆ†æ
        fields1.update(item.keys())
    for item in data2[:1000]:
        fields2.update(item.keys())

    result["field_changes"] = {
        "added_fields": list(fields2 - fields1),
        "removed_fields": list(fields1 - fields2),
        "common_fields": list(fields1 & fields2),
    }

    return result


def _print_diff_report(diff_result: Dict[str, Any], name1: str, name2: str) -> None:
    """æ‰“å°å·®å¼‚æŠ¥å‘Š"""
    summary = diff_result["summary"]
    field_changes = diff_result["field_changes"]

    try:
        from rich.console import Console
        from rich.panel import Panel
        from rich.table import Table

        console = Console()

        # æ¦‚è§ˆ
        overview = (
            f"[bold]{name1}:[/bold] {summary['file1_count']:,} æ¡\n"
            f"[bold]{name2}:[/bold] {summary['file2_count']:,} æ¡\n"
            f"\n"
            f"[green]+ æ–°å¢:[/green] {summary['added']:,} æ¡\n"
            f"[red]- åˆ é™¤:[/red] {summary['removed']:,} æ¡\n"
            f"[yellow]~ ä¿®æ”¹:[/yellow] {summary['modified']:,} æ¡\n"
            f"[dim]= æœªå˜:[/dim] {summary['unchanged']:,} æ¡"
        )
        console.print(Panel(overview, title="ğŸ“Š å·®å¼‚æ¦‚è§ˆ", expand=False))

        # å­—æ®µå˜åŒ–
        if field_changes["added_fields"] or field_changes["removed_fields"]:
            console.print("\n[bold]ğŸ“‹ å­—æ®µå˜åŒ–:[/bold]")
            if field_changes["added_fields"]:
                console.print(
                    f"  [green]+ æ–°å¢å­—æ®µ:[/green] {', '.join(field_changes['added_fields'])}"
                )
            if field_changes["removed_fields"]:
                console.print(
                    f"  [red]- åˆ é™¤å­—æ®µ:[/red] {', '.join(field_changes['removed_fields'])}"
                )

    except ImportError:
        print(f"\n{'=' * 50}")
        print("ğŸ“Š å·®å¼‚æ¦‚è§ˆ")
        print(f"{'=' * 50}")
        print(f"{name1}: {summary['file1_count']:,} æ¡")
        print(f"{name2}: {summary['file2_count']:,} æ¡")
        print()
        print(f"+ æ–°å¢: {summary['added']:,} æ¡")
        print(f"- åˆ é™¤: {summary['removed']:,} æ¡")
        print(f"~ ä¿®æ”¹: {summary['modified']:,} æ¡")
        print(f"= æœªå˜: {summary['unchanged']:,} æ¡")

        if field_changes["added_fields"] or field_changes["removed_fields"]:
            print(f"\nğŸ“‹ å­—æ®µå˜åŒ–:")
            if field_changes["added_fields"]:
                print(f"  + æ–°å¢å­—æ®µ: {', '.join(field_changes['added_fields'])}")
            if field_changes["removed_fields"]:
                print(f"  - åˆ é™¤å­—æ®µ: {', '.join(field_changes['removed_fields'])}")
