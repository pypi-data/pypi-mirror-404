"""
Pipeline é…ç½®æ¨¡å—

æ”¯æŒå°†æ•°æ®å¤„ç†æµç¨‹å¯¼å‡ºä¸º YAML é…ç½®ï¼Œå®ç°å¯å¤ç°çš„æ•°æ®å¤„ç†ã€‚
"""

import random
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Union

from .core import DataTransformer
from .presets import PRESETS, get_preset
from .storage.io import load_data, save_data

# ============ Pipeline é…ç½®æ ¼å¼ ============

PIPELINE_VERSION = "1.0"


def _load_yaml(filepath: str) -> Dict[str, Any]:
    """åŠ è½½ YAML é…ç½®æ–‡ä»¶"""
    try:
        import yaml
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… PyYAML: pip install pyyaml")

    with open(filepath, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def _save_yaml(data: Dict[str, Any], filepath: str) -> None:
    """ä¿å­˜ YAML é…ç½®æ–‡ä»¶"""
    try:
        import yaml
    except ImportError:
        raise ImportError("éœ€è¦å®‰è£… PyYAML: pip install pyyaml")

    Path(filepath).parent.mkdir(parents=True, exist_ok=True)
    with open(filepath, "w", encoding="utf-8") as f:
        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, sort_keys=False)


# ============ æ­¥éª¤æ‰§è¡Œå™¨ ============


def _execute_filter(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """
    æ‰§è¡Œ filter æ­¥éª¤ã€‚

    æ”¯æŒçš„æ¡ä»¶æ ¼å¼ï¼š
    - ç®€å•æ¯”è¾ƒï¼šfield > value, field == value, field != value
    - é•¿åº¦è¿‡æ»¤ï¼šlen(field) > value
    - éç©ºè¿‡æ»¤ï¼šfield is not None, field is not empty
    """
    condition = step.get("condition", "")
    field = step.get("field")

    if not condition and not field:
        raise ValueError("filter æ­¥éª¤éœ€è¦æŒ‡å®š condition æˆ– field")

    # ç®€å•å­—æ®µéç©ºè¿‡æ»¤
    if field and not condition:
        return dt.filter(lambda x, f=field: bool(x.get(f)), raw=True)

    # è§£ææ¡ä»¶è¡¨è¾¾å¼
    filter_func = _parse_condition(condition)
    return dt.filter(filter_func, raw=True)


def _parse_condition(condition: str) -> Callable:
    """
    è§£ææ¡ä»¶è¡¨è¾¾å¼ä¸ºè¿‡æ»¤å‡½æ•°ã€‚

    æ”¯æŒçš„æ ¼å¼ï¼š
    - "score > 0.5"
    - "len(text) > 10"
    - "category == 'A'"
    - "field is not empty"
    """
    import re

    condition = condition.strip()

    # é•¿åº¦æ¯”è¾ƒï¼šlen(field) op value
    len_match = re.match(r"len\((\w+)\)\s*(>|<|>=|<=|==|!=)\s*(\d+)", condition)
    if len_match:
        field, op, value = len_match.groups()
        value = int(value)
        ops = {
            ">": lambda a, b: a > b,
            "<": lambda a, b: a < b,
            ">=": lambda a, b: a >= b,
            "<=": lambda a, b: a <= b,
            "==": lambda a, b: a == b,
            "!=": lambda a, b: a != b,
        }
        return lambda x, f=field, o=ops[op], v=value: o(len(str(x.get(f, ""))), v)

    # éç©ºåˆ¤æ–­ï¼šfield is not empty / field is not None
    nonempty_match = re.match(r"(\w+)\s+is\s+not\s+(empty|None)", condition)
    if nonempty_match:
        field = nonempty_match.group(1)
        return lambda x, f=field: bool(x.get(f))

    # æ•°å€¼æ¯”è¾ƒï¼šfield op value
    num_match = re.match(r"(\w+)\s*(>|<|>=|<=|==|!=)\s*([\d.]+)", condition)
    if num_match:
        field, op, value = num_match.groups()
        value = float(value)
        ops = {
            ">": lambda a, b: a > b,
            "<": lambda a, b: a < b,
            ">=": lambda a, b: a >= b,
            "<=": lambda a, b: a <= b,
            "==": lambda a, b: a == b,
            "!=": lambda a, b: a != b,
        }
        return lambda x, f=field, o=ops[op], v=value: o(float(x.get(f, 0)), v)

    # å­—ç¬¦ä¸²æ¯”è¾ƒï¼šfield == 'value' æˆ– field != 'value'
    str_match = re.match(r"(\w+)\s*(==|!=)\s*['\"](.+)['\"]", condition)
    if str_match:
        field, op, value = str_match.groups()
        if op == "==":
            return lambda x, f=field, v=value: x.get(f) == v
        else:
            return lambda x, f=field, v=value: x.get(f) != v

    raise ValueError(f"æ— æ³•è§£ææ¡ä»¶è¡¨è¾¾å¼: {condition}")


def _execute_transform(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """æ‰§è¡Œ transform æ­¥éª¤"""
    preset = step.get("preset")
    params = step.get("params", {})

    if not preset:
        raise ValueError("transform æ­¥éª¤éœ€è¦æŒ‡å®š preset")

    if preset not in PRESETS:
        available = ", ".join(PRESETS.keys())
        raise ValueError(f"æœªçŸ¥é¢„è®¾: {preset}ã€‚å¯ç”¨é¢„è®¾: {available}")

    transform_func = get_preset(preset, **params)
    return dt.transform(transform_func)


def _execute_dedupe(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """æ‰§è¡Œ dedupe æ­¥éª¤"""
    key = step.get("key")
    similar = step.get("similar")

    if similar is not None:
        if not key:
            raise ValueError("ç›¸ä¼¼åº¦å»é‡éœ€è¦æŒ‡å®š key")
        return dt.dedupe_similar(key, threshold=similar)

    # ç²¾ç¡®å»é‡
    if key:
        # æ”¯æŒé€—å·åˆ†éš”çš„å¤šå­—æ®µ
        if isinstance(key, str) and "," in key:
            key = [k.strip() for k in key.split(",")]
    return dt.dedupe(key)


def _execute_sample(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """æ‰§è¡Œ sample æ­¥éª¤"""
    num = step.get("num", 10)
    seed = step.get("seed")
    return dt.sample(num, seed=seed)


def _execute_head(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """æ‰§è¡Œ head æ­¥éª¤"""
    num = step.get("num", 10)
    return dt.head(num)


def _execute_tail(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """æ‰§è¡Œ tail æ­¥éª¤"""
    num = step.get("num", 10)
    return dt.tail(num)


def _execute_shuffle(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """æ‰§è¡Œ shuffle æ­¥éª¤"""
    seed = step.get("seed")
    return dt.shuffle(seed=seed)


def _execute_split(dt: DataTransformer, step: Dict[str, Any]) -> DataTransformer:
    """
    æ‰§è¡Œ split æ­¥éª¤ã€‚

    æ³¨æ„ï¼šsplit ä¼šäº§ç”Ÿä¸¤ä¸ªè¾“å‡ºï¼Œè¿™é‡Œåªè¿”å›ç¬¬ä¸€ä¸ªï¼ˆtrainï¼‰ï¼Œ
    ç¬¬äºŒä¸ªï¼ˆtestï¼‰ä¼šåœ¨ run_pipeline ä¸­ç‰¹æ®Šå¤„ç†ã€‚
    """
    ratio = step.get("ratio", 0.8)
    seed = step.get("seed")
    train, _ = dt.split(ratio=ratio, seed=seed)
    return train


# æ­¥éª¤æ‰§è¡Œå™¨æ˜ å°„
STEP_EXECUTORS = {
    "filter": _execute_filter,
    "transform": _execute_transform,
    "dedupe": _execute_dedupe,
    "sample": _execute_sample,
    "head": _execute_head,
    "tail": _execute_tail,
    "shuffle": _execute_shuffle,
    "split": _execute_split,
}


# ============ Pipeline æ‰§è¡Œå™¨ ============


def run_pipeline(
    config_path: str,
    input_file: Optional[str] = None,
    output_file: Optional[str] = None,
    verbose: bool = True,
) -> DataTransformer:
    """
    æ‰§è¡Œ Pipeline é…ç½®æ–‡ä»¶ã€‚

    Args:
        config_path: YAML é…ç½®æ–‡ä»¶è·¯å¾„
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®ä¸­çš„ inputï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®ä¸­çš„ outputï¼‰
        verbose: æ˜¯å¦æ‰“å°æ‰§è¡Œè¿‡ç¨‹

    Returns:
        å¤„ç†åçš„ DataTransformer

    Examples:
        >>> run_pipeline("pipeline.yaml")
        >>> run_pipeline("pipeline.yaml", input_file="new_data.jsonl")
    """
    # åŠ è½½é…ç½®
    config = _load_yaml(config_path)

    # éªŒè¯ç‰ˆæœ¬
    version = config.get("version", "1.0")
    if version != PIPELINE_VERSION:
        if verbose:
            print(f"âš  é…ç½®ç‰ˆæœ¬ {version} ä¸å½“å‰ç‰ˆæœ¬ {PIPELINE_VERSION} ä¸ä¸€è‡´")

    # è®¾ç½®å…¨å±€éšæœºç§å­
    seed = config.get("seed")
    if seed is not None:
        random.seed(seed)
        if verbose:
            print(f"ğŸ² è®¾ç½®éšæœºç§å­: {seed}")

    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    input_path = input_file or config.get("input")
    if not input_path:
        raise ValueError("æœªæŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼Œè¯·åœ¨é…ç½®ä¸­è®¾ç½® input æˆ–ä½¿ç”¨ --input å‚æ•°")

    # åŠ è½½æ•°æ®
    if verbose:
        print(f"ğŸ“‚ åŠ è½½æ•°æ®: {input_path}")
    dt = DataTransformer.load(input_path)
    if verbose:
        print(f"   å…± {len(dt)} æ¡æ•°æ®")

    # æ‰§è¡Œæ­¥éª¤
    steps = config.get("steps", [])
    for i, step in enumerate(steps, 1):
        step_type = step.get("type")
        if not step_type:
            raise ValueError(f"æ­¥éª¤ {i} æœªæŒ‡å®š type")

        if step_type not in STEP_EXECUTORS:
            available = ", ".join(STEP_EXECUTORS.keys())
            raise ValueError(f"æœªçŸ¥æ­¥éª¤ç±»å‹: {step_type}ã€‚å¯ç”¨ç±»å‹: {available}")

        if verbose:
            step_desc = _format_step_description(step)
            print(f"ğŸ”„ æ­¥éª¤ {i}: {step_desc}")

        before_count = len(dt)
        dt = STEP_EXECUTORS[step_type](dt, step)
        after_count = len(dt)

        if verbose and before_count != after_count:
            print(f"   {before_count} â†’ {after_count} æ¡")

    # ä¿å­˜ç»“æœ
    output_path = output_file or config.get("output")
    if output_path:
        if verbose:
            print(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")
        dt.save(output_path)
        if verbose:
            print(f"\nâœ… å®Œæˆ! å…± {len(dt)} æ¡æ•°æ®")

    return dt


def _format_step_description(step: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ­¥éª¤æè¿°"""
    step_type = step.get("type", "")

    if step_type == "filter":
        cond = step.get("condition") or step.get("field")
        return f"filter ({cond})"
    elif step_type == "transform":
        preset = step.get("preset", "")
        return f"transform ({preset})"
    elif step_type == "dedupe":
        key = step.get("key", "å…¨é‡")
        similar = step.get("similar")
        if similar:
            return f"dedupe ({key}, ç›¸ä¼¼åº¦={similar})"
        return f"dedupe ({key})"
    elif step_type == "sample":
        num = step.get("num", 10)
        return f"sample ({num})"
    elif step_type in ("head", "tail"):
        num = step.get("num", 10)
        return f"{step_type} ({num})"
    elif step_type == "shuffle":
        return "shuffle"
    elif step_type == "split":
        ratio = step.get("ratio", 0.8)
        return f"split (ratio={ratio})"
    else:
        return step_type


# ============ Pipeline æ¨¡æ¿ç”Ÿæˆ ============


def generate_pipeline_template(
    input_file: str,
    output_file: str = "pipeline.yaml",
    preset: Optional[str] = None,
) -> str:
    """
    ç”Ÿæˆ Pipeline é…ç½®æ¨¡æ¿ã€‚

    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: é…ç½®æ–‡ä»¶è¾“å‡ºè·¯å¾„

    Returns:
        ç”Ÿæˆçš„é…ç½®æ–‡ä»¶è·¯å¾„
    """
    # åˆ†æè¾“å…¥æ•°æ®
    data = load_data(input_file)
    if not data:
        raise ValueError("è¾“å…¥æ–‡ä»¶ä¸ºç©º")

    sample = data[0]
    fields = list(sample.keys())

    # æ„å»ºé…ç½®
    config = {
        "version": PIPELINE_VERSION,
        "seed": 42,
        "input": input_file,
        "output": Path(input_file).stem + "_output.jsonl",
        "steps": [],
    }

    # æ·»åŠ ç¤ºä¾‹æ­¥éª¤
    if preset:
        config["steps"].append(
            {
                "type": "transform",
                "preset": preset,
            }
        )
    else:
        # æ ¹æ®å­—æ®µæ¨æ–­å¯èƒ½çš„æ­¥éª¤
        config["steps"].append(
            {
                "type": "filter",
                "condition": f"len({fields[0]}) > 0",
            }
        )

        # å¦‚æœæœ‰ messages æˆ– q/a å­—æ®µï¼Œæ·»åŠ  transform æ­¥éª¤
        if "messages" in fields:
            pass  # å·²ç»æ˜¯ messages æ ¼å¼
        elif "q" in fields and "a" in fields:
            config["steps"].append(
                {
                    "type": "transform",
                    "preset": "openai_chat",
                    "params": {"user_field": "q", "assistant_field": "a"},
                }
            )
        elif "instruction" in fields and "output" in fields:
            config["steps"].append(
                {
                    "type": "transform",
                    "preset": "alpaca",
                }
            )

        # æ·»åŠ å»é‡æ­¥éª¤
        config["steps"].append(
            {
                "type": "dedupe",
                "key": fields[0] if fields else None,
            }
        )

    # ä¿å­˜é…ç½®
    _save_yaml(config, output_file)

    return output_file


def validate_pipeline(config_path: str) -> List[str]:
    """
    éªŒè¯ Pipeline é…ç½®æ–‡ä»¶ã€‚

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„

    Returns:
        é”™è¯¯åˆ—è¡¨ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºéªŒè¯é€šè¿‡
    """
    errors = []

    try:
        config = _load_yaml(config_path)
    except Exception as e:
        return [f"æ— æ³•è§£æé…ç½®æ–‡ä»¶: {e}"]

    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    if "steps" not in config:
        errors.append("ç¼ºå°‘ steps å­—æ®µ")

    # æ£€æŸ¥æ­¥éª¤
    steps = config.get("steps", [])
    for i, step in enumerate(steps, 1):
        if "type" not in step:
            errors.append(f"æ­¥éª¤ {i} ç¼ºå°‘ type å­—æ®µ")
            continue

        step_type = step["type"]
        if step_type not in STEP_EXECUTORS:
            available = ", ".join(STEP_EXECUTORS.keys())
            errors.append(f"æ­¥éª¤ {i}: æœªçŸ¥ç±»å‹ '{step_type}'ï¼Œå¯ç”¨: {available}")

        # ç‰¹å®šæ­¥éª¤çš„éªŒè¯
        if step_type == "transform" and "preset" not in step:
            errors.append(f"æ­¥éª¤ {i}: transform éœ€è¦æŒ‡å®š preset")

        if step_type == "filter" and not step.get("condition") and not step.get("field"):
            errors.append(f"æ­¥éª¤ {i}: filter éœ€è¦æŒ‡å®š condition æˆ– field")

    return errors
