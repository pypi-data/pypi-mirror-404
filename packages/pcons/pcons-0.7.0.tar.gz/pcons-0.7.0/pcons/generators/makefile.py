# SPDX-License-Identifier: MIT
"""GNU Makefile generator for pcons.

Generates Makefiles from a configured pcons Project.
Requires GNU Make 3.80+ for order-only prerequisites.
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import TYPE_CHECKING, Any, TextIO, cast

from pcons.core.node import FileNode, Node
from pcons.generators.generator import BaseGenerator

if TYPE_CHECKING:
    from pcons.core.environment import Environment
    from pcons.core.project import Project
    from pcons.core.target import Target


class MakefileGenerator(BaseGenerator):
    """Generator that produces GNU Makefiles.

    Generates a complete Makefile including:
    - Variable definitions
    - Directory creation rules
    - Build rules with dependencies
    - Phony targets for aliases
    - Default target
    - Depfile includes for incremental builds
    - Clean target

    Note: Requires GNU Make 3.80+ for order-only prerequisites.

    Example:
        project = Project("myapp", build_dir="build")
        # ... configure project ...

        generator = MakefileGenerator()
        generator.generate(project)
        # Creates build/Makefile
    """

    # Characters that need escaping in Makefiles
    # $ -> $$, # -> \#, spaces in targets need escaping
    ESCAPE_DOLLAR = re.compile(r"\$")

    def __init__(self) -> None:
        super().__init__("makefile")
        self._directories: set[Path] = set()
        self._depfile_dirs: set[Path] = set()
        self._project_root: Path | None = None
        self._build_dir: Path | None = None
        self._relative_build_dir: Path | None = None

    def _generate_impl(self, project: Project, output_dir: Path) -> None:
        """Generate Makefile.

        Args:
            project: Configured project to generate for.
            output_dir: Directory to write Makefile to.
        """
        output_dir.mkdir(parents=True, exist_ok=True)
        makefile_path = output_dir / "Makefile"

        # Reset state for this generation
        self._directories = set()
        self._depfile_dirs = set()
        self._project_root = project.root_dir.resolve()
        self._build_dir = output_dir
        self._relative_build_dir = project.build_dir

        with open(makefile_path, "w") as f:
            self._write_header(f, project)
            self._write_variables(f, project, output_dir)
            self._write_phony_declaration(f, project)
            self._collect_directories(project)
            self._write_directory_rules(f)
            self._write_build_rules(f, project)
            self._write_aliases(f, project)
            self._write_default_target(f, project)
            self._write_depfile_includes(f)
            self._write_clean_target(f, output_dir)

    def _write_header(self, f: TextIO, project: Project) -> None:
        """Write file header comment."""
        f.write(f"# Generated by pcons for project: {project.name}\n")
        f.write("# Do not edit - regenerate with 'pcons generate'\n")
        f.write("\n")
        # Disable built-in rules for cleaner output and faster make
        f.write("# Disable built-in rules\n")
        f.write(".SUFFIXES:\n")
        f.write("MAKEFLAGS += --no-builtin-rules\n")
        f.write("\n")

    def _write_variables(self, f: TextIO, project: Project, output_dir: Path) -> None:
        """Write global variables."""
        f.write("# Variables\n")
        f.write(f"BUILDDIR := {self._escape_path(output_dir)}\n")
        f.write("\n")

    def _write_phony_declaration(self, f: TextIO, project: Project) -> None:
        """Write .PHONY declaration for all phony targets."""
        phony_targets = ["all", "clean"]

        # Add aliases
        for name in project.aliases.keys():
            phony_targets.append(name)

        f.write("# Phony targets\n")
        f.write(f".PHONY: {' '.join(phony_targets)}\n")
        f.write("\n")

    def _collect_directories(self, project: Project) -> None:
        """Collect all directories that need to be created."""
        # Collect from targets
        for target in project.targets:
            for node in self._get_target_build_nodes(target):
                parent = node.path.parent
                if parent != Path(".") and parent != Path(""):
                    self._directories.add(parent)
                # Track depfile directories
                build_info = getattr(node, "_build_info", None) or {}
                depfile = build_info.get("depfile")
                if depfile:
                    from pcons.core.subst import PathToken

                    if isinstance(depfile, PathToken):
                        # PathToken: construct path from path + suffix
                        depfile_path = Path(depfile.path + depfile.suffix)
                        self._depfile_dirs.add(depfile_path.parent)

        # Collect from environment-tracked nodes
        for env in project.environments:
            for node in getattr(env, "_created_nodes", []):
                if isinstance(node, FileNode):
                    parent = node.path.parent
                    if parent != Path(".") and parent != Path(""):
                        self._directories.add(parent)

    def _write_directory_rules(self, f: TextIO) -> None:
        """Write rules to create directories."""
        if not self._directories:
            return

        f.write("# Directory creation\n")
        for directory in sorted(self._directories):
            # Directories need build_dir prefix stripped since make runs from build_dir
            escaped = self._make_build_relative_path(directory)
            f.write(f"{escaped}:\n")
            f.write("\tmkdir -p $@\n")
            f.write("\n")

    def _write_build_rules(self, f: TextIO, project: Project) -> None:
        """Write all build rules."""
        f.write("# Build rules\n")
        written_nodes: set[Path] = set()

        for target in project.targets:
            self._write_target_builds(f, target, project, written_nodes)

        # Also write builds for nodes tracked in environments
        for env in project.environments:
            for node in getattr(env, "_created_nodes", []):
                if isinstance(node, FileNode) and node.builder is not None:
                    if node.path not in written_nodes:
                        self._write_build_rule(f, node, None, project)
                        written_nodes.add(node.path)

        f.write("\n")

    def _write_target_builds(
        self,
        f: TextIO,
        target: Target,
        project: Project,
        written_nodes: set[Path],
    ) -> None:
        """Write build rules for a single target."""
        for node in self._get_target_build_nodes(target):
            if node.path not in written_nodes:
                self._write_build_rule(f, node, target, project)
                written_nodes.add(node.path)

    def _write_build_rule(
        self,
        f: TextIO,
        node: FileNode,
        target: Target | None,
        project: Project,
    ) -> None:
        """Write a single build rule."""
        build_info = getattr(node, "_build_info", None)
        if build_info is None:
            return

        # Skip secondary nodes from multi-output builds (they reference primary_node)
        if "primary_node" in build_info:
            return

        sources: list[Node] = build_info.get("sources", [])

        # Handle multi-output builds
        # Output paths need build_dir prefix stripped since make runs from build_dir
        outputs_info = build_info.get("outputs")
        if outputs_info:
            # Multi-output build - list all outputs
            all_outputs = [
                self._make_build_relative_path(info["path"])
                for info in outputs_info.values()
            ]
            output = " ".join(all_outputs)
        else:
            output = self._make_build_relative_path(node.path)

        # Get source paths - use PathResolver for consistent handling
        # Make runs from build directory (via make -C), so:
        # - Build outputs: strip build_dir prefix
        # - Source files: use absolute paths to work from any directory
        def get_source_path(s: FileNode) -> str:
            # Build outputs need build_dir prefix stripped
            if getattr(s, "_build_info", None) is not None or s.is_target:
                return self._make_build_relative_path(s.path)

            # Source file - make absolute using project root
            path_obj = s.path
            if not path_obj.is_absolute() and self._project_root is not None:
                path_obj = self._project_root / path_obj
            return self._escape_path(path_obj)

        # Build list of prerequisites
        prereqs: list[str] = []

        # Add sources
        for s in sources:
            if isinstance(s, FileNode):
                prereqs.append(get_source_path(s))

        # Add explicit deps (e.g., libraries for linking, generated headers)
        # All paths are stripped of build_dir prefix since make runs from build_dir
        source_paths_set = {s.path for s in sources if isinstance(s, FileNode)}
        for dep in node.explicit_deps:
            if isinstance(dep, FileNode) and dep.path not in source_paths_set:
                prereqs.append(self._make_build_relative_path(dep.path))

        # Add implicit deps (e.g., headers discovered by scanners)
        for dep in node.implicit_deps:
            if isinstance(dep, FileNode) and dep.path not in source_paths_set:
                prereqs.append(self._make_build_relative_path(dep.path))

        # Order-only prerequisites (directories)
        # Directories need build_dir prefix stripped since make runs from build_dir
        order_only: list[str] = []
        output_dir = node.path.parent
        if output_dir != Path(".") and output_dir != Path(""):
            order_only.append(self._make_build_relative_path(output_dir))

        # Build the target line
        prereq_str = " ".join(prereqs)
        if order_only:
            order_only_str = " | " + " ".join(order_only)
        else:
            order_only_str = ""

        f.write(f"{output}: {prereq_str}{order_only_str}\n")

        # Write the command
        command = self._get_command(node, target, project, sources)
        if command:
            f.write(f"\t{command}\n")

        f.write("\n")

    def _get_command(
        self,
        node: FileNode,
        target: Target | None,
        project: Project,
        sources: list[Node],
    ) -> str:
        """Get the build command for a node."""
        build_info = getattr(node, "_build_info", {})
        tool_name = build_info.get("tool", "unknown")
        command_var = build_info.get("command_var", "cmdline")

        # Get the environment from target or build_info
        env: Environment | None = None
        if target is not None:
            env = getattr(target, "_env", None)

        if env is None:
            # Check if env is stored in build_info (e.g., Install nodes)
            env = build_info.get("env")

        if env is None:
            # Try to find from project environments
            for e in project.environments:
                if node in getattr(e, "_created_nodes", []):
                    env = e
                    break

        # Check for command in build_info first (generic commands, install, archive)
        # This covers: Install, InstallAs, InstallDir, Tarfile, Zipfile, lipo, and
        # any custom builder that sets command in _build_info
        custom_command = build_info.get("command")
        if custom_command:
            # Builder provided command directly - use it
            # Command can be a list of tokens or a string
            if isinstance(custom_command, list):
                # Process PathToken objects (Makefile runs from project root,
                # so paths relative to project root don't need transformation)
                processed_tokens = self._process_path_tokens(custom_command)

                # Expand $SOURCES/$TARGET tokens to actual file paths at token level.
                # This must happen BEFORE to_shell_command() so each path is a separate
                # token and gets quoted individually (not as one space-separated string).
                expanded_tokens = self._expand_source_target_tokens(
                    processed_tokens, node, sources, build_info
                )

                # Convert token list to shell command with proper quoting
                from pcons.core.subst import to_shell_command

                command = to_shell_command(expanded_tokens, shell="bash")
            else:
                # String command - use old substitution approach
                command = str(custom_command)
                command = self._convert_command_variables(command)
                command = self._substitute_make_vars(command, node, sources, build_info)
            return self._append_post_build(command, node, target, sources)

        # Get context overrides if available
        context = build_info.get("context")
        context_overrides: dict[str, object] = {}
        if context is not None and hasattr(context, "get_env_overrides"):
            context_overrides = context.get_env_overrides()

        if env is None:
            # Try standalone tools (install, archive) when no environment is available
            cmd_template = self._get_standalone_tool_command(tool_name, command_var)
            if cmd_template is None:
                return f"@echo 'No environment for {node.path}'"

            # Process the command template
            from pcons.core.subst import to_shell_command

            # Process PathToken and SourcePath/TargetPath objects
            processed_tokens = self._process_path_tokens(cmd_template)

            # Apply context overrides for standalone tools
            if context_overrides:
                processed_tokens = self._apply_context_overrides(
                    processed_tokens, tool_name, context_overrides
                )

            # Expand SourcePath/TargetPath markers to actual paths
            expanded_tokens = self._expand_source_target_tokens(
                processed_tokens, node, sources, build_info
            )

            # Convert to shell command
            command = to_shell_command(expanded_tokens, shell="bash")
            return self._append_post_build(command, node, target, sources)

        # Get command template from tool config
        tool_config = getattr(env, tool_name, None)
        if tool_config is None:
            return f"@echo 'Unknown tool: {tool_name}'"

        command_template = getattr(tool_config, command_var, None)
        if command_template is None:
            return f"@echo 'No command template: {tool_name}.{command_var}'"

        # Expand the command template to get tokens (may include PathTokens)
        # We use the raw subst() function to get tokens, not env.subst() which
        # converts to string without proper path relativization for make.
        from pcons.core.subst import subst as subst_fn
        from pcons.core.subst import to_shell_command

        # Check if env has _build_namespace (real Environment objects do,
        # but mock objects in tests may not)
        if hasattr(env, "_build_namespace"):
            namespace = env._build_namespace()
            tokens = subst_fn(command_template, namespace)

            # Relativize PathTokens for make's execution context (make runs from build_dir)
            relativized_tokens = self._process_path_tokens(tokens)

            # Expand $SOURCES/$TARGET tokens to actual file paths at token level.
            # This must happen BEFORE to_shell_command() so each path is a separate
            # token and gets quoted individually (not as one space-separated string).
            expanded_tokens = self._expand_source_target_tokens(
                relativized_tokens, node, sources, build_info
            )

            # Convert token list to shell command string
            command = to_shell_command(expanded_tokens, shell="bash")
        else:
            # Fallback for mock objects or non-standard environments
            command = env.subst(command_template, shell="bash")
            # For fallback, still need to substitute variables
            command = self._convert_command_variables(command)
            command = self._substitute_make_vars(command, node, sources, build_info)

        # Append post-build commands if any
        command = self._append_post_build(command, node, target, sources)

        return command

    def _append_post_build(
        self,
        command: str,
        node: FileNode,
        target: Target | None,
        sources: list[Node],
    ) -> str:
        """Append post-build commands to the main command."""
        if target is None:
            return command

        # Check if this is an output node (not an intermediate object file)
        is_output_node = hasattr(target, "output_nodes") and node in target.output_nodes
        # Also check output nodes in target.nodes (for interface targets like Install)
        if not is_output_node:
            is_output_node = node in target.nodes

        if not is_output_node:
            return command

        builder_data = getattr(target, "_builder_data", {}) or {}
        post_build_cmds = builder_data.get("post_build_commands", [])
        if not post_build_cmds:
            return command

        # Substitute $out and $in in each command
        out_path = str(node.path)
        in_paths = " ".join(str(s.path) for s in sources if isinstance(s, FileNode))

        substituted_cmds = []
        for cmd in post_build_cmds:
            cmd = cmd.replace("$out", out_path)
            cmd = cmd.replace("$in", in_paths)
            substituted_cmds.append(cmd)

        # Chain commands with &&
        return command + " && " + " && ".join(substituted_cmds)

    def _quote_tokens_for_make(self, tokens: list[str]) -> str:
        """Quote and join tokens for use in Makefile shell commands.

        Handles:
        - Shell quoting for tokens with spaces or special characters
        - Escaping $ as $$ for Make
        """
        if not tokens:
            return ""

        quoted = []
        for token in tokens:
            # Escape $ as $$ for Make (must be done first)
            escaped = token.replace("$", "$$")
            # Shell quote if needed (spaces, special chars)
            if self._needs_shell_quote(escaped):
                # Use single quotes, but handle existing single quotes
                if "'" not in escaped:
                    escaped = f"'{escaped}'"
                else:
                    # Escape for double quotes
                    escaped = escaped.replace("\\", "\\\\")
                    escaped = escaped.replace('"', '\\"')
                    escaped = escaped.replace("`", "\\`")
                    escaped = f'"{escaped}"'
            quoted.append(escaped)
        return " ".join(quoted)

    def _needs_shell_quote(self, s: str) -> bool:
        """Check if a string needs shell quoting."""
        if not s:
            return True
        # Characters that trigger quoting
        return any(c in s for c in " \t\n\"'\\`!*?[](){}|&;<>")

    def _substitute_make_vars(
        self,
        command: str,
        node: FileNode,
        sources: list[Node],
        build_info: dict[str, object],
    ) -> str:
        """Substitute $in/$out with actual paths (not Make automatic vars).

        We use explicit paths rather than $< and $@ because the sources
        may not match Make's automatic variable semantics exactly.

        Note: Make runs from the build directory (via -C), so:
        - Output paths use node.path directly (relative to build_dir)
        - Source paths are made absolute to work from any directory

        $in includes both sources (from build_info) and explicit_deps (e.g.,
        libraries for linking). This matches ninja's behavior where $in is
        ALL explicit dependencies in the build statement.
        """

        # Get source paths - must match prerequisite handling in _write_build_rule
        def get_source_path(s: FileNode) -> str:
            # Build outputs - strip build_dir prefix since make runs from build_dir
            if getattr(s, "_build_info", None) is not None or s.is_target:
                return self._strip_build_dir_prefix(s.path)
            # Source files - make absolute using project root
            path_obj = s.path
            if not path_obj.is_absolute() and self._project_root is not None:
                path_obj = self._project_root / path_obj
            return str(path_obj)

        # Build $in from sources AND explicit_deps (e.g., libraries)
        # This matches ninja's behavior where $in includes all explicit deps
        in_paths: list[str] = []

        # Add sources first
        for s in sources:
            if isinstance(s, FileNode):
                in_paths.append(get_source_path(s))

        # Add explicit deps that aren't already in sources (e.g., libraries)
        source_paths_set = {s.path for s in sources if isinstance(s, FileNode)}
        for dep in node.explicit_deps:
            if isinstance(dep, FileNode) and dep.path not in source_paths_set:
                in_paths.append(get_source_path(dep))

        source_paths = " ".join(in_paths)

        # Substitute $in and $out
        # $out uses node.path with build_dir prefix stripped (make runs from build_dir)
        command = command.replace("$in", source_paths)
        command = command.replace("$out", self._strip_build_dir_prefix(node.path))

        # Handle depfile if present (also strip build_dir prefix)
        depfile = build_info.get("depfile")
        if depfile:
            from pcons.core.subst import PathToken

            if isinstance(depfile, PathToken):
                # PathToken: construct actual depfile path from path + suffix
                depfile_actual = depfile.path + depfile.suffix
                command = command.replace(
                    "$out.d", self._strip_build_dir_prefix(depfile_actual)
                )

        return command

    def _write_aliases(self, f: TextIO, project: Project) -> None:
        """Write alias targets."""
        if not project.aliases:
            return

        f.write("# Aliases\n")
        for name, alias in project.aliases.items():
            # Alias targets need build_dir prefix stripped since make runs from build_dir
            targets = " ".join(
                self._make_build_relative_path(t.path)
                for t in alias.targets
                if isinstance(t, FileNode)
            )
            if targets:
                f.write(f"{name}: {targets}\n")
        f.write("\n")

    def _write_default_target(self, f: TextIO, project: Project) -> None:
        """Write the default and 'all' targets."""
        user_defaults: list[str] = []

        # Add nodes from user-specified default targets
        for target in project.default_targets:
            if target.output_nodes:
                for out_node in target.output_nodes:
                    if isinstance(out_node, FileNode):
                        user_defaults.append(
                            self._make_build_relative_path(out_node.path)
                        )
            else:
                for target_node in target.nodes:
                    if isinstance(target_node, FileNode):
                        user_defaults.append(
                            self._make_build_relative_path(target_node.path)
                        )

        # Collect all target outputs for 'all'
        all_outputs: list[str] = []
        for target in project.targets:
            if getattr(target, "_resolved", False):
                for node in target.output_nodes:
                    if isinstance(node, FileNode):
                        all_outputs.append(self._make_build_relative_path(node.path))

        # If no resolved targets, find final nodes from env-created nodes
        if not all_outputs:
            all_outputs = self._find_final_nodes(project)

        # Collect programs and libraries for implicit default
        prog_lib_outputs: list[str] = []
        if not user_defaults:
            for target in project.targets:
                if getattr(target, "_resolved", False):
                    if target.target_type in (
                        "program",
                        "shared_library",
                        "static_library",
                    ):
                        for node in target.output_nodes:
                            if isinstance(node, FileNode):
                                prog_lib_outputs.append(
                                    self._make_build_relative_path(node.path)
                                )

        # Write targets
        f.write("# Default target\n")

        # Determine what 'make' with no args builds
        defaults = user_defaults or prog_lib_outputs or all_outputs
        if defaults:
            f.write(f"default: {' '.join(defaults)}\n")
            f.write(".DEFAULT_GOAL := default\n")

        # 'make all' builds every target in the project
        if all_outputs:
            f.write(f"all: {' '.join(all_outputs)}\n")

        f.write("\n")

    def _find_final_nodes(self, project: Project) -> list[str]:
        """Find nodes that are 'final' outputs (nothing depends on them).

        This handles cases where examples create nodes directly via
        env.cc.Object() / env.link.Program() without registering targets.

        Returns:
            List of relative paths for final output nodes.
        """
        # Collect all nodes with builders (outputs, not sources)
        output_nodes: set[Path] = set()
        # Collect all nodes that are dependencies of something
        dependency_nodes: set[Path] = set()

        for env in project.environments:
            for node in getattr(env, "_created_nodes", []):
                if isinstance(node, FileNode) and node.builder is not None:
                    output_nodes.add(node.path)
                    # Track what this node depends on
                    build_info = getattr(node, "_build_info", None) or {}
                    for source in build_info.get("sources", []):
                        if isinstance(source, FileNode):
                            dependency_nodes.add(source.path)
                    for dep in node.explicit_deps:
                        if isinstance(dep, FileNode):
                            dependency_nodes.add(dep.path)

        # Final nodes are outputs that aren't dependencies of other nodes
        final_nodes = output_nodes - dependency_nodes

        # Return relative paths
        return [self._make_build_relative_path(path) for path in sorted(final_nodes)]

    def _write_depfile_includes(self, f: TextIO) -> None:
        """Write includes for dependency files."""
        if not self._directories:
            return

        f.write("# Include dependency files (generated by compiler -MD flag)\n")
        # Include .d files from all directories that might have objects
        # Directories need build_dir prefix stripped since make runs from build_dir
        for directory in sorted(self._directories):
            f.write(f"-include {self._make_build_relative_path(directory)}/*.d\n")
        f.write("\n")

    def _write_clean_target(self, f: TextIO, output_dir: Path) -> None:
        """Write the clean target."""
        f.write("# Clean target\n")
        f.write("clean:\n")
        f.write(f"\trm -rf {self._escape_path(output_dir)}\n")

    def _strip_build_dir_prefix(self, path: Path | str) -> str:
        """Strip the build_dir prefix from a path.

        Since make runs from the build directory (via -C), paths that have
        the build_dir prefix need to have it stripped.

        Tries both the output_dir (which may be absolute) and the project's
        relative build_dir to handle canonical node paths.

        Args:
            path: Path that may have build_dir prefix.

        Returns:
            Path as string with build_dir prefix stripped if present.
        """
        path_obj = Path(path)

        if not path_obj.is_absolute():
            # Try stripping the output_dir prefix (absolute)
            if self._build_dir:
                try:
                    rel = path_obj.relative_to(self._build_dir)
                    return str(rel)
                except ValueError:
                    pass
            # Try stripping the project's relative build_dir prefix
            if self._relative_build_dir:
                try:
                    rel = path_obj.relative_to(self._relative_build_dir)
                    return str(rel)
                except ValueError:
                    pass

        return str(path_obj)

    def _escape_path(self, path: Path | str) -> str:
        """Escape a path for use in Makefiles.

        In Makefiles, $ must be escaped as $$. Spaces are tricky
        and generally should be avoided in build paths.
        """
        path_str = str(path)
        # Escape $ as $$
        return self.ESCAPE_DOLLAR.sub("$$", path_str)

    def _make_build_relative_path(self, path: Path | str) -> str:
        """Convert a path to be relative to build_dir and escape it.

        Since make runs from the build directory (via -C), output paths that
        have the build_dir prefix need to have it stripped.

        Args:
            path: Path that may have build_dir prefix.

        Returns:
            Path escaped for Makefile, with build_dir prefix stripped if present.
        """
        path_str = self._strip_build_dir_prefix(path)
        return self.ESCAPE_DOLLAR.sub("$$", path_str)

    def _process_path_tokens(self, tokens: list) -> list:
        """Process PathToken objects in a command token list.

        Since make runs from the build directory (via -C), paths need to be
        transformed:
        - Build directory paths become "."
        - Project-relative paths need to be made absolute

        SourcePath/TargetPath markers are passed through unchanged for
        _expand_source_target_tokens() to handle (it has access to node/sources).

        Uses PathToken.relativize() with _relativize_path_for_make().

        Args:
            tokens: List of command tokens (str, PathToken, SourcePath, TargetPath).

        Returns:
            List of tokens with PathTokens relativized; SourcePath/TargetPath preserved.
        """
        from pcons.core.subst import PathToken, SourcePath, TargetPath

        result: list = []
        for token in tokens:
            if isinstance(token, (SourcePath, TargetPath)):
                # Pass through for _expand_source_target_tokens() to handle
                result.append(token)
            elif isinstance(token, PathToken):
                # Use PathToken's relativize() with make path transformer
                result.append(token.relativize(self._relativize_path_for_make))
            else:
                result.append(str(token))
        return result

    def _relativize_path_for_make(self, path: str) -> str:
        """Transform a path for make's execution context.

        Since make runs from the build directory (via -C), paths that reference
        the build directory become ".", and project-relative paths need to be
        made absolute (so they work from any directory).

        Args:
            path: Path string (project-root-relative or absolute).

        Returns:
            Transformed path suitable for make command.
        """
        from pathlib import Path as PathlibPath

        path_obj = PathlibPath(path)

        # Absolute paths stay unchanged
        if path_obj.is_absolute():
            return path

        # Build directory becomes "."
        if self._build_dir:
            build_dir_str = str(self._build_dir)
            if path == build_dir_str:
                return "."
            # Paths starting with build_dir/ should strip that prefix
            if path.startswith(build_dir_str + "/"):
                return path[len(build_dir_str) + 1 :]

        # Project-relative paths need to be made absolute since make runs from build_dir
        if self._project_root:
            return str(self._project_root / path)

        return path

    def _expand_source_target_tokens(
        self,
        tokens: list,
        node: FileNode,
        sources: list[Node],
        build_info: dict[str, object],
    ) -> list[str]:
        """Expand source/target tokens to actual file paths at the token level.

        This expands pcons template variables to actual paths BEFORE shell quoting,
        so each path becomes a separate token that gets quoted individually.
        This is critical for commands like linkers where $SOURCES expands to
        multiple files.

        Handles:
        - SourcePath markers -> all input files (sources + explicit_deps)
        - TargetPath markers -> output file (with optional suffix like ".d")
        - $SOURCES, $SOURCE -> all input files (legacy string support)
        - $TARGET, $TARGETS -> output file (legacy string support)
        - $TARGET.d -> depfile path (legacy string support)
        - Embedded variables like /Fo$TARGET -> /Fo<actual_path>

        Args:
            tokens: Command tokens (str, SourcePath, or TargetPath).
            node: The output node being built.
            sources: Source nodes from build_info.
            build_info: Build info dict (for depfile).

        Returns:
            Expanded token list with sources/targets replaced by actual paths.
        """
        from pcons.core.subst import SourcePath, TargetPath

        # Helper to get a source path for make's execution context
        def get_source_path(s: FileNode) -> str:
            # Build outputs - strip build_dir prefix since make runs from build_dir
            if getattr(s, "_build_info", None) is not None or s.is_target:
                return self._strip_build_dir_prefix(s.path)
            # Source files - make absolute using project root
            path_obj = s.path
            if not path_obj.is_absolute() and self._project_root is not None:
                path_obj = self._project_root / path_obj
            return str(path_obj)

        # Build list of all input paths (sources + explicit_deps)
        in_paths: list[str] = []
        for s in sources:
            if isinstance(s, FileNode):
                in_paths.append(get_source_path(s))
        # Add explicit deps (e.g., libraries) that aren't already in sources
        source_paths_set = {s.path for s in sources if isinstance(s, FileNode)}
        for dep in node.explicit_deps:
            if isinstance(dep, FileNode) and dep.path not in source_paths_set:
                in_paths.append(get_source_path(dep))

        # Output path (single path)
        out_path = self._strip_build_dir_prefix(node.path)

        # Depfile path - get from build_info (PathToken with suffix)
        depfile = build_info.get("depfile")
        depfile_path = ""
        if depfile:
            from pcons.core.subst import PathToken

            if isinstance(depfile, PathToken):
                # PathToken: construct actual depfile path from path + suffix
                # Path is relative to build dir, strip that prefix
                depfile_path = self._strip_build_dir_prefix(
                    depfile.path + depfile.suffix
                )

        # Get all target paths for multi-output commands
        # Check both all_targets (generic commands) and outputs dict (MultiOutputBuilder)
        all_targets = build_info.get("all_targets")
        outputs_info = build_info.get("outputs")
        out_paths: list[str] = []
        if all_targets and isinstance(all_targets, list):
            # Generic command with multiple output nodes
            for t in all_targets:
                path = getattr(t, "path", None)
                if path is not None:
                    out_paths.append(self._strip_build_dir_prefix(path))
        elif outputs_info and isinstance(outputs_info, dict):
            # MultiOutputBuilder with outputs dict (e.g., SharedLibrary on Windows)
            # Outputs are ordered by insertion order in dict
            for _name, info in outputs_info.items():
                if isinstance(info, dict) and "path" in info:
                    info_dict = cast(dict[str, Any], info)
                    out_paths.append(self._strip_build_dir_prefix(info_dict["path"]))
        if not out_paths:
            out_paths = [out_path]

        # Expand tokens
        # Handle typed markers (SourcePath/TargetPath) first, then string patterns
        result: list[str] = []
        for token in tokens:
            # Handle typed marker objects (clean path)
            if isinstance(token, SourcePath):
                prefix = token.prefix if token.prefix else ""
                suffix = token.suffix if token.suffix else ""
                # Indexed access or all sources
                if token.index > 0 or any(
                    isinstance(t, SourcePath) and t.index > 0 for t in tokens
                ):
                    # Indexed access: use specific source
                    if token.index < len(in_paths):
                        result.append(f"{prefix}{in_paths[token.index]}{suffix}")
                    elif in_paths:
                        result.append(f"{prefix}{in_paths[0]}{suffix}")
                else:
                    # Non-indexed: expand to all input paths
                    for p in in_paths:
                        result.append(f"{prefix}{p}{suffix}")
            elif isinstance(token, TargetPath):
                # Indexed access or single output
                prefix = token.prefix if token.prefix else ""
                suffix = token.suffix if token.suffix else ""
                if token.index > 0 or any(
                    isinstance(t, TargetPath) and t.index > 0 for t in tokens
                ):
                    # Indexed access: use specific target
                    if token.index < len(out_paths):
                        result.append(f"{prefix}{out_paths[token.index]}{suffix}")
                    else:
                        result.append(f"{prefix}{out_path}{suffix}")
                else:
                    # Non-indexed: use primary output
                    result.append(f"{prefix}{out_path}{suffix}")
            # Handle string patterns (legacy support)
            elif isinstance(token, str):
                if token in ("$SOURCES", "$SOURCE", "$in"):
                    # Expand to multiple path tokens (one per file)
                    result.extend(in_paths)
                elif token in ("$TARGET", "$TARGETS", "$out"):
                    result.append(out_path)
                elif token in ("$TARGET.d", "$out.d"):
                    result.append(depfile_path if depfile_path else token)
                elif (
                    "$TARGET" in token
                    or "$SOURCE" in token
                    or "$in" in token
                    or "$out" in token
                ):
                    # Handle embedded variables like /Fo$TARGET or -MF$TARGET.d
                    # These are single tokens with variables inside
                    # Also handles ninja-style $in/$out embedded in tokens
                    expanded = token
                    # Order matters: $TARGET.d/$out.d before $TARGET/$out,
                    # $TARGETS before $TARGET, $SOURCES before $SOURCE
                    if "$TARGET.d" in expanded:
                        expanded = expanded.replace(
                            "$TARGET.d", depfile_path if depfile_path else "$TARGET.d"
                        )
                    if "$out.d" in expanded:
                        expanded = expanded.replace(
                            "$out.d", depfile_path if depfile_path else "$out.d"
                        )
                    if "$TARGETS" in expanded:
                        expanded = expanded.replace("$TARGETS", out_path)
                    if "$TARGET" in expanded:
                        expanded = expanded.replace("$TARGET", out_path)
                    if "$out" in expanded:
                        expanded = expanded.replace("$out", out_path)
                    if "$SOURCES" in expanded:
                        # For embedded $SOURCES, join with space (unusual case)
                        expanded = expanded.replace("$SOURCES", " ".join(in_paths))
                    if "$SOURCE" in expanded:
                        # For embedded $SOURCE, use first source
                        first_source = in_paths[0] if in_paths else ""
                        expanded = expanded.replace("$SOURCE", first_source)
                    if "$in" in expanded:
                        # For embedded $in, join with space (unusual case)
                        expanded = expanded.replace("$in", " ".join(in_paths))
                    result.append(expanded)
                else:
                    result.append(token)
            else:
                # Unknown type - convert to string
                result.append(str(token))

        return result

    def _convert_command_variables(self, command: str) -> str:
        """Convert generator-agnostic variables to Make-compatible variables.

        Converts pcons template variables to intermediate $in/$out:
        - $SOURCE, $SOURCES -> $in
        - $TARGET, $TARGETS -> $out
        - $TARGET.d -> $out.d (depfile pattern)
        - $TARGET_xxx -> $out_xxx (multi-output pattern)
        - ${SOURCES[n]} -> indexed source (handled later)
        - ${TARGETS[n]} -> indexed target (handled later)

        These intermediate variables are then substituted with actual paths
        by _substitute_make_vars().

        Args:
            command: The command template with generator-agnostic variables.

        Returns:
            Command with Make-compatible variables.
        """
        import re

        # Convert plural forms first (so they don't match singular)
        command = command.replace("$SOURCES", "$in")
        command = command.replace("$TARGETS", "$out")

        # Convert singular forms
        command = command.replace("$SOURCE", "$in")
        # Handle $TARGET_xxx patterns before plain $TARGET (e.g., $TARGET_import_lib)
        command = re.sub(r"\$TARGET_(\w+)", r"$out_\1", command)
        # Handle $TARGET.d pattern for depfiles
        command = command.replace("$TARGET.d", "$out.d")
        # Convert plain $TARGET
        command = command.replace("$TARGET", "$out")

        # Handle indexed access ${SOURCES[n]} and ${TARGETS[n]}
        # These need special handling - for now, expand to all sources/targets
        # (Makefile doesn't have a direct equivalent for indexed access)
        command = re.sub(r"\$\{SOURCES\[\d+\]\}", "$in", command)
        command = re.sub(r"\$\{TARGETS\[\d+\]\}", "$out", command)

        return command

    def _get_standalone_tool_command(
        self, tool_name: str, command_var: str
    ) -> list | None:
        """Get command template from a standalone tool.

        Used when no environment is available (e.g., Install targets without
        an associated env). Instantiates the standalone tool to get its
        default command template.

        Args:
            tool_name: Tool name (e.g., "install", "archive").
            command_var: Command variable name (e.g., "copycmd", "tarcmd").

        Returns:
            Command template as list of tokens (may include SourcePath/TargetPath
            markers), or None if not available.
        """
        # Import standalone tools here to avoid circular imports
        if tool_name == "install":
            from pcons.tools.install import InstallTool

            tool = InstallTool()
        elif tool_name == "archive":
            from pcons.tools.archive import ArchiveTool

            tool = ArchiveTool()
        else:
            return None

        defaults = tool.default_vars()
        cmd_template = defaults.get(command_var)
        if cmd_template is None:
            return None

        # Return as list, preserving SourcePath/TargetPath markers
        if isinstance(cmd_template, list):
            return list(cmd_template)

        return [cmd_template]

    def _apply_context_overrides(
        self, tokens: list[str], tool_name: str, context_overrides: dict[str, object]
    ) -> list[str]:
        """Apply context overrides to command tokens.

        Replaces $tool.var patterns with actual values from context overrides.

        Args:
            tokens: List of command tokens.
            tool_name: Tool name for pattern matching.
            context_overrides: Dict of override values.

        Returns:
            Modified token list with overrides applied.
        """
        from pcons.core.subst import SourcePath, TargetPath

        result: list[str] = []
        for token in tokens:
            # Pass through marker objects without modification
            if isinstance(token, (SourcePath, TargetPath)):
                result.append(token)
                continue

            modified = str(token)
            for key, val in context_overrides.items():
                pattern = f"${tool_name}.{key}"
                if pattern in modified:
                    if isinstance(val, list):
                        val_str = " ".join(str(v) for v in val)
                    else:
                        val_str = str(val)
                    modified = modified.replace(pattern, val_str)
            result.append(modified)
        return result
