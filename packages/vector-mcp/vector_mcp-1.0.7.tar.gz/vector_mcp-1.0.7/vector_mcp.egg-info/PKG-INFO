Metadata-Version: 2.4
Name: vector-mcp
Version: 1.0.7
Summary: Integrate RAG into AI Agents via MCP Server. Supports multiple Vector database technologies.
Author-email: Audel Rouhi <knucklessg1@gmail.com>
Classifier: Development Status :: 5 - Production/Stable
Classifier: License :: Public Domain
Classifier: Environment :: Console
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: fastmcp>=3.0.0b1
Requires-Dist: markdownify>=1.2.2
Requires-Dist: beautifulsoup4>=4.14.3
Requires-Dist: ebooklib>=0.19
Requires-Dist: html2text>=2025.4.15
Requires-Dist: ipython>=9.9.0
Requires-Dist: pypdf>=6.6.2
Requires-Dist: protobuf>=6.33.4
Requires-Dist: llama-index-core>=0.14.13
Requires-Dist: llama-index-llms-langchain>=0.7.1
Requires-Dist: llama-index-vector-stores-chroma>=0.5.5
Requires-Dist: chromadb>=1.4.1
Requires-Dist: llama-index-readers-file>=0.2.0
Requires-Dist: eunomia-mcp>=0.3.10
Provides-Extra: pgvector
Requires-Dist: pgvector>=0.4.2; extra == "pgvector"
Requires-Dist: psycopg>=3.3.2; extra == "pgvector"
Requires-Dist: llama-index-vector-stores-postgres>=0.7.3; extra == "pgvector"
Provides-Extra: chromadb
Requires-Dist: chromadb>=1.4.1; extra == "chromadb"
Requires-Dist: llama-index-vector-stores-chroma>=0.5.5; extra == "chromadb"
Provides-Extra: couchbase
Requires-Dist: couchbase>=4.5.0; extra == "couchbase"
Requires-Dist: llama-index-vector-stores-couchbase>=0.6.0; extra == "couchbase"
Provides-Extra: qdrant
Requires-Dist: qdrant-client>=1.16.2; extra == "qdrant"
Requires-Dist: fastembed>=0.7.4; extra == "qdrant"
Requires-Dist: llama-index-vector-stores-qdrant>=0.9.1; extra == "qdrant"
Provides-Extra: mongodb
Requires-Dist: pymongo>=4.16.0; extra == "mongodb"
Requires-Dist: llama-index-vector-stores-mongodb>=0.9.1; extra == "mongodb"
Provides-Extra: huggingface
Requires-Dist: llama-index-embeddings-huggingface>=0.6.1; extra == "huggingface"
Requires-Dist: sentence_transformers>=5.2.2; extra == "huggingface"
Provides-Extra: a2a
Requires-Dist: pydantic-ai-slim[a2a,ag-ui,anthropic,fastmcp,google,huggingface,openai,web]>=1.48.0; extra == "a2a"
Requires-Dist: pydantic-ai-skills>=0.4.0; extra == "a2a"
Requires-Dist: fastapi>=0.128.0; extra == "a2a"
Provides-Extra: all
Requires-Dist: fastmcp>=3.0.0b1; extra == "all"
Requires-Dist: sentence_transformers>=5.2.2; extra == "all"
Requires-Dist: markdownify>=1.2.2; extra == "all"
Requires-Dist: beautifulsoup4>=4.14.3; extra == "all"
Requires-Dist: ebooklib>=0.19; extra == "all"
Requires-Dist: html2text>=2025.4.15; extra == "all"
Requires-Dist: ipython>=9.9.0; extra == "all"
Requires-Dist: pypdf>=6.6.2; extra == "all"
Requires-Dist: protobuf>=6.33.4; extra == "all"
Requires-Dist: llama-index-core>=0.14.13; extra == "all"
Requires-Dist: llama-index-llms-langchain>=0.7.1; extra == "all"
Requires-Dist: llama-index-embeddings-huggingface>=0.6.1; extra == "all"
Requires-Dist: llama-index-vector-stores-mongodb>=0.9.1; extra == "all"
Requires-Dist: llama-index-vector-stores-qdrant>=0.9.1; extra == "all"
Requires-Dist: llama-index-vector-stores-couchbase>=0.6.0; extra == "all"
Requires-Dist: llama-index-vector-stores-chroma>=0.5.5; extra == "all"
Requires-Dist: llama-index-vector-stores-postgres>=0.7.3; extra == "all"
Requires-Dist: pgvector>=0.4.2; extra == "all"
Requires-Dist: psycopg>=3.3.2; extra == "all"
Requires-Dist: chromadb>=1.4.1; extra == "all"
Requires-Dist: couchbase>=4.5.0; extra == "all"
Requires-Dist: qdrant-client>=1.16.2; extra == "all"
Requires-Dist: fastembed>=0.7.4; extra == "all"
Requires-Dist: pymongo>=4.16.0; extra == "all"
Requires-Dist: pydantic-ai-slim[a2a,ag-ui,anthropic,fastmcp,google,huggingface,openai,web]>=1.48.0; extra == "all"
Requires-Dist: pydantic-ai-skills>=0.4.0; extra == "all"
Requires-Dist: fastapi>=0.128.0; extra == "all"
Dynamic: license-file

# Vector Database - A2A | AG-UI | MCP

![PyPI - Version](https://img.shields.io/pypi/v/vector-mcp)
![MCP Server](https://badge.mcpx.dev?type=server 'MCP Server')
![PyPI - Downloads](https://img.shields.io/pypi/dd/vector-mcp)
![GitHub Repo stars](https://img.shields.io/github/stars/Knuckles-Team/vector-mcp)
![GitHub forks](https://img.shields.io/github/forks/Knuckles-Team/vector-mcp)
![GitHub contributors](https://img.shields.io/github/contributors/Knuckles-Team/vector-mcp)
![PyPI - License](https://img.shields.io/pypi/l/vector-mcp)
![GitHub](https://img.shields.io/github/license/Knuckles-Team/vector-mcp)

![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Knuckles-Team/vector-mcp)
![GitHub pull requests](https://img.shields.io/github/issues-pr/Knuckles-Team/vector-mcp)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/Knuckles-Team/vector-mcp)
![GitHub issues](https://img.shields.io/github/issues/Knuckles-Team/vector-mcp)

![GitHub top language](https://img.shields.io/github/languages/top/Knuckles-Team/vector-mcp)
![GitHub language count](https://img.shields.io/github/languages/count/Knuckles-Team/vector-mcp)
![GitHub repo size](https://img.shields.io/github/repo-size/Knuckles-Team/vector-mcp)
![GitHub repo file count (file type)](https://img.shields.io/github/directory-file-count/Knuckles-Team/vector-mcp)
![PyPI - Wheel](https://img.shields.io/pypi/wheel/vector-mcp)
![PyPI - Implementation](https://img.shields.io/pypi/implementation/vector-mcp)

*Version: 1.0.7*

## Overview

This is an MCP Server implementation which allows for a standardized
collection management system across vector database technologies.

This was heavily inspired by the RAG implementation of Microsoft's Autogen V1 framework, however,
this was changed to an MCP server model instead.

AI Agents can:

- Hybrid search for document information (lexical/vector)
- Create collections with documents stored on the local filesystem or URLs
- Add documents to a collection
- Utilize collection for retrieval augmented generation (RAG)
- Delete collection

Supports:

- ChromaDB
- PGVector
- Couchbase
- Qdrant
- MongoDB

This repository is actively maintained - Contributions and bug reports are welcome!

Automated tests are planned

## MCP

### MCP Tools

| Function Name       | Description                                                                                                                        | Tag(s)                  |
|:--------------------|:-----------------------------------------------------------------------------------------------------------------------------------|:------------------------|
| `create_collection` | Creates a new collection or retrieves an existing one in the vector database.                                                      | `collection_management` |
| `semantic_search`           | Retrieves and gathers related knowledge from the vector database instance using the question variable.                             | `semantic_search`              |
| `add_documents`     | Adds documents to an existing collection in the vector database. This can be used to extend collections with additional documents. | `collection_management` |
| `delete_collection` | Deletes a collection from the vector database.                                                                                     | `collection_management` |
| `list_collections`  | Lists all collections in the vector database.                                                                                      | `collection_management` |

## A2A Agent

### Architecture:

```mermaid
---
config:
  layout: dagre
---
flowchart TB
 subgraph subGraph0["Agent Capabilities"]
        C["Agent"]
        B["A2A Server - Uvicorn/FastAPI"]
        D["MCP Tools"]
        F["Agent Skills"]
  end
    C --> D & F
    A["User Query"] --> B
    B --> C
    D --> E["Platform API"]

     C:::agent
     B:::server
     A:::server
    classDef server fill:#f9f,stroke:#333
    classDef agent fill:#bbf,stroke:#333,stroke-width:2px
    style B stroke:#000000,fill:#FFD600
    style D stroke:#000000,fill:#BBDEFB
    style F fill:#BBDEFB
    style A fill:#C8E6C9
    style subGraph0 fill:#FFF9C4
```

### Component Interaction Diagram

```mermaid
sequenceDiagram
    participant User
    participant Server as A2A Server
    participant Agent as Agent
    participant Skill as Agent Skills
    participant MCP as MCP Tools

    User->>Server: Send Query
    Server->>Agent: Invoke Agent
    Agent->>Skill: Analyze Skills Available
    Skill->>Agent: Provide Guidance on Next Steps
    Agent->>MCP: Invoke Tool
    MCP-->>Agent: Tool Response Returned
    Agent-->>Agent: Return Results Summarized
    Agent-->>Server: Final Response
    Server-->>User: Output
```

## Usage


### MCP CLI

| Short Flag | Long Flag                          | Description                                                                 |
|------------|------------------------------------|-----------------------------------------------------------------------------|
| -h         | --help                             | Display help information                                                    |
| -t         | --transport                        | Transport method: 'stdio', 'http', or 'sse' [legacy] (default: stdio)       |
| -s         | --host                             | Host address for HTTP transport (default: 0.0.0.0)                          |
| -p         | --port                             | Port number for HTTP transport (default: 8000)                              |
|            | --auth-type                        | Authentication type: 'none', 'static', 'jwt', 'oauth-proxy', 'oidc-proxy', 'remote-oauth' (default: none) |
|            | --token-jwks-uri                   | JWKS URI for JWT verification                                              |
|            | --token-issuer                     | Issuer for JWT verification                                                |
|            | --token-audience                   | Audience for JWT verification                                              |
|            | --oauth-upstream-auth-endpoint     | Upstream authorization endpoint for OAuth Proxy                             |
|            | --oauth-upstream-token-endpoint    | Upstream token endpoint for OAuth Proxy                                    |
|            | --oauth-upstream-client-id         | Upstream client ID for OAuth Proxy                                         |
|            | --oauth-upstream-client-secret     | Upstream client secret for OAuth Proxy                                     |
|            | --oauth-base-url                   | Base URL for OAuth Proxy                                                   |
|            | --oidc-config-url                  | OIDC configuration URL                                                     |
|            | --oidc-client-id                   | OIDC client ID                                                             |
|            | --oidc-client-secret               | OIDC client secret                                                         |
|            | --oidc-base-url                    | Base URL for OIDC Proxy                                                    |
|            | --remote-auth-servers              | Comma-separated list of authorization servers for Remote OAuth             |
|            | --remote-base-url                  | Base URL for Remote OAuth                                                  |
|            | --allowed-client-redirect-uris     | Comma-separated list of allowed client redirect URIs                       |
|            | --eunomia-type                     | Eunomia authorization type: 'none', 'embedded', 'remote' (default: none)   |
|            | --eunomia-policy-file              | Policy file for embedded Eunomia (default: mcp_policies.json)              |
|            | --eunomia-remote-url               | URL for remote Eunomia server                                              |

### Using as an MCP Server

The MCP Server can be run in two modes: `stdio` (for local testing) or `http` (for networked access). To start the server, use the following commands:

#### Run in stdio mode (default):
```bash
vector-mcp --transport "stdio"
```

#### Run in HTTP mode:
```bash
vector-mcp --transport "http"  --host "0.0.0.0"  --port "8000"
```

### Creating Collection
AI Prompt:
```text
Create a collection called zapdos with the documents in this directory:
/home/user/Documents/Chroma
```

AI Response:
```text
The collection named "zapdos" has been successfully created or retrieved from the vector database
using the documents in the directory /home/user/Documents/Chroma.
Let me know if you'd like to perform any further actions, such as querying the collection or adding more documents!
```

### Retrieving from Collection

AI Prompt:
```text
Create a collection called zapdos with the documents in this directory:
/home/user/Documents/Chroma
```

AI Response:
```text
The collection named "zapdos" has been successfully created or retrieved from the vector database
using the documents in the directory /home/user/Documents/Chroma.
Let me know if you'd like to perform any further actions, such as querying the collection or adding more documents!
```

### Deleting Collection

AI Prompt:
```text
Delete the collection called memory
```

AI Response:
```text
The collection named "memory" has been successfully deleted.
Let me know if you'd like to create a new collection or perform any other actions!
```

### A2A CLI
#### Endpoints
- **Web UI**: `http://localhost:8000/` (if enabled)
- **A2A**: `http://localhost:8000/a2a` (Discovery: `/a2a/.well-known/agent.json`)
- **AG-UI**: `http://localhost:8000/ag-ui` (POST)

| Short Flag | Long Flag         | Description                                                            |
|------------|-------------------|------------------------------------------------------------------------|
| -h         | --help            | Display help information                                               |
|            | --host            | Host to bind the server to (default: 0.0.0.0)                          |
|            | --port            | Port to bind the server to (default: 9000)                             |
|            | --reload          | Enable auto-reload                                                     |
|            | --provider        | LLM Provider: 'openai', 'anthropic', 'google', 'huggingface'           |
|            | --model-id        | LLM Model ID (default: qwen3:4b)                                       |
|            | --base-url        | LLM Base URL (for OpenAI compatible providers)                         |
|            | --api-key         | LLM API Key                                                            |
|            | --mcp-url         | MCP Server URL (default: http://localhost:8000/mcp)                    |
|            | --web             | Enable Pydantic AI Web UI                                              | False (Env: ENABLE_WEB_UI) |



### Deploy MCP Server as a Service

The MCP server can be deployed using Docker, with configurable authentication, middleware, and Eunomia authorization.

#### Using Docker Run

```bash
docker pull knucklessg1/vector-mcp:latest

docker run -d \
  --name vector-mcp \
  -p 8004:8004 \
  -e HOST=0.0.0.0 \
  -e PORT=8004 \
  -e TRANSPORT=http \
  -e AUTH_TYPE=none \
  -e EUNOMIA_TYPE=none \
  knucklessg1/vector-mcp:latest
```

For advanced authentication (e.g., JWT, OAuth Proxy, OIDC Proxy, Remote OAuth) or Eunomia, add the relevant environment variables:

```bash
docker run -d \
  --name vector-mcp \
  -p 8004:8004 \
  -e HOST=0.0.0.0 \
  -e PORT=8004 \
  -e TRANSPORT=http \
  -e AUTH_TYPE=oidc-proxy \
  -e OIDC_CONFIG_URL=https://provider.com/.well-known/openid-configuration \
  -e OIDC_CLIENT_ID=your-client-id \
  -e OIDC_CLIENT_SECRET=your-client-secret \
  -e OIDC_BASE_URL=https://your-server.com \
  -e ALLOWED_CLIENT_REDIRECT_URIS=http://localhost:*,https://*.example.com/* \
  -e EUNOMIA_TYPE=embedded \
  -e EUNOMIA_POLICY_FILE=/app/mcp_policies.json \
  knucklessg1/vector-mcp:latest
```

#### Using Docker Compose

Create a `docker-compose.yml` file:

```yaml
services:
  vector-mcp:
    image: knucklessg1/vector-mcp:latest
    environment:
      - HOST=0.0.0.0
      - PORT=8004
      - TRANSPORT=http
      - AUTH_TYPE=none
      - EUNOMIA_TYPE=none
    ports:
      - 8004:8004
```

For advanced setups with authentication and Eunomia:

```yaml
services:
  vector-mcp:
    image: knucklessg1/vector-mcp:latest
    environment:
      - HOST=0.0.0.0
      - PORT=8004
      - TRANSPORT=http
      - AUTH_TYPE=oidc-proxy
      - OIDC_CONFIG_URL=https://provider.com/.well-known/openid-configuration
      - OIDC_CLIENT_ID=your-client-id
      - OIDC_CLIENT_SECRET=your-client-secret
      - OIDC_BASE_URL=https://your-server.com
      - ALLOWED_CLIENT_REDIRECT_URIS=http://localhost:*,https://*.example.com/*
      - EUNOMIA_TYPE=embedded
      - EUNOMIA_POLICY_FILE=/app/mcp_policies.json
    ports:
      - 8004:8004
    volumes:
      - ./mcp_policies.json:/app/mcp_policies.json
```

Run the service:

```bash
docker-compose up -d
```

#### Configure `mcp.json` for AI Integration

```json
{
  "mcpServers": {
    "vector_mcp": {
      "command": "uv",
      "args": [
        "run",
        "--with",
        "vector-mcp",
        "vector-mcp"
      ],
      "env": {
        "DATABASE_TYPE": "chromadb",                   // Optional
        "COLLECTION_NAME": "memory",                   // Optional
        "DOCUMENT_DIRECTORY": "/home/user/Documents/"  // Optional
      },
      "timeout": 300000
    }
  }
}

```

## Install Python Package

```bash
python -m pip install vector-mcp
```

PGVector dependencies

```bash
python -m pip install vector-mcp[pgvector]
```

All

```bash
python -m pip install vector-mcp[all]
```

or

```bash
uv pip install --upgrade vector-mcp[all]
```

## Repository Owners


<img width="100%" height="180em" src="https://github-readme-stats.vercel.app/api?username=Knucklessg1&show_icons=true&hide_border=true&&count_private=true&include_all_commits=true" />

![GitHub followers](https://img.shields.io/github/followers/Knucklessg1)
![GitHub User's stars](https://img.shields.io/github/stars/Knucklessg1)

Special shoutouts to Microsoft Autogen V1 ♥️
