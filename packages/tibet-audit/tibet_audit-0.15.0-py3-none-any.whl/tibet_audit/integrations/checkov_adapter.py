"""
TIBET Audit → Checkov Integration Adapter

Export tibet-audit regulatory checks as Checkov custom policies.
This gives Checkov users access to GDPR, NIS2, AI Act, PIPA, APPI, PDPA, LGPD checks.

Usage:
    # Generate Checkov policies from tibet-audit
    python -m tibet_audit.integrations.checkov_adapter --output ./checkov-policies/

    # Use with Checkov
    checkov -d . --external-checks-dir ./checkov-policies/

Why Checkov wants this:
    - 750 IaC checks, 0 regulatory checks
    - EU market needs NIS2/GDPR/AI Act compliance
    - Enterprise sales: "Prisma Cloud with Regulatory Pack"
    - Differentiation vs tfsec, terrascan, trivy

Authors: Root AI & Jasper van de Meent
One love, one fAmIly!
"""

import os
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

# Template for Checkov Python check
CHECKOV_CHECK_TEMPLATE = '''"""
{name}

Category: {category}
Regulation: {regulation}
Reference: {reference}

Generated by tibet-audit Checkov Adapter
https://github.com/jaspertvdm/tibet-audit
"""

from checkov.common.models.enums import CheckResult, CheckCategories
from checkov.terraform.checks.resource.base_resource_check import BaseResourceCheck


class {class_name}(BaseResourceCheck):
    def __init__(self):
        name = "{name}"
        id = "TIBET_{check_id}"
        supported_resources = {supported_resources}
        categories = [CheckCategories.{checkov_category}]
        super().__init__(name=name, id=id, categories=categories, supported_resources=supported_resources)

    def scan_resource_conf(self, conf) -> CheckResult:
        """
        {description}

        Severity: {severity}
        Score Impact: {score_impact}
        """
        {scan_logic}


check = {class_name}()
'''

# Mapping tibet-audit categories to Checkov categories
CATEGORY_MAPPING = {
    'gdpr': 'GENERAL_SECURITY',  # Checkov doesn't have GDPR category
    'ai_act': 'GENERAL_SECURITY',
    'nis2': 'GENERAL_SECURITY',
    'pipa': 'GENERAL_SECURITY',
    'appi': 'GENERAL_SECURITY',
    'pdpa': 'GENERAL_SECURITY',
    'lgpd': 'GENERAL_SECURITY',
    'sovereignty': 'GENERAL_SECURITY',
}

# Resource mappings for different check types
RESOURCE_MAPPINGS = {
    'data_residency': [
        'aws_s3_bucket',
        'aws_rds_instance',
        'aws_dynamodb_table',
        'azurerm_storage_account',
        'azurerm_sql_database',
        'google_storage_bucket',
        'google_sql_database_instance',
    ],
    'encryption': [
        'aws_s3_bucket',
        'aws_ebs_volume',
        'aws_rds_instance',
        'azurerm_storage_account',
        'google_storage_bucket',
    ],
    'logging': [
        'aws_cloudtrail',
        'aws_s3_bucket',
        'azurerm_monitor_diagnostic_setting',
        'google_logging_project_sink',
    ],
    'access_control': [
        'aws_iam_policy',
        'aws_iam_role',
        'azurerm_role_assignment',
        'google_project_iam_member',
    ],
    'cloud_provider': [
        'aws_s3_bucket',
        'aws_instance',
        'azurerm_resource_group',
        'google_project',
    ],
}


@dataclass
class TibetCheck:
    """Representation of a tibet-audit check."""
    check_id: str
    name: str
    category: str
    severity: str
    score_weight: int
    description: str
    reference: Optional[str] = None


# Core regulatory checks to export
TIBET_CHECKS = [
    # GDPR Checks
    TibetCheck(
        check_id="GDPR_001",
        name="Data Residency - EU Only",
        category="gdpr",
        severity="critical",
        score_weight=15,
        description="Ensure personal data is stored within EU/EEA boundaries (GDPR Art. 44-49)",
        reference="https://gdpr.eu/article-44/"
    ),
    TibetCheck(
        check_id="GDPR_002",
        name="Encryption at Rest",
        category="gdpr",
        severity="high",
        score_weight=12,
        description="Personal data must be encrypted at rest (GDPR Art. 32)",
        reference="https://gdpr.eu/article-32/"
    ),
    TibetCheck(
        check_id="GDPR_003",
        name="Audit Logging Enabled",
        category="gdpr",
        severity="high",
        score_weight=10,
        description="Audit logs must be enabled for accountability (GDPR Art. 5(2))",
        reference="https://gdpr.eu/article-5/"
    ),

    # NIS2 Checks
    TibetCheck(
        check_id="NIS2_001",
        name="Incident Response Plan",
        category="nis2",
        severity="critical",
        score_weight=15,
        description="Organizations must have incident response procedures (NIS2 Art. 21)",
        reference="https://eur-lex.europa.eu/eli/dir/2022/2555"
    ),
    TibetCheck(
        check_id="NIS2_002",
        name="Supply Chain Security",
        category="nis2",
        severity="high",
        score_weight=12,
        description="Assess and secure supply chain dependencies (NIS2 Art. 21(2)(d))",
        reference="https://eur-lex.europa.eu/eli/dir/2022/2555"
    ),
    TibetCheck(
        check_id="NIS2_008",
        name="Digital Sovereignty (no-digid)",
        category="nis2",
        severity="high",
        score_weight=12,
        description="Check for foreign cloud dependencies (US CLOUD Act risk). Named after Dutch DigiD sold to Kyndryl.",
        reference="https://www.rijksoverheid.nl/onderwerpen/nis2-richtlijn"
    ),

    # AI Act Checks
    TibetCheck(
        check_id="AI_ACT_001",
        name="AI System Risk Classification",
        category="ai_act",
        severity="critical",
        score_weight=15,
        description="AI systems must be classified by risk level (AI Act Art. 6)",
        reference="https://eur-lex.europa.eu/eli/reg/2024/1689"
    ),
    TibetCheck(
        check_id="AI_ACT_002",
        name="AI Training Data Documentation",
        category="ai_act",
        severity="high",
        score_weight=10,
        description="High-risk AI must document training data (AI Act Art. 10)",
        reference="https://eur-lex.europa.eu/eli/reg/2024/1689"
    ),
]


def generate_scan_logic(check: TibetCheck) -> str:
    """Generate the scan logic based on check type."""

    if 'residency' in check.check_id.lower() or 'sovereignty' in check.check_id.lower():
        return '''
        # Check for non-EU regions
        non_eu_regions = ['us-', 'ap-', 'sa-', 'me-', 'af-']

        region = conf.get('region', [''])[0] if isinstance(conf.get('region'), list) else conf.get('region', '')
        location = conf.get('location', [''])[0] if isinstance(conf.get('location'), list) else conf.get('location', '')

        check_region = region or location or ''

        for non_eu in non_eu_regions:
            if non_eu in check_region.lower():
                return CheckResult.FAILED

        return CheckResult.PASSED
'''

    elif 'encryption' in check.check_id.lower():
        return '''
        # Check for encryption configuration
        encryption_keys = ['encryption', 'kms_key_id', 'encrypted', 'server_side_encryption']

        for key in encryption_keys:
            if key in conf:
                value = conf[key]
                if value and value not in [False, 'false', 'disabled', None, []]:
                    return CheckResult.PASSED

        return CheckResult.FAILED
'''

    elif 'logging' in check.check_id.lower() or 'audit' in check.check_id.lower():
        return '''
        # Check for logging/audit configuration
        logging_keys = ['logging', 'audit', 'monitor', 'trail', 'log_']

        for key in conf:
            for log_key in logging_keys:
                if log_key in key.lower():
                    return CheckResult.PASSED

        return CheckResult.FAILED
'''

    else:
        # Generic check - always flag for manual review
        return '''
        # Regulatory check requires manual review
        # Flag resource for compliance team assessment
        return CheckResult.UNKNOWN
'''


def get_resource_types(check: TibetCheck) -> List[str]:
    """Determine which resource types this check applies to."""

    check_lower = check.check_id.lower() + check.name.lower()

    if 'residency' in check_lower or 'sovereignty' in check_lower or 'digid' in check_lower:
        return RESOURCE_MAPPINGS['data_residency'] + RESOURCE_MAPPINGS['cloud_provider']
    elif 'encryption' in check_lower:
        return RESOURCE_MAPPINGS['encryption']
    elif 'logging' in check_lower or 'audit' in check_lower:
        return RESOURCE_MAPPINGS['logging']
    elif 'access' in check_lower:
        return RESOURCE_MAPPINGS['access_control']
    else:
        return ['*']  # Apply to all resources


def generate_checkov_policy(check: TibetCheck) -> str:
    """Generate a Checkov policy file from a tibet-audit check."""

    class_name = f"Tibet{check.check_id.replace('-', '_').replace(' ', '_')}"
    supported_resources = get_resource_types(check)
    scan_logic = generate_scan_logic(check)
    checkov_category = CATEGORY_MAPPING.get(check.category, 'GENERAL_SECURITY')

    return CHECKOV_CHECK_TEMPLATE.format(
        name=check.name,
        category=check.category.upper(),
        regulation=check.category.upper(),
        reference=check.reference or '',
        class_name=class_name,
        check_id=check.check_id,
        supported_resources=supported_resources,
        checkov_category=checkov_category,
        description=check.description,
        severity=check.severity,
        score_impact=check.score_weight,
        scan_logic=scan_logic,
    )


def export_checkov_policies(output_dir: str) -> Dict[str, Any]:
    """Export all tibet-audit checks as Checkov policies."""

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # Create __init__.py
    init_file = output_path / "__init__.py"
    init_file.write_text('"""tibet-audit regulatory checks for Checkov."""\n')

    exported = []

    for check in TIBET_CHECKS:
        filename = f"tibet_{check.check_id.lower().replace('-', '_')}.py"
        filepath = output_path / filename

        policy_code = generate_checkov_policy(check)
        filepath.write_text(policy_code)

        exported.append({
            'check_id': f"TIBET_{check.check_id}",
            'name': check.name,
            'category': check.category,
            'file': filename,
        })

    # Create metadata file
    metadata = {
        'source': 'tibet-audit',
        'version': '0.13.0',
        'checks_count': len(exported),
        'categories': list(set(c.category for c in TIBET_CHECKS)),
        'checks': exported,
    }

    metadata_file = output_path / "tibet_metadata.json"
    metadata_file.write_text(json.dumps(metadata, indent=2))

    return metadata


def main():
    """CLI entry point."""
    import argparse

    parser = argparse.ArgumentParser(
        description='Export tibet-audit checks as Checkov policies'
    )
    parser.add_argument(
        '--output', '-o',
        default='./checkov-tibet-policies/',
        help='Output directory for Checkov policies'
    )
    parser.add_argument(
        '--list', '-l',
        action='store_true',
        help='List available checks without exporting'
    )

    args = parser.parse_args()

    if args.list:
        print("tibet-audit checks available for Checkov export:\n")
        for check in TIBET_CHECKS:
            print(f"  TIBET_{check.check_id}: {check.name}")
            print(f"    Category: {check.category.upper()}")
            print(f"    Severity: {check.severity}")
            print()
        return

    print(f"Exporting tibet-audit checks to Checkov format...")
    print(f"Output directory: {args.output}\n")

    metadata = export_checkov_policies(args.output)

    print(f"✓ Exported {metadata['checks_count']} checks")
    print(f"✓ Categories: {', '.join(metadata['categories'])}")
    print(f"\nUsage with Checkov:")
    print(f"  checkov -d . --external-checks-dir {args.output}")
    print(f"\nOr add to .checkov.yaml:")
    print(f"  external-checks-dir:")
    print(f"    - {args.output}")


if __name__ == '__main__':
    main()
