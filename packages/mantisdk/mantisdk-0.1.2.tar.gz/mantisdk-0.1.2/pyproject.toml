[project]
name = "mantisdk"
version = "0.1.2"
description = "Mantisdk - AI Agent Training and Evaluation Platform"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [
    {name = "Metis Team", email = "team@withmetis.ai"}
]
keywords = [
    "ai", "agents", "llm", "training", "evaluation",
    "reinforcement-learning", "mantis", "observability"
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
  "graphviz",
  "psutil",
  "gpustat",
  "setproctitle",
  "flask",
  "agentops>=0.4.13",
  "uvicorn",
  "fastapi",
  "aiohttp",
  "opentelemetry-api>=1.35",
  "opentelemetry-sdk>=1.35",
  "opentelemetry-exporter-otlp>=1.35",
  "litellm[proxy]>=1.74",
  "pydantic>=2.11",
  "openai",
  "rich",
  "portpicker",
  "gunicorn",
  "uvicorn_worker",
  "aiologic",
  "gepa>=0.0.24",
]

[project.urls]
Homepage = "https://github.com/withmetis/mantis"
Documentation = "https://withmetis.github.io/mantis/mantisdk/"
Repository = "https://github.com/withmetis/mantis"
Issues = "https://github.com/withmetis/mantis/issues"

[project.scripts]
msk = "mantisdk.cli:main"

[project.optional-dependencies]
apo = [
  "poml",
]
# It's not recommended to use mantisdk[verl] to install VERL and its dependencies.
# though it's listed here for completeness.
verl = [
  "verl>=0.5.0",
  "vllm>=0.8.4",
]
weave = [
  "weave>=0.52.22",
]
# Store-related dependencies.
mongo = [
  "pymongo",
]

[dependency-groups]
dev = [
  "flake8",
  "pytest",
  "hatch",
  "pytest-asyncio",
  "pre-commit",
  "pytest-rerunfailures",
  "black",
  "isort",
  "pyright",
  "mkdocs",
  "mkdocs-material",
  "mkdocstrings[python]",
  "mike",
  "mkdocs-git-revision-date-localized-plugin",
  "mkdocs-git-authors-plugin",
  "mkdocs-macros-plugin",
  "mkdocs-autorefs",
  "prometheus-client",
]
experiment = [
  "random-word",
  "gdown",
]

core-legacy = [
  "agentops<=0.4.18",
  "openai<2.0.0",
]
core-stable = [
  "agentops>=0.4.21",
  "openai>=2.0.0",
]

# For PyTorch.
# CPU and GPU groups.
torch-cpu = [
  "torch",
  "torchvision",
]
torch-cu128 = [
  "torch",
  "torchvision",
]

# Training-heavy dependencies.
torch-stable = [
  {include-group = "core-stable"},
  "torch>=2.8.0",
  "torchvision>=0.23.0",
  "transformers>=4.55.0,!=4.57.2",
  "vllm>=0.10.2,!=0.11.1,!=0.11.2,!=0.12.0",
  "litellm[proxy]>=1.78",
]
torch-legacy = [
  {include-group = "core-legacy"},
  "torch==2.7.0",
  "torchvision==0.22.0",
  "transformers==4.53.3",
  "tokenizers>=0.21,<0.22",
  "vllm==0.9.2",
  "litellm[proxy]==1.74.15",
]

# Specific vllm versions for compatibility testing or workarounds.
vllm-0-10-2 = [
  {include-group = "torch-stable"},
  "vllm==0.10.2",
]
vllm-0-11-0 = [
  {include-group = "torch-stable"},
  "vllm==0.11.0",
]

# Flash-attention must build with CUDA toolkit.
torch-gpu-stable = [
  {include-group = "torch-stable"},
  {include-group = "torch-cu128"},
  "flash-attn>=2.8.3",
  "tensordict>=0.9.1",
  "verl>=0.6.0",
]
torch-gpu-legacy = [
  {include-group = "torch-legacy"},
  {include-group = "torch-cu128"},
  "flash-attn==2.8.1",
  "verl==0.5.0",
]

# For the TRL/Unsloth example.
trl = [
  {include-group = "torch-stable"},
  "unsloth>=2025.10.1,!=2025.10.2,!=2025.10.3,!=2025.10.4,!=2025.10.5,!=2025.10.6,!=2025.10.7,!=2025.10.8",
  "unsloth_zoo>=2025.10.1,!=2025.10.2,!=2025.10.3,!=2025.10.4,!=2025.10.5,!=2025.10.6,!=2025.10.7,!=2025.10.8",
  "bitsandbytes",
  "peft",
  "datasets",
  "transformers",
  "trl",
  "kernels",
  "vllm",
]

# For Tinker integration.
tinker = [
  {include-group = "torch-stable"},
  "tinker>=0.2.2",
  "tinker_cookbook>=0.1.0",
  "wandb",
]

# For Multi-modality supports.
image = [
  "datasets",
  "Pillow",
  "pandas",
  "pyarrow",
  "qwen-vl-utils",
]

# Agent-related dependencies.
autogen = [
  "autogen-agentchat",
  "autogen-ext[openai]",
  "mcp>=1.10.0",
]
openai-agents = [
  "openai-agents",
  "openai",
  "mcp",
  "pandas",
]
anthropic = [
  "anthropic",
]
langchain = [
  "langgraph>=1.0.0",
  "langchain[openai]>=1.0.0",
  "langchain-community>=0.4.0",
  "langchain-text-splitters>=1.0.0",
]
sql = [
  "sqlparse",
  "nltk",
]
rag = [
  "fastmcp>=2.13.1",
  "faiss-cpu>=1.11.0",
  "sentence-transformers>=4.1.0",
]
crewai = [
  "crewai[tools]>=1.2.0,!=1.2.1,!=1.3.0,!=1.4.0,!=1.4.1,!=1.5.0",
]
swebench = [
  "swebench",
]

# Summarize into large installable groups.
agents = [
  {include-group = "autogen"},
  {include-group = "openai-agents"},
  {include-group = "sql"},
  {include-group = "anthropic"},
  {include-group = "crewai"},
  {include-group = "swebench"},
]

[tool.uv]
required-version = ">=0.9.9"
conflicts = [
  [
    { group = "core-legacy" },
    { group = "core-stable" },
  ],
  [
    { group = "torch-cpu" },
    { group = "torch-cu128" },
  ],
  [
    { group = "torch-stable" },
    { group = "torch-legacy" },
  ],
  [
    { group = "vllm-0-10-2" },
    { group = "vllm-0-11-0" },
  ],
  [
    { group = "langchain" },
    { group = "torch-legacy" },
  ],
]
environments = [
  "sys_platform == 'linux'",
]
dependency-metadata = [
  { name = "instructor", version = "1.11.3", requires-dist = ["openai", "pydantic", "docstring-parser", "typer", "rich", "aiohttp", "tenacity", "pydantic-core", "jiter", "jinja2", "requests", "diskcache"] },
]

override-dependencies = [
  "mcp>=1.19.0",
  "uvicorn>=0.38.0",
  "packaging>=24.0",
  "websockets>=15.0.1",
  "rich>=13.9.4",
  "numpy>=2.0.0,<2.3.0",
  "setuptools>=80.9.0",
]

[tool.uv.sources]
torch = [
  { index = "pytorch-cu128", group = "torch-cu128" },
  { index = "pytorch-cpu", group = "torch-cpu" },
]

[[tool.uv.index]]
name = "pypi"
url = "https://pypi.org/simple"

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"

[tool.uv.extra-build-dependencies]
flash-attn = [
  { requirement = "torch", match-runtime = true },
]

[tool.uv.dependency-groups]
tinker = {requires-python = ">=3.11"}

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/mantisdk"]
include = [
  "src/mantisdk/**/*.yaml",
  "src/mantisdk/**/*.yml",
  "src/mantisdk/**/*.poml",
]

[tool.hatch.build.targets.sdist]
exclude = [
  "/examples/**",
  "/tests/**",
  "/docs/**",
  "/scripts/**",
  "/.github/**",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
markers = [
  "openai: tests that require OpenAI API",
  "gpu: tests that require GPU",
  "agentops: tests that require AgentOps",
  "weave: tests that require Weave",
  "llmproxy: tests that require LiteLLM",
  "mongo: tests that require MongoDB",
  "store: tests for mantisdk.store module",
  "prometheus: tests that require Prometheus",
  "utils: tests for utility functions",
  "langchain: tests that require LangChain",
]

[tool.black]
line-length = 120
target-version = ['py312']
include = '\.pyi?$'
extend-exclude = '''
/(
  _version\.py
)
'''

[tool.isort]
profile = "black"
line_length = 120
known_first_party = ["mantisdk"]
extend_skip_glob = [
  "data/**",
  "_version.py",
]
