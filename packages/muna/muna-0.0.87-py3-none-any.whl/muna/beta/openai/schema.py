# 
#   Muna
#   Copyright Â© 2026 NatML Inc. All Rights Reserved.
#

from __future__ import annotations
from pydantic import BaseModel, ConfigDict
from requests import Response
from typing import Literal, TypedDict

ChatCompletionReasoningEffort = Literal["minimal", "low", "medium", "high", "xhigh"]
SpeechResponseFormat = Literal["mp3", "opus", "aac", "flac", "wav", "pcm"]
SpeechStreamFormat = Literal["audio", "sse"]

class ChatCompletion(BaseModel):
    class Usage(BaseModel):
        prompt_tokens: int
        completion_tokens: int
        total_tokens: int
    object: Literal["chat.completion"] = "chat.completion"
    id: str
    created: int
    model: str
    choices: list[Choice]
    usage: Usage

class ChatCompletionChunk(BaseModel):
    object: Literal["chat.completion.chunk"] = "chat.completion.chunk"
    id: str
    created: int
    model: str
    choices: list[StreamChoice]
    usage: ChatCompletion.Usage | None = None

class Choice(BaseModel):
    index: int
    message: Message
    finish_reason: Literal["stop", "length", "content_filter", "tool_calls"] | None = None

class StreamChoice(BaseModel):
    index: int
    delta: DeltaMessage | None
    finish_reason: Literal["stop", "length", "content_filter", "tool_calls"] | None = None

class Message(BaseModel):
    role: Literal["assistant", "user", "system"]
    content: str | None = None

class DeltaMessage(BaseModel):
    role: Literal["assistant", "user", "system"] | None = None
    content: str | None = None

class Embedding(BaseModel):
    object: Literal["embedding"]
    embedding: list[float] | str
    index: int

class EmbeddingCreateResponse(BaseModel):
    class Usage(BaseModel):
        prompt_tokens: int
        total_tokens: int
    object: Literal["list"]
    model: str
    data: list[Embedding]
    usage: Usage

class SpeechCreateResponse(BaseModel, **ConfigDict(arbitrary_types_allowed=True)):
    content: bytes
    response: Response

class Transcription(BaseModel):
    class TokenUsage(BaseModel):
        class InputTokenDetails(BaseModel):
            audio_tokens: int
            text_tokens: int
        type: Literal["tokens"]
        input_tokens: int
        output_tokens: int
        total_tokens: int
        input_token_details: InputTokenDetails
    class DurationUsage(BaseModel):
        type: Literal["duration"]
        seconds: float
    text: str
    usage: TokenUsage | DurationUsage

class _MessageDict(TypedDict): # For text completion
    role: Literal["assistant", "user", "system"]
    content: str | None

class _ResponseFormatTextDict(TypedDict):
    type: Literal["text"]

class _ResponseFormatJsonSchemaDict(TypedDict):
    type: Literal["json_schema"]
    json_schema: dict[str, object]

_ResponseFormatDict = _ResponseFormatTextDict | _ResponseFormatJsonSchemaDict