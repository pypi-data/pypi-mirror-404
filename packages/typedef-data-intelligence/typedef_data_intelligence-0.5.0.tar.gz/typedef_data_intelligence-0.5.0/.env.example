# =============================================================================
# TypeDef Data Intelligence - Environment Configuration
# =============================================================================
# This file provides example values for all environment variables used by the
# typedef data intelligence platform. Copy this file to .env and fill in your
# actual values.
#
# Configuration files reference these variables using ${VAR_NAME} syntax.
#
# IMPORTANT: Never commit the actual .env file - it contains secrets!
# =============================================================================

# -----------------------------------------------------------------------------
# LLM API Keys
# -----------------------------------------------------------------------------
# Required for semantic analysis and agent operations.
# At minimum, set ANTHROPIC_API_KEY (used by default for agents).

# Anthropic Claude (primary - used by agents)
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI (optional - for GPT models in semantic analysis)
OPENAI_API_KEY=sk-proj-...

# Google API Key (optional - for Gemini models)
GOOGLE_API_KEY=...

# OpenRouter (optional - for multi-model access, used by semantic analysis)
OPENROUTER_API_KEY=sk-or-v1-...

# Pydantic AI Gateway (optional, used for agents in the future)
PYDANTIC_AI_GATEWAY_API_KEY=paig_...

# -----------------------------------------------------------------------------
# AWS Bedrock Configuration (Optional)
# -----------------------------------------------------------------------------
# Use AWS Bedrock as an alternative LLM provider for PydanticAI agents.
# Bedrock uses IAM authentication - credentials are resolved via boto3's
# default credential chain:
#   1. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
#   2. AWS credentials file (~/.aws/credentials)
#   3. IAM role (when running on AWS infrastructure like EC2, ECS, Lambda)
#
# Model format in config: bedrock:anthropic.claude-3-sonnet-20240229-v1:0
# With explicit region: bedrock:us-east-1/anthropic.claude-3-sonnet-20240229-v1:0

# AWS Region for Bedrock (defaults to us-east-1 if not set)
AWS_DEFAULT_REGION=us-west-2

# AWS credentials (optional if using IAM roles or ~/.aws/credentials)
# AWS_ACCESS_KEY_ID=AKIA...
# AWS_SECRET_ACCESS_KEY=...

# AWS Session Token (for temporary credentials only)
# AWS_SESSION_TOKEN=...

# AWS Profile (if using named profiles in ~/.aws/credentials)
# AWS_PROFILE=default

# -----------------------------------------------------------------------------
# dbt Project Configuration
# -----------------------------------------------------------------------------
# These variables define which dbt project to analyze and where it's located.
#
# The platform supports external git-managed dbt projects via environment vars.
# Example projects: medallion-reference, mattermost-data-warehouse
#
# Usage: just medallion-quickstart (handles git clone + setup automatically)

# Parent directory containing your dbt projects
GITHUB_DBT_PROJECT_LOCAL_PATH=/Users/you/dev/dbt-workspace

# =============================================================================
# OPTION 1: Medallion Reference Test Project (simpler setup)
# =============================================================================
# A demo SaaS finance analytics project for testing
GITHUB_DBT_PROJECT_REPO_NAME=medallion-reference
DBT_PROJECT_ROOT=.

# =============================================================================
# OPTION 2: Mattermost Analytics (production-scale example)
# =============================================================================
# Uncomment these and comment out the medallion settings above
# GITHUB_DBT_PROJECT_REPO_NAME=mattermost-data-warehouse
# DBT_PROJECT_NAME_OVERRIDE=mattermost-analytics
# DBT_PROJECT_ROOT=transform/mattermost-analytics
# DBT_PROFILES_DIR=profile

# -----------------------------------------------------------------------------
# Snowflake Configuration
# -----------------------------------------------------------------------------
# Data warehouse credentials for:
# - Querying semantic models
# - Profiling tables/columns
# - Running data quality checks
# - Agent SQL execution

SNOWFLAKE_ACCOUNT=your-account.region
SNOWFLAKE_USER=your-username
SNOWFLAKE_ROLE=ANALYST
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=ANALYTICS
SNOWFLAKE_SCHEMA=MARTS

# Path to private key file for key-pair authentication
# Generate: openssl genrsa 2048 | openssl pkcs8 -topk8 -inform PEM -out key.p8 -nocrypt
SNOWFLAKE_PRIVATE_KEY_PATH=/Users/you/.dbt/snowflake_key.p8

# -----------------------------------------------------------------------------
# Mattermost-specific Snowflake Configuration (Optional)
# -----------------------------------------------------------------------------
# Additional databases/schemas for mattermost-analytics project
# SNOWFLAKE_TRANSFORM_DATABASE=ANALYTICS
# SNOWFLAKE_TRANSFORM_SCHEMA=MATTERMOST_ANALYTICS
# SNOWFLAKE_TRANSFORM_ROLE=ENGINEER
# MATTERMOST_RAW_DB=RAW
# MATTERMOST_ANALYTICS_DB=ANALYTICS

# -----------------------------------------------------------------------------
# User Context
# -----------------------------------------------------------------------------
# Default user/org for agent operations
DEFAULT_USER_ID=your-username
DEFAULT_ORG_ID=your-org

# -----------------------------------------------------------------------------
# Linear Configuration (Optional)
# -----------------------------------------------------------------------------
# Ticket management for agent collaboration.
# If not set, falls back to filesystem-based tickets.
#
# Setup:
# 1. Create Linear team: https://linear.app/
# 2. Get team ID from URL or API
# 3. Generate API keys: Settings -> API -> Personal API Keys

LINEAR_TEAM_ID=your-team-uuid
LINEAR_ANALYST_API_KEY=lin_api_...
LINEAR_DATA_ENGINEER_API_KEY=lin_api_...

# -----------------------------------------------------------------------------
# GitHub Configuration (Optional)
# -----------------------------------------------------------------------------
# For data-engineer agent git operations
# If unset, agent uses your local git credentials
# GITHUB_TOKEN=ghp_...

# -----------------------------------------------------------------------------
# Observability (Optional)
# -----------------------------------------------------------------------------
# Logfire token for Pydantic AI observability
# Get from: https://logfire.pydantic.dev/
LOGFIRE_TOKEN=pylf_v1_...

# -----------------------------------------------------------------------------
# Slack Integration (Optional)
# -----------------------------------------------------------------------------
# For Slack bot notifications
SLACK_SIGNING_SECRET=your-signing-secret
SLACK_BOT_TOKEN=xoxb-...

# AG UI base URL (for agent UI)
AG_UI_BASE_URL=http://localhost:8000

# -----------------------------------------------------------------------------
# OpenLineage Configuration (Optional)
# -----------------------------------------------------------------------------
# For collecting runtime lineage from dbt runs.
# Enables tracking actual execution patterns vs static DAG.

# OpenLineage collection endpoint (if using lineage serve)
# OPENLINEAGE_URL=http://localhost:8080/api/v1/lineage

# Namespace for grouping lineage events
# OPENLINEAGE_NAMESPACE=dbt://demo_finance

# Set to false to enable collection
# OPENLINEAGE_DISABLED=false

# -----------------------------------------------------------------------------
# Configuration File Selection
# -----------------------------------------------------------------------------
# The platform uses different config files for different modes:
#
# config.ingest.yml  - For loading dbt projects (just medallion-full)
# config.cli.yml     - For CLI agent operations (lineage-agent-anthropic)
# config.api.yml     - For web API + UI (just dev-webui)
#
# Each file can reference these environment variables using ${VAR_NAME} syntax.
# See the individual config files for specific variable usage.
# -----------------------------------------------------------------------------
