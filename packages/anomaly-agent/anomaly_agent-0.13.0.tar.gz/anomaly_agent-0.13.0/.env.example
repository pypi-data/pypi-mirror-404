# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Option 1: OpenAI (default)
OPENAI_API_KEY="<your-openai-api-key>"

# Option 2: OpenRouter (access to multiple providers via single API)
# Uncomment these to use OpenRouter instead of OpenAI directly:
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_API_KEY="<your-openrouter-api-key>"
#
# With OpenRouter, use provider/model format for model_name:
#   - "openai/gpt-4o"
#   - "anthropic/claude-3.5-sonnet"
#   - "google/gemini-pro-1.5"
#   - "meta-llama/llama-3.1-70b-instruct"
#
# See https://openrouter.ai/models for full list

# Option 3: Any OpenAI-compatible API
# Set OPENAI_BASE_URL to point to your custom endpoint:
# OPENAI_BASE_URL=https://your-api-endpoint.com/v1

# =============================================================================
# LangChain/LangSmith Configuration (Optional)
# =============================================================================
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="<your-langsmith-api-key>"
LANGSMITH_PROJECT="anomaly-agent"

# =============================================================================
# PostHog LLM Analytics Configuration (Optional)
# =============================================================================
# Set POSTHOG_ENABLED=true to enable PostHog LLM analytics tracking
POSTHOG_ENABLED=false
POSTHOG_API_KEY=your-posthog-api-key-here
POSTHOG_HOST=https://app.posthog.com
POSTHOG_DISTINCT_ID=
POSTHOG_PRIVACY_MODE=false
# Optional: Set POSTHOG_AI_SESSION_ID to group multiple traces together
# If not set, traces will not be grouped by session
# Example scripts generate this automatically with uuid.uuid4()
POSTHOG_AI_SESSION_ID=
