% EMK: Episodic Memory Kernel — A Layer 1 Primitive for Agent Experience Storage
% Template for academic publication

\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{algpseudocode}

% Code listing style
\lstdefinestyle{python}{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    commentstyle=\color{gray},
    numbers=left,
    numberstyle=\tiny,
    breaklines=true,
    frame=single
}

% Title
\title{EMK: Episodic Memory Kernel\\
\large A Layer 1 Primitive for Agent Experience Storage}

\author{
    Imran Siddique\\
    \texttt{imran@example.com}\\
    GitHub: \url{https://github.com/imran-siddique/emk}
}

\date{January 2026}

\begin{document}

\maketitle

\begin{abstract}
We present \textbf{EMK} (Episodic Memory Kernel), a lightweight, immutable storage layer for AI agent experiences. As autonomous agents become increasingly prevalent, the need for structured, queryable memory of past actions and outcomes becomes critical. EMK provides a minimalist yet powerful primitive that captures the complete agent experience cycle—Goal $\rightarrow$ Action $\rightarrow$ Result $\rightarrow$ Reflection—in an append-only ledger with $O(1)$ write complexity and $O(n)$ retrieval with optional vector similarity search. We demonstrate that EMK achieves sub-millisecond episode creation latency while maintaining full audit trails, making it suitable for production agent systems.
\end{abstract}

\section{Introduction}

\subsection{Motivation}

The proliferation of Large Language Model (LLM) powered autonomous agents has created an urgent need for robust memory systems. Current approaches often conflate storage with summarization, leading to systems that are both opinionated and heavyweight. EMK addresses this by providing a ``Layer 1'' primitive that focuses solely on storage and retrieval.

\subsection{Contributions}

Our contributions are:
\begin{enumerate}
    \item \textbf{EMK Schema}: A minimal, immutable data structure for agent experiences (Section~\ref{sec:schema})
    \item \textbf{Pluggable Storage}: Abstract interface with multiple implementations (Section~\ref{sec:storage})
    \item \textbf{Indexer Utilities}: Tag extraction and search text generation (Section~\ref{sec:indexer})
    \item \textbf{Reproducible Benchmarks}: Controlled experiments with fixed seeds (Section~\ref{sec:experiments})
\end{enumerate}

\section{Related Work}

\subsection{Agent Memory Systems}

Table~\ref{tab:comparison} compares EMK with existing agent memory systems.

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{System} & \textbf{Immutable} & \textbf{Vector Search} & \textbf{Dependencies} \\
\midrule
LangChain Memory & \texttimes & \checkmark & Heavy \\
MemGPT & \texttimes & \checkmark & Heavy \\
AutoGPT Memory & \texttimes & \texttimes & Medium \\
\textbf{EMK (Ours)} & \checkmark & \checkmark & Minimal \\
\bottomrule
\end{tabular}
\caption{Comparison of agent memory systems}
\label{tab:comparison}
\end{table}

\section{Methodology}

\subsection{The Episode Schema}
\label{sec:schema}

An episode captures the complete agent experience cycle:

\begin{lstlisting}[style=python]
class Episode(BaseModel):
    goal: str        # What the agent intended
    action: str      # What the agent did
    result: str      # What happened
    reflection: str  # What the agent learned
    timestamp: datetime
    metadata: Dict[str, Any]
    episode_id: str  # SHA-256 content hash
\end{lstlisting}

\textbf{Implementation Reference:} \texttt{emk/schema.py}

\subsection{Storage Interface}
\label{sec:storage}

The \texttt{VectorStoreAdapter} defines the contract for all storage backends:

\begin{algorithm}
\caption{Episode Storage Interface}
\begin{algorithmic}[1]
\Function{Store}{$episode$, $embedding$}
    \State \Return $episode\_id$
\EndFunction
\Function{Retrieve}{$query$, $filters$, $limit$}
    \State \Return $episodes[]$
\EndFunction
\Function{GetById}{$episode\_id$}
    \State \Return $episode$ or $None$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Indexer}
\label{sec:indexer}

The Indexer provides utilities for making episodes searchable without coupling to specific embedding models.

\section{Experiments}
\label{sec:experiments}

\subsection{Setup}

All experiments use:
\begin{itemize}
    \item Random seed: 42
    \item Python 3.11
    \item EMK version 0.1.0
\end{itemize}

\textbf{Reproduction:} \texttt{python experiments/reproduce\_results.py}

\subsection{Results}

% TODO: Fill in actual benchmark results
\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Operation} & \textbf{Mean (ms)} & \textbf{Std Dev} & \textbf{Ops/sec} \\
\midrule
Episode Creation & 0.036 & 0.069 & 27,694 \\
Storage Write & 1.53 & 1.01 & 652 \\
Retrieval & 25.82 & 9.17 & 39 \\
Indexer & 0.088 & 0.084 & 11,346 \\
\bottomrule
\end{tabular}
\caption{Benchmark results}
\label{tab:benchmarks}
\end{table}

\section{Conclusion}

EMK provides a foundational primitive for agent memory systems. By embracing immutability and minimalism, it enables higher-level systems to build sophisticated memory architectures without reinventing storage.

\section*{Code Availability}

\url{https://github.com/imran-siddique/emk}

Installation: \texttt{pip install emk}

\bibliographystyle{plain}
\begin{thebibliography}{9}

\bibitem{tulving1972}
E. Tulving,
\textit{Episodic and semantic memory},
Organization of Memory, 1972.

\bibitem{langchain2023}
LangChain Team,
\textit{LangChain: Building applications with LLMs},
2023.

\end{thebibliography}

\end{document}
