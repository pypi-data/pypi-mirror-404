"""Main Textual App for Leon CLI"""

import asyncio
import os
import queue
import threading
from pathlib import Path
from typing import Any

from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.containers import Container, VerticalScroll
from textual.widgets import Footer, Header, Static

from tui.widgets.chat_input import ChatInput
from tui.widgets.history_browser import HistoryBrowser
from tui.widgets.loading import ThinkingSpinner
from tui.widgets.messages import AssistantMessage, SystemMessage, ToolCallMessage, ToolResultMessage, UserMessage
from tui.widgets.status import StatusBar
from tui.widgets.thread_browser import ThreadBrowser


class WelcomeBanner(Static):
    """Welcome banner widget"""

    DEFAULT_CSS = """
    WelcomeBanner {
        height: auto;
        margin-bottom: 1;
        color: $accent;
    }
    """

    def compose(self):
        banner = """
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                                                                  â”ƒ
â”ƒ       â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—                       â”ƒ
â”ƒ       â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘                       â”ƒ
â”ƒ       â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘                       â”ƒ
â”ƒ       â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘                       â”ƒ
â”ƒ       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘                       â”ƒ
â”ƒ       â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•                       â”ƒ
â”ƒ                                                                  â”ƒ
â”ƒ              Proactive AI Partner                                â”ƒ
â”ƒ              äººæœºååŒ Â· ä¸»åŠ¨æ™ºèƒ½                                   â”ƒ
â”ƒ                                                                  â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
"""
        yield Static(banner, id="welcome-text")


class LeonApp(App):
    """Leon Agent Textual Application"""

    CSS = """
    Screen {
        layout: vertical;
    }

    #chat-container {
        height: 1fr;
        padding: 1 2;
        background: $background;
        scrollbar-gutter: stable;
        scrollbar-size: 1 1;
    }
    
    #chat-container:focus {
        border: none;
    }
    
    /* Disable scrollbar dragging - only allow wheel scroll */
    #chat-container > ScrollBar {
        background: $surface-darken-1;
    }

    #messages {
        height: auto;
    }

    #input-container {
        height: auto;
        min-height: 3;
        max-height: 10;
        padding: 0 2 1 2;
        background: $surface;
    }

    ChatInput {
        height: 100%;
        border: solid $primary;
    }
    """

    BINDINGS = [
        Binding("ctrl+c", "quit_or_interrupt", "ä¸­æ–­/é€€å‡º", show=False),
        Binding("ctrl+d", "quit", "é€€å‡º", show=False),
        Binding("ctrl+l", "clear_history", "æ¸…ç©ºå†å²", show=False),
        Binding("ctrl+t", "switch_thread", "åˆ‡æ¢å¯¹è¯", show=False),
        Binding("ctrl+up", "history_up", "å†å²ä¸Šä¸€æ¡", show=False),
        Binding("ctrl+down", "history_down", "å†å²ä¸‹ä¸€æ¡", show=False),
        Binding("ctrl+e", "export_conversation", "å¯¼å‡ºå¯¹è¯", show=False),
        Binding("ctrl+y", "copy_last_message", "å¤åˆ¶æœ€åæ¶ˆæ¯", show=False),
    ]

    def __init__(self, agent, workspace_root: Path, thread_id: str = "default", session_mgr=None):
        super().__init__()
        self.agent = agent
        self.workspace_root = workspace_root
        self.thread_id = thread_id
        self.session_mgr = session_mgr
        self._current_assistant_msg = None
        self._shown_tool_calls = set()
        self._shown_tool_results = set()
        self._message_count = 0
        self._last_assistant_message = ""
        # Agent interruption support
        self._agent_running = False
        self._agent_worker = None
        self._quit_pending = False

    def compose(self) -> ComposeResult:
        yield Header()
        with VerticalScroll(id="chat-container"):
            yield WelcomeBanner()
            yield Container(id="messages")
        with Container(id="input-container"):
            yield ChatInput(id="chat-input")
        yield StatusBar(thread_id=self.thread_id, id="status-bar")
        yield Footer()

    def on_mount(self) -> None:
        """Focus input on mount"""
        chat_input = self.query_one("#chat-input", ChatInput)
        chat_input.focus_input()

        # Ensure scroll container can receive focus for scrolling
        chat_container = self.query_one("#chat-container", VerticalScroll)
        chat_container.can_focus = True

        # åŠ è½½å†å² messages
        self.run_worker(self._load_history(), exclusive=False)
    
    def on_key(self, event) -> None:
        """Handle global key events for double-ESC detection"""
        if event.key == "escape":
            chat_input = self.query_one("#chat-input", ChatInput)
            if chat_input.check_double_esc():
                event.prevent_default()
                event.stop()
                self.action_show_history()

    def on_chat_input_submitted(self, event: ChatInput.Submitted) -> None:
        """Handle message submission"""
        content = event.value

        # Handle special commands
        if content.lower() == "/help":
            self._show_help()
            return

        if content.lower() == "/clear":
            self.action_clear_history()
            return

        if content.lower() in ["/exit", "/quit"]:
            self.exit()
            return
        
        if content.lower() == "/history":
            self.action_show_history()
            return
        
        # Handle /rollback N command
        if content.lower().startswith("/rollback ") or content.lower().startswith("/å›é€€ "):
            try:
                parts = content.split()
                if len(parts) == 2:
                    steps = int(parts[1])
                    self._rollback_history(steps)
                    return
            except ValueError:
                self.notify("âš  ç”¨æ³•: /rollback <æ•°å­—> æˆ– /å›é€€ <æ•°å­—>", severity="warning")
                return

        # Run async handler with worker tracking for interruption
        self._agent_running = True
        self._quit_pending = False
        self._agent_worker = self.run_worker(self._handle_submission(content), exclusive=False)
    
    async def _handle_submission(self, content: str) -> None:
        """Handle message submission asynchronously to ensure proper rendering"""
        import time
        t0 = time.perf_counter()
        
        messages_container = self.query_one("#messages", Container)
        chat_container = self.query_one("#chat-container", VerticalScroll)
        chat_input = self.query_one("#chat-input", ChatInput)
        
        # CRITICAL: Use await mount() to ensure user message renders BEFORE agent starts
        user_msg = UserMessage(content)
        await messages_container.mount(user_msg)
        t_mount = (time.perf_counter() - t0) * 1000
        
        # Show thinking spinner
        thinking = ThinkingSpinner()
        await messages_container.mount(thinking)
        
        # Single scroll after mounting both widgets
        chat_container.scroll_end(animate=False)
        
        # FORCE screen update to make message visible NOW
        self.refresh()
        await asyncio.sleep(0.05)  # Give UI time to actually render
        
        # Log timing
        print(f"\n[LATENCY] User message rendered in {t_mount:.2f}ms")
        
        # NOW process with agent (user message is already visible)
        t_agent_start = time.perf_counter()
        await self._process_message(content, thinking)
        t_agent_total = (time.perf_counter() - t_agent_start) * 1000
        print(f"[LATENCY] Agent processing took {t_agent_total:.2f}ms\n")

    
    async def _process_message(self, message: str, thinking_spinner: ThinkingSpinner | None = None) -> None:
        """Process message with agent using async astream"""
        import time
        
        messages_container = self.query_one("#messages", Container)
        chat_container = self.query_one("#chat-container", VerticalScroll)

        # Reset tracking
        self._current_assistant_msg = None
        self._shown_tool_calls = set()
        self._shown_tool_results = set()
        self._tool_call_widgets = {}
        
        last_content = ""
        last_update_time = 0
        update_interval = 0.05

        config = {"configurable": {"thread_id": self.thread_id}}
        
        try:
            async for chunk in self.agent.agent.astream(
                {"messages": [{"role": "user", "content": message}]},
                config=config,
                stream_mode="updates",
            ):
                if not chunk:
                    continue
                
                # Process chunk
                for node_name, node_update in chunk.items():
                    if not isinstance(node_update, dict) or "messages" not in node_update:
                        continue
                    
                    new_messages = node_update["messages"]
                    if not new_messages:
                        continue
                    
                    if not isinstance(new_messages, (list, tuple)):
                        new_messages = [new_messages]
                    
                    for msg in new_messages:
                        msg_class = msg.__class__.__name__
                        
                        if msg_class == "HumanMessage":
                            continue

                        if msg_class == "AIMessage":
                            raw_content = getattr(msg, "content", "")
                            
                            if isinstance(raw_content, str):
                                content = raw_content
                            elif isinstance(raw_content, list):
                                text_parts = []
                                for block in raw_content:
                                    if isinstance(block, dict) and block.get("type") == "text":
                                        text_parts.append(block.get("text", ""))
                                    elif isinstance(block, str):
                                        text_parts.append(block)
                                content = "".join(text_parts)
                            else:
                                content = str(raw_content)
                            
                            if content and content != last_content:
                                if thinking_spinner and thinking_spinner.is_mounted:
                                    await thinking_spinner.remove()
                                    thinking_spinner = None
                                
                                if not self._current_assistant_msg:
                                    self._current_assistant_msg = AssistantMessage()
                                    await messages_container.mount(self._current_assistant_msg)

                                current_time = time.time()
                                if current_time - last_update_time >= update_interval:
                                    self._current_assistant_msg.update_content(content)
                                    last_update_time = current_time
                                else:
                                    self._current_assistant_msg.update_content(content)
                                
                                last_content = content
                                self._last_assistant_message = content
                            
                            tool_calls = getattr(msg, "tool_calls", [])
                            if tool_calls:
                                self._current_assistant_msg = None
                                
                                for tool_call in tool_calls:
                                    tool_id = tool_call.get("id", "")
                                    tool_name = tool_call.get("name", "unknown")
                                    
                                    if tool_id and tool_id not in self._shown_tool_calls:
                                        if thinking_spinner and thinking_spinner.is_mounted:
                                            thinking_spinner.set_tool_execution(tool_name)
                                        
                                        tool_widget = ToolCallMessage(
                                            tool_name,
                                            tool_call.get("args", {}),
                                        )
                                        await messages_container.mount(tool_widget)
                                        
                                        self._tool_call_widgets[tool_id] = tool_widget
                                        self._shown_tool_calls.add(tool_id)

                        elif msg_class == "ToolMessage":
                            tool_call_id = getattr(msg, "tool_call_id", None)
                            if tool_call_id and tool_call_id not in self._shown_tool_results:
                                if tool_call_id in self._tool_call_widgets:
                                    self._tool_call_widgets[tool_call_id].mark_completed()
                                
                                await messages_container.mount(ToolResultMessage(msg.content))
                                self._shown_tool_results.add(tool_call_id)

        except asyncio.CancelledError:
            # Agent was interrupted by user
            interrupt_msg = SystemMessage("âš  å·²ä¸­æ–­")
            await messages_container.mount(interrupt_msg)
        except Exception as e:
            error_msg = AssistantMessage(f"âŒ é”™è¯¯: {str(e)}")
            await messages_container.mount(error_msg)
        finally:
            # Reset agent state
            self._agent_running = False
            self._agent_worker = None
            
            if thinking_spinner and thinking_spinner.is_mounted:
                await thinking_spinner.remove()
            
            if self._current_assistant_msg and last_content:
                self._current_assistant_msg.update_content(last_content)
            
            self._message_count += 1
            self._update_status_bar()
            
            chat_container.scroll_end(animate=False)
            
            chat_input = self.query_one("#chat-input", ChatInput)
            self.call_after_refresh(chat_input.focus_input)

    def action_history_up(self) -> None:
        """Navigate to previous input in history"""
        chat_input = self.query_one("#chat-input", ChatInput)
        chat_input.navigate_history("up")
    
    def action_history_down(self) -> None:
        """Navigate to next input in history"""
        chat_input = self.query_one("#chat-input", ChatInput)
        chat_input.navigate_history("down")
    
    def action_show_history(self) -> None:
        """Show history browser (double-ESC or /history)"""
        chat_input = self.query_one("#chat-input", ChatInput)
        history = chat_input.get_history()
        
        if not history:
            self.notify("æš‚æ— å†å²è®°å½•", severity="information")
            return
        
        def handle_history_selection(selected_index: int | None) -> None:
            """Handle history selection from browser"""
            if selected_index is not None:
                chat_input.set_text(history[selected_index])
                self.notify(f"âœ“ å·²åŠ è½½å†å²è®°å½• #{selected_index + 1}")
        
        self.push_screen(HistoryBrowser(history), handle_history_selection)
    
    def _rollback_history(self, steps: int) -> None:
        """Rollback to N steps ago in history"""
        chat_input = self.query_one("#chat-input", ChatInput)
        history = chat_input.get_history()
        
        if not history:
            self.notify("æš‚æ— å†å²è®°å½•", severity="warning")
            return
        
        if steps < 1 or steps > len(history):
            self.notify(f"âš  å›é€€æ­¥æ•°å¿…é¡»åœ¨ 1-{len(history)} ä¹‹é—´", severity="warning")
            return
        
        # å›é€€åˆ°å€’æ•°ç¬¬Næ¡
        target_index = len(history) - steps
        chat_input.set_text(history[target_index])
        self.notify(f"âœ“ å·²å›é€€åˆ° {steps} æ­¥å‰çš„è¾“å…¥")
    
    def action_copy_last_message(self) -> None:
        """Copy last assistant message to clipboard"""
        if self._last_assistant_message:
            import pyperclip
            try:
                pyperclip.copy(self._last_assistant_message)
                self.notify("âœ“ å·²å¤åˆ¶æœ€åä¸€æ¡æ¶ˆæ¯")
            except Exception:
                self.notify("âš  å¤åˆ¶å¤±è´¥ï¼ˆéœ€è¦å®‰è£… pyperclipï¼‰", severity="warning")
        else:
            self.notify("âš  æ²¡æœ‰å¯å¤åˆ¶çš„æ¶ˆæ¯", severity="warning")
    
    def action_export_conversation(self) -> None:
        """Export conversation to markdown file"""
        import datetime
        from pathlib import Path
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        export_path = self.workspace_root / f"conversation_{timestamp}.md"
        
        messages_container = self.query_one("#messages", Container)
        
        content = f"# Leon Agent å¯¹è¯è®°å½•\n\n"
        content += f"**å¯¼å‡ºæ—¶é—´**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        content += f"**Thread ID**: {self.thread_id}\n\n"
        content += "---\n\n"
        
        for widget in messages_container.children:
            widget_class = widget.__class__.__name__
            
            if widget_class == "UserMessage":
                content += f"## ğŸ‘¤ ç”¨æˆ·\n\n{widget._content}\n\n"
            elif widget_class == "AssistantMessage":
                content += f"## ğŸ¤– Leon\n\n{widget._content}\n\n"
            elif widget_class == "ToolCallMessage":
                content += f"### ğŸ”§ å·¥å…·è°ƒç”¨: {widget._tool_name}\n\n"
                if widget._tool_args:
                    content += "**å‚æ•°**:\n\n"
                    for k, v in widget._tool_args.items():
                        content += f"- `{k}`: {v}\n"
                content += "\n"
            elif widget_class == "ToolResultMessage":
                content += f"### ğŸ“¤ å·¥å…·è¿”å›\n\n```\n{widget._result}\n```\n\n"
        
        try:
            export_path.write_text(content, encoding="utf-8")
            self.notify(f"âœ“ å¯¹è¯å·²å¯¼å‡ºåˆ°: {export_path.name}")
        except Exception as e:
            self.notify(f"âš  å¯¼å‡ºå¤±è´¥: {str(e)}", severity="error")
    
    def _show_help(self) -> None:
        """Show help information as system message"""
        help_text = """Leon å¸®åŠ©ä¿¡æ¯

å¿«æ·é”®:
  â€¢ Enter: å‘é€æ¶ˆæ¯
  â€¢ Shift+Enter: æ¢è¡Œ
  â€¢ ESC ESC: æµè§ˆå†å²è¾“å…¥ï¼ˆå¼¹çª—é€‰æ‹©ï¼‰
  â€¢ Ctrl+C: ä¸­æ–­å½“å‰æ‰§è¡Œ / å†æŒ‰ä¸€æ¬¡é€€å‡º
  â€¢ Ctrl+D: ç›´æ¥é€€å‡º
  â€¢ Ctrl+T: åˆ‡æ¢å¯¹è¯ Thread
  â€¢ Ctrl+Y: å¤åˆ¶æœ€åä¸€æ¡æ¶ˆæ¯
  â€¢ Ctrl+E: å¯¼å‡ºå¯¹è¯ä¸º Markdown
  â€¢ Ctrl+L: æ¸…ç©ºå¯¹è¯å†å²

å‘½ä»¤:
  â€¢ /help: æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  â€¢ /history: æŸ¥çœ‹å†å²è¾“å…¥
  â€¢ /rollback N æˆ– /å›é€€ N: å›é€€åˆ°Næ­¥å‰çš„è¾“å…¥
  â€¢ /clear: æ¸…ç©ºå¯¹è¯å†å²
  â€¢ /exit æˆ– /quit: é€€å‡ºç¨‹åº
"""
        messages_container = self.query_one("#messages")
        chat_container = self.query_one("#chat-container", VerticalScroll)
        
        help_msg = SystemMessage(help_text)
        messages_container.mount(help_msg)
        # Scroll after help message is mounted
        self.call_after_refresh(lambda: chat_container.scroll_end(animate=False))
    
    def _update_status_bar(self) -> None:
        """Update status bar with message count"""
        status_bar = self.query_one("#status-bar", StatusBar)
        status_bar.update_stats(self._message_count)
    
    def action_quit_or_interrupt(self) -> None:
        """Handle Ctrl+C - interrupt agent or quit on double press.
        
        Priority:
        1. If agent is running, interrupt it
        2. If double press (quit_pending), quit
        3. Otherwise show quit hint
        """
        # If agent is running, interrupt it
        if self._agent_running and self._agent_worker:
            self._agent_worker.cancel()
            self._quit_pending = False
            self.notify("âš  æ­£åœ¨ä¸­æ–­...", timeout=2)
            return
        
        # Double Ctrl+C to quit
        if self._quit_pending:
            self.exit()
        else:
            self._quit_pending = True
            self.notify("å†æŒ‰ä¸€æ¬¡ Ctrl+C é€€å‡ºï¼Œæˆ–æŒ‰ Ctrl+D ç›´æ¥é€€å‡º", timeout=3)
    
    def action_clear_history(self) -> None:
        """Clear chat history"""
        import uuid

        # Generate new thread ID
        self.thread_id = f"chat-{uuid.uuid4().hex[:8]}"

        # Clear messages
        messages_container = self.query_one("#messages", Container)
        messages_container.remove_children()

        # Re-add welcome banner
        messages_container.mount(WelcomeBanner())

        # Update status bar
        status_bar = self.query_one("#status-bar", StatusBar)
        status_bar.update_thread(self.thread_id)

        # Reset counters
        self._message_count = 0
        self._last_assistant_message = ""

        # Save new thread
        if self.session_mgr:
            self.session_mgr.save_session(self.thread_id)

        # Show notification
        self.notify("âœ“ å¯¹è¯å†å²å·²æ¸…ç©º")

    def action_switch_thread(self) -> None:
        """åˆ‡æ¢åˆ°å…¶ä»–å¯¹è¯"""
        if not self.session_mgr:
            self.notify("âš  Session ç®¡ç†å™¨æœªåˆå§‹åŒ–", severity="warning")
            return

        threads = self.session_mgr.get_threads()
        if not threads:
            self.notify("æš‚æ— å†å²å¯¹è¯", severity="information")
            return

        # æ˜¾ç¤º thread åˆ—è¡¨ä¾›é€‰æ‹©
        from tui.widgets.thread_browser import ThreadBrowser

        def handle_thread_selection(selected_thread: str | None) -> None:
            if selected_thread and selected_thread != self.thread_id:
                self.thread_id = selected_thread
                self.session_mgr.save_session(self.thread_id)

                # æ¸…ç©ºå½“å‰æ¶ˆæ¯
                messages_container = self.query_one("#messages", Container)
                messages_container.remove_children()
                messages_container.mount(WelcomeBanner())

                # æ›´æ–°çŠ¶æ€æ 
                status_bar = self.query_one("#status-bar", StatusBar)
                status_bar.update_thread(self.thread_id)

                # é‡ç½®è®¡æ•°å™¨
                self._message_count = 0
                self._last_assistant_message = ""

                # åŠ è½½å†å²
                self.run_worker(self._load_history(), exclusive=False)
                self.notify(f"âœ“ å·²åˆ‡æ¢åˆ°å¯¹è¯: {self.thread_id}")

        self.push_screen(ThreadBrowser(threads, self.thread_id), handle_thread_selection)

    async def _load_history(self) -> None:
        """åŠ è½½å†å² messages"""
        try:
            config = {"configurable": {"thread_id": self.thread_id}}
            state = await self.agent.agent.aget_state(config)

            if not state or not state.values.get("messages"):
                return

            messages = state.values["messages"]
            if not messages:
                return

            messages_container = self.query_one("#messages", Container)
            chat_container = self.query_one("#chat-container", VerticalScroll)

            # ç§»é™¤ welcome banner
            try:
                welcome = messages_container.query_one(WelcomeBanner)
                await welcome.remove()
            except Exception:
                pass

            # æ¸²æŸ“å†å²æ¶ˆæ¯
            for msg in messages:
                msg_class = msg.__class__.__name__

                if msg_class == "HumanMessage":
                    await messages_container.mount(UserMessage(msg.content))
                    self._message_count += 1
                elif msg_class == "AIMessage":
                    content = msg.content
                    if isinstance(content, list):
                        text_parts = [b.get("text", "") if isinstance(b, dict) else str(b) for b in content]
                        content = "".join(text_parts)
                    if content:
                        await messages_container.mount(AssistantMessage(content))
                        self._last_assistant_message = content

                    # æ˜¾ç¤º tool calls
                    tool_calls = getattr(msg, "tool_calls", [])
                    for tool_call in tool_calls:
                        await messages_container.mount(
                            ToolCallMessage(tool_call.get("name", "unknown"), tool_call.get("args", {}))
                        )
                elif msg_class == "ToolMessage":
                    await messages_container.mount(ToolResultMessage(msg.content))

            # æ›´æ–°çŠ¶æ€æ 
            self._update_status_bar()

            # æ»šåŠ¨åˆ°åº•éƒ¨
            chat_container.scroll_end(animate=False)

            if self._message_count > 0:
                self.notify(f"âœ“ å·²åŠ è½½ {self._message_count} æ¡å†å²æ¶ˆæ¯")
        except Exception as e:
            self.notify(f"âš  åŠ è½½å†å²å¤±è´¥: {str(e)}", severity="warning")


def run_tui(agent, workspace_root: Path, thread_id: str = "default", session_mgr=None) -> None:
    """Run the Textual TUI"""
    app = LeonApp(agent, workspace_root, thread_id, session_mgr)
    app.run()
