# IOPS Benchmark Configuration - PlaFRIM SLURM Example
#
# This example demonstrates running IOR benchmarks on PlaFRIM cluster using SLURM.
#
# New Features Demonstrated:
# - Budget tracking: max_core_hours and cores_expr for resource management
# - Cache exclusion: cache_exclude_vars to exclude path-based variables from cache keys
# - Estimated time: estimated_time_seconds for dry-run analysis
# - Metadata saving: Automatic run_metadata.json for report generation
# - Analysis reports: Use --analyze to generate HTML reports with plots
# - Report vars: report_vars to specify which variables to use in reports (useful when you have string vars)
#
# Usage:
#   Normal run:  python -m iops.main example_plafrim.yaml
#   Dry-run:     python -m iops.main example_plafrim.yaml --dry-run --estimated-time "300,600,900"
#   Analysis:    python -m iops.main --analyze /path/to/workdir/run_XXX
#

benchmark:
  name: "IOR Benchmark"
  description: "A benchmark to measure I/O performance using the IOR tool."
  workdir: "/home/lgouveia/workdir/"
  cache_file: "/home/lgouveia/iops.db"
  repetitions: 1 # global repetitions for each test case. It is ignored when rounds has its own value
  search_method: "exhaustive" # used to define the policy for test execution selection
  executor : "slurm" # specify the executor to use : local | slurm
  # slurm_options:  # Optional: customize SLURM commands (useful for wrapper systems)
  #   commands:
  #     submit: "sbatch"                                     # default: sbatch (can be overridden per-script)
  #     status: "squeue -j {job_id} --noheader --format=%T" # default (use {job_id} placeholder)
  #     info: "scontrol show job {job_id}"                  # default
  #     cancel: "scancel {job_id}"                          # default
  #   poll_interval: 30                                      # default: 30 seconds (job status polling)
  random_seed: 43  # seed for any random operations in the benchmark
  cache_exclude_vars: ["summary_file"]  # Exclude path-based derived vars from cache key
  # Budget configuration (optional)
  max_core_hours: 1000  # Maximum CPU core-hours budget (can be overridden by --max-core-hours CLI argument)
  cores_expr: "{{ ntasks }}"  # Jinja expression to compute cores for SLURM (total tasks across all nodes)
  estimated_time_seconds: 300  # Estimated execution time per test for dry-run analysis (5 minutes)
  # Report configuration (optional)
  report_vars: ["nodes", "processes_per_node", "ost_number", "volume_size_gb"]  # Variables to use in analysis reports (excludes string 'ost_count')


vars:
  nodes:
    type: int
    sweep:
      mode: list
      values: [4, 8, 32]

  # Swept variables (global definition) 
  processes_per_node:
    type: int
    sweep:
      mode: list
      values: [8]

  volume_size_gb:
    type: int
    sweep:
      mode: list
      values: [32]
    
  ost_count:
    type: str
    sweep:
      mode: list
      values: ["/beegfs/lgouveia/ior_1", "/beegfs/lgouveia/ior_2", "/beegfs/lgouveia/ior_4", "/beegfs/lgouveia/ior_8"]
  
  ost_number:
    type: str
    expr: "{{ ost_count.split('_')[-1]  }}"  # Assuming each OST can handle 4GB

  block_size_mb:
    type: int
    expr: "((volume_size_gb * 1024) / (processes_per_node) )"

  ntasks:
    type: int
    expr: "{{ nodes * processes_per_node }}"

    
  summary_file:
    type: str
    expr: "{{ execution_dir }}/summary_{{ execution_id }}_{{ repetition }}.json"


  
    
command:
  template: >    
    ior -w -b {{ block_size_mb }}mb -t 1mb
    -O summaryFile={{summary_file}} -O summaryFormat=JSON
    -o {{ost_count}}/output.ior 

  labels:
    operation: "write"
    io_engine: "MPI-IO"
    access_pattern: "contiguous"

scripts:
  - name: "ior" 
    script_template: ../scripts/ior_slurm.sh
    

    post:
      script: |
        #!/bin/bash
        echo "Job completed. Summary file located at {{ summary_file }}"

    parser:
      file: "{{ summary_file }}"
      metrics:
        - name: bwMiB
      parser_script: ../scripts/ior_parser.py
     
output:
  sink:
    type: csv          # parquet | csv | sqlite
    path: "{{ workdir }}/results.csv"
    exclude: ["benchmark.name", "benchmark.description"]            # optional, exclude fields from output
    table: results         # only for sqlite


