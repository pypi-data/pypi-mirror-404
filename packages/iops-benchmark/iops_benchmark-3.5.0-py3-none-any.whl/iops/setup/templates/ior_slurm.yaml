# =============================================================================
# IOPS Configuration - IOR Benchmark (SLURM Cluster)
# =============================================================================
#
# A simple configuration for running IOR benchmarks on a SLURM cluster.
#
# Quick Start:
#   1. Update paths: workdir, output file path in command template
#   2. Update SLURM directives: partition, time limit, modules
#   3. Validate: iops check my_config.yaml
#   4. Dry run:  iops run my_config.yaml --dry-run
#   5. Execute:  iops run my_config.yaml
#
# For a fully documented template with all options, run: iops generate --full
# =============================================================================

benchmark:
  name: "IOR Benchmark"
  workdir: "./"
  repetitions: 3
  search_method: "exhaustive"
  executor: "slurm"
  cache_file: "./iops_cache.db"

vars:
  # Number of compute nodes
  nodes:
    type: int
    sweep:
      mode: list
      values: [1, 2, 4]

  # MPI processes per node
  processes_per_node:
    type: int
    sweep:
      mode: list
      values: [4, 8, 16]

  # Data volume size in GB
  volume_size_gb:
    type: int
    sweep:
      mode: list
      values: [8, 16, 32]

  # Total MPI tasks
  ntasks:
    type: int
    expr: "{{ nodes * processes_per_node }}"

  # Computed block size per process
  block_mb:
    type: int
    expr: "(volume_size_gb * 1024) // (nodes * processes_per_node)"

  # Output file for IOR JSON summary
  summary_file:
    type: str
    expr: "{{ execution_dir }}/summary.json"

command:
  template: >
    ior -w -r -b {{ block_mb }}m -t 1m
    -O summaryFile={{ summary_file }} -O summaryFormat=JSON
    -o /path/to/testfs/testfile.ior

scripts:
  - name: "ior"
    script_template: |
      #!/bin/bash

      #SBATCH --job-name=iops_{{ execution_id }}
      #SBATCH --nodes={{ nodes }}
      #SBATCH --ntasks={{ ntasks }}
      #SBATCH --ntasks-per-node={{ processes_per_node }}
      #SBATCH --time=01:00:00
      #SBATCH --chdir={{ execution_dir }}
      #SBATCH -o batch%j.out
      #SBATCH -e batch%j.err
      #SBATCH --exclusive

      # Customize these for your cluster:
      # #SBATCH --partition=your_partition
      # #SBATCH --account=your_account

      # Load required modules (customize for your cluster)
      module purge
      module load mpi

      echo "=== SLURM Allocation ==="
      echo "Nodes: $SLURM_JOB_NUM_NODES"
      echo "Tasks: $SLURM_NTASKS"
      echo "========================"

      # Execute the benchmark
      mpirun {{ command.template }}

    parser:
      file: "{{ summary_file }}"
      metrics:
        - name: bwMiB
      parser_script: |
        import json

        def parse(file_path: str):
            """Parse IOR JSON output and extract bandwidth metric."""
            with open(file_path, "r") as f:
                data = json.load(f)

            tests = data.get("tests", [])
            if not tests:
                raise ValueError("No tests found in IOR JSON output")

            results = tests[0].get("Results", [])
            if not results:
                raise ValueError("No Results found in IOR JSON output")

            # Get write result (or first result if only one exists)
            write_res = next(
                (r for r in results if str(r.get("access", "")).lower() == "write"),
                results[0],
            )

            return {"bwMiB": write_res.get("bwMiB")}

output:
  sink:
    type: csv
    path: "{{ workdir }}/results.csv"
