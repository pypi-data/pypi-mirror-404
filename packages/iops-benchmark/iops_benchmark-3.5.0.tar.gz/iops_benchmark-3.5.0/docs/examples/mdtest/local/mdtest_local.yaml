# =============================================================================
# IOPS mdtest Benchmark Configuration (Local Execution)
# =============================================================================
#
# This configuration runs mdtest locally using the local executor.
# Suitable for testing on a single machine or workstation.
#
# Quick Start:
#   1. Update the workdir and test_dir paths below
#   2. Ensure mdtest and MPI are installed and available
#   3. Validate: iops check examples/mdtest_config_local.yaml
#   4. Dry run: iops run examples/mdtest_config_local.yaml --dry-run
#   5. Execute: iops run examples/mdtest_config_local.yaml
#
# Documentation: https://lgouveia.gitlabpages.inria.fr/iops/reference/yaml-schema/
# =============================================================================


# =============================================================================
# BENCHMARK CONFIGURATION
# =============================================================================
benchmark:
  # Required: Name of the benchmark (used in logs and job names)
  name: "mdtest Benchmark (Local)"

  # Optional: Description of what this benchmark measures
  description: "Local mdtest benchmark to measure metadata performance"

  # Required: Working directory where all run outputs will be stored
  # Structure: <workdir>/run_NNN/runs/ and <workdir>/run_NNN/logs/
  workdir: "/tmp/iops_mdtest_workdir"

  # Optional: SQLite database for caching execution results
  # When --use_cache is specified, results are reused if parameters match
  cache_file: "/tmp/iops_mdtest_cache.db"

  # Optional: Number of repetitions for each test case (default: 1)
  repetitions: 2

  # Required: Test selection strategy
  search_method: "exhaustive"

  # Required: Execution backend
  executor: "local"

  # Optional: Random seed for reproducible random operations (default: None)
  random_seed: 42

  # Optional: Variables to exclude from cache key computation
  cache_exclude_vars: ["output_file", "test_dir"]

  # Optional: Variables to include in analysis reports
  report_vars: ["mpi_processes", "files_per_task", "tree_depth", "branch_factor", "file_size_bytes"]


# =============================================================================
# VARIABLES CONFIGURATION
# =============================================================================
vars:
  # ---------------------------------------------------------------------------
  # SWEPT VARIABLES (define parameter space)
  # ---------------------------------------------------------------------------

  # Number of MPI processes (local execution - typically lower values)
  mpi_processes:
    type: int
    sweep:
      mode: list
      values: [1, 2, 4]

  # Number of files to create per MPI task
  # Reduced for local testing to keep runtime reasonable
  files_per_task:
    type: int
    sweep:
      mode: list
      values: [10, 100, 1000]

  # Directory tree depth (0 = flat structure)
  tree_depth:
    type: int
    sweep:
      mode: list
      values: [0, 1]

  # Branching factor for directory tree (directories per level)
  # Only relevant when tree_depth > 0
  branch_factor:
    type: int
    sweep:
      mode: list
      values: [1, 5]

  # File size in bytes (mdtest focuses on metadata, so typically small)
  file_size_bytes:
    type: int
    sweep:
      mode: list
      values: [0, 4096]  # 0 = empty files, 4096 = 4KB

  # ---------------------------------------------------------------------------
  # DERIVED VARIABLES (computed from other variables)
  # ---------------------------------------------------------------------------

  # Total number of files created in the test
  total_files:
    type: int
    expr: "{{ files_per_task * mpi_processes }}"

  # Test directory path
  test_dir:
    type: str
    expr: "/tmp/mdtest_test_{{ execution_id }}"

  # Output file for mdtest results
  output_file:
    type: str
    expr: "{{ execution_dir }}/mdtest_output_{{ execution_id }}_{{ repetition }}.txt"


# =============================================================================
# COMMAND CONFIGURATION
# =============================================================================
command:
  # The command template - can be multiline using YAML '>' or '|' syntax
  template: >
    mdtest -n {{ files_per_task }} -d {{ test_dir }}
    -z {{ tree_depth }} -b {{ branch_factor }}
    -w {{ file_size_bytes }} -F -C -T -r

  # Optional: User-defined labels to attach to results
  labels:
    benchmark_type: "metadata"
    operations: "create,stat,remove"
    execution_mode: "local"


# =============================================================================
# SCRIPTS CONFIGURATION
# =============================================================================
scripts:
  # Script name (can define multiple scripts)
  - name: "mdtest"

    # Submission method for local executor

    # Script template for local execution
    script_template: |
      #!/bin/bash

      # Set error handling
      set -e

      # Create test directory
      mkdir -p {{ test_dir }}

      # Execute the benchmark command with MPI
      # For local execution, mpirun determines the number of processes
      # Redirect output to file since mdtest writes to stdout
      mpirun -np {{ mpi_processes }} {{ command.template }} > {{ output_file }} 2>&1

      # Cleanup test directory after benchmark
      rm -rf {{ test_dir }}

    # ---------------------------------------------------------------------------
    # POST-EXECUTION SCRIPT (optional)
    # ---------------------------------------------------------------------------
    post:
      script: |
        #!/bin/bash
        echo "Job completed at $(date)"
        echo "Output file: {{ output_file }}"
        echo "Total files tested: {{ total_files }}"

    # ---------------------------------------------------------------------------
    # PARSER CONFIGURATION
    # ---------------------------------------------------------------------------
    parser:
      # File to parse (typically a variable pointing to the output)
      file: "{{ output_file }}"

      # List of metrics to extract from mdtest output
      metrics:
        - name: file_creation_rate    # Files created per second
        - name: file_stat_rate         # Files stat'd per second
        - name: file_read_rate         # Files read per second
        - name: file_removal_rate      # Files removed per second
        - name: tree_creation_rate     # Tree creation rate
        - name: tree_removal_rate      # Tree removal rate

      # External parser script for mdtest output
      # Parses the SUMMARY rate table from mdtest output
      parser_script: example/scripts/mdtest_parser.py


# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
output:
  sink:
    # Output format: csv | parquet | sqlite
    type: csv

    # Output path (supports Jinja2 templating)
    path: "{{ workdir }}/results.csv"

    # Optional: Exclude specific fields (mutually exclusive with 'include')
    exclude: ["benchmark.description"]


# =============================================================================
# REPORTING CONFIGURATION
# =============================================================================
# Automatic HTML report generation with interactive plots
# Reports include performance analysis, best configurations, and custom visualizations
# =============================================================================
reporting:
  # Enable automatic report generation after execution
  enabled: true

  # Output configuration
  output_filename: "mdtest_performance_report.html"
  # output_dir defaults to workdir if not specified

  # -------------------- Theme Configuration --------------------
  theme:
    style: "plotly_white"              # Clean white background
    # Other options: "plotly", "plotly_dark", "ggplot2", "seaborn", "simple_white"

    colors:
      - "#1f77b4"  # Blue
      - "#ff7f0e"  # Orange
      - "#2ca02c"  # Green
      - "#d62728"  # Red
      - "#9467bd"  # Purple

    font_family: "Segoe UI, Tahoma, Geneva, Verdana, sans-serif"

  # -------------------- Section Control --------------------
  sections:
    test_summary: true           # Execution statistics and parameter space
    best_results: true           # Top configurations per metric
    variable_impact: true        # Variable importance analysis
    parallel_coordinates: true   # Multi-dimensional visualization
    custom_plots: true           # User-defined plots

  # -------------------- Best Results Configuration --------------------
  best_results:
    top_n: 5                     # Show top 5 configurations per metric
    show_command: true           # Include the rendered command

  # -------------------- Per-Metric Custom Plots --------------------
  metrics:
    # File creation performance
    file_creation_rate:
      plots:
        - type: "line"
          x_var: "files_per_task"
          group_by: "mpi_processes"
          title: "File Creation Rate by Files per Task"
          xaxis_label: "Files per Task"
          yaxis_label: "Creation Rate (ops/sec)"
          show_error_bars: true

        - type: "heatmap"
          x_var: "mpi_processes"
          y_var: "files_per_task"
          title: "File Creation Rate Heatmap"
          colorscale: "Viridis"

    # File stat performance
    file_stat_rate:
      plots:
        - type: "bar"
          x_var: "tree_depth"
          group_by: "branch_factor"
          title: "Stat Rate by Tree Depth"
          xaxis_label: "Tree Depth"
          yaxis_label: "Stat Rate (ops/sec)"

    # File removal performance
    file_removal_rate:
      plots:
        - type: "line"
          x_var: "files_per_task"
          group_by: "file_size_bytes"
          title: "File Removal Rate"
          xaxis_label: "Files per Task"
          yaxis_label: "Removal Rate (ops/sec)"

  # -------------------- Default Plots --------------------
  # For metrics without custom configuration
  default_plots:
    - type: "bar"
      per_variable: true         # One plot per swept variable
      show_error_bars: true


# =============================================================================
# ADDITIONAL NOTES
# =============================================================================
#
# Local Execution Notes:
#   - This configuration uses the "local" executor which runs scripts directly
#   - No SLURM cluster required - runs on your local machine
#   - MPI processes are limited to what your machine can handle
#   - Test parameters are scaled down for faster local testing
#
# Before Running:
#   - Ensure mdtest is installed and in your PATH
#   - Ensure MPI (OpenMPI or MPICH) is installed
#   - Update workdir and test_dir paths as needed
#   - The test directory will be created and cleaned up automatically
#
# To Run:
#   iops run examples/mdtest_config_local.yaml
#
# With Caching:
#   iops run examples/mdtest_config_local.yaml --use-cache
#
# =============================================================================
