"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""

import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import frogml._proto.qwak.feature_store.features.aggregation_pb2
import frogml._proto.qwak.feature_store.features.execution_pb2
import frogml._proto.qwak.feature_store.features.monitoring_pb2
import frogml._proto.qwak.feature_store.features.real_time_feature_extractor_pb2
import frogml._proto.qwak.feature_store.sinks.sink_pb2
import frogml._proto.qwak.feature_store.sources.batch_pb2
import frogml._proto.qwak.feature_store.sources.streaming_pb2
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _FeatureSetTypeView:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _FeatureSetTypeViewEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_FeatureSetTypeView.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    FEATURE_SET_TYPE_VIEW_INVALID: _FeatureSetTypeView.ValueType  # 0
    FEATURE_SET_TYPE_VIEW_BATCH: _FeatureSetTypeView.ValueType  # 1
    FEATURE_SET_TYPE_VIEW_STREAMING: _FeatureSetTypeView.ValueType  # 2

class FeatureSetTypeView(_FeatureSetTypeView, metaclass=_FeatureSetTypeViewEnumTypeWrapper): ...

FEATURE_SET_TYPE_VIEW_INVALID: FeatureSetTypeView.ValueType  # 0
FEATURE_SET_TYPE_VIEW_BATCH: FeatureSetTypeView.ValueType  # 1
FEATURE_SET_TYPE_VIEW_STREAMING: FeatureSetTypeView.ValueType  # 2
global___FeatureSetTypeView = FeatureSetTypeView

@typing.final
class FeatureSetType(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    BATCH_FEATURE_SET_FIELD_NUMBER: builtins.int
    ON_THE_FLY_FEATURE_SET_FIELD_NUMBER: builtins.int
    STREAMING_FEATURE_SET_FIELD_NUMBER: builtins.int
    STREAMING_FEATURE_SET_V1_FIELD_NUMBER: builtins.int
    BATCH_FEATURE_SET_V1_FIELD_NUMBER: builtins.int
    STREAMING_AGGREGATION_FEATURE_SET_FIELD_NUMBER: builtins.int
    @property
    def batch_feature_set(self) -> global___BatchFeatureSet: ...
    @property
    def on_the_fly_feature_set(self) -> global___OnTheFlyFeatureSet: ...
    @property
    def streaming_feature_set(self) -> global___StreamingFeatureSet: ...
    @property
    def streaming_feature_set_v1(self) -> global___StreamingFeatureSetV1: ...
    @property
    def batch_feature_set_v1(self) -> global___BatchFeatureSetV1: ...
    @property
    def streaming_aggregation_feature_set(self) -> global___StreamingAggregationFeatureSet: ...
    def __init__(
        self,
        *,
        batch_feature_set: global___BatchFeatureSet | None = ...,
        on_the_fly_feature_set: global___OnTheFlyFeatureSet | None = ...,
        streaming_feature_set: global___StreamingFeatureSet | None = ...,
        streaming_feature_set_v1: global___StreamingFeatureSetV1 | None = ...,
        batch_feature_set_v1: global___BatchFeatureSetV1 | None = ...,
        streaming_aggregation_feature_set: global___StreamingAggregationFeatureSet | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["batch_feature_set", b"batch_feature_set", "batch_feature_set_v1", b"batch_feature_set_v1", "on_the_fly_feature_set", b"on_the_fly_feature_set", "set_type", b"set_type", "streaming_aggregation_feature_set", b"streaming_aggregation_feature_set", "streaming_feature_set", b"streaming_feature_set", "streaming_feature_set_v1", b"streaming_feature_set_v1"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["batch_feature_set", b"batch_feature_set", "batch_feature_set_v1", b"batch_feature_set_v1", "on_the_fly_feature_set", b"on_the_fly_feature_set", "set_type", b"set_type", "streaming_aggregation_feature_set", b"streaming_aggregation_feature_set", "streaming_feature_set", b"streaming_feature_set", "streaming_feature_set_v1", b"streaming_feature_set_v1"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["set_type", b"set_type"]) -> typing.Literal["batch_feature_set", "on_the_fly_feature_set", "streaming_feature_set", "streaming_feature_set_v1", "batch_feature_set_v1", "streaming_aggregation_feature_set"] | None: ...

global___FeatureSetType = FeatureSetType

@typing.final
class BatchFeatureSet(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SCHEDULING_POLICY_FIELD_NUMBER: builtins.int
    DATA_SOURCES_FIELD_NUMBER: builtins.int
    BACKFILL_FIELD_NUMBER: builtins.int
    FUNCTION_FIELD_NUMBER: builtins.int
    FEATURE_SET_BATCH_SOURCES_FIELD_NUMBER: builtins.int
    MONITORING_CONFIGURATIONS_FIELD_NUMBER: builtins.int
    scheduling_policy: builtins.str
    """Scheduling policy of the resulting ETL that will generate data for this feature"""
    @property
    def data_sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[qwak.feature_store.sources.batch_pb2.BatchSource]:
        """Data sources used by the feature set
        Will assume the DataSourceReadPolicy of these sources are of type ReadOnce
        """

    @property
    def backfill(self) -> global___Backfill:
        """Backfill strategy"""

    @property
    def function(self) -> global___Function:
        """Actual function code"""

    @property
    def feature_set_batch_sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FeatureSetBatchSource]:
        """Data sources and their properties which are used by the feature set"""

    @property
    def monitoring_configurations(self) -> frogml._proto.qwak.feature_store.features.monitoring_pb2.MonitoringConfigurations:
        """Monitoring configuration"""

    def __init__(
        self,
        *,
        scheduling_policy: builtins.str = ...,
        data_sources: collections.abc.Iterable[qwak.feature_store.sources.batch_pb2.BatchSource] | None = ...,
        backfill: global___Backfill | None = ...,
        function: global___Function | None = ...,
        feature_set_batch_sources: collections.abc.Iterable[global___FeatureSetBatchSource] | None = ...,
        monitoring_configurations: frogml._proto.qwak.feature_store.features.monitoring_pb2.MonitoringConfigurations | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["backfill", b"backfill", "function", b"function", "monitoring_configurations", b"monitoring_configurations"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["backfill", b"backfill", "data_sources", b"data_sources", "feature_set_batch_sources", b"feature_set_batch_sources", "function", b"function", "monitoring_configurations", b"monitoring_configurations", "scheduling_policy", b"scheduling_policy"]) -> None: ...

global___BatchFeatureSet = BatchFeatureSet

@typing.final
class BatchFeatureSetV1(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SCHEDULING_POLICY_FIELD_NUMBER: builtins.int
    BACKFILL_FIELD_NUMBER: builtins.int
    FUNCTION_FIELD_NUMBER: builtins.int
    FEATURE_SET_BATCH_SOURCES_FIELD_NUMBER: builtins.int
    EXECUTION_SPEC_FIELD_NUMBER: builtins.int
    OFFLINE_SINK_FIELD_NUMBER: builtins.int
    ONLINE_SINK_FIELD_NUMBER: builtins.int
    MONITORING_CONFIGURATIONS_FIELD_NUMBER: builtins.int
    TIMESTAMP_COLUMN_NAME_FIELD_NUMBER: builtins.int
    TRANSFORMATION_FIELD_NUMBER: builtins.int
    QWAK_INTERNAL_PROTOCOL_VERSION_FIELD_NUMBER: builtins.int
    REAL_TIME_FEATURE_EXTRACTOR_FIELD_NUMBER: builtins.int
    scheduling_policy: builtins.str
    """Scheduling policy of batch feature set. Can be a cron string format or @annotation: @daily, @monthly, @yearly"""
    offline_sink: builtins.bool
    """Is Feature set has offline store"""
    online_sink: builtins.bool
    """Is Feature set has online store"""
    timestamp_column_name: builtins.str
    """Name of the timestamp column (must exist in the result), i.e: event time column"""
    qwak_internal_protocol_version: builtins.int
    """Qwak featureset version"""
    @property
    def backfill(self) -> global___Backfill:
        """Backfill strategy"""

    @property
    def function(self) -> global___Function:
        """Actual function code"""

    @property
    def feature_set_batch_sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FeatureSetBatchSource]:
        """Data sources and their properties which are used by the feature set"""

    @property
    def execution_spec(self) -> frogml._proto.qwak.feature_store.features.execution_pb2.ExecutionSpec:
        """Execution Spec of the FeatureSet"""

    @property
    def monitoring_configurations(self) -> frogml._proto.qwak.feature_store.features.monitoring_pb2.MonitoringConfigurations:
        """Monitoring configuration"""

    @property
    def transformation(self) -> global___Transformation:
        """Transformation"""

    @property
    def real_time_feature_extractor(self) -> frogml._proto.qwak.feature_store.features.real_time_feature_extractor_pb2.RealTimeFeatureExtractor: ...
    def __init__(
        self,
        *,
        scheduling_policy: builtins.str = ...,
        backfill: global___Backfill | None = ...,
        function: global___Function | None = ...,
        feature_set_batch_sources: collections.abc.Iterable[global___FeatureSetBatchSource] | None = ...,
        execution_spec: frogml._proto.qwak.feature_store.features.execution_pb2.ExecutionSpec | None = ...,
        offline_sink: builtins.bool = ...,
        online_sink: builtins.bool = ...,
        monitoring_configurations: frogml._proto.qwak.feature_store.features.monitoring_pb2.MonitoringConfigurations | None = ...,
        timestamp_column_name: builtins.str = ...,
        transformation: global___Transformation | None = ...,
        qwak_internal_protocol_version: builtins.int = ...,
        real_time_feature_extractor: frogml._proto.qwak.feature_store.features.real_time_feature_extractor_pb2.RealTimeFeatureExtractor | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["backfill", b"backfill", "execution_spec", b"execution_spec", "feature_extractor", b"feature_extractor", "function", b"function", "monitoring_configurations", b"monitoring_configurations", "real_time_feature_extractor", b"real_time_feature_extractor", "transformation", b"transformation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["backfill", b"backfill", "execution_spec", b"execution_spec", "feature_extractor", b"feature_extractor", "feature_set_batch_sources", b"feature_set_batch_sources", "function", b"function", "monitoring_configurations", b"monitoring_configurations", "offline_sink", b"offline_sink", "online_sink", b"online_sink", "qwak_internal_protocol_version", b"qwak_internal_protocol_version", "real_time_feature_extractor", b"real_time_feature_extractor", "scheduling_policy", b"scheduling_policy", "timestamp_column_name", b"timestamp_column_name", "transformation", b"transformation"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["feature_extractor", b"feature_extractor"]) -> typing.Literal["real_time_feature_extractor"] | None: ...

global___BatchFeatureSetV1 = BatchFeatureSetV1

@typing.final
class FeatureSetBatchSource(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_SOURCE_FIELD_NUMBER: builtins.int
    READ_POLICY_FIELD_NUMBER: builtins.int
    @property
    def data_source(self) -> frogml._proto.qwak.feature_store.sources.batch_pb2.BatchSource:
        """Batch data source definition"""

    @property
    def read_policy(self) -> global___DataSourceReadPolicy:
        """Read policy of this batch source"""

    def __init__(
        self,
        *,
        data_source: frogml._proto.qwak.feature_store.sources.batch_pb2.BatchSource | None = ...,
        read_policy: global___DataSourceReadPolicy | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["data_source", b"data_source", "read_policy", b"read_policy"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["data_source", b"data_source", "read_policy", b"read_policy"]) -> None: ...

global___FeatureSetBatchSource = FeatureSetBatchSource

@typing.final
class StreamingFeatureSet(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_SOURCES_FIELD_NUMBER: builtins.int
    @property
    def data_sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[qwak.feature_store.sources.streaming_pb2.StreamingSource]:
        """Data sources used by the feature"""

    def __init__(
        self,
        *,
        data_sources: collections.abc.Iterable[qwak.feature_store.sources.streaming_pb2.StreamingSource] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["data_sources", b"data_sources"]) -> None: ...

global___StreamingFeatureSet = StreamingFeatureSet

@typing.final
class StreamingFeatureSetV1(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_SOURCES_FIELD_NUMBER: builtins.int
    TRANSFORMATION_FIELD_NUMBER: builtins.int
    EXECUTION_SPEC_FIELD_NUMBER: builtins.int
    TIMESTAMP_COLUMN_NAME_FIELD_NUMBER: builtins.int
    ONLINE_TRIGGER_INTERVAL_FIELD_NUMBER: builtins.int
    OFFLINE_SCHEDULING_POLICY_FIELD_NUMBER: builtins.int
    QWAK_INTERNAL_PROTOCOL_VERSION_FIELD_NUMBER: builtins.int
    AUXILIARY_SINKS_FIELD_NUMBER: builtins.int
    timestamp_column_name: builtins.str
    """Name of the timestamp column (must exist in the result),
    used for creating a total order over the events
    """
    online_trigger_interval: builtins.int
    """Trigger interval for the Online, in seconds"""
    offline_scheduling_policy: builtins.str
    """scheduling policy for the offline jobs"""
    qwak_internal_protocol_version: builtins.int
    """Qwak featureset version"""
    @property
    def data_sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[qwak.feature_store.sources.streaming_pb2.StreamingSource]:
        """Data sources used by the FeatureSet"""

    @property
    def transformation(self) -> global___Transformation:
        """transformation flavour"""

    @property
    def execution_spec(self) -> frogml._proto.qwak.feature_store.features.execution_pb2.StreamingExecutionSpec:
        """Execution Spec of the FeatureSet"""

    @property
    def auxiliary_sinks(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[qwak.feature_store.sinks.sink_pb2.StreamingSink]:
        """Auxiliary Sinks defined for this Featureset"""

    def __init__(
        self,
        *,
        data_sources: collections.abc.Iterable[qwak.feature_store.sources.streaming_pb2.StreamingSource] | None = ...,
        transformation: global___Transformation | None = ...,
        execution_spec: frogml._proto.qwak.feature_store.features.execution_pb2.StreamingExecutionSpec | None = ...,
        timestamp_column_name: builtins.str = ...,
        online_trigger_interval: builtins.int = ...,
        offline_scheduling_policy: builtins.str = ...,
        qwak_internal_protocol_version: builtins.int = ...,
        auxiliary_sinks: collections.abc.Iterable[qwak.feature_store.sinks.sink_pb2.StreamingSink] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["execution_spec", b"execution_spec", "transformation", b"transformation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["auxiliary_sinks", b"auxiliary_sinks", "data_sources", b"data_sources", "execution_spec", b"execution_spec", "offline_scheduling_policy", b"offline_scheduling_policy", "online_trigger_interval", b"online_trigger_interval", "qwak_internal_protocol_version", b"qwak_internal_protocol_version", "timestamp_column_name", b"timestamp_column_name", "transformation", b"transformation"]) -> None: ...

global___StreamingFeatureSetV1 = StreamingFeatureSetV1

@typing.final
class StreamingAggregationFeatureSet(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_SOURCES_FIELD_NUMBER: builtins.int
    TRANSFORMATION_FIELD_NUMBER: builtins.int
    EXECUTION_SPEC_FIELD_NUMBER: builtins.int
    TIMESTAMP_COLUMN_NAME_FIELD_NUMBER: builtins.int
    ONLINE_TRIGGER_INTERVAL_FIELD_NUMBER: builtins.int
    COMPACTION_SCHEDULING_POLICY_FIELD_NUMBER: builtins.int
    AGGREGATION_SPEC_FIELD_NUMBER: builtins.int
    BACKFILL_SPEC_FIELD_NUMBER: builtins.int
    QWAK_INTERNAL_PROTOCOL_VERSION_FIELD_NUMBER: builtins.int
    BACKFILL_MAX_TIMESTAMP_FIELD_NUMBER: builtins.int
    timestamp_column_name: builtins.str
    """Name of the timestamp column (must exist in the result),
    used for creating a total order over the events
    """
    online_trigger_interval: builtins.int
    """Trigger interval for the Online, in seconds"""
    compaction_scheduling_policy: builtins.str
    """scheduling policy for the compaction job, cron expression"""
    qwak_internal_protocol_version: builtins.int
    """Qwak featureset version"""
    @property
    def data_sources(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[qwak.feature_store.sources.streaming_pb2.StreamingSource]:
        """Data sources used by the FeatureSet"""

    @property
    def transformation(self) -> global___Transformation:
        """transformation flavour"""

    @property
    def execution_spec(self) -> frogml._proto.qwak.feature_store.features.execution_pb2.StreamingExecutionSpec:
        """Execution Spec of the FeatureSet"""

    @property
    def aggregation_spec(self) -> global___AggregationSpec:
        """Aggregation spec for the feature set"""

    @property
    def backfill_spec(self) -> global___BackfillSpec:
        """Backfill spec"""

    @property
    def backfill_max_timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Event-time cutoff point between backfill jobs and compaction/row-level jobs"""

    def __init__(
        self,
        *,
        data_sources: collections.abc.Iterable[qwak.feature_store.sources.streaming_pb2.StreamingSource] | None = ...,
        transformation: global___Transformation | None = ...,
        execution_spec: frogml._proto.qwak.feature_store.features.execution_pb2.StreamingExecutionSpec | None = ...,
        timestamp_column_name: builtins.str = ...,
        online_trigger_interval: builtins.int = ...,
        compaction_scheduling_policy: builtins.str = ...,
        aggregation_spec: global___AggregationSpec | None = ...,
        backfill_spec: global___BackfillSpec | None = ...,
        qwak_internal_protocol_version: builtins.int = ...,
        backfill_max_timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["aggregation_spec", b"aggregation_spec", "backfill_max_timestamp", b"backfill_max_timestamp", "backfill_spec", b"backfill_spec", "execution_spec", b"execution_spec", "transformation", b"transformation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["aggregation_spec", b"aggregation_spec", "backfill_max_timestamp", b"backfill_max_timestamp", "backfill_spec", b"backfill_spec", "compaction_scheduling_policy", b"compaction_scheduling_policy", "data_sources", b"data_sources", "execution_spec", b"execution_spec", "online_trigger_interval", b"online_trigger_interval", "qwak_internal_protocol_version", b"qwak_internal_protocol_version", "timestamp_column_name", b"timestamp_column_name", "transformation", b"transformation"]) -> None: ...

global___StreamingAggregationFeatureSet = StreamingAggregationFeatureSet

@typing.final
class BackfillBatchDataSourceSpec(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DATA_SOURCE_FIELD_NUMBER: builtins.int
    START_TIMESTAMP_FIELD_NUMBER: builtins.int
    END_TIMESTAMP_FIELD_NUMBER: builtins.int
    @property
    def data_source(self) -> frogml._proto.qwak.feature_store.sources.batch_pb2.BatchSource:
        """Batch data source"""

    @property
    def start_timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Optional start timestamp"""

    @property
    def end_timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Optional end timestamp"""

    def __init__(
        self,
        *,
        data_source: frogml._proto.qwak.feature_store.sources.batch_pb2.BatchSource | None = ...,
        start_timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        end_timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["data_source", b"data_source", "end_timestamp", b"end_timestamp", "start_timestamp", b"start_timestamp"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["data_source", b"data_source", "end_timestamp", b"end_timestamp", "start_timestamp", b"start_timestamp"]) -> None: ...

global___BackfillBatchDataSourceSpec = BackfillBatchDataSourceSpec

@typing.final
class BackfillDataSourceSpec(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    BATCH_DATA_SOURCE_SPEC_FIELD_NUMBER: builtins.int
    @property
    def batch_data_source_spec(self) -> global___BackfillBatchDataSourceSpec: ...
    def __init__(
        self,
        *,
        batch_data_source_spec: global___BackfillBatchDataSourceSpec | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["batch_data_source_spec", b"batch_data_source_spec", "type", b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["batch_data_source_spec", b"batch_data_source_spec", "type", b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["type", b"type"]) -> typing.Literal["batch_data_source_spec"] | None: ...

global___BackfillDataSourceSpec = BackfillDataSourceSpec

@typing.final
class BackfillSpec(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    EXECUTION_SPEC_FIELD_NUMBER: builtins.int
    START_TIMESTAMP_FIELD_NUMBER: builtins.int
    END_TIMESTAMP_FIELD_NUMBER: builtins.int
    TRANSFORMATION_FIELD_NUMBER: builtins.int
    DATA_SOURCE_SPECS_FIELD_NUMBER: builtins.int
    @property
    def execution_spec(self) -> frogml._proto.qwak.feature_store.features.execution_pb2.BackfillExecutionSpec:
        """Backfill resource spec"""

    @property
    def start_timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Backfill start timestamp"""

    @property
    def end_timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Backfill end timestamp"""

    @property
    def transformation(self) -> global___Transformation:
        """Transformation"""

    @property
    def data_source_specs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___BackfillDataSourceSpec]: ...
    def __init__(
        self,
        *,
        execution_spec: frogml._proto.qwak.feature_store.features.execution_pb2.BackfillExecutionSpec | None = ...,
        start_timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        end_timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        transformation: global___Transformation | None = ...,
        data_source_specs: collections.abc.Iterable[global___BackfillDataSourceSpec] | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["end_timestamp", b"end_timestamp", "execution_spec", b"execution_spec", "start_timestamp", b"start_timestamp", "transformation", b"transformation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["data_source_specs", b"data_source_specs", "end_timestamp", b"end_timestamp", "execution_spec", b"execution_spec", "start_timestamp", b"start_timestamp", "transformation", b"transformation"]) -> None: ...

global___BackfillSpec = BackfillSpec

@typing.final
class AggregationSpec(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    AGGREGATIONS_FIELD_NUMBER: builtins.int
    SLIDE_SECONDS_FIELD_NUMBER: builtins.int
    ALLOWED_LATE_ARRIVAL_SECONDS_FIELD_NUMBER: builtins.int
    slide_seconds: builtins.int
    """Aggregation slide in seconds"""
    allowed_late_arrival_seconds: builtins.int
    """Watermark"""
    @property
    def aggregations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[qwak.feature_store.features.aggregation_pb2.AggregationField]:
        """List of aggregations"""

    def __init__(
        self,
        *,
        aggregations: collections.abc.Iterable[qwak.feature_store.features.aggregation_pb2.AggregationField] | None = ...,
        slide_seconds: builtins.int = ...,
        allowed_late_arrival_seconds: builtins.int = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["aggregations", b"aggregations", "allowed_late_arrival_seconds", b"allowed_late_arrival_seconds", "slide_seconds", b"slide_seconds"]) -> None: ...

global___AggregationSpec = AggregationSpec

@typing.final
class Transformation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    UDF_TRANSFORMATION_FIELD_NUMBER: builtins.int
    SQL_TRANSFORMATION_FIELD_NUMBER: builtins.int
    KOALAS_TRANSFORMATION_FIELD_NUMBER: builtins.int
    PYSPARK_TRANSFORMATION_FIELD_NUMBER: builtins.int
    PANDAS_ON_SPARK_TRANSFORMATION_FIELD_NUMBER: builtins.int
    ARTIFACT_PATH_FIELD_NUMBER: builtins.int
    artifact_path: builtins.str
    @property
    def udf_transformation(self) -> global___UdfTransformation:
        """UDF Transformation - a pandas_udf that gets the entire row"""

    @property
    def sql_transformation(self) -> global___SqlTransformation:
        """User provided sql"""

    @property
    def koalas_transformation(self) -> global___KoalasTransformation:
        """Koalas provided transformation"""

    @property
    def pyspark_transformation(self) -> global___PySparkTransformation:
        """PySpark provided transformation"""

    @property
    def pandas_on_spark_transformation(self) -> global___PandasOnSparkTransformation:
        """Pandas provided transformation"""

    def __init__(
        self,
        *,
        udf_transformation: global___UdfTransformation | None = ...,
        sql_transformation: global___SqlTransformation | None = ...,
        koalas_transformation: global___KoalasTransformation | None = ...,
        pyspark_transformation: global___PySparkTransformation | None = ...,
        pandas_on_spark_transformation: global___PandasOnSparkTransformation | None = ...,
        artifact_path: builtins.str = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["koalas_transformation", b"koalas_transformation", "pandas_on_spark_transformation", b"pandas_on_spark_transformation", "pyspark_transformation", b"pyspark_transformation", "sql_transformation", b"sql_transformation", "type", b"type", "udf_transformation", b"udf_transformation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["artifact_path", b"artifact_path", "koalas_transformation", b"koalas_transformation", "pandas_on_spark_transformation", b"pandas_on_spark_transformation", "pyspark_transformation", b"pyspark_transformation", "sql_transformation", b"sql_transformation", "type", b"type", "udf_transformation", b"udf_transformation"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["type", b"type"]) -> typing.Literal["udf_transformation", "sql_transformation", "koalas_transformation", "pyspark_transformation", "pandas_on_spark_transformation"] | None: ...

global___Transformation = Transformation

@typing.final
class UdfTransformation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FUNCTION_NAME_FIELD_NUMBER: builtins.int
    function_name: builtins.str
    """The user defined function name"""
    def __init__(
        self,
        *,
        function_name: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["function_name", b"function_name"]) -> None: ...

global___UdfTransformation = UdfTransformation

@typing.final
class SqlTransformation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SQL_FIELD_NUMBER: builtins.int
    FUNCTION_NAMES_FIELD_NUMBER: builtins.int
    sql: builtins.str
    """Sql string to run on the input data frame"""
    @property
    def function_names(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
        """The user defined functions names"""

    def __init__(
        self,
        *,
        sql: builtins.str = ...,
        function_names: collections.abc.Iterable[builtins.str] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["function_names", b"function_names", "sql", b"sql"]) -> None: ...

global___SqlTransformation = SqlTransformation

@typing.final
class KoalasTransformation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FUNCTION_NAME_FIELD_NUMBER: builtins.int
    QWARGS_FIELD_NUMBER: builtins.int
    function_name: builtins.str
    """User defined Koalas function name"""
    @property
    def qwargs(self) -> global___TransformArguments: ...
    def __init__(
        self,
        *,
        function_name: builtins.str = ...,
        qwargs: global___TransformArguments | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["args_option", b"args_option", "qwargs", b"qwargs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["args_option", b"args_option", "function_name", b"function_name", "qwargs", b"qwargs"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["args_option", b"args_option"]) -> typing.Literal["qwargs"] | None: ...

global___KoalasTransformation = KoalasTransformation

@typing.final
class PySparkTransformation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FUNCTION_NAME_FIELD_NUMBER: builtins.int
    QWARGS_FIELD_NUMBER: builtins.int
    function_name: builtins.str
    """User defined pyspark function name"""
    @property
    def qwargs(self) -> global___TransformArguments: ...
    def __init__(
        self,
        *,
        function_name: builtins.str = ...,
        qwargs: global___TransformArguments | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["args_option", b"args_option", "qwargs", b"qwargs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["args_option", b"args_option", "function_name", b"function_name", "qwargs", b"qwargs"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["args_option", b"args_option"]) -> typing.Literal["qwargs"] | None: ...

global___PySparkTransformation = PySparkTransformation

@typing.final
class PandasOnSparkTransformation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FUNCTION_NAME_FIELD_NUMBER: builtins.int
    QWARGS_FIELD_NUMBER: builtins.int
    function_name: builtins.str
    """Used defined Pandas function name"""
    @property
    def qwargs(self) -> global___TransformArguments: ...
    def __init__(
        self,
        *,
        function_name: builtins.str = ...,
        qwargs: global___TransformArguments | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["args_option", b"args_option", "qwargs", b"qwargs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["args_option", b"args_option", "function_name", b"function_name", "qwargs", b"qwargs"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["args_option", b"args_option"]) -> typing.Literal["qwargs"] | None: ...

global___PandasOnSparkTransformation = PandasOnSparkTransformation

@typing.final
class TransformArguments(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    @typing.final
    class QwargsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor

        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: builtins.str
        value: builtins.str
        def __init__(
            self,
            *,
            key: builtins.str = ...,
            value: builtins.str = ...,
        ) -> None: ...
        def ClearField(self, field_name: typing.Literal["key", b"key", "value", b"value"]) -> None: ...

    QWARGS_FIELD_NUMBER: builtins.int
    @property
    def qwargs(self) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]: ...
    def __init__(
        self,
        *,
        qwargs: collections.abc.Mapping[builtins.str, builtins.str] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["qwargs", b"qwargs"]) -> None: ...

global___TransformArguments = TransformArguments

@typing.final
class OnTheFlyFeatureSet(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FUNCTION_FIELD_NUMBER: builtins.int
    REQUIREMENTS_FIELD_NUMBER: builtins.int
    requirements: builtins.bytes
    """The needed requirements"""
    @property
    def function(self) -> global___UdfFunction:
        """Actual function code"""

    def __init__(
        self,
        *,
        function: global___UdfFunction | None = ...,
        requirements: builtins.bytes = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["function", b"function"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["function", b"function", "requirements", b"requirements"]) -> None: ...

global___OnTheFlyFeatureSet = OnTheFlyFeatureSet

@typing.final
class Function(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SQL_FUNCTION_FIELD_NUMBER: builtins.int
    UDF_FUNCTION_FIELD_NUMBER: builtins.int
    @property
    def sql_function(self) -> global___SqlFunction: ...
    @property
    def udf_function(self) -> global___UdfFunction: ...
    def __init__(
        self,
        *,
        sql_function: global___SqlFunction | None = ...,
        udf_function: global___UdfFunction | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["sql_function", b"sql_function", "type", b"type", "udf_function", b"udf_function"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["sql_function", b"sql_function", "type", b"type", "udf_function", b"udf_function"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["type", b"type"]) -> typing.Literal["sql_function", "udf_function"] | None: ...

global___Function = Function

@typing.final
class Backfill(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class _FillUpMethod:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _FillUpMethodEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[Backfill._FillUpMethod.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        AS_SCHEDULED: Backfill._FillUpMethod.ValueType  # 0
        SNAPSHOT: Backfill._FillUpMethod.ValueType  # 1

    class FillUpMethod(_FillUpMethod, metaclass=_FillUpMethodEnumTypeWrapper):
        """FillUp method for the backfill"""

    AS_SCHEDULED: Backfill.FillUpMethod.ValueType  # 0
    SNAPSHOT: Backfill.FillUpMethod.ValueType  # 1

    START_DATE_FIELD_NUMBER: builtins.int
    FILLUP_METHOD_FIELD_NUMBER: builtins.int
    fillup_method: global___Backfill.FillUpMethod.ValueType
    @property
    def start_date(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Backfill start date"""

    def __init__(
        self,
        *,
        start_date: google.protobuf.timestamp_pb2.Timestamp | None = ...,
        fillup_method: global___Backfill.FillUpMethod.ValueType = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["start_date", b"start_date"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["fillup_method", b"fillup_method", "start_date", b"start_date"]) -> None: ...

global___Backfill = Backfill

@typing.final
class SqlFunction(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SQL_FIELD_NUMBER: builtins.int
    sql: builtins.str
    def __init__(
        self,
        *,
        sql: builtins.str = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["sql", b"sql"]) -> None: ...

global___SqlFunction = SqlFunction

@typing.final
class UdfFunction(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    CODE_FIELD_NUMBER: builtins.int
    code: builtins.bytes
    def __init__(
        self,
        *,
        code: builtins.bytes = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["code", b"code"]) -> None: ...

global___UdfFunction = UdfFunction

@typing.final
class NewOnly(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(
        self,
    ) -> None: ...

global___NewOnly = NewOnly

@typing.final
class TimeFrame(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MINUTES_FIELD_NUMBER: builtins.int
    VANILLA_FIELD_NUMBER: builtins.int
    AGGREGATION_FIELD_NUMBER: builtins.int
    minutes: builtins.int
    """Time frame size in minutes to read from a datasource"""
    @property
    def vanilla(self) -> global___Vanilla: ...
    @property
    def aggregation(self) -> global___Aggregation: ...
    def __init__(
        self,
        *,
        minutes: builtins.int = ...,
        vanilla: global___Vanilla | None = ...,
        aggregation: global___Aggregation | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["aggregation", b"aggregation", "flavor", b"flavor", "vanilla", b"vanilla"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["aggregation", b"aggregation", "flavor", b"flavor", "minutes", b"minutes", "vanilla", b"vanilla"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["flavor", b"flavor"]) -> typing.Literal["vanilla", "aggregation"] | None: ...

global___TimeFrame = TimeFrame

@typing.final
class Aggregation(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    AGGREGATION_POPULATION_FIELD_NUMBER: builtins.int
    @property
    def aggregation_population(self) -> global___AggregationPopulation: ...
    def __init__(
        self,
        *,
        aggregation_population: global___AggregationPopulation | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["aggregation_population", b"aggregation_population", "type", b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["aggregation_population", b"aggregation_population", "type", b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["type", b"type"]) -> typing.Literal["aggregation_population"] | None: ...

global___Aggregation = Aggregation

@typing.final
class AggregationPopulation(google.protobuf.message.Message):
    """Apply time frame aggregation"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(
        self,
    ) -> None: ...

global___AggregationPopulation = AggregationPopulation

@typing.final
class PopulationTimeframeNewOnly(google.protobuf.message.Message):
    """Get life time data for new only population"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(
        self,
    ) -> None: ...

global___PopulationTimeframeNewOnly = PopulationTimeframeNewOnly

@typing.final
class PopulationTimeframe(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    NEW_ONLY_FIELD_NUMBER: builtins.int
    @property
    def new_only(self) -> global___PopulationTimeframeNewOnly: ...
    def __init__(
        self,
        *,
        new_only: global___PopulationTimeframeNewOnly | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["new_only", b"new_only", "type", b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["new_only", b"new_only", "type", b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["type", b"type"]) -> typing.Literal["new_only"] | None: ...

global___PopulationTimeframe = PopulationTimeframe

@typing.final
class Vanilla(google.protobuf.message.Message):
    """FullRead policy default value"""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(
        self,
    ) -> None: ...

global___Vanilla = Vanilla

@typing.final
class FullRead(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DEFAULT_FIELD_NUMBER: builtins.int
    POPULATION_TIMEFRAME_FIELD_NUMBER: builtins.int
    @property
    def default(self) -> global___Vanilla: ...
    @property
    def population_timeframe(self) -> global___PopulationTimeframe: ...
    def __init__(
        self,
        *,
        default: global___Vanilla | None = ...,
        population_timeframe: global___PopulationTimeframe | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["default", b"default", "flavor", b"flavor", "population_timeframe", b"population_timeframe"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["default", b"default", "flavor", b"flavor", "population_timeframe", b"population_timeframe"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["flavor", b"flavor"]) -> typing.Literal["default", "population_timeframe"] | None: ...

global___FullRead = FullRead

@typing.final
class DataSourceReadPolicy(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    NEW_ONLY_FIELD_NUMBER: builtins.int
    TIME_FRAME_FIELD_NUMBER: builtins.int
    FULL_READ_FIELD_NUMBER: builtins.int
    @property
    def new_only(self) -> global___NewOnly:
        """Read only new records from the data source - each batch reads from where the last batch finished with no end limit"""

    @property
    def time_frame(self) -> global___TimeFrame:
        """Read records starting from (scheduled batch time - time defined in the time frame) ending at the scheduled batch time"""

    @property
    def full_read(self) -> global___FullRead:
        """Read all records from the data source each batch"""

    def __init__(
        self,
        *,
        new_only: global___NewOnly | None = ...,
        time_frame: global___TimeFrame | None = ...,
        full_read: global___FullRead | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["full_read", b"full_read", "new_only", b"new_only", "time_frame", b"time_frame", "type", b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["full_read", b"full_read", "new_only", b"new_only", "time_frame", b"time_frame", "type", b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing.Literal["type", b"type"]) -> typing.Literal["new_only", "time_frame", "full_read"] | None: ...

global___DataSourceReadPolicy = DataSourceReadPolicy
