# ZMLX SFT with QLoRA (4-bit base model)
# Usage: zmlx train --config configs/sft_qlora.yaml

model: "mlx-community/Llama-3.2-1B-Instruct-4bit"
dataset: "mlx-community/WikiSQL"

# LoRA on quantized base
lora: true
lora_rank: 16
lora_alpha: 32.0
quantize: true
q_bits: 4
q_group_size: 64

# Training
iters: 1000
batch_size: 2
learning_rate: 2.0e-4
lr_schedule: cosine
warmup_steps: 50
max_seq_length: 1024

# Evaluation
eval_interval: 100
save_interval: 500
output_dir: adapters/sft_qlora

# ZMLX
patch: true
