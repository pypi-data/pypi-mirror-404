# ZMLX GRPO training
# Usage: zmlx train --config configs/grpo.yaml

model: "mlx-community/Llama-3.2-1B-Instruct"
dataset: ""  # Requires custom dataset with preference pairs

# LoRA
lora: true
lora_rank: 16
lora_alpha: 32.0
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj

# Training
iters: 500
batch_size: 2
learning_rate: 5.0e-5
lr_schedule: cosine
warmup_steps: 50
max_seq_length: 2048

# Evaluation
eval_interval: 50
save_interval: 250
output_dir: adapters/grpo

# ZMLX
patch: true
patch_compute_dtype: float32
