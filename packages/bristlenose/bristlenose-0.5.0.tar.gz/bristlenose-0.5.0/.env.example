# Bristlenose Configuration
# Copy this file to .env and fill in your values

# LLM Provider: "anthropic" or "openai"
BRISTLENOSE_LLM_PROVIDER=anthropic

# API Keys (set the one matching your provider)
BRISTLENOSE_ANTHROPIC_API_KEY=
BRISTLENOSE_OPENAI_API_KEY=

# LLM Model (default: claude-sonnet-4-20250514)
# BRISTLENOSE_LLM_MODEL=claude-sonnet-4-20250514

# Whisper transcription backend: auto, mlx (Apple Silicon GPU), faster-whisper (CUDA/CPU)
# "auto" detects your hardware and picks the best option
# BRISTLENOSE_WHISPER_BACKEND=auto

# Whisper model size: tiny, base, small, medium, large-v3, large-v3-turbo
# BRISTLENOSE_WHISPER_MODEL=large-v3-turbo

# Whisper language (default: en)
# BRISTLENOSE_WHISPER_LANGUAGE=en

# Whisper device: cpu, cuda, auto (faster-whisper only, ignored when using mlx)
# BRISTLENOSE_WHISPER_DEVICE=auto

# Whisper compute type: int8, float16, float32 (faster-whisper only)
# BRISTLENOSE_WHISPER_COMPUTE_TYPE=int8
