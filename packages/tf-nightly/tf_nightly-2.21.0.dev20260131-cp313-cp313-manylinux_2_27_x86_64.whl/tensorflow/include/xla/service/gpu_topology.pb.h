// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: xla/service/gpu_topology.proto
// Protobuf C++ Version: 6.31.1

#ifndef xla_2fservice_2fgpu_5ftopology_2eproto_2epb_2eh
#define xla_2fservice_2fgpu_5ftopology_2eproto_2epb_2eh

#include <limits>
#include <string>
#include <type_traits>
#include <utility>

#include "google/protobuf/runtime_version.h"
#if PROTOBUF_VERSION != 6031001
#error "Protobuf C++ gencode is built with an incompatible version of"
#error "Protobuf C++ headers/runtime. See"
#error "https://protobuf.dev/support/cross-version-runtime-guarantee/#cpp"
#endif
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/arena.h"
#include "google/protobuf/arenastring.h"
#include "google/protobuf/generated_message_tctable_decl.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/metadata_lite.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/message.h"
#include "google/protobuf/message_lite.h"
#include "google/protobuf/repeated_field.h"  // IWYU pragma: export
#include "google/protobuf/extension_set.h"  // IWYU pragma: export
#include "google/protobuf/unknown_field_set.h"
#include "xla/stream_executor/device_description.pb.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"

#define PROTOBUF_INTERNAL_EXPORT_xla_2fservice_2fgpu_5ftopology_2eproto PROTOBUF_EXPORT

namespace google {
namespace protobuf {
namespace internal {
template <typename T>
::absl::string_view GetAnyMessageName();
}  // namespace internal
}  // namespace protobuf
}  // namespace google

// Internal implementation detail -- do not use these members.
struct PROTOBUF_EXPORT TableStruct_xla_2fservice_2fgpu_5ftopology_2eproto {
  static const ::uint32_t offsets[];
};
extern "C" {
PROTOBUF_EXPORT extern const ::google::protobuf::internal::DescriptorTable descriptor_table_xla_2fservice_2fgpu_5ftopology_2eproto;
}  // extern "C"
namespace xla {
class GpuTopologyProto;
struct GpuTopologyProtoDefaultTypeInternal;
PROTOBUF_EXPORT extern GpuTopologyProtoDefaultTypeInternal _GpuTopologyProto_default_instance_;
PROTOBUF_EXPORT extern const ::google::protobuf::internal::ClassDataFull GpuTopologyProto_class_data_;
}  // namespace xla
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google

namespace xla {

// ===================================================================


// -------------------------------------------------------------------

class PROTOBUF_EXPORT GpuTopologyProto final : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:xla.GpuTopologyProto) */ {
 public:
  inline GpuTopologyProto() : GpuTopologyProto(nullptr) {}
  ~GpuTopologyProto() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(GpuTopologyProto* PROTOBUF_NONNULL msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(GpuTopologyProto));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR GpuTopologyProto(::google::protobuf::internal::ConstantInitialized);

  inline GpuTopologyProto(const GpuTopologyProto& from) : GpuTopologyProto(nullptr, from) {}
  inline GpuTopologyProto(GpuTopologyProto&& from) noexcept
      : GpuTopologyProto(nullptr, ::std::move(from)) {}
  inline GpuTopologyProto& operator=(const GpuTopologyProto& from) {
    CopyFrom(from);
    return *this;
  }
  inline GpuTopologyProto& operator=(GpuTopologyProto&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* PROTOBUF_NONNULL mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* PROTOBUF_NONNULL descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* PROTOBUF_NONNULL GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* PROTOBUF_NONNULL GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const GpuTopologyProto& default_instance() {
    return *reinterpret_cast<const GpuTopologyProto*>(
        &_GpuTopologyProto_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 0;
  friend void swap(GpuTopologyProto& a, GpuTopologyProto& b) { a.Swap(&b); }
  inline void Swap(GpuTopologyProto* PROTOBUF_NONNULL other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(GpuTopologyProto* PROTOBUF_NONNULL other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  GpuTopologyProto* PROTOBUF_NONNULL New(::google::protobuf::Arena* PROTOBUF_NULLABLE arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<GpuTopologyProto>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const GpuTopologyProto& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const GpuTopologyProto& from) { GpuTopologyProto::MergeImpl(*this, from); }

  private:
  static void MergeImpl(::google::protobuf::MessageLite& to_msg,
                        const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* PROTOBUF_NONNULL _InternalSerialize(
      const ::google::protobuf::MessageLite& msg, ::uint8_t* PROTOBUF_NONNULL target,
      ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* PROTOBUF_NONNULL _InternalSerialize(
      ::uint8_t* PROTOBUF_NONNULL target,
      ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* PROTOBUF_NONNULL _InternalSerialize(
      ::uint8_t* PROTOBUF_NONNULL target,
      ::google::protobuf::io::EpsCopyOutputStream* PROTOBUF_NONNULL stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* PROTOBUF_NULLABLE arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(GpuTopologyProto* PROTOBUF_NONNULL other);
 private:
  template <typename T>
  friend ::absl::string_view(::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "xla.GpuTopologyProto"; }

 protected:
  explicit GpuTopologyProto(::google::protobuf::Arena* PROTOBUF_NULLABLE arena);
  GpuTopologyProto(::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const GpuTopologyProto& from);
  GpuTopologyProto(
      ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, GpuTopologyProto&& from) noexcept
      : GpuTopologyProto(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* PROTOBUF_NONNULL GetClassData() const PROTOBUF_FINAL;
  static void* PROTOBUF_NONNULL PlacementNew_(
      const void* PROTOBUF_NONNULL, void* PROTOBUF_NONNULL mem,
      ::google::protobuf::Arena* PROTOBUF_NULLABLE arena);
  static constexpr auto InternalNewImpl_();

 public:
  static constexpr auto InternalGenerateClassData_();

  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kPlatformVersionFieldNumber = 3,
    kGpuTargetConfigFieldNumber = 8,
    kNumPartitionsFieldNumber = 4,
    kNumHostsPerPartitionFieldNumber = 5,
    kNumDevicesPerHostFieldNumber = 6,
  };
  // string platform_version = 3;
  void clear_platform_version() ;
  const ::std::string& platform_version() const;
  template <typename Arg_ = const ::std::string&, typename... Args_>
  void set_platform_version(Arg_&& arg, Args_... args);
  ::std::string* PROTOBUF_NONNULL mutable_platform_version();
  [[nodiscard]] ::std::string* PROTOBUF_NULLABLE release_platform_version();
  void set_allocated_platform_version(::std::string* PROTOBUF_NULLABLE value);

  private:
  const ::std::string& _internal_platform_version() const;
  PROTOBUF_ALWAYS_INLINE void _internal_set_platform_version(const ::std::string& value);
  ::std::string* PROTOBUF_NONNULL _internal_mutable_platform_version();

  public:
  // .stream_executor.GpuTargetConfigProto gpu_target_config = 8;
  bool has_gpu_target_config() const;
  void clear_gpu_target_config() ;
  const ::stream_executor::GpuTargetConfigProto& gpu_target_config() const;
  [[nodiscard]] ::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE release_gpu_target_config();
  ::stream_executor::GpuTargetConfigProto* PROTOBUF_NONNULL mutable_gpu_target_config();
  void set_allocated_gpu_target_config(::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE value);
  void unsafe_arena_set_allocated_gpu_target_config(::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE value);
  ::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE unsafe_arena_release_gpu_target_config();

  private:
  const ::stream_executor::GpuTargetConfigProto& _internal_gpu_target_config() const;
  ::stream_executor::GpuTargetConfigProto* PROTOBUF_NONNULL _internal_mutable_gpu_target_config();

  public:
  // int32 num_partitions = 4;
  void clear_num_partitions() ;
  ::int32_t num_partitions() const;
  void set_num_partitions(::int32_t value);

  private:
  ::int32_t _internal_num_partitions() const;
  void _internal_set_num_partitions(::int32_t value);

  public:
  // int32 num_hosts_per_partition = 5;
  void clear_num_hosts_per_partition() ;
  ::int32_t num_hosts_per_partition() const;
  void set_num_hosts_per_partition(::int32_t value);

  private:
  ::int32_t _internal_num_hosts_per_partition() const;
  void _internal_set_num_hosts_per_partition(::int32_t value);

  public:
  // int32 num_devices_per_host = 6;
  void clear_num_devices_per_host() ;
  ::int32_t num_devices_per_host() const;
  void set_num_devices_per_host(::int32_t value);

  private:
  ::int32_t _internal_num_devices_per_host() const;
  void _internal_set_num_devices_per_host(::int32_t value);

  public:
  // @@protoc_insertion_point(class_scope:xla.GpuTopologyProto)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<3, 5,
                                   1, 45,
                                   2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(
        ::google::protobuf::internal::InternalVisibility visibility,
        ::google::protobuf::Arena* PROTOBUF_NULLABLE arena);
    inline explicit Impl_(
        ::google::protobuf::internal::InternalVisibility visibility,
        ::google::protobuf::Arena* PROTOBUF_NULLABLE arena, const Impl_& from,
        const GpuTopologyProto& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::google::protobuf::internal::ArenaStringPtr platform_version_;
    ::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE gpu_target_config_;
    ::int32_t num_partitions_;
    ::int32_t num_hosts_per_partition_;
    ::int32_t num_devices_per_host_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_xla_2fservice_2fgpu_5ftopology_2eproto;
};

PROTOBUF_EXPORT extern const ::google::protobuf::internal::ClassDataFull GpuTopologyProto_class_data_;

// ===================================================================




// ===================================================================


#ifdef __GNUC__
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// -------------------------------------------------------------------

// GpuTopologyProto

// string platform_version = 3;
inline void GpuTopologyProto::clear_platform_version() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.platform_version_.ClearToEmpty();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
inline const ::std::string& GpuTopologyProto::platform_version() const
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:xla.GpuTopologyProto.platform_version)
  return _internal_platform_version();
}
template <typename Arg_, typename... Args_>
PROTOBUF_ALWAYS_INLINE void GpuTopologyProto::set_platform_version(Arg_&& arg, Args_... args) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_._has_bits_[0] |= 0x00000001u;
  _impl_.platform_version_.Set(static_cast<Arg_&&>(arg), args..., GetArena());
  // @@protoc_insertion_point(field_set:xla.GpuTopologyProto.platform_version)
}
inline ::std::string* PROTOBUF_NONNULL GpuTopologyProto::mutable_platform_version()
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::std::string* _s = _internal_mutable_platform_version();
  // @@protoc_insertion_point(field_mutable:xla.GpuTopologyProto.platform_version)
  return _s;
}
inline const ::std::string& GpuTopologyProto::_internal_platform_version() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return _impl_.platform_version_.Get();
}
inline void GpuTopologyProto::_internal_set_platform_version(const ::std::string& value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_._has_bits_[0] |= 0x00000001u;
  _impl_.platform_version_.Set(value, GetArena());
}
inline ::std::string* PROTOBUF_NONNULL GpuTopologyProto::_internal_mutable_platform_version() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_._has_bits_[0] |= 0x00000001u;
  return _impl_.platform_version_.Mutable( GetArena());
}
inline ::std::string* PROTOBUF_NULLABLE GpuTopologyProto::release_platform_version() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:xla.GpuTopologyProto.platform_version)
  if ((_impl_._has_bits_[0] & 0x00000001u) == 0) {
    return nullptr;
  }
  _impl_._has_bits_[0] &= ~0x00000001u;
  auto* released = _impl_.platform_version_.Release();
  if (::google::protobuf::internal::DebugHardenForceCopyDefaultString()) {
    _impl_.platform_version_.Set("", GetArena());
  }
  return released;
}
inline void GpuTopologyProto::set_allocated_platform_version(::std::string* PROTOBUF_NULLABLE value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  _impl_.platform_version_.SetAllocated(value, GetArena());
  if (::google::protobuf::internal::DebugHardenForceCopyDefaultString() && _impl_.platform_version_.IsDefault()) {
    _impl_.platform_version_.Set("", GetArena());
  }
  // @@protoc_insertion_point(field_set_allocated:xla.GpuTopologyProto.platform_version)
}

// int32 num_partitions = 4;
inline void GpuTopologyProto::clear_num_partitions() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.num_partitions_ = 0;
  _impl_._has_bits_[0] &= ~0x00000004u;
}
inline ::int32_t GpuTopologyProto::num_partitions() const {
  // @@protoc_insertion_point(field_get:xla.GpuTopologyProto.num_partitions)
  return _internal_num_partitions();
}
inline void GpuTopologyProto::set_num_partitions(::int32_t value) {
  _internal_set_num_partitions(value);
  _impl_._has_bits_[0] |= 0x00000004u;
  // @@protoc_insertion_point(field_set:xla.GpuTopologyProto.num_partitions)
}
inline ::int32_t GpuTopologyProto::_internal_num_partitions() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return _impl_.num_partitions_;
}
inline void GpuTopologyProto::_internal_set_num_partitions(::int32_t value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.num_partitions_ = value;
}

// int32 num_hosts_per_partition = 5;
inline void GpuTopologyProto::clear_num_hosts_per_partition() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.num_hosts_per_partition_ = 0;
  _impl_._has_bits_[0] &= ~0x00000008u;
}
inline ::int32_t GpuTopologyProto::num_hosts_per_partition() const {
  // @@protoc_insertion_point(field_get:xla.GpuTopologyProto.num_hosts_per_partition)
  return _internal_num_hosts_per_partition();
}
inline void GpuTopologyProto::set_num_hosts_per_partition(::int32_t value) {
  _internal_set_num_hosts_per_partition(value);
  _impl_._has_bits_[0] |= 0x00000008u;
  // @@protoc_insertion_point(field_set:xla.GpuTopologyProto.num_hosts_per_partition)
}
inline ::int32_t GpuTopologyProto::_internal_num_hosts_per_partition() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return _impl_.num_hosts_per_partition_;
}
inline void GpuTopologyProto::_internal_set_num_hosts_per_partition(::int32_t value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.num_hosts_per_partition_ = value;
}

// int32 num_devices_per_host = 6;
inline void GpuTopologyProto::clear_num_devices_per_host() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.num_devices_per_host_ = 0;
  _impl_._has_bits_[0] &= ~0x00000010u;
}
inline ::int32_t GpuTopologyProto::num_devices_per_host() const {
  // @@protoc_insertion_point(field_get:xla.GpuTopologyProto.num_devices_per_host)
  return _internal_num_devices_per_host();
}
inline void GpuTopologyProto::set_num_devices_per_host(::int32_t value) {
  _internal_set_num_devices_per_host(value);
  _impl_._has_bits_[0] |= 0x00000010u;
  // @@protoc_insertion_point(field_set:xla.GpuTopologyProto.num_devices_per_host)
}
inline ::int32_t GpuTopologyProto::_internal_num_devices_per_host() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return _impl_.num_devices_per_host_;
}
inline void GpuTopologyProto::_internal_set_num_devices_per_host(::int32_t value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.num_devices_per_host_ = value;
}

// .stream_executor.GpuTargetConfigProto gpu_target_config = 8;
inline bool GpuTopologyProto::has_gpu_target_config() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.gpu_target_config_ != nullptr);
  return value;
}
inline const ::stream_executor::GpuTargetConfigProto& GpuTopologyProto::_internal_gpu_target_config() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::stream_executor::GpuTargetConfigProto* p = _impl_.gpu_target_config_;
  return p != nullptr ? *p : reinterpret_cast<const ::stream_executor::GpuTargetConfigProto&>(::stream_executor::_GpuTargetConfigProto_default_instance_);
}
inline const ::stream_executor::GpuTargetConfigProto& GpuTopologyProto::gpu_target_config() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:xla.GpuTopologyProto.gpu_target_config)
  return _internal_gpu_target_config();
}
inline void GpuTopologyProto::unsafe_arena_set_allocated_gpu_target_config(
    ::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.gpu_target_config_);
  }
  _impl_.gpu_target_config_ = reinterpret_cast<::stream_executor::GpuTargetConfigProto*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:xla.GpuTopologyProto.gpu_target_config)
}
inline ::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE GpuTopologyProto::release_gpu_target_config() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::stream_executor::GpuTargetConfigProto* released = _impl_.gpu_target_config_;
  _impl_.gpu_target_config_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE GpuTopologyProto::unsafe_arena_release_gpu_target_config() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:xla.GpuTopologyProto.gpu_target_config)

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::stream_executor::GpuTargetConfigProto* temp = _impl_.gpu_target_config_;
  _impl_.gpu_target_config_ = nullptr;
  return temp;
}
inline ::stream_executor::GpuTargetConfigProto* PROTOBUF_NONNULL GpuTopologyProto::_internal_mutable_gpu_target_config() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.gpu_target_config_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::stream_executor::GpuTargetConfigProto>(GetArena());
    _impl_.gpu_target_config_ = reinterpret_cast<::stream_executor::GpuTargetConfigProto*>(p);
  }
  return _impl_.gpu_target_config_;
}
inline ::stream_executor::GpuTargetConfigProto* PROTOBUF_NONNULL GpuTopologyProto::mutable_gpu_target_config()
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000002u;
  ::stream_executor::GpuTargetConfigProto* _msg = _internal_mutable_gpu_target_config();
  // @@protoc_insertion_point(field_mutable:xla.GpuTopologyProto.gpu_target_config)
  return _msg;
}
inline void GpuTopologyProto::set_allocated_gpu_target_config(::stream_executor::GpuTargetConfigProto* PROTOBUF_NULLABLE value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.gpu_target_config_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::Message*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }

  _impl_.gpu_target_config_ = reinterpret_cast<::stream_executor::GpuTargetConfigProto*>(value);
  // @@protoc_insertion_point(field_set_allocated:xla.GpuTopologyProto.gpu_target_config)
}

#ifdef __GNUC__
#pragma GCC diagnostic pop
#endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)
}  // namespace xla


// @@protoc_insertion_point(global_scope)

#include "google/protobuf/port_undef.inc"

#endif  // xla_2fservice_2fgpu_5ftopology_2eproto_2epb_2eh
