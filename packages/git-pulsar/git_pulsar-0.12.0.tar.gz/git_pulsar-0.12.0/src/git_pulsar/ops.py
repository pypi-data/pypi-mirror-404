import os
import shutil
import socket
import subprocess
import sys
import textwrap
import time
from pathlib import Path

from .constants import BACKUP_NAMESPACE
from .git_wrapper import GitRepo
from .system import get_machine_id, get_machine_id_file


def get_backup_ref(branch: str) -> str:
    """Constructs the namespaced ref for the current machine/branch."""
    machine_id = get_machine_id()
    return f"refs/heads/{BACKUP_NAMESPACE}/{machine_id}/{branch}"


def configure_identity() -> None:
    """Interactive setup to establish machine identity."""
    id_file = get_machine_id_file()
    if id_file.exists():
        return

    print("ü§ñ Git Pulsar Machine Identity Setup")
    print("   To enable seamless roaming, this machine needs a unique name.")

    # 1. Fetch existing identities from remote
    # We need a repo context to fetch, but we might not be in one.
    # We'll try to guess or just let the user type.
    # For robust implementation, we'd need to find a valid git repo to query the remote.
    # Simulating the list for now based on user intent:

    default_name = socket.gethostname().split(".")[0]
    print(f"\n   Suggested name: [bold]{default_name}[/bold]")

    choice = input("   Enter name (or press Enter to accept): ").strip()
    name = choice if choice else default_name

    # 2. Persist
    id_file.parent.mkdir(parents=True, exist_ok=True)
    with open(id_file, "w") as f:
        f.write(name)
    print(f"‚úÖ Machine ID set to: '{name}'\n")


def bootstrap_env() -> None:
    """
    Scaffolds a macOS Python environment: uv, direnv, and VS Code.
    """
    if sys.platform != "darwin":
        print("‚ùå The --env workflow is currently optimized for macOS.")
        return

    cwd = Path.cwd()
    print(f"‚ö° Setting up dev environment in {cwd.name}...")

    # 1. Dependency Check
    missing = []
    if not shutil.which("uv"):
        missing.append("uv")
    if not shutil.which("direnv"):
        missing.append("direnv")

    if missing:
        print(f"‚ùå Missing tools: {', '.join(missing)}")
        print("   Please run:")
        install_cmd = f"brew install {' '.join(missing)}"
        if not shutil.which("brew"):
            install_cmd = f"(Check your package manager) install {' '.join(missing)}"

        print(f"     {install_cmd}")
        sys.exit(1)

    # 2. Project Scaffold (uv)
    if not (cwd / "pyproject.toml").exists():
        print("üì¶ Initializing Python project...")
        # 'uv init' is safe; it creates a standard pyproject.toml
        subprocess.run(["uv", "init", "--no-workspace", "--python", "3.12"], check=True)
    else:
        print("   Existing pyproject.toml found. Skipping init.")

    # 3. Direnv Configuration
    envrc_path = cwd / ".envrc"
    if not envrc_path.exists():
        print("üîå Creating .envrc...")
        envrc_content = textwrap.dedent("""\
            # Auto-generated by git-pulsar
            if [ ! -d ".venv" ]; then
                echo "Creating virtual environment..."
                uv sync
            fi
            source .venv/bin/activate
            
            source_env_if_exists .envrc.local
        """)
        with open(envrc_path, "w") as f:
            f.write(envrc_content)

        subprocess.run(["direnv", "allow"], check=True)
    else:
        print("   .envrc exists. Skipping.")

    # 4. VS Code Settings
    vscode_dir = cwd / ".vscode"
    settings_path = vscode_dir / "settings.json"

    if not settings_path.exists():
        vscode_dir.mkdir(exist_ok=True)
        print("‚öôÔ∏è  Configuring VS Code...")
        settings_content = textwrap.dedent("""\
            {
                "python.defaultInterpreterPath": ".venv/bin/python",
                "python.terminal.activateEnvironment": true,
                "files.exclude": {
                    "**/__pycache__": true,
                    "**/.ipynb_checkpoints": true,
                    "**/.DS_Store": true,
                    "**/.venv": true
                },
                "search.exclude": {
                    "**/.venv": true
                }
            }
        """)
        with open(settings_path, "w") as f:
            f.write(settings_content)

    print("\n‚úÖ Environment ready.")

    if "DIRENV_DIR" not in os.environ:
        print("\nüëâ Action Required: Enable direnv")
        print("   1. Open your config:")
        print("      code ~/.zshrc  (or nano ~/.zshrc)")
        print("   2. Add this line to the bottom:")
        print('      eval "$(direnv hook zsh)"')
        print("   3. Reload:")
        print("      source ~/.zshrc")


def restore_file(path_str: str, force: bool = False) -> None:
    repo = GitRepo(Path.cwd())
    path = Path(path_str)

    current_branch = repo.current_branch()
    backup_ref = get_backup_ref(current_branch)

    # 1. Safety Check: Is the file dirty?
    if not force and path.exists():
        # Check specifically for this file
        if repo.status_porcelain(path_str):
            print(f"‚ùå Aborted: '{path_str}' has uncommitted changes.")
            print("   Use --force to overwrite them.")
            sys.exit(1)

    # 2. Restore
    print(f"üöë Restoring '{path_str}' from {backup_ref}...")
    try:
        repo.checkout(backup_ref, file=path_str)
        print("‚úÖ Restore complete.")
    except Exception as e:
        print(f"‚ùå Failed to restore: {e}")
        sys.exit(1)


def sync_session() -> None:
    """
    Smart Handoff: Scans ALL machine backups for the current branch
    and resets the working directory to the absolute latest version.
    """
    repo = GitRepo(Path.cwd())
    current_branch = repo.current_branch()

    print(f"üì° Scanning for latest session on '{current_branch}'...")

    # 1. Fetch everything (all machines)
    try:
        repo._run(
            [
                "fetch",
                "origin",
                f"refs/heads/{BACKUP_NAMESPACE}/*:refs/heads/{BACKUP_NAMESPACE}/*",
            ],
            capture=False,
        )
    except Exception:
        print("‚ö†Ô∏è  Fetch warning: network might be down.")

    # 2. Find candidates
    # Pattern: refs/heads/{namespace}/{machine}/{branch}
    candidates = repo.list_refs(f"refs/heads/{BACKUP_NAMESPACE}/*/{current_branch}")

    if not candidates:
        print("‚ùå No backups found anywhere.")
        return

    # 3. Sort by commit date (newest first)
    # We need to parse the commit timestamp for each ref
    latest_ref = None
    latest_time = 0

    for ref in candidates:
        # Get unix timestamp
        try:
            ts_str = repo._run(["log", "-1", "--format=%ct", ref])
            ts = int(ts_str.strip())
            if ts > latest_time:
                latest_time = ts
                latest_ref = ref
        except Exception:
            continue

    if not latest_ref:
        print("‚ùå Could not determine latest backup.")
        return

    # 4. Compare with local
    machine_name = latest_ref.split("/")[-2]
    human_time = repo._run(["log", "-1", "--format=%cr", latest_ref])

    print("\nüéØ Found latest session:")
    print(f"   ‚Ä¢ Source: {machine_name}")
    print(f"   ‚Ä¢ Time:   {human_time}")

    # Check if this IS our current state (approx)
    local_tree = repo.write_tree()  # Current worktree state
    remote_tree = repo._run(["rev-parse", f"{latest_ref}^{{tree}}"])

    if local_tree == remote_tree:
        print("‚úÖ You are already up to date.")
        return

    # 5. Confirmation
    print("\n‚ö†Ô∏è  WARNING: This will overwrite your local changes to match the backup.")
    confirm = input("   Proceed with sync? [y/N] ").lower()
    if confirm != "y":
        print("‚ùå Aborted.")
        sys.exit(0)

    # 6. execution
    try:
        # Checkout the contents of the backup ref to the worktree
        # We use checkout with path '.' to update files without switching HEAD
        repo._run(["checkout", latest_ref, "--", "."])
        print("‚úÖ Session synced. You may resume work.")
    except Exception as e:
        print(f"‚ùå Sync failed: {e}")
        sys.exit(1)


def finalize_work() -> None:
    print("üöÄ Finalizing work...")
    repo = GitRepo(Path.cwd())

    # 1. Check for uncommitted changes
    if repo.status_porcelain():
        print("‚ö†Ô∏è  You have uncommitted changes.")
        print("   Please commit or stash them before finalizing.")
        sys.exit(1)

    # Resolve the backup ref for the branch we were just working on
    # (Assuming we are finalizing the *current* context)
    working_branch = repo.current_branch()

    try:
        # 2. Sync with Remote (Anti-Race + Backup Aggregation)
        print("-> Syncing with origin...")
        try:
            # Fetch main AND all pulsar backups to ensure we see 'library' work
            repo._run(["fetch", "origin", "main"], capture=False)
            repo._run(
                [
                    "fetch",
                    "origin",
                    f"refs/heads/{BACKUP_NAMESPACE}/*:refs/heads/{BACKUP_NAMESPACE}/*",
                ],
                capture=False,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è  Fetch warning: {e}")

        # 3. Identify Backup Candidates
        # Find ALL refs that match: refs/heads/{namespace}/*/current_branch
        candidates = repo.list_refs(f"refs/heads/{BACKUP_NAMESPACE}/*/{working_branch}")

        if not candidates:
            print("‚ùå No backups found for this branch.")
            sys.exit(1)

        print(f"-> Found {len(candidates)} backup stream(s):")
        for c in candidates:
            print(f"   ‚Ä¢ {c}")

        # 4. Checkout Main
        target = "main"
        if not repo.rev_parse("main") and repo.rev_parse("master"):
            target = "master"

        print(f"-> Switching to {target}...")
        repo.checkout(target)

        # 5. Octopus Squash
        print("-> Collapsing backup streams...")
        try:
            repo.merge_squash(*candidates)
        except RuntimeError:
            print("‚ö†Ô∏è  Merge conflicts detected. Please resolve them, then commit.")
            # We exit here to let the user resolve conflicts manually
            sys.exit(0)

        # 5. Commit (Interactive)
        print("-> Committing (opens editor)...")
        repo.commit_interactive()

        # 6. No Reset Needed
        # In the shadow-commit model, we don't reset the backup ref manually.
        # It continues to grow as a history log, or is abandoned if the branch dies.

        print("\n‚úÖ Work finalized!")
        print(f"   Your backup history remains in refs/{BACKUP_NAMESPACE}/...")

    except Exception as e:
        print(f"\n‚ùå Error during finalize: {e}")
        sys.exit(1)


def prune_backups(days: int, repo_path: Path | None = None) -> None:
    """Garbage collects backup refs older than the specified retention period."""
    repo = GitRepo(repo_path or Path.cwd())
    cutoff = time.time() - (days * 86400)

    print(f"üßπ Scanning for backups older than {days} days...")

    refs = repo.list_refs(f"refs/heads/{BACKUP_NAMESPACE}/")
    deleted_count = 0

    for ref in refs:
        try:
            ts_str = repo._run(["log", "-1", "--format=%ct", ref])
            ts = int(ts_str.strip())

            if ts < cutoff:
                age_days = (time.time() - ts) / 86400
                print(f"   Deleting {ref} (Age: {age_days:.1f} days)")
                repo._run(["update-ref", "-d", ref], capture=False)
                deleted_count += 1
        except Exception:
            continue

    if deleted_count == 0:
        print("‚ú® No stale backups found.")
    else:
        print(f"üíÄ Dropped {deleted_count} stale refs. Running git gc...")
        repo._run(["gc", "--auto"], capture=False)


def add_ignore(pattern: str) -> None:
    """Adds a pattern to .gitignore and ensures it's untracked."""
    cwd = Path.cwd()
    gitignore = cwd / ".gitignore"

    # 1. Append to .gitignore
    content = ""
    if gitignore.exists():
        with open(gitignore, "r") as f:
            content = f.read()

    if pattern in content:
        print(f"‚ÑπÔ∏è  '{pattern}' is already in .gitignore.")
    else:
        with open(gitignore, "a") as f:
            prefix = "\n" if content and not content.endswith("\n") else ""
            f.write(f"{prefix}{pattern}\n")
        print(f"‚úÖ Added '{pattern}' to .gitignore.")

    # 2. Check if currently tracked (common mistake)
    repo = GitRepo(cwd)
    try:
        # Check if git knows about files matching this pattern
        tracked = repo._run(["ls-files", pattern])
        if tracked:
            print(f"‚ö†Ô∏è  Files matching '{pattern}' are currently tracked by git.")
            confirm = input("   Stop tracking them (keep local file)? [y/N] ").lower()
            if confirm == "y":
                repo._run(["rm", "--cached", pattern], capture=False)
                print("   Removed from index (file preserved on disk).")
    except Exception:
        pass
