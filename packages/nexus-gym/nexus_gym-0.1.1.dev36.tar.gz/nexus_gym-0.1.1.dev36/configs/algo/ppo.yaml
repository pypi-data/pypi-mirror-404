name: "ppo"
verbose: 1
learning_rate: 3e-4
n_steps: 1024
batch_size: 64
n_epochs: 10
gamma: 0.99
ent_coef: 0.02
tensorboard_log: "./tensorboard_logs"
policy_kwargs:
  net_arch:
    pi: [256, 256, 128]
    vf: [256, 256, 128]
gae_lambda: 0.95
clip_range: 0.2
vf_coef: 0.5
max_grad_norm: 0.5
resume_path: null
