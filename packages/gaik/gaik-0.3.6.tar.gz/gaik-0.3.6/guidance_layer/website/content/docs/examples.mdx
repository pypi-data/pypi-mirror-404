---
title: Examples
description: Real-world examples and use cases for GAIK toolkit
---

## Common Use Cases

### Data Extraction

Extract structured information from unstructured text:

```python
from gaik.software_components.extractor import (
    SchemaGenerator, DataExtractor, get_openai_config
)

config = get_openai_config(use_azure=True)

# Generate schema
generator = SchemaGenerator(config=config)
schema = generator.generate_schema(
    user_requirements="""
    Extract:
    - invoice_number: Invoice ID
    - amount: Total in USD (decimal)
    - vendor: Company name
    - date: Invoice date
    """
)

# Extract data
extractor = DataExtractor(config=config)
results = extractor.extract(
    extraction_model=schema,
    requirements=generator.item_requirements,
    user_requirements="Extract invoice data",
    documents=["Invoice #12345 from Acme Corp. Total: $1,500. Date: 2024-01-15"]
)

print(results)
```

**Use Cases:**
- Invoice and receipt processing
- Form data extraction
- Resume/CV parsing
- Customer data extraction

### PDF Processing

Convert PDFs to Markdown for further processing:

```python
from gaik.software_components.parsers import VisionParser, get_openai_config

# Vision-based parsing
config = get_openai_config(use_azure=True)
parser = VisionParser(openai_config=config)
pages = parser.convert_pdf("report.pdf", clean_output=True)
markdown = "\n\n".join(pages)
```

**Use Cases:**
- Report digitization
- Document archival
- Content extraction from scanned documents
- Table extraction from PDFs

### End-to-End Document Pipeline

Complete document processing with a single pipeline:

```python
from gaik.software_modules.documents_to_structured_data import (
    DocumentsToStructuredData
)
from pathlib import Path

pipeline = DocumentsToStructuredData(use_azure=True)

result = pipeline.run(
    file_path=Path("invoice.pdf"),
    user_requirements="""
    Extract:
    - invoice_number
    - vendor
    - total_amount
    - line_items
    """,
    parser_choice="vision_parser"
)

print(f"Parsed: {len(result.parsed_documents)} pages")
print(f"Extracted: {result.extracted_fields}")
```

### Audio Transcription

Transcribe audio and video files:

```python
from gaik.software_components.transcriber import Transcriber, get_openai_config

config = get_openai_config(use_azure=True)
transcriber = Transcriber(
    api_config=config,
    output_dir="transcripts/",
    enhanced_transcript=True  # Optional GPT enhancement
)

result = transcriber.transcribe(
    file_path="meeting.mp3",
    custom_context="Business meeting about Q4 results"
)

print(result.raw_transcript)
print(result.enhanced_transcript)
```

**Use Cases:**
- Meeting transcription
- Interview processing
- Podcast indexing
- Video content extraction

### Document Classification

Categorize documents automatically:

```python
from gaik.software_components.doc_classifier import DocumentClassifier, get_openai_config

config = get_openai_config(use_azure=True)
classifier = DocumentClassifier(config=config)

result = classifier.classify(
    file_or_dir="documents/",
    classes=["invoice", "receipt", "contract", "report"]
)

for filename, classification in result.items():
    print(f"{filename}: {classification['class']} "
          f"(confidence: {classification['confidence']:.2f})")
```

### Batch Document Processing

Process multiple documents efficiently:

```python
from gaik.software_components.extractor import (
    SchemaGenerator, DataExtractor, get_openai_config
)

config = get_openai_config(use_azure=True)

# Generate schema once
generator = SchemaGenerator(config=config)
schema = generator.generate_schema(
    user_requirements="""
    Extract:
    - document_type: Type of document
    - key_points: Main findings (list)
    - date: Document date
    - author: Author or organization
    """
)

# Process multiple documents
documents = [
    "Report by ACME Corp dated 2024-01-15: Sales increased 25%",
    "Research by Dr. Smith (2024-02-01): AI accuracy improved to 90%",
    "Memo from Finance (2024-01-20): Budget approved"
]

extractor = DataExtractor(config=config)
results = extractor.extract(
    extraction_model=schema,
    requirements=generator.item_requirements,
    user_requirements="Extract document info",
    documents=documents,
    save_json=True,
    json_path="results.json"
)

for i, result in enumerate(results, 1):
    print(f"Document {i}: {result}")
```

## Advanced Patterns

### Combined PDF + Extraction

```python
from gaik.software_components.parsers import PyMuPDFParser
from gaik.software_components.extractor import (
    SchemaGenerator, DataExtractor, get_openai_config
)

# Step 1: Extract text from PDF
parser = PyMuPDFParser()
text = parser.parse_pdf("contract.pdf")

# Step 2: Generate schema and extract data
config = get_openai_config(use_azure=True)

generator = SchemaGenerator(config=config)
schema = generator.generate_schema(
    user_requirements="""
    Extract from contract:
    - parties: List of parties involved
    - effective_date: Contract start date
    - terms: Key terms and conditions
    - amount: Contract value if mentioned
    """
)

extractor = DataExtractor(config=config)
results = extractor.extract(
    extraction_model=schema,
    requirements=generator.item_requirements,
    user_requirements="Extract contract data",
    documents=[text]
)

print(results[0])
```

## More Examples

Additional examples are available in the [GitHub examples folder](https://github.com/GAIK-project/gaik-toolkit/tree/main/implementation_layer/examples):

- `implementation_layer/examples/software_components/extractor/` - Data extraction examples
- `implementation_layer/examples/software_components/parsers/` - PDF parsing examples
- `implementation_layer/examples/software_components/transcriber/` - Audio transcription examples
- `implementation_layer/examples/software_components/classifier/` - Document classification examples
- `implementation_layer/examples/software_modules/` - End-to-end pipeline examples
