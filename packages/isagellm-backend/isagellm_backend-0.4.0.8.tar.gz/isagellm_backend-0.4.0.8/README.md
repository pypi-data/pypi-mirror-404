# sagellm-backend

## Protocol Compliance (Mandatory)

- MUST follow Protocol v0.1: <https://github.com/intellistream/sagellm-docs/blob/main/docs/specs/protocol_v0.1.md>
- Any globally shared definitions (fields, error codes, metrics, IDs, schemas) MUST be added to Protocol first.

[![CI](https://github.com/intellistream/sagellm-backend/actions/workflows/ci.yml/badge.svg)](https://github.com/intellistream/sagellm-backend/actions/workflows/ci.yml)
[![PyPI version](https://badge.fury.io/py/isagellm-backend.svg)](https://badge.fury.io/py/isagellm-backend)
[![Python Version](https://img.shields.io/pypi/pyversions/isagellm-backend.svg)](https://pypi.org/project/isagellm-backend/)
[![License](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)

ç¡¬ä»¶æŠ½è±¡å±‚ - ä¸º sageLLM æä¾›ç»Ÿä¸€çš„ç¡¬ä»¶æ¥å£ï¼ˆCUDA/Ascend/Kunlunï¼‰

## æ¶æ„å®šä½

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sagellm-core (å¼•æ“åè°ƒå±‚)                                   â”‚
â”‚  â€¢ LLMEngine (ç¡¬ä»¶æ— å…³çš„ç»Ÿä¸€å¼•æ“)                           â”‚
â”‚  â€¢ è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯ (cuda > ascend > cpu)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  sagellm-backend (ç¡¬ä»¶æŠ½è±¡å±‚) â† æœ¬ä»“åº“                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  BackendProvider Interface                         â”‚    â”‚
â”‚  â”‚  â€¢ Stream/Event å¼‚æ­¥æµ                              â”‚    â”‚
â”‚  â”‚  â€¢ KVBlock å†…å­˜ç®¡ç†                                 â”‚    â”‚
â”‚  â”‚  â€¢ Collective æ“ä½œï¼ˆall_reduce/all_gatherï¼‰        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  CUDA    â”‚  â”‚  Ascend  â”‚  â”‚  Kunlun  â”‚                  â”‚
â”‚  â”‚ Provider â”‚  â”‚ Provider â”‚  â”‚ Provider â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Hardware SDK Layer                                          â”‚
â”‚  CUDA/cuDNN/NCCL â”‚ CANN/HCCL â”‚ XPU SDK â”‚ DCU SDK           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**èŒè´£åˆ†ç¦»ï¼ˆv0.2.0 é‡æ„ï¼‰**ï¼š

- âœ… **æœ¬ä»“åº“è´Ÿè´£**ï¼šç¡¬ä»¶æŠ½è±¡ã€è®¾å¤‡ç®¡ç†ã€å†…å­˜åŸè¯­
- âŒ **ä¸å†åŒ…å«**ï¼šBaseEngine, EngineFactoryï¼ˆå·²ç§»è‡³ sagellm-coreï¼‰
- ğŸ”— **è¢«ä½¿ç”¨äº**ï¼šsagellm-core ä¸­çš„å¼•æ“å®ç°

## Features

- **ç»Ÿä¸€ç¡¬ä»¶æŠ½è±¡**ï¼šå•ä¸€ API æ”¯æŒå¤šç¡¬ä»¶åç«¯
- **CPU Backend**ï¼šæ—  GPU ç¯å¢ƒçš„é»˜è®¤åç«¯
- **CUDA Support**ï¼šåŸç”Ÿ CUDA åç«¯å®ç°
- **CPU Support**ï¼šCPU-only åç«¯å®ç°
- **èƒ½åŠ›å‘ç°**ï¼šç¡¬ä»¶èƒ½åŠ›æŸ¥è¯¢ä¸éªŒè¯

## Installation

```bash
pip install isagellm-backend
```

## Quick Start

```bash
git clone git@github.com:intellistream/sagellm-backend.git
cd sagellm-backend
./quickstart.sh

# Run tests
pytest tests/ -v
```

## Usage Examples

### Basic Backend Usage

```python
from sagellm_backend import CPUBackendProvider, DType

# Create backend
backend = CPUBackendProvider()

# Query capabilities
cap = backend.capability()
print(cap.supported_dtypes)

# Allocate KV block
block = backend.kv_block_alloc(128, DType.FP16)
```

### Using with sagellm-core LLMEngine

Backend ç°åœ¨ä¸“æ³¨äºç¡¬ä»¶æŠ½è±¡ï¼Œå¼•æ“ä½¿ç”¨ `sagellm-core` çš„ `LLMEngine`ã€‚

```python
# LLMEngine ä½äº sagellm-core
from sagellm_core import LLMEngine, LLMEngineConfig

# LLMEngine è‡ªåŠ¨é€‰æ‹©æœ€ä½³åç«¯
config = LLMEngineConfig(
    model_path="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    backend_type="auto",  # è‡ªåŠ¨é€‰æ‹©: cuda > ascend > cpu
    max_new_tokens=100,
)
engine = LLMEngine(config)
await engine.start()

# æ¨ç†
output = await engine.generate("Hello, world!")
print(output)

await engine.stop()
```

## Extending with New Backends

```python
# Create provider in providers/ directory
class AscendBackendProvider:
    def capability(self) -> CapabilityDescriptor:
        return CapabilityDescriptor(
            supported_dtypes=[DType.FP16, DType.BF16, DType.INT8],
            # ...
        )

    # Implement other interface methods...

# Register via entry point in pyproject.toml
[project.entry-points."sagellm.backends"]
ascend_cann = "sagellm_backend.providers.ascend:create_ascend_backend"
```

## Documentation

- [Architecture](docs/ARCHITECTURE.md)
- [Contributing](CONTRIBUTING.md)
- [Team](docs/TEAM.md)

## ğŸ”„ è´¡çŒ®æŒ‡å—

è¯·éµå¾ªä»¥ä¸‹å·¥ä½œæµç¨‹ï¼š

1. **åˆ›å»º Issue** - æè¿°é—®é¢˜/éœ€æ±‚

   ```bash
   gh issue create --title "[Bug] æè¿°" --label "bug,sagellm-backend"
   ```

2. **å¼€å‘ä¿®å¤** - åœ¨æœ¬åœ° `fix/#123-xxx` åˆ†æ”¯è§£å†³

   ```bash
   git checkout -b fix/#123-xxx origin/main-dev
   # å¼€å‘ã€æµ‹è¯•...
   pytest -v
   ruff format . && ruff check . --fix
   ```

3. **å‘èµ· PR** - æäº¤åˆ° `main-dev` åˆ†æ”¯

   ```bash
   gh pr create --base main-dev --title "Fix: æè¿°" --body "Closes #123"
   ```

4. **åˆå¹¶** - å®¡æ‰¹ååˆå¹¶åˆ° `main-dev`

æ›´å¤šè¯¦æƒ…è§ [.github/copilot-instructions.md](.github/copilot-instructions.md)

## License

Proprietary
